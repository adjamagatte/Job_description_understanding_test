{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ade2d1f7-2122-4a00-99fb-c4242bdf4636",
   "metadata": {},
   "source": [
    "# Text traitement with spacy/NLTK to extract skills"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326ebae9-6d27-4611-98d6-ad2a5a7e16ef",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67720fac-d794-4ddc-8479-359f06132a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import feature_extraction\n",
    "import nltk\n",
    "from nltk import sent_tokenize \n",
    "from nltk.tokenize import word_tokenize,MWETokenizer \n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import spacy\n",
    "from spacy.util import filter_spans\n",
    "from spacy.tokens import Span\n",
    "from spacy.matcher import Matcher\n",
    "from spacy import displacy\n",
    "from IPython.display import HTML, display\n",
    "import gensim\n",
    "# nltk.download('all')\n",
    "# nltk.download('maxent_ne_chunker')\n",
    "# nltk.download('words')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02b71d3b-c137-4fa9-b471-86762b87d5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.util import filter_spans\n",
    "from spacy.tokens import Span\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00d2b264-0074-47c0-9a0d-105e0c60e3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f3fadda-e33f-4b53-b663-461f7dc96b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "stop_words=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035a01d0-9214-455d-8853-af25353ea12e",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c88c538c-1d1b-4b24-8f08-432516c3b7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>source</th>\n",
       "      <th>job_title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Infoserv LLC\\nData Scientist\\nRemote\\nEmployer...</td>\n",
       "      <td>glassdoor</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>job_description</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExxonMobil\\n3.1\\nData Scientist\\nClinton, NJ\\n...</td>\n",
       "      <td>glassdoor</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>job_description</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eBay Inc.\\n4.1\\nData Scientist/Applied Researc...</td>\n",
       "      <td>glassdoor</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>job_description</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TikTok\\n3.7\\nData Scientist, University Gradua...</td>\n",
       "      <td>glassdoor</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>job_description</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mastercard\\n4.3\\nData Scientist, AI Services -...</td>\n",
       "      <td>glassdoor</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>job_description</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content     source  \\\n",
       "0  Infoserv LLC\\nData Scientist\\nRemote\\nEmployer...  glassdoor   \n",
       "1  ExxonMobil\\n3.1\\nData Scientist\\nClinton, NJ\\n...  glassdoor   \n",
       "2  eBay Inc.\\n4.1\\nData Scientist/Applied Researc...  glassdoor   \n",
       "3  TikTok\\n3.7\\nData Scientist, University Gradua...  glassdoor   \n",
       "4  Mastercard\\n4.3\\nData Scientist, AI Services -...  glassdoor   \n",
       "\n",
       "        job_title            label  \n",
       "0  Data Scientist  job_description  \n",
       "1  Data Scientist  job_description  \n",
       "2  Data Scientist  job_description  \n",
       "3  Data Scientist  job_description  \n",
       "4  Data Scientist  job_description  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_description = pd.read_csv(\"data/unbalanced.csv\")\n",
    "job_description.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8f41bd0-2a68-4fbe-b191-ce8420a6ab3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples1 = job_description['Content'][0]\n",
    "type(examples1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90eeb991-b619-4c46-b828-b0c1298d95ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = list(job_description[job_description['source']==\"assan\"]['Content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcef833-3f9d-419d-93d7-2bbe8258738d",
   "metadata": {},
   "source": [
    "## Tokenisation with nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dbfaa3-c351-4119-86cc-5a58d8efc3c2",
   "metadata": {},
   "source": [
    "### Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "059f0ccb-0a08-47e8-b4f1-b89c01602638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    \"\"\"\n",
    "    Remove punctuation from text\n",
    "    input: text\n",
    "    output: text\n",
    "    \"\"\"\n",
    "    text_tok = word_tokenize(text)\n",
    "    l=[]\n",
    "    for word in text_tok:\n",
    "        if  word not in string.punctuation:\n",
    "            l.append(word)\n",
    "    resultat=\" \".join(l)        \n",
    "    return resultat,text_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "565d2741-e5a2-42fe-aeb5-9296f1850367",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = remove_punct(examples1)\n",
    "nltk_tokens = results[1]\n",
    "text = results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a729ae1b-56fd-4a25-8e74-cfcd3a8b15d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f95f48-73a1-42d2-b933-c396eb01c150",
   "metadata": {},
   "source": [
    "### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "e86b1d66-b4fa-49e7-a8d2-3311d80120cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopword(text):\n",
    "    stop=set(stopwords.words('english'))\n",
    "#     text_tok = word_tokenize(text)\n",
    "    l=[]\n",
    "    for word in text.split():\n",
    "        if not word in stop:\n",
    "            l.append(word)\n",
    "    resultat=\" \".join(l) \n",
    "    return resultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76f507a9-5706-4b7e-bbb5-8f9b2f653b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Infoserv LLC Data Scientist Remote Employer Provided Salary 30.00 35.00 Per Hour Only W2 candidates right unable work employer Programming Skills â€“ knowledge statistical programming languages like R Python database query languages like SQL Hive Pig desirable Familiarity Scala Java C++ added advantage Job Type Contract Pay 30.00 35.00 per hour Schedule 8 hour shift Supplemental pay types Bonus pay Work Location Remote'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_stopwords = remove_stopword(text)\n",
    "tokens_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffb1b54e-b880-4eff-af89-e4752a3f6215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    \"\"\"\n",
    "    transform text to a list of word\n",
    "    input: text/str\n",
    "    output: list of tuples containing the individual words in the sentence and their associated part-of-speech\n",
    "    \"\"\"\n",
    "    tokenizer = MWETokenizer([('Machine', 'Learning'), ('Data','Scientist'),('Data','Engineer'),('Data','Analyst'),\n",
    "                              ('Cloud','Computing'),('Artificial','Intelligence'),('Business','Managers'),\n",
    "                             ('Big', 'Data'),('Big', 'Data','Developer'),('Data','Driven'),('Big','Query'),('data','lake'),\n",
    "                             ('data','sources'),('job','description')],separator=' ')\n",
    "    for t in sent_tokenize(text):\n",
    "        x=tokenizer.tokenize(t.split())\n",
    "        x = nltk.pos_tag(x)\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fa887da3-a9e0-4a3d-ae6c-cddbcba9bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_token = tokenizer(tokens_stopwords)\n",
    "# nlp_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319d67f9-2869-4ae6-9fd8-af5d82b7041f",
   "metadata": {},
   "source": [
    "* Find ngrams\n",
    "http://locallyoptimal.com/blog/2013/01/20/elegant-n-gram-generation-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6519776d-d432-4de9-9c53-bb985fd4904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(words, ngram=2):\n",
    "    return [words[i:i+ngram] for i in range(len(words)-ngram+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3eee7f0-cdf8-41f4-8ce6-c9c6c637de7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = examples1.split()\n",
    "# words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a88e843-e1f0-45b7-a202-a62ac160a90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = generate_ngrams(words, ngram=2)\n",
    "# res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d38d82eb-7023-405c-8492-466b870fb38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.util import ngrams\n",
    "\n",
    "s = examples1.lower()\n",
    "s = re.sub(r'[^a-zA-Z0-9\\s]', ' ', s)\n",
    "tokens = [token for token in s.split(\" \") if token != \"\"]\n",
    "output = list(ngrams(tokens, 2))\n",
    "# output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda11a9a-6e4b-4351-a409-7f4a780ac468",
   "metadata": {},
   "source": [
    "## Tokenisation with spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a991219-b4f0-49f2-9ee0-26b413bd70f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_token = nlp(str(examples))\n",
    "# spacy_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed648d7-9e7f-483e-8cf4-31c6ab02f262",
   "metadata": {},
   "source": [
    "* NER-Tagging â€” (Named Entity Recognition)\n",
    "\n",
    "a subtask of information extraction that seeks to locate and classify named entities mentioned in unstructured text into pre-defined categories such as person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages, etc.\n",
    "* The Part Of Speech (POS) explains how a word is used in a sentence. \n",
    "\n",
    "There are eight main parts of speech â€” nouns, pronouns, adjectives, verbs, adverbs, prepositions, conjunctions, and interjections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4f6cc3d-4a90-4591-b01f-35420392f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for token in spacy_token:\n",
    "#     print(token.text, token.ent_type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb9cb716-57f6-4705-82b2-761026c7ef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for token in spacy_token:\n",
    "#     print(token.text, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa6b1d7f-cac4-43b2-89e1-0d56e6547b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entities</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Data, Engineer)</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(GCP-)</td>\n",
       "      <td>PRODUCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(C2C)</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Wednesday, ,, April, 20, ,, 2022)</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(10:36:49)</td>\n",
       "      <td>TIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>(99)</td>\n",
       "      <td>CARDINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>(308)</td>\n",
       "      <td>MONEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>(Iselin)</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>(which\\nimplies)</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>(cloudHQ\\n\\n1/1, \\n, \\n, \\n, \\n, \\n, \\n, \\n, \\...</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1259 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Entities    Labels\n",
       "0                                      (Data, Engineer)       ORG\n",
       "1                                                (GCP-)   PRODUCT\n",
       "2                                                 (C2C)       GPE\n",
       "3                    (Wednesday, ,, April, 20, ,, 2022)      DATE\n",
       "4                                            (10:36:49)      TIME\n",
       "...                                                 ...       ...\n",
       "1254                                               (99)  CARDINAL\n",
       "1255                                              (308)     MONEY\n",
       "1256                                           (Iselin)       GPE\n",
       "1257                                   (which\\nimplies)      DATE\n",
       "1258  (cloudHQ\\n\\n1/1, \\n, \\n, \\n, \\n, \\n, \\n, \\n, \\...    PERSON\n",
       "\n",
       "[1259 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities =[]\n",
    "labels = []\n",
    "pos_start = []\n",
    "pos_end = []\n",
    "for ent in spacy_token.ents:\n",
    "    entities.append(ent)\n",
    "    labels.append(ent.label_)\n",
    "tokens_data = pd.DataFrame({\"Entities\":entities,\"Labels\":labels })\n",
    "tokens_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b423428a-dcc0-4bd4-9acf-0078b20b955b",
   "metadata": {},
   "source": [
    " The magic of spaCy â€” just like that, weâ€™ve managed to get rid of stopwords, punctuation markers, and added lemmatized words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29ec413c-5f93-42a8-8a05-1f9f1cfd502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7e04a98-37c0-498e-9af1-3916f64cf51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('IDC Technologies', 34), ('8/24/22', 20), ('408', 19)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = [x.text for x in spacy_token.ents]\n",
    "Counter(items).most_common(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf5350b-f794-4169-bc27-95efb17c04ff",
   "metadata": {},
   "source": [
    "Only tokennize the text raise words that may be are not skills. To have a better input for our model, we need to extract skills from the text iand use it as input for our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeaf8be-b6d4-43fc-9aca-85a5cd7396ff",
   "metadata": {},
   "source": [
    "To extract skills \n",
    "IDEA 1 \n",
    "Edward Ross's 3 part series\n",
    " * part 1: https://skeptric.com/extract-skills-1-noun-phrase/\n",
    " * part 2: https://skeptric.com/extract-skills-2-adpositions/\n",
    " * part 3: https://skeptric.com/extract-skills-3-conjugations/\n",
    " \n",
    " * Finding Types of Experience: https://skeptric.com/notebooks/Parsing%20Experience%20from%20Adzuna%20Job%20Ads.html\n",
    " \n",
    " * GitHub page of Edward Ross https://github.com/EdwardJRoss/job-advert-analysis/blob/master/notebooks/Extracting%20Role%20Title%20Words.ipynb\n",
    " \n",
    "\n",
    "IDEA 2, after WWWC\n",
    "use a pretrained or word2Vec model that you trained on the corpus to get a list of technical skills close to a list \n",
    "you could get from the internet. For each datapoint you could have a column of the most similar skills\n",
    "Cluster unigrams and bigrams until you get a technical skills cluster\n",
    "Some ideas\n",
    " * https://datascience.stackexchange.com/questions/30057/to-extract-the-skills-required-for-the-job-given-the-job-description/30066\n",
    "\n",
    "Detecting the Skills\n",
    "\n",
    "* Tokenize your raw text into words and expressions\n",
    "* Remove stop words\n",
    "* Encode your tokens using an embedding (Word2Vec, FastText, etc)\n",
    "* Use the list from the previous step to add labels to your data (anything on the list is True, other as False)\n",
    "* Train a binary classifier (Naive Bayes classifier should be good enough)\n",
    "* Evaluate your model, feature set, and labels. If needed, refine and repeat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ef76e6-01bf-4b50-9bf7-abbc208009ce",
   "metadata": {},
   "source": [
    "We could look to extract:\n",
    "\n",
    "* a series of nouns before the word experience (e.g. \"subsea cable engineering experience\")\n",
    "* orexperience as/in something (e.g \"experience as a Chef de Partie\")\n",
    "\n",
    "we'll do this using Spacy's Rule Based Matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175d040f-dddc-4d50-9082-afda31859947",
   "metadata": {},
   "source": [
    "### Skills extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc2f6db-92c2-4326-8be4-413843ae08f0",
   "metadata": {},
   "source": [
    "#### Highlight experiences and synonyms terms  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "087b1465-e643-42fc-a7bb-d1fe9b0d6e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for l in syn.lemmas():\n",
    "#             if word != l.name():\n",
    "            synonyms.append(l.name())\n",
    "    return synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3e8beaad-c380-4603-a531-2ea0034e6b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_terms(terms, texts):\n",
    "    for doc in nlp.pipe(texts):\n",
    "        for sentence in set([tok.sent for tok in doc if tok.lower_ in terms]):\n",
    "            text = sentence.text.strip()\n",
    "            markup = re.sub(fr'(?i)\\b({\"|\".join(terms)})\\b', r'<strong>\\1</strong>', text)\n",
    "            display(HTML(markup))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fbea6f2c-0629-44d8-a47c-8b9ee4470311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# highlight_terms(['experience','skills','title','knowlege','degree','expertise'],examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b4580b-b7a4-4bcb-b2c5-bb303d156bf2",
   "metadata": {},
   "source": [
    "with the highlighting functions, we can see that skills are often before or after word experience or skill or synonyms like expertise exposure..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4719a06c-e1a2-4127-a70a-df4288201594",
   "metadata": {},
   "source": [
    "#### Extract words in the right of words designating experinces or skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c3f01df8-ae25-4bde-9cd7-66af5f8af0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conjugations(tok):\n",
    "    \"\"\"\n",
    "    take a token and append token that are separated to it by a conjonction or a comma(its children)\n",
    "    input: tok, a text  that is already tokenised\n",
    "    output: list of token that are children of tok\"\"\"\n",
    "    new = [tok] # list of token\n",
    "    while new:\n",
    "        tok = new.pop()\n",
    "        yield tok\n",
    "        for child in tok.children:\n",
    "            if( child.dep_ == 'conj')|( child.dep_ == 'prep'):# chek if the Syntactic dependency relation equal is conjunction.\n",
    "                new.append(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "98a76b72-089a-4408-94c1-52fa02ea8a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_left_span(tok, label='', include=True):\n",
    "    offset = 1 if include else 0\n",
    "    idx = tok.i\n",
    "    while idx > tok.left_edge.i:\n",
    "        if tok.doc[idx - 1].pos_ in ('NOUN', 'PROPN', 'ADJ', 'X'):\n",
    "            idx -= 1\n",
    "        else:\n",
    "            break\n",
    "    return label, idx, tok.i+offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "43b1e3a9-fec6-4fee-b95a-b749aed56271",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_TERMS = ['experience','knowledge',\"skills\",\"language\",\"background\",\"familiarity\",\"passion\",\"degree\"]\n",
    "def extract_adp_conj_experience(doc, label='SKILLS'):\n",
    "    for tok in doc:\n",
    "        if tok.lower_ in EXP_TERMS:\n",
    "            #loop into wold just after EXP_TERMS\n",
    "            for child in tok.rights:\n",
    "                if child.dep_ == 'prep': # if the word is tagged as a preposition\n",
    "                    for obj in child.children: # take the wold after the preposition(children)\n",
    "                        if obj.dep_ == 'pobj': # If  children are tagged as pobj\n",
    "                            for conj in get_conjugations(obj):# take children with their conjugated(separated by a comma/conjonction)\n",
    "                                yield get_left_span(conj, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "486b7f00-ff67-4968-848e-c5d809f12678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_extraction(examples, *extractors):\n",
    "    seen = set()\n",
    "    for doc in nlp.pipe(examples):\n",
    "        doc.ents = filter_spans([Span(doc, start, end, label) for extractor in extractors for label, start, end in extractor(doc)])\n",
    "        for tok in doc:\n",
    "            if tok.lower_ == 'experience':\n",
    "                sentence = tok.sent\n",
    "                if sentence.text in seen:\n",
    "                    continue\n",
    "                seen.update([sentence.text])\n",
    "                if not sentence.ents:\n",
    "                    doc.ents = list(doc.ents) + [Span(doc, tok.i, tok.i+1, 'MISSING')]\n",
    "                displacy.render(sentence, style='ent', options = {'colors': {'MISSING': 'pink',\n",
    "                                                                            'EXPERIENCE': 'lightgreen',\n",
    "                                                                            \"SKILLS\": \"red\"}})\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "9e769e07-f61e-47ac-b9f5-577d340cb3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_extraction(examples, extract_adp_conj_experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "a239199e-b14d-4935-9a06-443dfdd1fa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_adp_conj_experience(doc,label):\n",
    "    extacted_words = []\n",
    "    extacted_word = []\n",
    "    for tok in doc:\n",
    "        if tok.lower_ ==label:\n",
    "            for child in tok.rights:\n",
    "                if (child.dep_ == 'prep')|(child.pos_ ==\"ADP\"):\n",
    "                    for obj in child.children:\n",
    "                        if obj.dep_ == 'pobj':\n",
    "                            for conj in get_conjugations(obj):\n",
    "                                extacted_word.append(get_left_span(conj, label))\n",
    "#                                 extacted_word.append(obj)\n",
    "        extacted_words.append(extacted_word)\n",
    "    return extacted_word                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "c7c8bb52-b93a-4143-9fe3-f70eba225964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_adp_conj_experience(doc,labels):\n",
    "    extacted_words = []\n",
    "    extacted_word = []\n",
    "    for label in labels:\n",
    "        for tok in doc:\n",
    "            if tok.lower_ ==label:\n",
    "                for child in tok.rights:\n",
    "                    if (child.dep_ == 'prep')|(child.pos_ ==\"ADP\"):\n",
    "                        for obj in child.children:\n",
    "                            if obj.dep_ == 'pobj':\n",
    "                                for conj in get_conjugations(obj):\n",
    "                                    extacted_word.append(conj)\n",
    "#                                     extacted_word.append(child)\n",
    "    return extacted_word                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "3522da40-aab3-40f5-a512-1a8ee93845e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[languages, like, Scala]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_adp_conj_experience(nlp(examples1),EXP_TERMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "59b7bfe7-b7ab-4993-b969-5baaab735295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Infoserv LLC\\nData Scientist\\nRemote\\nEmployer Provided Salary:$30.00 - $35.00 Per Hour\\n\\n Only W2 candidates right now we are unable to work with the employer\\nProgramming Skills â€“ knowledge of statistical programming languages like R, Python, and database query languages like SQL, Hive, Pig is desirable. Familiarity with Scala, Java, or C++ is an added advantage.\\nJob Type: Contract\\nPay: $30.00 - $35.00 per hour\\nSchedule:\\n8 hour shift\\nSupplemental pay types:\\nBonus pay\\nWork Location: Remote'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "496f3e41-23be-4665-9a96-97284b1c2176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# str(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "6430b765-c6de-45f4-a191-d3df324b2e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = extract_adp_conj_experience(nlp(examples1),EXP_TERMS)\n",
    "y = [str(i).strip() for i in x]\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "30c17260-91bc-4c76-a003-b8b55a0ea6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_terms(y[:100],examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7170d0c-fcb5-43c5-95ba-e8bc6cd582ea",
   "metadata": {},
   "source": [
    "#### Extract words in the left of words designating experinces or skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c1cbf9ef-8d08-4099-96ad-40079a9ebec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_noun_phrase_experience(doc):\n",
    "    data = []\n",
    "    for np in doc.noun_chunks:\n",
    "        if (np[-1].lower_ == 'experience'):\n",
    "            if len(np) > 1:\n",
    "                data.append(np[0])\n",
    "#                 yield 'EXPERIENCE', np[0].i, np[-1].i\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "afdbafaf-32e1-4121-b9a8-ff010ee4d0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Infoserv, LLC, \\n, Data, Scientist, \\n, Remote, \\n, Employer, Provided, Salary:$30.00, -, $, 35.00, Per, Hour, \\n\\n , Only, W2, candidates, right, now, we, are, unable, to, work, with, the, employer, \\n, Programming, Skills, â€“, knowledge, of, statistical, programming, languages, like, R, ,, Python, ,, and, database, query, languages, like, SQL, ,, Hive, ,, Pig, is, desirable, ., Familiarity, with, Scala, ,, Java, ,, or, C++, is, an, added, advantage, ., \\n, Job, Type, :, Contract, \\n, Pay, :, $, 30.00, -, $, 35.00, per, hour, \\n, Schedule, :, \\n, 8, hour, shift, \\n, Supplemental, pay, types, :, \\n, Bonus, pay, \\n, Work, Location, :, Remote]'"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = list(nlp(examples1)) #list(nlp(str(examples)).noun_chunks)\n",
    "str(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "d8448e2d-96ae-48d9-a4ba-3a2b2a2235e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Infoserv LLC Data Scientist Remote Employer Provided Salary 30.00 35.00 Per Hour Only W2 candidates right now we are unable to work with the employer Programming Skills â€“ knowledge of statistical programming languages like R Python and database query languages like SQL Hive Pig is desirable Familiarity with Scala Java or C++ is an added advantage Job Type Contract Pay 30.00 35.00 per hour Schedule 8 hour shift Supplemental pay types Bonus pay Work Location Remote',\n",
       " ['[',\n",
       "  'Infoserv',\n",
       "  ',',\n",
       "  'LLC',\n",
       "  ',',\n",
       "  ',',\n",
       "  'Data',\n",
       "  ',',\n",
       "  'Scientist',\n",
       "  ',',\n",
       "  ',',\n",
       "  'Remote',\n",
       "  ',',\n",
       "  ',',\n",
       "  'Employer',\n",
       "  ',',\n",
       "  'Provided',\n",
       "  ',',\n",
       "  'Salary',\n",
       "  ':',\n",
       "  '$',\n",
       "  '30.00',\n",
       "  ',',\n",
       "  '-',\n",
       "  ',',\n",
       "  '$',\n",
       "  ',',\n",
       "  '35.00',\n",
       "  ',',\n",
       "  'Per',\n",
       "  ',',\n",
       "  'Hour',\n",
       "  ',',\n",
       "  ',',\n",
       "  'Only',\n",
       "  ',',\n",
       "  'W2',\n",
       "  ',',\n",
       "  'candidates',\n",
       "  ',',\n",
       "  'right',\n",
       "  ',',\n",
       "  'now',\n",
       "  ',',\n",
       "  'we',\n",
       "  ',',\n",
       "  'are',\n",
       "  ',',\n",
       "  'unable',\n",
       "  ',',\n",
       "  'to',\n",
       "  ',',\n",
       "  'work',\n",
       "  ',',\n",
       "  'with',\n",
       "  ',',\n",
       "  'the',\n",
       "  ',',\n",
       "  'employer',\n",
       "  ',',\n",
       "  ',',\n",
       "  'Programming',\n",
       "  ',',\n",
       "  'Skills',\n",
       "  ',',\n",
       "  'â€“',\n",
       "  ',',\n",
       "  'knowledge',\n",
       "  ',',\n",
       "  'of',\n",
       "  ',',\n",
       "  'statistical',\n",
       "  ',',\n",
       "  'programming',\n",
       "  ',',\n",
       "  'languages',\n",
       "  ',',\n",
       "  'like',\n",
       "  ',',\n",
       "  'R',\n",
       "  ',',\n",
       "  ',',\n",
       "  ',',\n",
       "  'Python',\n",
       "  ',',\n",
       "  ',',\n",
       "  ',',\n",
       "  'and',\n",
       "  ',',\n",
       "  'database',\n",
       "  ',',\n",
       "  'query',\n",
       "  ',',\n",
       "  'languages',\n",
       "  ',',\n",
       "  'like',\n",
       "  ',',\n",
       "  'SQL',\n",
       "  ',',\n",
       "  ',',\n",
       "  ',',\n",
       "  'Hive',\n",
       "  ',',\n",
       "  ',',\n",
       "  ',',\n",
       "  'Pig',\n",
       "  ',',\n",
       "  'is',\n",
       "  ',',\n",
       "  'desirable',\n",
       "  ',',\n",
       "  '.',\n",
       "  ',',\n",
       "  'Familiarity',\n",
       "  ',',\n",
       "  'with',\n",
       "  ',',\n",
       "  'Scala',\n",
       "  ',',\n",
       "  ',',\n",
       "  ',',\n",
       "  'Java',\n",
       "  ',',\n",
       "  ',',\n",
       "  ',',\n",
       "  'or',\n",
       "  ',',\n",
       "  'C++',\n",
       "  ',',\n",
       "  'is',\n",
       "  ',',\n",
       "  'an',\n",
       "  ',',\n",
       "  'added',\n",
       "  ',',\n",
       "  'advantage',\n",
       "  ',',\n",
       "  '.',\n",
       "  ',',\n",
       "  ',',\n",
       "  'Job',\n",
       "  ',',\n",
       "  'Type',\n",
       "  ',',\n",
       "  ':',\n",
       "  ',',\n",
       "  'Contract',\n",
       "  ',',\n",
       "  ',',\n",
       "  'Pay',\n",
       "  ',',\n",
       "  ':',\n",
       "  ',',\n",
       "  '$',\n",
       "  ',',\n",
       "  '30.00',\n",
       "  ',',\n",
       "  '-',\n",
       "  ',',\n",
       "  '$',\n",
       "  ',',\n",
       "  '35.00',\n",
       "  ',',\n",
       "  'per',\n",
       "  ',',\n",
       "  'hour',\n",
       "  ',',\n",
       "  ',',\n",
       "  'Schedule',\n",
       "  ',',\n",
       "  ':',\n",
       "  ',',\n",
       "  ',',\n",
       "  '8',\n",
       "  ',',\n",
       "  'hour',\n",
       "  ',',\n",
       "  'shift',\n",
       "  ',',\n",
       "  ',',\n",
       "  'Supplemental',\n",
       "  ',',\n",
       "  'pay',\n",
       "  ',',\n",
       "  'types',\n",
       "  ',',\n",
       "  ':',\n",
       "  ',',\n",
       "  ',',\n",
       "  'Bonus',\n",
       "  ',',\n",
       "  'pay',\n",
       "  ',',\n",
       "  ',',\n",
       "  'Work',\n",
       "  ',',\n",
       "  'Location',\n",
       "  ',',\n",
       "  ':',\n",
       "  ',',\n",
       "  'Remote',\n",
       "  ']'])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punct(str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "13db08ef-0190-4107-ac25-d4b968560601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[#,\n",
       " some,\n",
       " strong,\n",
       " industry,\n",
       " overall,\n",
       " ER,\n",
       " overall,\n",
       " Knowledge,\n",
       " advantage\\n\\n-,\n",
       " Python.\\n\\n-,\n",
       " migration,\n",
       " \\nPrior,\n",
       " 3,\n",
       " Prior,\n",
       " Strong,\n",
       " Prior,\n",
       " Strong,\n",
       " \\nSN,\n",
       " Prior,\n",
       " Strong,\n",
       " Prior,\n",
       " 3,\n",
       " Prior,\n",
       " Strong,\n",
       " Prior,\n",
       " industry,\n",
       " and\\nSaaS,\n",
       " security,\n",
       " data,\n",
       " large\\nscale,\n",
       " AI,\n",
       " software,\n",
       " \\n,\n",
       " \\n,\n",
       " hands,\n",
       " \\nAI,\n",
       " (,\n",
       " least,\n",
       " not,\n",
       " least,\n",
       " not,\n",
       " This,\n",
       " relevant,\n",
       " This,\n",
       " all,\n",
       " IT,\n",
       " the,\n",
       " relevant,\n",
       " and\\ncausal,\n",
       " working,\n",
       " Applied,\n",
       " least,\n",
       " new,\n",
       " base,\n",
       " any,\n",
       " 3,\n",
       " Prior,\n",
       " Strong,\n",
       " Prior,\n",
       " AI,\n",
       " customer,\n",
       " etc.\\nâ€¢,\n",
       " Redshift\\nâ€¢,\n",
       " etc.\\nâ€¢,\n",
       " industry,\n",
       " hands,\n",
       " This]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_noun_phrase_experience(nlp(str(examples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "fb3e0cbf-c538-42b5-bc1e-97f596b6282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_extraction(examples, extract_noun_phrase_experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d931bfce-f3c3-4c03-a761-b221ab87b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extractions(examples, *extractors):\n",
    "    # Could use context instead of enumerate\n",
    "    for idx, doc in enumerate(nlp.pipe(examples, batch_size=100, disable=['ner'])):\n",
    "        for ent in filter_spans([Span(doc, start, end, label) for extractor in extractors for label, start, end in extractor(doc)]):\n",
    "            sent = ent.root.sent\n",
    "            yield ent.text, idx, ent.start, ent.end, ent.label_, sent.start, sent.end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32e30efd-b3cf-44fb-93e7-a15922119e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_df(*extractors, n_max=None, **kwargs):\n",
    "    if n_max is None:\n",
    "        n_max = len(df)\n",
    "    ent_df = pd.DataFrame(list(get_extractions(job_description[:n_max].Content, *extractors)),\n",
    "                          columns=['text', 'docidx', 'start', 'end', 'skill', 'sent_start', 'sent_end'])\n",
    "    return ent_df.merge(job_description, how='left', left_on='docidx', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a04917d-7370-43ef-a26e-1d650819020a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function __main__.extract_adp_conj_experience(doc, label='SKILLS')>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_exps = [extract_adp_conj_experience,]\n",
    "extract_exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36f30db2-8c2e-4958-98c4-372c256e7fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ents = extract_df(*extract_exps, n_max=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "753c8a40-8ca6-4e72-988c-4772d100d2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_df = extract_df(extract_noun_phrase_experience, n_max=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "11d14363-543d-4c5d-8016-e7f9fb398452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>docidx</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>skill</th>\n",
       "      <th>sent_start</th>\n",
       "      <th>sent_end</th>\n",
       "      <th>Content</th>\n",
       "      <th>source</th>\n",
       "      <th>job_title</th>\n",
       "      <th>label</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scala</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>SKILLS</td>\n",
       "      <td>57</td>\n",
       "      <td>71</td>\n",
       "      <td>Infoserv LLC\\nData Scientist\\nRemote\\nEmployer...</td>\n",
       "      <td>glassdoor</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>job_description</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>multivariate statistics</td>\n",
       "      <td>1</td>\n",
       "      <td>493</td>\n",
       "      <td>495</td>\n",
       "      <td>SKILLS</td>\n",
       "      <td>490</td>\n",
       "      <td>547</td>\n",
       "      <td>ExxonMobil\\n3.1\\nData Scientist\\nClinton, NJ\\n...</td>\n",
       "      <td>glassdoor</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>job_description</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shell scripting</td>\n",
       "      <td>1</td>\n",
       "      <td>613</td>\n",
       "      <td>615</td>\n",
       "      <td>SKILLS</td>\n",
       "      <td>547</td>\n",
       "      <td>619</td>\n",
       "      <td>ExxonMobil\\n3.1\\nData Scientist\\nClinton, NJ\\n...</td>\n",
       "      <td>glassdoor</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>job_description</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>following</td>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>625</td>\n",
       "      <td>SKILLS</td>\n",
       "      <td>619</td>\n",
       "      <td>646</td>\n",
       "      <td>ExxonMobil\\n3.1\\nData Scientist\\nClinton, NJ\\n...</td>\n",
       "      <td>glassdoor</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>job_description</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>databases</td>\n",
       "      <td>1</td>\n",
       "      <td>658</td>\n",
       "      <td>659</td>\n",
       "      <td>SKILLS</td>\n",
       "      <td>646</td>\n",
       "      <td>665</td>\n",
       "      <td>ExxonMobil\\n3.1\\nData Scientist\\nClinton, NJ\\n...</td>\n",
       "      <td>glassdoor</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>job_description</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>management information Essential</td>\n",
       "      <td>1033</td>\n",
       "      <td>140</td>\n",
       "      <td>143</td>\n",
       "      <td>EXPERIENCE</td>\n",
       "      <td>91</td>\n",
       "      <td>146</td>\n",
       "      <td>Database Analyst  ****K Wetherby This role sha...</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>job_description</td>\n",
       "      <td>1904.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>Posses solid commercial</td>\n",
       "      <td>1034</td>\n",
       "      <td>51</td>\n",
       "      <td>54</td>\n",
       "      <td>EXPERIENCE</td>\n",
       "      <td>51</td>\n",
       "      <td>69</td>\n",
       "      <td>Data Analyst / Data Analysis / Modelling / SQL...</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>job_description</td>\n",
       "      <td>1905.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>Solid</td>\n",
       "      <td>1034</td>\n",
       "      <td>482</td>\n",
       "      <td>483</td>\n",
       "      <td>EXPERIENCE</td>\n",
       "      <td>446</td>\n",
       "      <td>510</td>\n",
       "      <td>Data Analyst / Data Analysis / Modelling / SQL...</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>job_description</td>\n",
       "      <td>1906.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>desirable Data/market or modeling/intelligence</td>\n",
       "      <td>1034</td>\n",
       "      <td>499</td>\n",
       "      <td>507</td>\n",
       "      <td>EXPERIENCE</td>\n",
       "      <td>446</td>\n",
       "      <td>510</td>\n",
       "      <td>Data Analyst / Data Analysis / Modelling / SQL...</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>job_description</td>\n",
       "      <td>1907.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>a great learning</td>\n",
       "      <td>1034</td>\n",
       "      <td>537</td>\n",
       "      <td>540</td>\n",
       "      <td>EXPERIENCE</td>\n",
       "      <td>533</td>\n",
       "      <td>605</td>\n",
       "      <td>Data Analyst / Data Analysis / Modelling / SQL...</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>job_description</td>\n",
       "      <td>1908.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5281 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  docidx  start  end  \\\n",
       "0                                              Scala       0     59   60   \n",
       "1                            multivariate statistics       1    493  495   \n",
       "2                                    shell scripting       1    613  615   \n",
       "3                                          following       1    624  625   \n",
       "4                                          databases       1    658  659   \n",
       "...                                              ...     ...    ...  ...   \n",
       "1904                management information Essential    1033    140  143   \n",
       "1905                         Posses solid commercial    1034     51   54   \n",
       "1906                                           Solid    1034    482  483   \n",
       "1907  desirable Data/market or modeling/intelligence    1034    499  507   \n",
       "1908                                a great learning    1034    537  540   \n",
       "\n",
       "           skill  sent_start  sent_end  \\\n",
       "0         SKILLS          57        71   \n",
       "1         SKILLS         490       547   \n",
       "2         SKILLS         547       619   \n",
       "3         SKILLS         619       646   \n",
       "4         SKILLS         646       665   \n",
       "...          ...         ...       ...   \n",
       "1904  EXPERIENCE          91       146   \n",
       "1905  EXPERIENCE          51        69   \n",
       "1906  EXPERIENCE         446       510   \n",
       "1907  EXPERIENCE         446       510   \n",
       "1908  EXPERIENCE         533       605   \n",
       "\n",
       "                                                Content     source  \\\n",
       "0     Infoserv LLC\\nData Scientist\\nRemote\\nEmployer...  glassdoor   \n",
       "1     ExxonMobil\\n3.1\\nData Scientist\\nClinton, NJ\\n...  glassdoor   \n",
       "2     ExxonMobil\\n3.1\\nData Scientist\\nClinton, NJ\\n...  glassdoor   \n",
       "3     ExxonMobil\\n3.1\\nData Scientist\\nClinton, NJ\\n...  glassdoor   \n",
       "4     ExxonMobil\\n3.1\\nData Scientist\\nClinton, NJ\\n...  glassdoor   \n",
       "...                                                 ...        ...   \n",
       "1904  Database Analyst  ****K Wetherby This role sha...     Kaggle   \n",
       "1905  Data Analyst / Data Analysis / Modelling / SQL...     Kaggle   \n",
       "1906  Data Analyst / Data Analysis / Modelling / SQL...     Kaggle   \n",
       "1907  Data Analyst / Data Analysis / Modelling / SQL...     Kaggle   \n",
       "1908  Data Analyst / Data Analysis / Modelling / SQL...     Kaggle   \n",
       "\n",
       "           job_title            label      Id  \n",
       "0     Data Scientist  job_description     NaN  \n",
       "1     Data Scientist  job_description     NaN  \n",
       "2     Data Scientist  job_description     NaN  \n",
       "3     Data Scientist  job_description     NaN  \n",
       "4     Data Scientist  job_description     NaN  \n",
       "...              ...              ...     ...  \n",
       "1904    Data Analyst  job_description  1904.0  \n",
       "1905    Data Analyst  job_description  1905.0  \n",
       "1906    Data Analyst  job_description  1906.0  \n",
       "1907    Data Analyst  job_description  1907.0  \n",
       "1908    Data Analyst  job_description  1908.0  \n",
       "\n",
       "[5281 rows x 12 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_skills = pd.concat([df_ents,ent_df],axis=0)\n",
    "all_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e22b399-9d35-498e-9a34-0fd85fe8b029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# right_skills = df_ents.groupby(by=[\"docidx\",\"Content\",\"source\",\"job_title\",\"label\"]).agg({\"text\":\"sum\"})\n",
    "# right_skills.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "facbd3e1-7d56-4068-93df-9c59f82443a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left_skills = ent_df.groupby(by=[\"docidx\",\"Content\",\"source\",\"job_title\",\"label\"]).agg({\"text\":\"sum\"})\n",
    "# left_skills.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b4fd15e4-ec3c-4da0-9533-51b4e38204ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = all_skills.groupby(by=[\"docidx\",\"Content\",\"source\",\"job_title\",\"label\"]).agg({\"text\":\"sum\"})\n",
    "skills.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d8aab57b-231f-424f-a2ef-2226f0f8c8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docidx</th>\n",
       "      <th>Content</th>\n",
       "      <th>source</th>\n",
       "      <th>job_title</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Infoserv LLC\\nData Scientist\\nRemote\\nEmployer...</td>\n",
       "      <td>glassdoor</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>job_description</td>\n",
       "      <td>Scala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ExxonMobil\\n3.1\\nData Scientist\\nClinton, NJ\\n...</td>\n",
       "      <td>glassdoor</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>job_description</td>\n",
       "      <td>multivariate statisticsshell scriptingfollowin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>eBay Inc.\\n4.1\\nData Scientist/Applied Researc...</td>\n",
       "      <td>glassdoor</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>job_description</td>\n",
       "      <td>computer sciencemathScalaR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>TikTok\\n3.7\\nData Scientist, University Gradua...</td>\n",
       "      <td>glassdoor</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>job_description</td>\n",
       "      <td>Software DevelopmentComputer ScienceComputer E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Mastercard\\n4.3\\nData Scientist, AI Services -...</td>\n",
       "      <td>glassdoor</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>job_description</td>\n",
       "      <td>sideleadership</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>1031</td>\n",
       "      <td>Are you an experienced Data Analyst? Are you e...</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>job_description</td>\n",
       "      <td>Data Analysismodelling techniquesData Processi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>1032</td>\n",
       "      <td>Data Analyst  Data extraction, Storage, Back u...</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>job_description</td>\n",
       "      <td>data extractionstoragebackup methodologiesemai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>1033</td>\n",
       "      <td>Database Analyst  ****K Wetherby This role sha...</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>job_description</td>\n",
       "      <td>management information Essential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>1034</td>\n",
       "      <td>Data Analyst / Data Analysis / Modelling / SQL...</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>job_description</td>\n",
       "      <td>developerMicrosoft AccessSQL ServerdatabasesPo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>1035</td>\n",
       "      <td>Data Analyst  6months  London My NHS Client ur...</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>job_description</td>\n",
       "      <td>statutory returns</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>856 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     docidx                                            Content     source  \\\n",
       "0         0  Infoserv LLC\\nData Scientist\\nRemote\\nEmployer...  glassdoor   \n",
       "1         1  ExxonMobil\\n3.1\\nData Scientist\\nClinton, NJ\\n...  glassdoor   \n",
       "2         2  eBay Inc.\\n4.1\\nData Scientist/Applied Researc...  glassdoor   \n",
       "3         3  TikTok\\n3.7\\nData Scientist, University Gradua...  glassdoor   \n",
       "4         4  Mastercard\\n4.3\\nData Scientist, AI Services -...  glassdoor   \n",
       "..      ...                                                ...        ...   \n",
       "851    1031  Are you an experienced Data Analyst? Are you e...     Kaggle   \n",
       "852    1032  Data Analyst  Data extraction, Storage, Back u...     Kaggle   \n",
       "853    1033  Database Analyst  ****K Wetherby This role sha...     Kaggle   \n",
       "854    1034  Data Analyst / Data Analysis / Modelling / SQL...     Kaggle   \n",
       "855    1035  Data Analyst  6months  London My NHS Client ur...     Kaggle   \n",
       "\n",
       "          job_title            label  \\\n",
       "0    Data Scientist  job_description   \n",
       "1    Data Scientist  job_description   \n",
       "2    Data Scientist  job_description   \n",
       "3    Data Scientist  job_description   \n",
       "4    Data Scientist  job_description   \n",
       "..              ...              ...   \n",
       "851    Data Analyst  job_description   \n",
       "852    Data Analyst  job_description   \n",
       "853    Data Analyst  job_description   \n",
       "854    Data Analyst  job_description   \n",
       "855    Data Analyst  job_description   \n",
       "\n",
       "                                                  text  \n",
       "0                                                Scala  \n",
       "1    multivariate statisticsshell scriptingfollowin...  \n",
       "2                           computer sciencemathScalaR  \n",
       "3    Software DevelopmentComputer ScienceComputer E...  \n",
       "4                                       sideleadership  \n",
       "..                                                 ...  \n",
       "851  Data Analysismodelling techniquesData Processi...  \n",
       "852  data extractionstoragebackup methodologiesemai...  \n",
       "853                   management information Essential  \n",
       "854  developerMicrosoft AccessSQL ServerdatabasesPo...  \n",
       "855                                  statutory returns  \n",
       "\n",
       "[856 rows x 6 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bdcdff4c-9d17-4a4b-bb62-df66b933567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills[\"text\"] = skills[\"text\"].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b01d61ae-98ff-48f7-8b0d-67282d8ad2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docidx</th>\n",
       "      <th>Content</th>\n",
       "      <th>source</th>\n",
       "      <th>job_title</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Infoserv LLC\\nData Scientist\\nRemote\\nEmployer...</td>\n",
       "      <td>glassdoor</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>job_description</td>\n",
       "      <td>[Scala]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ExxonMobil\\n3.1\\nData Scientist\\nClinton, NJ\\n...</td>\n",
       "      <td>glassdoor</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>job_description</td>\n",
       "      <td>[multivariate, statisticsshell, scriptingfollo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>eBay Inc.\\n4.1\\nData Scientist/Applied Researc...</td>\n",
       "      <td>glassdoor</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>job_description</td>\n",
       "      <td>[computer, sciencemathScalaR]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>TikTok\\n3.7\\nData Scientist, University Gradua...</td>\n",
       "      <td>glassdoor</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>job_description</td>\n",
       "      <td>[Software, DevelopmentComputer, ScienceCompute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Mastercard\\n4.3\\nData Scientist, AI Services -...</td>\n",
       "      <td>glassdoor</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>job_description</td>\n",
       "      <td>[sideleadership]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   docidx                                            Content     source  \\\n",
       "0       0  Infoserv LLC\\nData Scientist\\nRemote\\nEmployer...  glassdoor   \n",
       "1       1  ExxonMobil\\n3.1\\nData Scientist\\nClinton, NJ\\n...  glassdoor   \n",
       "2       2  eBay Inc.\\n4.1\\nData Scientist/Applied Researc...  glassdoor   \n",
       "3       3  TikTok\\n3.7\\nData Scientist, University Gradua...  glassdoor   \n",
       "4       4  Mastercard\\n4.3\\nData Scientist, AI Services -...  glassdoor   \n",
       "\n",
       "        job_title            label  \\\n",
       "0  Data Scientist  job_description   \n",
       "1  Data Scientist  job_description   \n",
       "2  Data Scientist  job_description   \n",
       "3  Data Scientist  job_description   \n",
       "4  Data Scientist  job_description   \n",
       "\n",
       "                                                text  \n",
       "0                                            [Scala]  \n",
       "1  [multivariate, statisticsshell, scriptingfollo...  \n",
       "2                      [computer, sciencemathScalaR]  \n",
       "3  [Software, DevelopmentComputer, ScienceCompute...  \n",
       "4                                   [sideleadership]  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# left_skills[\"text\"]\n",
    "skills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff68018a-2398-4215-9eed-dfd9fda89123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Software DevelopmentComputer ScienceComputer EngineeringFinal yearrecent graduatewithSoftware DevelopmentComputer ScienceComputer Engineeringrelated technical discipline'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills[\"text\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa454c78-03d1-4166-a5db-eb53f58ccaa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
