,Content,Label
0,"Teknic
Data Engineer
Remote

 Role: Data Engineer
Location: Remote
JOb Description:
Skills and Experience :
Good experience on designing and developing data pipelines for data ingestion and transformation using Spark.
Distributed computing experience using Pyspark.
Good understanding of spark framework and spark architecture.
Experience working in Cloud based big data infrastructure.
Excellent in trouble shooting the performance and data skew issues.
Must have a good understanding of spark run time metrics and tune applications based on metrics.
Deep knowledge in partitioning, bucketing concepts of data ingestion.
Good understanding of AWS services like Glue, Athena, S3, Lambda, Cloud formation.
Preferred working knowledge on the implementation of datalake ETL using AWS glue, Databricks etc.
Experience with data modelling techniques for cloud data stores and on prem databases like Teradata, Teradata Vantage (TDV) etc.
Preferred working experience in ETL development in Teradata vantage and data migration from on prem to Teradata vantage.
Proficiency in SQL, relational and non-relational databases, query optimization and data modelling.
Experience with source code control systems like Gitlab.
Experience with large scale distributed relational and NoSQL database systems.
Job Type: Contract
8 hour shift
Experience:
Data engineer: 10 years (Preferred)
Spark.: 3 years (Preferred)
Cloud based big data infrastructure.: 1 year (Preferred)
datalake ETL: 1 year (Preferred)
AWS Glue: 1 year (Preferred)
Work Location: Remote",glassdoor
1,"Expression Networks
4.4
Data Engineer
Remote

 Founded in 1997 and headquartered in Washington DC, Expression Networks provides data fusion, data analytics, software engineering, information technology, and electromagnetic spectrum management solutions to the U.S. Department of Defense, Department of State, and national security community. Expression's “Perpetual Innovation” culture focuses on creating immediate and sustainable value for our clients via agile delivery of tailored solutions built through constant engagement with our clients. Expression Networks was ranked #1 on the Washington Technology 2018's Fast 50 list of fastest-growing small business Government contractors and a Top 20 Big Data Solutions Provider by CIO Review.

We make sure to provide everyone the tools and opportunities to grow while working on some of the newest technologies in the industry. With Covid-19 being a major theme the last two years having a growing collaborative culture has been one of the key focus of our C-suite and upper management. We get excited about celebrating our professionals' milestones, accomplishments, promotions, overcoming challenges, and many other aspects that make an engaging collaborative environment.

We are looking to bring on a mid-level Data Engineer to add to the continued growth of our Data Science division. This position will work in a team led by a principal data engineer on tasks related to designing and delivering high-impact data architecture and engineering solutions to our customers across a breadth of domains and use cases.
Location:
Remote, with the ability to travel per project requirements.
Security Clearance:
Ability to obtain Secret Clearance or Higher
Responsibilities:
Developing, testing, and documenting software code for data extraction, ingestion, transformation, cleaning, correlation, and analytics
Participating in end-to-end architectural design and development lifecycle for new data services/products, and making them operate at scale
Participating in cross-functional team collaboration to understand customer requirements, design prototypes, and optimize existing data services/products
Demonstrating Data Science excellence in the teams you work with across the organization, and mentoring junior members in the Data Science division
Participating in research, case studies, and prototypes on cutting-edge technologies and how they can be leveraged
Required Qualifications:
3+ years of experience bringing databases, data integration, and data analytics/ML technologies to production with a Bachelor's degree in Computer Science/Data Science/Computer Engineering or relevant field
Mastery in developing software code in one or more programming languages (Python, JavaScript, Java, Matlab, etc.)
Expert knowledge in databases (SQL, NoSQL, Graph, etc.) and data architecture (Data Lake, Delta Lake)
Knowledgeable in machine learning/AI methodologies
Experience with one or more SQL-on-Hadoop technology (Hive, Impala, Spark SQL, Presto, etc.)
Preferred Qualifications:
Experience in short release cycles and the full software lifecycle
Experience with Agile development methodology (e.g., Scrum)
Strong writing and oral communication skills to deliver design documents, technical reports, and presentations to a variety of audiences
Benefits:
Expression Networks offers competitive salaries and benefits, such as:
401k matching
PPO and HDHP medical/dental/vision insurance
Education reimbursement up to $10,000/yr.
Complimentary life insurance
Generous roll over PTO and 11 days of holiday leave
Onsite gym facility and trainer
Commuter Benefits Plan
In office Cold Brew Coffee
Equal Opportunity Employer/Veterans/Disabled",glassdoor
2,"TikTok
3.7
(HackerRank) Software Engineer, University Graduate (TikTok-Data-Comment)- 2023 Start (BS/MS)
Mountain View, CA
$115K - $189K (Glassdoor est.)

 Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

Team Introduction
Our team is in charge of two main scopes, TikTok content growth and comment. For the first one, we are working on building the best experience for creators and facilitate the growth of high quality contents on the platform. For the second one, we are working on improving our user experience in our comment section, including comment safety, ranking, atmosphere and interactions.

We are looking for talented individuals to join our team in 2023. As a graduate, you will get unparalleled opportunities for you to kickstart your career, pursue bold ideas and explore limitless growth opportunities. Co-create a future driven by your inspiration with TikTok.

Successful candidates must be able to commit to one of the following start dates below:
1. January 16, 2023
2. February 6, 2023
3. March 6, 2023
4. May 22, 2023
5. June 12, 2023
6. July 17, 2023
7. August 14, 2023
We will prioritize candidates who are able to commit to these start dates. Please state your availability and graduation date clearly in your resume.

Application deadline: February 15th, 2023
Candidates can apply to a maximum of two positions and will be considered for jobs in the order you apply. The application limit is applicable to TikTok and its affiliates' jobs globally. Applications will be reviewed on a rolling basis - we encourage you to apply early.

Technical Assessment
Candidates who pass resume evaluation will be invited to participate in TikTok's technical online assessment in HackerRank.

Responsibilities
Build new features that touch hundreds of millions of people around the world
Solve unique, large-scale, highly complex technical problems
Partner with PMs, designers, engineers from different teams on building backend support for mobile application
Participate in technical discussions related to team's product and engineering work
Qualifications
Bachelor's or Master's degree in Computer Science or related fields or equivalent practical experience
Bachelor's or Master's degree in Computer Science or related fields or equivalent practical experience
Final year or recent graduate with a background in Software Development, Computer Science, Computer Engineering, or a related technical discipline
Experience with coding in Python, Java, Golang, C#, or C++
Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment.
Preferred Qualifications:
Demonstrated software engineering experience from previous internship, work experience, coding competitions, or publications
Curiosity towards new technologies and entrepreneurship
High levels of creativity and quick problem-solving capabilities
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations during our recruitment process. If you need assistance or an accommodation, please reach out to us at Accommodations-AMS@tiktok.com.

By submitting an application for this role, you accept and agree to our global applicant privacy policy, which may be accessed here: https://careers.tiktok.com/legal/privacy.",glassdoor
3,"Denken Solution's Inc
Data Engineer
California, KY
Employer Provided Salary:$84K - $189K

 Role: Data Engineer
Location: Avery Rd, California
Duration: W2 Full Time
Job Description:
""Big Data developers with hands-on experience in building data pipeline applications
5+ yrs of hands-on experience in building Big Data applications using SQL/NoSQL technologies in the Hadoop ecosystem
-Strong MapReduce/Java app development experience & UNIX shell scripting skill
-Prepare Env for science model training
-Investigation and initial work to connect with new system (Ex. key-value store, remote service)
-SHP, eSHP topology
-TnV web crawling pipeline
-SRT batch scoring pipeline
-SRT model updating pipeline
-Hive, Pig with custom UDF implementation in Java
-MySQL
-Oozie
-Git, Maven
-Spark
-Plus: Kafka, DevOps, CI/CD""
Primary Skills:
""Java, Python, Oozie, Pig, Scala, SageMaker, Hive, Airflow, AWS
Job Types: Full-time, Contract
Salary: $84,227.91 - $189,097.26 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Flexible schedule
Health insurance
Life insurance
Paid time off
Professional development assistance
Relocation assistance
Schedule:
8 hour shift
Supplemental pay types:
Commission pay
Signing bonus
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: One location
Speak with the employer
+91 (949) 822 -3203",glassdoor
4,"Sedna Consulting Group
4.1
Data Engineer
Remote
Employer Provided Salary:$60.00 - $70.00 Per Hour

 **W2 Candidates Only**
USC and GC
Title: Data Engineers-
Location: Remote
Rate: $__/hr W2
Start Date: Immediate,
Duration: 1 year
Job Description:
Handles Data Analytics Platforms for Pepsico, incl Master Data for SAP, HANA, Azure, essentially all data. Large organization.
Looking for data engineers, hands on, individual contributors, to functionally map/move data from SAP and load it into Pepsico’s Legacy systems. Must understand mapping and have basic SAP knowledge. ETL knowledge (Informatica) a must.
7+ years of experie
Job Type: Contract
Pay: $60.00 - $70.00 per hour
Schedule:
8 hour shift
Experience:
SQL: 7 years (Preferred)
Data warehouse: 7 years (Preferred)
Azure: 7 years (Preferred)
SAP HANA: 7 years (Preferred)
Work Location: Remote",glassdoor
5,"DGN Technologies
4.8
Data Engineer
Peachtree Corners, GA
Employer Provided Salary:$70.00 Per Hour

 Position Title: Data Engineer 3
Location: Norcross, GA (hybrid)
Role Type: Long term contract
Description
Primary Function of Position:
Roles and Responsibilities:
Data Engineer: Designs, builds and oversees the deployment and operation of technology architecture, solutions and software to capture, manage, store and utilize structured and unstructured data from internal and external sources. Establishes and builds processes and structures based on business and technical requirements to channel data from multiple inputs, route appropriately and store using any combination of distributed (cloud) structures, local databases, and other applicable storage forms as required. Develops technical tools and programming that leverage artificial intelligence, machine learning and big-data techniques to cleanse, organize and transform data and to maintain, defend and update data structures and integrity on an automated basis. Creates and establishes design standards and assurance processes for software, systems and applications development to ensure compatibility and operability of data connections, flows and storage requirements. Reviews internal and external business and product requirements for data operations and activity and suggests changes and upgrades to systems and storage to accommodate ongoing needs.
Designing, implementing and testing cloud computing solutions using Snowflake technology
Strong SQL, Python, Tableau Skills
Create, Monitor, and optimize processes
A solid experience and understanding of architecting, designing and operationalization of large scale data and analytics solutions on Snowflake Cloud Data Warehouse is a must
Good written and communication skills
Excellent team-building skills
Thank you
Job Type: Contract
Pay: $70.00 per hour
Benefits:
401(k)
Health insurance
Schedule:
8 hour shift
Education:
Bachelor's (Preferred)
Experience:
DATA ENGINEERING: 5 years (Required)
SNOWFLAKE: 3 years (Required)
SQL: 5 years (Required)
Python: 1 year (Preferred)
Work Location: One location",glassdoor
6,"confidentioal
Data Engineer
Remote
Employer Provided Salary:$60.00 - $63.00 Per Hour

 Heavy spark and SCALA everything else is a nice to have
SPARK / SCALA/ SQL > PYTHON and JAVA are fine as long as they understand SPARK/SCALA
“Really need someone who is a smart with some data structures
Good to have: Data science experience, data pipelines, data structures
They have extensive pipelines in spark and Scala but also building new ones
SQL- do not do a lot of SQL. Someone who is advanced in Spark will be good enough in SQL for this role.
Batch processing; not real time data
Good in spark, scala, good with data structures
Cloud requirement is GCP; cloud experience is good to have from Azure, GCP, AWS
Fundamentally understand how to create tables, not too high level
Do not need data mining
Job Types: Full-time, Contract
Salary: $60.00 - $63.00 per hour
Schedule:
8 hour shift
Work Location: Remote",glassdoor
7,"Violet Ink
4.2
Data Analytics Engineer
Remote
Employer Provided Salary:$130K

 RESPONSIBILITIES:
Participate effectively in relevant aspects of software development life cycle (SDLC) including planning, construction, testing, reviews and demonstrations.
Collaborate with team to design, develop, test and refine deliverables.
Investigate and resolve application issues as needed
Package, configure and deploy software
Collaborate with clients, Product Managers, Architects, & Analysts to develop and review requirements & design.
Review and create system, software and functional design specifications that address requirements.
Write scripts/procedures/statements using DML and DDL (SQL statements) against databases such as Oracle, SQL Server, DB2, etc.
Design and develop multi-dimensional data models using star and snowflake schemas, denormalized data structures, slowly changing dimensions, etc.
Use data architectural techniques such as enterprise data warehouse, data federation, hub & spoke architectures, independent data marts, etc.
Use data integration tools and techniques such as ETL (Extract Transform Load), CDC (Change Data Capture), etc.
Design and develop analytical data models to support static and ad-hoc reports, analytics and research, dashboards, data mining, trending, creation of key performance indicators, predictive modeling, etc.
Deliver BI content via portals, thin/thick clients, email, mobile, etc.
Participate in project planning and release management.
Expected to manage broader or multiple projects at a time.
Acts as an expert source of technology and application knowledge within their domain technologies
Participating in Business planning, IT strategy and setting direction
Performs other related duties as assigned.
QUALIFICATIONS REQUIRED:
7-10 yrs of directly related experience in Data Analytics / Business Intelligence
Minimum of 6 years of hands-on experience with SQL and RDBMS
Minimum of 6 years of hands-on experience with data engineering including ETL and data warehousing
Minimum of 4 years of hands-on experience with building semantic-layer business intelligence solutions including metrics, dashboards and data visualizations
Expert problem-solving skills to rapidly create ad-hoc queries to answer complex business questions or debug data issues
Experience developing complex queries against the normalized and dimensional data model
Ability to work cooperatively as part of a team, as well as independently
Excellent verbal and written communication skills
Job Type: Full-time
Pay: From $130,000.00 per year
Schedule:
8 hour shift
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: Remote",glassdoor
8,"Quadrant Resource
4.3
Data Engineer
Remote

 JOB DESCRIPTION:
We are looking for a Data Engineer. Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. He should have experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Should have strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
They should also have experience using the following software/tools:
Should be experienced in Python, Azure Data Bricks and Azure Synapse.
Job Type: Contract
Schedule:
8 hour shift
Experience:
Python: 5 years (Preferred)
SQL: 5 years (Preferred)
Data Bricks: 3 years (Preferred)
Azure: 3 years (Preferred)
Azure Synapse: 3 years (Preferred)
Work Location: Remote",glassdoor
9,"Laiba Technologies
3.6
GCP Data Engineer
Remote
Employer Provided Salary:$70.00 - $75.00 Per Hour

 Experience with Google Cloud Platform GCP, BigQuery, and the challenges of building GCP based data lakes, APIGEE Terraform Understand the challenge of migrating legacy data platforms to cloud and modern architecture.
Experience with the following services:
PubSub, Cloud Functions, DataFlow, DataProc Cloud Storage, BigQuery, BigTable, DataLab, DataStudio, Micro services APIGEE Expertise in traditional SQL and NoSQL databases Experience with Data lake, data warehouse ETL, SOAP to REST Microservices migration Build Design Deploy Must be good in Java. Must have GCP experience with Java Background 8 years of experience as a Data Engineer or Analytics Engineer handling large data pipelines and platforms.
Job Type: Contract
Salary: $70.00 - $75.00 per hour
Schedule:
8 hour shift
COVID-19 considerations:
Wear mask
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: Remote",glassdoor
10,"NucleusTeq
4.9
Data Engineer
Remote

 Data Engineer
Role Info:
Hands on BI Data Engineer role with strong
Creating KPI Dashboards - Interactive Dashboards using tableau / Quicksight
Top Skills:
BI Tableau / AWS Quicksight exp is a must
AWS (IAM, RDS, S3, Lambda) exp is a must
SQL exp is a must
Python knowledge is required
Nice to have:
AWS Certified Solutions Architect
About the Company:
NucleusTeq is a software services, solutions & products company empowering & transforming customer's business through the use of digital technologies such as Big-Data, Analytics, Cloud, Enterprise Automation, Block-chain, Mobility, etc.
We are enabling several fortune 1000 clients in the USA, Canada, UK & India to navigate their digital transformation.",glassdoor
11,"Purple Drive Technologies
4.5
Azure Data Engineer
Remote
Employer Provided Salary:$50.00 - $55.00 Per Hour

 Hi
Hope you are doing great!!
Greetings, This is Hari from Purple Drive Technologies. We are looking for Azure Data Engineer @ Remote. Kindly send me your updated profile if you interested with the below job description.
Position: Azure Data Engineer
Location: Remote
Duration: Contract
Job Qualifications / Requirements:
8-12 years experience
Azure Data Factory
PostgreSQL
Writing / maintaining SQL
Writing / maintaining stored procedures
Postman
To access our source system APIs
Data Bricks
Linux familiarity
Writing shell scripts
Viewing log files
Generating a cert signing request
Some simple system administration
Registering a service to start at system start, etc.
Azure experience
ADLS Gen 2
Logic Apps
Azure Functions
Azure network security group
key vault
Event Grid
Azure devops familiarity
writing/maintaining ARM Templates
Job Type: Contract
Salary: $50.00 - $55.00 per hour
Schedule:
8 hour shift
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: Remote",glassdoor
12,"Apptrics LLC
5.0
Data engineer
Remote
Employer Provided Salary:$45.00 - $50.00 Per Hour

 Data engineer
Redmond, WA (Initial Remote for 3 months and later on onsite)
Long Term Contract
JD:
Azure Data factory, SQL and PowerBI
Job Type: Contract
Pay: $45.00 - $50.00 per hour
Schedule:
8 hour shift
Monday to Friday
Education:
Bachelor's (Required)
Experience:
SQL: 6 years (Required)
Power BI: 5 years (Required)
Azure Data factory: 4 years (Required)
Work Location: Remote",glassdoor
13,"PLAXONIC
4.6
Data Engineer (AWS Redshift/ Pyspark)
Ashburn, VA
Employer Provided Salary:$55.00 - $65.00 Per Hour

 . At least 5 Years of experience performing below
2. Proficient in advanced SQL and ETL Tools
3. Proven experience in data warehousing -AWS Redshift
4. Hands On Programming experience in Python/PySpark
5. Hands on with Orchestration tools like airflow
6. Excellent Problem-solving and debugging skills
7. Must Have Experience with AWS/redshift, Python/PySpark, data pipelining, advanced SQL, and ETL
8. Ability to build, and optimize pipelines/systems for data collection, storage, access, and analytics at scale
9. Demonstrate at least 2 project experience and successfully implementations
Technical Expertise - >
1. Proficient in advanced SQL and ETL Tools
2. Proven experience in data warehousing -AWS Redshift
3. Hands On Programming experience in Python/PySpark
4. Hands on with Orchestration tools like airflow
5. Must Have Experience with AWS/redshift, Python/PySpark, data pipelining, advanced SQL, and ETL
Job Types: Contract, Full-time
Salary: $55.00 - $65.00 per hour
Schedule:
8 hour shift
Ability to commute/relocate:
Ashburn, VA 20147: Reliably commute or planning to relocate before starting work (Required)
Experience:
AWS Redshift: 5 years (Preferred)
ETL: 5 years (Preferred)
Python /Pyspark: 5 years (Preferred)
Airflow: 2 years (Preferred)
Data warehouse: 5 years (Preferred)
Work Location: One location
Speak with the employer
+91 727 - 216 - 7642",glassdoor
14,"BuzzClan LLC
4.4
Data Engineer
Remote
Employer Provided Salary:$60.00 - $70.00 Per Hour

 Hiring data engineer with following skills.
Role
Senior data engineer (GlUE/PYSPARK)
Develops and maintains scalable data pipelines and builds out new API integrations for data transfer.
Performs data analysis required to troubleshoot data-related issues and assist in the resolution of data issues.
Must-have
BS or MS degree in Computer Science or a related technical field
5+ years of extensive ETL development experience using Pyspark/Glue on AWS
5+ years of experience in CSV, JSON, Parquet file formats, especially with nested data types
5+ years of experience in S3, Athena, RDS, Glue catalogue, Cloudformation
Strong understanding of ETL/Data-pipelines/BigData architecture
Strong Database/SQL experience in any RDBMS
Nice-to-have
Experience in schema design, data ingestion experience on Snowflake (or equivalent MPP)
Experience in orchestrating data processing jobs using Step Function/Glue workflow/Apache Airflow (MWAA)
Experience in data analysis using Excel formulas, vlookup, pivot, slicers
Job Type: Contract
Pay: $60.00 - $70.00 per hour
Schedule:
8 hour shift
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: Remote",glassdoor
15,"Freemind solutions
3.5
Big Data Engineer
Remote
Employer Provided Salary:$55.00 - $60.00 Per Hour

 Big data with python, Spark
· 5-10 years of experience as a Big Data Developer
· In-depth knowledge of Big Data technologies - Spark, HDFS, Hive, Kudu, Impala
· Solid programming experience in Python
· Production experience in core Hadoop technologies including HDFS, Hive and YARN
· Strong working knowledge of SQL and the ability to write, debug, and optimize distributed SQL queries
· Strong analytical abilities; ability to translate business requirements and use cases into a Hadoop solution, including ingestion of many data sources, ETL processing, data access, and consumption, as well as custom analytics
· Experience working with Data Governance tools like Apache Sentry, Kerberos, Atlas, Ranger
· Experience working with streaming data with technologies like Kafka, Spark streaming
· Strong understanding of big data performance tuning
· Experience handling different kinds of structured and unstructured data formats (Parquet/Delta Lake/Avro/XML/JSON/YAML/CSV/Zip/Xlsx/Text etc.)
Job Type: Contract
Pay: $55.00 - $60.00 per hour
Schedule:
8 hour shift
Experience:
Data warehouse: 4 years (Preferred)
Spark: 5 years (Required)
Python: 5 years (Required)
Work Location: Remote",glassdoor
16,"Faire
4.8
Data Engineer
San Francisco, CA
$117K - $170K (Glassdoor est.)

 About Faire
Faire is an online wholesale marketplace built on the belief that the future is local — there are over 2 million independent retailers in North America and Europe doing more than $2 trillion in revenue. At Faire, we're using the power of tech, data, and machine learning to connect this thriving community of entrepreneurs across the globe. Picture your favorite boutique in town — we help them discover the best products from around the world to sell in their stores. With the right tools and insights, we believe that we can level the playing field so that small businesses everywhere can compete with these big box and e-commerce giants.
By supporting the growth of independent businesses, Faire is driving positive economic impact in local communities, globally. We're looking for smart, resourceful and passionate people to join us as we power the shop local movement. If you believe in community, come join ours.
Job Description
The Data Engineering team is the backbone of all data-related processes and enables the Data Science teams to develop and deploy a wide variety of algorithms and models that power the marketplace. Our infrastructure is used by the whole company for analytics, reporting, forecasting and research. We care about having a reliable & scalable infrastructure with quality data and building machine learning models that help our customers thrive.
As a Data Engineer you'll be responsible for developing and automating large scale, high-performance data storage and processing systems.
Our team already includes experienced Data Scientists and Engineers from Airbnb, Facebook, Quora, Square, Uber, TripAdvisor, and Overstock. Faire will soon be known as a top destination for data science and machine learning, and you will help take us there!
What you will be doing:
Develop our data infrastructure to help us scale for where we're going over the next several years
orchestrating pipelines using modern Big Data tools/architectures as well as design and engineering of existing transactional processing systems
Manage our data infrastructure and ETL platform
What it takes:
2+ years experience in a Data Engineering role with an emphasis on managing data warehouses
Strong skills in Python, Git, Docker, SQL, Airflow, real time ETL pipelines
Managing data infrastructure (AWS services, Data orchestrator) and providing framework to rationalize and simplify both real time and batch data pipelines
Familiarity with Snowflake or BigQuery
A passion for programming and solving problems with code
A bachelor's degree in Computer Science/Software Engineering or equivalent industry experience
A love for technology, and an insatiable curiosity for new tools to tackle real problems
Faire's flexible work model aims to meet the needs of our diverse employee community by making work more flexible, connected, and inclusive. Depending on the role and needs of the team, Faire employees have the flexibility to choose how they work–whether that's mainly in the office, remotely, or a mix of both.
Roles that list only a country in the location are eligible for fully remote work in that country or in- office work at a Faire office in that country, provided employees are located in the registered country/province/state. Roles with only a city location are eligible for in-office or hybrid office work in that city. Our talent team will work with candidates to determine what locations and roles are eligible for each option.
Why you'll love working at Faire
We are entrepreneurs: Faire is being built for entrepreneurs, by entrepreneurs. We believe entrepreneurship is a calling and our mission is to empower entrepreneurs to chase their dreams. Every member of our team is an owner of the business and taking part in the founding process.
We are using technology and data to level the playing field: We are leveraging the power of product innovation and machine learning to connect brands and boutiques from all over the world, building a growing community of more than 350,000 small business owners.
We build products our customers love: Everything we do is ultimately in the service of helping our customers grow their business because our goal is to grow the pie - not steal a piece from it. Running a small business is hard work, but using Faire makes it easy.
We are curious and resourceful: Inquisitive by default, we explore every possibility, test every assumption, and develop creative solutions to the challenges at hand. We lead with curiosity and data in our decision making, and reason from a first principles mentality.
Faire was founded in 2017 by a team of early product and engineering leads from Square. We're backed by some of the top investors in retail and tech including: Y Combinator, Lightspeed Venture Partners, Forerunner Ventures, Khosla Ventures, Sequoia Capital, Founders Fund, and DST Global. We have headquarters in San Francisco and Kitchener-Waterloo, and a global employee presence across offices in Salt Lake City, Atlanta, Toronto, London, New York, LA, and Sao Paulo. To learn more about Faire and our customers, you can read more on our blog.
Faire provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity or gender expression.
Faire is committed to providing access, equal opportunity and reasonable accommodation for individuals with disabilities in employment, its services, programs, and activities. To request reasonable accommodation, please fill out our Accommodation Request Form.",glassdoor
17,"Kollasoft Inc
3.3
Data Engineer
Remote
Employer Provided Salary:$39.94 - $86.24 Per Hour

 Job Role: Data Engineer
Location: Remote
Duration: Long Term
Visa : US Citizen
Skills and Areas of Expertise:
Candidate must have the following skills:
· 5+ years' experience with Snowflake development creating tables, views, excellent understanding how to connect to multiple databases to navigate the data; write SQL and Python. Good hands-on experience developing with Snowpipe and ability to write APIs.
· 5+ years' experience developing Matillion orchestrations and transformation jobs
· 5+ years' experience Informatica PowerCenter developing skills with mappings, sessions and workflows.
Candidate must have knowledgeable background in: Snowflake, Matillion, Oracle, Informatica PowerCenter, database modeling, star schema, DataVault and DataVault 2.0 methodology, Jenkins, GitHub, scheduling tools such as Tidal and RunMyJobs, Informatica Scheduler and familiarity with an SAP ERP system.
Behavioral:
Candidate must demonstrate soft skills in:
· highly effective communication with customers, business partners and stakeholders
· work well in an agile team environment
· hold self-accountable for committed deliverables
Job Functions / Responsibilities:
· Developing ELT ingest/egress orchestrations, mappings, pipelines in Matillion to Snowflake
· Perform data analysis and root cause analysis with tools such as SQL Developer to connect to data source and targets, perform data profiling tasks and root cause analysis
Qualifications & Skills:
· Bachelor degree in a STEM related field
Job Type: Contract
Pay: $39.94 - $86.24 per hour
Schedule:
8 hour shift
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: Remote",glassdoor
18,"Sunixa Solutions
Data Engineer
Remote
Employer Provided Salary:$39.60 Per Hour

 Job description:
Proven Experience in Azure Cloud with following skills:
Azure ADF
Azure Databricks with Python
Strong Database and SQL writing skills
Strong data analysis skills for new data sources/target
Informatica experience big plus
Insurance industry experience is plus
Job Type: Contract
Salary: From $39.60 per hour
Schedule:
8 hour shift
Work Location: Remote
Speak with the employer
+91 9086817115",glassdoor
19,"R4 Solutions
4.4
Data Engineer
Sunnyvale, CA
Employer Provided Salary:$65.00 Per Hour

 5+ years’ experience with highly scalable, high performance and high availability server development
2 years of work or educational experience in big data.
Experience with distributed processing and messaging systems, including Spark, Akka, Kafka, Pub/sub, Hive/pig, Mapreduce, etc.
Experience with various distributed databases like Cassandra, Redis, MongoDB, etc.
Demonstrate clear and concise communication and data-driven decision-making capability
Expertise in some or all of the following:
Data Pipelines
Data Warehousing
Statistics
Metrics development
Strong understanding of SQL
Broad knowledge of the data infrastructure ecosystem
Experience with one or more general purpose programming languages including but not limited to: Java/Scala, C/C++ or Python
Solid background in algorithms, data structures, and object-oriented programming concepts
B.S. and/or M.S. in Computer Science or a related technical field, or equivalent experience
Job Type: Contract
Salary: Up to $65.00 per hour
Schedule:
8 hour shift
Ability to commute/relocate:
Sunnyvale, CA 94089: Reliably commute or planning to relocate before starting work (Required)
Experience:
Big data: 3 years (Required)
Distributed systems: 3 years (Required)
Java: 5 years (Required)
Work Location: One location",glassdoor
20,"Narvee Tech
Data Engineer
Remote
Employer Provided Salary:$40.00 - $60.00 Per Hour

 Its W2 Position (No C2C)
Job Title: Data Engineer
Position: Remote
Responsibilities:
Assemble large, complex data sets that meet functional / non-functional business requirements
Optimize data delivery and design infrastructure for greater scalability
Build and leverage the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources both on premise and cloud
Design and manage models to handle large datasets of existing structured and unstructured data
Set up data replication processes to migrate and consolidate data from various internal and external sources
Qualifications:
Bachelor's Degree in Computer Science/Computer Engineering or equivalent years of software development experience required
5+ years of overall technology experience.
3+ years of Data Engineering, Data Modeling, and Data Warehousing experience required
2+ years of experience working with Agile teams preferred
Expert knowledge of full data engineering lifecycle
Expert experience with Data Engineering tools such as Talend
Strong experience with relational SQL and NoSQL databases
Expert experience in building data pipelines, data ingestions, data integrations, data preparations, and traditional Data warehouses and DataMarts
Strong experience in building processes supporting data transformation, data structures, metadata, and dependency and workload management
Expertise in designing, validating and implementing multiple projects across a hybrid infrastructure (cloud to on-premise and vice versa)
Experience with big data tools such as Kafka
Understanding of message queuing, stream processing, and highly scalable 'big data' data stores
Strong interpersonal skills, analytical skills, and a ""can do"" attitude are essential
Benefits:
H1B Visa sponsorship and assistance in getting CPT, OPT extension.
STEM extension is done as we are e-verified.
Green Card sponsorship for qualified candidates
Attractive Pay Scales
Health Insurance Cover Provided
100% Guaranteed successful placement
We will file H1B whenever it's required, if you are not in our project also at the time of filing
Interested candidates reach me at
Email: samuel(at)narveetech.com
Job Type: Full-time
Salary: $40.00 - $60.00 per hour
Schedule:
8 hour shift
Work Location: Remote",glassdoor
21,"HCL America Inc
3.7
Data Engineer
Remote
Employer Provided Salary:$30.00 Per Hour

 Position : Data Engineer
Location: Remote
Job Description
· Build and maintain database/bigdata clusters;
· Build dashboards for infrastructure management and reporting; Design, develop and support data pipelines;
· Design and deploy infrastructure management strategies to meet up time and monitoring SLA’s;
· Deploy code release in QA and PROD;
· Participate in building unit/performance/integration tests working with database developers;
· Participate in database SQL optimization plan;
· Deploy configuration and automation tools to remove manual steps in deploying, upgrading, and scaling systems and software across all environment.
Technical Skills
· Solid background in Python and SQL;
· BI tools knowledge
· Big data technologies: Hadoop and Kafka
· ML frameworks and libraries: TensorFlow, Spark, PyTorch, mlpack
· Knowledge of programming languages (langJava, Scala, Python, R, C/C#, Golang)
· Experience building data solutions using big data tools: Airflow, Spark, Kafka, AWS;
· Experience with data pipeline and workflow management tools
· Hands-on experience with requirements analysis, design, coding and testing patterns;
· Has experience in engineering (commercial and open source) software platforms and large-scale data infrastructures;
· Experience working with cloud computing environments
Job Types: Full-time, Contract
Pay: From $30.00 per hour
Benefits:
401(k)
Dental insurance
Health insurance
Paid time off
Vision insurance
Schedule:
8 hour shift
Experience:
Spark: 1 year (Required)
SQL: 1 year (Required)
frameworks and libraries: 1 year (Required)
Work Location: Remote",glassdoor
22,"Kaygen Inc.
4.2
Data Engineer
Remote
Employer Provided Salary:$55.00 - $60.00 Per Hour

 Hi ,
Hope you are doing Great!
Further below is the job description for “ Data Engineer ”
Job Title : Data Engineer
Job Location : Remote (Work From Home )
Job Duration : 6 months with Extension
Job Description :
ROLE: Data Engineer
Must be able to work in Central Time Zone.
Looking for a Data-focused test engineer:
With experience in Data Catalog, Data Quality, Data Governance, Master Data Management and/or Data Stewardship technologies and processes
To work as part of an agile product team, delivering tested changes aligned with each sprint to support development lifecycles
With the potential to evolve more predictive and intelligent testing approaches based on automation and innovative testing products & solutions
To be a proactive, self-motivated and independent contributor with the ability to work in a fast-paced environment and deliver high-quality work on tight schedules
Position responsibilities include:
Partner with Data Engineers, stewards and others to gather and define business requirements, understand technical designs and systems and to support the development lifecycle of the product team
Develop and drive risk-based testing strategies that may span multiple product teams, systems and dependencies
Understanding ETL logic in order to write complex SQL queries for data quality validation
Identify and analyze data discrepancies and data quality issues; work to ensure data consistency and integrity
Capture testing artifacts and provide reports based on meeting test deliverables
Ensure all defect artifacts are documented, triaged, and resolved in a timely manner
Coach and mentor others on testing practices and tools
Requirements
What You'll Need...
2-4 years of Python or Java scripting experience
Previous experience as a DBA and/or a strong understanding of DB structures
Ability to query databases using SQL to investigate discrepancies in data using comparative analysis techniques
Experience working with APIs and in analyzing JSON and/or XML outputs
Experience using tools such as ASG, Informatica, and/or Alation
Strong knowledge of data structures, algorithms, enterprise systems, and asynchronous architectures
Enterprise understanding in test planning, test data management, automated & manual test execution, and test management tools to support a complex data landscape
Proven experience in defining and executing testing strategies by partnering with business and development teams to understand project scope, risk and data workflows.
Must have experience with CI/CD pipelines, in-sprint test automation and CI integration
One plus years of agile experience using SCRUM or Kanban
Understanding of QA methodologies, life cycle and processes
Strong knowledge and extensive experience with unit, functional and performance testing is desired
Bachelor or higher-level degree in MIS, Data Analytics, Data Science, Computer Science or Computer Engineering preferred
Financial Services background desired?
if you are interested in this job or if you have references or friends looking for a job change then please share this mail with them and feel free to contact me
Rohit Justin . K
Technical Recruiter
Work: 949 608 7375
Email: Rohit.justin(@)kaygen.com
Job Type: Contract
Salary: $55.00 - $60.00 per hour
Schedule:
8 hour shift
Experience:
Python or Java scripting: 4 years (Preferred)
DBA: 4 years (Preferred)
SQL: 4 years (Preferred)
CI/CD: 4 years (Preferred)
SCRUM or Kanban: 4 years (Preferred)
Work Location: Remote",glassdoor
23,"Momentum Recruitment
Big Data Engineer
Remote
Employer Provided Salary:$60.00 - $70.00 Per Hour

 Requirements:
BS degree in computer science, computer engineering or equivalent
5 – 6 years of experience delivering enterprise software solutions
Proficient in Spark, Scala, Python, AWS Cloud technologies
3+ years of experience across multiple Hadoop / Spark technologies such as Hadoop, MapReduce, HDFS, HBase, Hive, Flume, Sqoop, Kafka, Scala
Flair for data, schema, data model, how to bring efficiency in big data related life cycle
Must be able to quickly understand technical and business requirements and can translate them into technical implementations
Experience with Agile Development methodologies
Experience with data ingestion and transformation
Solid understanding of secure application development methodologies
Experienced in developing microservices using spring framework is a plus
Experience in with Airflow and Python will be preferred
Understanding of automated QA needs related to Big data
Strong object-oriented design and analysis skills
Excellent written and verbal communication skills
Responsibilities:
Utilize your software engineering skills including Java, Spark, Python, Scala to Analyze disparate, complex systems and collaboratively design new products and services
Integrate new data sources and tools
Implement scalable and reliable distributed data replication strategies
Ability to mentor and provide direction in architecture and design to onsite/offshore developers
Collaborate with other teams to design and develop and deploy data tools that support both operations and product use cases
Perform analysis of large data sets using components from the Hadoop ecosystem
Own product features from the development, testing through to production deployment
Evaluate big data technologies and prototype solutions to improve our data processing architecture
Automate everything
Job Type: Full-time
Salary: $60.00 - $70.00 per hour
Schedule:
10 hour shift
8 hour shift
Experience:
big data engineer: 3 years (Preferred)
Work Location: Remote",glassdoor
24,"Farmers Insurance Group
3.7
Data Engineer (Application SME I)
Remote
Employer Provided Salary:$74K - $98K

 We are Farmers!
We are… more than just your favorite commercials. We are a passionate, award winning, equal opportunity employer, committed to the strength of a diverse workforce. We are dedicated to supporting the well-being of our people through our extensive suite of benefits, as well as the well-being of the communities we serve through employee volunteer programs and nonprofit partnerships. Helping others in their time of need isn’t just our business – it’s our culture! We are Farmers!

Do you thrive in a high-volume, fast-paced environment? Do you enjoy the challenge of a position where no two days are alike? We are looking for positive, high-energy professionals who are not just looking for a job, but a meaningful career!

Job Summary
Use MS SQL SSIS to build ETL process to create new business functionalities as well to solve business problems: Respond to new requests for reports/data understanding business objectives and processes; review and refine technical requirements/User Stories; and communicate estimated hours and timeline to complete; Extract data directly from relational databases (e.g. DB2, SQL Server), data warehouses, or other data stores using SQL; Ability to create manual as well as automated data exports/reports; and Support application unit testing for enhancements or system upgrades; identify and communicate data quality issues or data differences. Work productively on assigned tasks; Collaborate effectively with other team members; Demonstrate accountability to management and business for hours spent on assigned tasks; and diligently strive to deliver value.
Essential Job Functions
Work within structure of SAFe Agile team on the successful delivery of Business Intelligence projects, enhancements, and defects. Independently lead and deliver new projects and enhancements. Collaborate with Agile team members to understand functional and technical requirements. Prepare estimates based on high-level requirements and assumptions. Translate functional requirements into technical specifications for ETL development; develop source-to-target mappings and actively manage Development, Unit Testing and Implementation efforts. Troubleshoot production defects, perform root cause analysis and provide guidance to team on the fixes.
Education Requirements
High school diploma or equivalent required.
Bachelor’s degree preferred, in Information Systems or related field.
Experience Requirements
Experience in developing ETL and reporting applications using Microsoft SQL Server (strongly preferred), or Informatica or similar ETL technologies.
Experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process on MS SQL Server or DB2 or similar DB platform.
Experience with Python and unstructured data manipulation is a plus.
Experience with cloud technologies such as AWS Glue, Azure Data Factory, Snowflake is a plus.
Experience working in an Agile Environment is a plus.
Good knowledge of business intelligence best practices, processes, and methodologies.
Good programming experience in writing Stored Procedures, Queries, Views, User Defined Functions, and Common Table Expressions using SQL or T-SQL.
Highly committed, motivated, enthusiastic and a natural team player.
Good interpersonal and communication skills (both verbal and written) and ability to interact with and effectively address concerns.
Good prioritization, time management, analytical, and organization skills.
Experienced in facilitating in-person and remote meetings with business & IT.
Experienced in effective management of multiple competing and frequently changing assignments and priorities.

Benefits
Farmers offers a competitive salary commensurate with experience, qualifications and location
Colorado Only: The pay range for this job being performed in Colorado would be 73,600 - 98,100
Bonus Opportunity (based on Company and Individual Performance)
401(k)
Medical
Dental
Vision
Health Savings and Flexible Spending Accounts
Life Insurance
Paid Time Off
Paid Parental Leave
Tuition Assistance

Job Location(s): R_US - RW - Remote Work",glassdoor
25,"Apolis
4.2
Data Engineer
North Chicago, IL
Employer Provided Salary:$70.00 - $75.00 Per Hour

 Note: Rate could be flexible according to exp in required skills
Data Engineer
Contract
Chicago, IL(onsite Day 1)
Strong Experience in SQL Programming, Stored procedure & Views is must.
Strong analysis and debugging skills using tools and able to identify all data elements and carry out independently.
Experience/Knowledge in Azure Data factory & Azure Synapse/SQL
Good communication skill and able to lead the client requirement by leading the design and development.
Job Types: Contract, Full-time
Salary: $70.00 - $75.00 per hour
Schedule:
8 hour shift
Day shift
Monday to Friday
Ability to commute/relocate:
North Chicago, IL 60064: Reliably commute or planning to relocate before starting work (Required)
Experience:
Azure: 3 years (Required)
PL/QL: 3 years (Required)
Data warehouse: 1 year (Preferred)
Work Location: One location
Speak with the employer
+91 7322856236",glassdoor
26,"RD Solutions INC
4.4
Data engineer
Remote

 Job Description :
Strong in SQL and Python
Data warehousing concepts
Good to have big data technologies – Apache Spark, Kafka, Delta Lake
Job Type: Contract
Schedule:
8 hour shift
Experience:
SQL: 6 years (Preferred)
Data warehouse: 7 years (Preferred)
Work Location: Remote
Speak with the employer
+91 7324812709",glassdoor
27,"Antra, Inc
4.5
Jr. Data Engineer
Sterling, VA
Employer Provided Salary:$60K - $68K

 Antra started its services in the year 2008, since then we have been diligently serving every need of our clients professional and software solutions. With our unique amalgam of innovation and inspiration, backed by Agile processes, we deliver world-class services with our core values to our clients. We identify unique strategies to transforming organizations through picking their sweet spot for innovative thinking and helping them in implementing in-depth cultural shift; ultimately augmenting the innovation process to the next level – fostering the innovation race that never ends.
This role requires the design, development and implementation of data solutions to business problems. An Azure Data Engineer will be expected to perform duties such as: evaluating the performance of current data solutions, designing and implementing cloud and hybrid data solutions. Ability to adapt and learn new technologies per business requirements is also needed.
Responsibilities:
Design and implement data solutions using industry best practices.
Performs ETL, ELT operations and administration of data and systems securely and in accordance with enterprise data governance standards.
Monitor and maintain data pipelines proactively to ensure high service availability.
Works with Data Scientists and ML Engineers to understand mathematical models and optimize data solutions accordingly.
Continuous development through training and mentorship programs.
Create scripts and programs to automate data operations.
You meet our “must haves” for this role if you have:
Minimum Bachelor’s degree in Data Science, Business Intelligence, Computer Science or related fields, or the equivalent combination of education, professional training, and work experience.
0-3 years of experience working with one or more languages commonly used for data operations including SQL, Python, Scala and R.
Experience working with relational databases such as SQL Server, Oracle and MySQL.
Experience working with NoSQL databases such as Redis, Mongo DB, Cosmos DB.
Excellent problem-solving skills and ability to learn through scattered resources.
Thorough understanding of the responsibilities and duties of a data engineer, as well as established industry standards/best practices and documentation guidelines.
Outstanding communication skills, and the ability to stay self-motivated and work with little or no supervision.
Willing to relocate to any US location on Antra projects location.
Authorization(s) to work lawfully in the United States (OPT/CPT is acceptable).
Plus, if you meet any the of requirements:
Experience with cloud-based data technologies.
Experience with distributed systems utilizing tools such as Apache Hadoop, Spark or Kafka.
Working experience in Agile Scrum environments.
Experience with source control tools such as Git, SVN and TFS.
The intent of this position description is to provide a representative summary of the major duties and responsibilities performed by incumbent(s) in this position. Incumbent(s) may not be required to perform all duties in this description and incumbent(s) may be required to perform position-related tasks other than those specifically listed in this description.
Antra Inc. is an equal opportunity employer, providing equal employment opportunities (EEO). All employees and applicants for employment will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity or expression, pregnancy, protected veteran status or other status protected by law. This policy applies to all terms and conditions of employment.
Job Types: Full-time, Contract
Pay: $60,000.00 - $68,000.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Health savings account
Life insurance
Paid time off
Professional development assistance
Referral program
Relocation assistance
Vision insurance
Schedule:
Monday to Friday
Application Question(s):
Are you open for relocation within the US?
Education:
Bachelor's (Preferred)
Work Location: Hybrid remote in Sterling, VA 20166",glassdoor
28,"PCS Global Tech
4.7
Data Engineer | ENTRY LEVEL |
Utica, NY
Employer Provided Salary:$60K - $70K

 _ At PCS Global Tech we care about the professional growth of our employees, we will make your professional career successful. This opportunity is a career starter, we offer an opportunity that starts with an intensive bootcamp followed by a full-time employment, we also offer in house legal support for international students. _
Responsibilities
Analyze and organize raw data
Build data systems and pipelines
Evaluate business needs and objectives
Interpret trends and patterns
Conduct complex data analysis and report on results
Prepare data for prescriptive and predictive modeling
Build algorithms and prototypes
Combine raw information from different sources
Explore ways to enhance data quality and reliability
Identify opportunities for data acquisition
Develop analytical tools and programs
Collaborate with data scientists and architects on several projects
Requirements
Previous experience as a data engineer or in a similar role (such as internships)
Technical expertise with data models, data mining, and segmentation techniques
Knowledge of programming languages (e.g. Java and Python)
Hands-on experience with SQL database design (MUST HAVE)
Great numerical and analytical skills
Bachelor’s degree in Computer Science, IT, or similar field
Job Types: Full-time, Contract
Salary: $60,000.00 - $70,000.00 per year
Benefits:
Dental insurance
Employee assistance program
Health insurance
Relocation assistance
Vision insurance
Schedule:
8 hour shift
Monday to Friday
No weekends
Experience:
SQL: 1 year (Preferred)
Work Location: On the road",glassdoor
29,"Luxoft
4.3
Data Engineer
Remote

 Project Description
Luxoft has contract with a major Telecommunications provider to engage with DIRECTV organization to establish integrated cloud technology platforms to ingest information from various Network Engineering support applications in order to better optimize management and planning for the future network.

To do this DIRECTV is managing data ingestion into a Snowflake Azure based deployment which allows for one cohesive platform to serve all types of users and workloads in a consistent way. Centralizing data in a unified, governed, managed data platform allows all authorized users to access accurate and timely data for analysis that is useful for highly transnational datasets. It is also useful that it can store structured and unstructured data. Additionally DIRECTV is leveraging a Palantir Deep™ instance platform for the creation and management of cost forecasting scenarios.
Responsibilities
- Analysis on Data Libraries - evaluation of data sets and current data architecture for source data pipelines. This will allow us to scope the depth/breadth of data

- Data Quality Metrics - Audits analysis and setup to determine the appropriate data quality measures. This will be used to validate with clients/users in a later phase.

- DQF research - Analyze the current Data Quality Framework to leverage as possible/needed. Assess the need for extension and/or replacement of the current DQF.

- Architecture patterns research - Analysis of data translation and business rules associated.

- Current ingestion patterns - Study and enhancement research to evaluate data pipeline for current state and opportunity to optimize for increased data quality and rigor.
Skills
Must have
Cloud, Data Engineering, SnowFlake, Big Data
Nice to have
Microsoft Azure Cloud Platform
Languages
English: C2 Proficient
Seniority
Senior
Relocation package
If needed, we can help you with relocation process.
Vacancy Specialization
BigData Development
Ref Number
VR-81593",glassdoor
30,"1 Point Systems
4.0
Data Engineer
Morris Plains, NJ
Employer Provided Salary:$100.00 Per Hour

 About the job
Job Title: Data Engineer
Location(s): Morris Plains, NJ.
Contract Length: 4 months with the potential for extension/conversion.
Job Overview/ Responsibilities:
Provides counsel and advice to top management on significant Engineering matters, often requiring coordination between organizations.
Designs and develops a consolidated, conformed enterprise data warehouse and data lake which store all critical data across Customer, Provider, Claims, Client and Benefits data.
Manages processes that are highly complex and impact the greater organization.
Designs, develops and implements methods, processes, tools and analyses to sift through large amounts of data stored in a data warehouse or data mart to find relationships and patterns.
May lead or manage sizable projects.
Participates in the delivery of the definitive enterprise information environment that enables strategic decision-making capabilities across enterprise via an analytics and reporting.
Focuses on providing thought leadership and technical expertise across multiple disciplines.
Recognized internally as “the go-to person” for the most complex Information Management assignments.
Required Skills/ Familiarity:
ReactJS
Java
Database
Data Mart
Data Warehouse
Software Engineering
Thought Leadership
Claims background
Job Type: Contract
Salary: Up to $100.00 per hour
Schedule:
8 hour shift
Work Location: One location",glassdoor
31,"Milo's Tea Company
4.1
Data Engineer
Remote

 Overview: Milo’s Tea Company is one of the fastest growing beverage companies in the US. Our culture and operations are built on the belief that we can make a difference in the world. That’s why we put People First and strive to continually reduce our environmental impact on the planet. We leverage our world class operations and decades-long distribution partnerships to grow the footprint of our core products and create new, innovative beverage products.
We are the #1 and fastest growing brand in the Refrigerated Tea Category in the nation.
Our core mission is that we put people and the planet first and by doing this, it will be good for our business.
We are committed to unlocking the personal genius of every associate and have a strong focus on growth and learning.
Our Company is women-led (our Executive Team is 57% female) and strongly committed to Diversity, Inclusion and Belonging.
We are committed to annual charitable giving by delivering upon our 1% profit pledge.
We are Platinum Certified in Zero Waste Manufacturing; recycling, reducing, and reusing 95% of waste at all facilities.
Being a part of the Milo’s TEAm, you’ll get to collaborate with a group of passionate and high-performing people, where everyone feels empowered to do their best work and feels good about the work they’re doing.
And as a ""People First"" company, Milo’s is committed to the success and well-being of our associates, customers, and fans, no matter their gender, race or creed. Some of the benefits offered that reflect our commitment include:
Competitive salary with bonus opportunities
100% paid medical insurance for our associates and their families
401K with a company match
Partial tuition reimbursement assistance
A robust parental leave program
Paid time off to volunteer at the charity of your choice
Employee assistance program
Responsibilities: The Data Engineer is responsible for assisting with data management, modeling, development, transformation, and reporting activities.
*
Responsibilities: *
Identify business needs, determine possible solutions, and develop solutions that include systems components, and process improvements with data driven decision making.
Work with business groups to design and develop reporting and analytics solutions that will improve efficiency and effectiveness.
Designs, implements, tests, troubleshoots, documents, and supports data models, programs, scripts, and ETL (Extract, Transform, and Load) processes.
Develop, maintain, and curate large datasets from multiple platforms. Develop reporting capabilities to support business needs by creating and supporting SQL queries, data extraction packages, and interfaces. Explores ways to enhance data quality and reliability.
Perform data validation between analytical and source systems to support ongoing data management capabilities and data governance. Perform data testing to ensure the accuracy of data transformation.
Develop data analytics, reports, and dashboards using Power BI and other business intelligence tools.
Uphold and participate in all Corporate Responsibility programming including recycling, social advocacy and MMAD volunteering opportunities.
Invest in and is an example of Milo’s Responsibility commitment which includes environmental, social, and corporate governance components.
Other duties as assigned
Supervisory: This role does not have supervisory responsibilities.
Qualifications:
BA in computer science, information systems, statistics, applied math, or any other related field.
Up to 3 years of experience in information systems or related field.
Strong experience with SQL server solutions (queries, functions, stored procedures, views, etc.).
Cloud based computing and data solutions.
Proficient with Excel and Business Intelligence tools (Power BI, Power Query, Tableau, etc.).
Understanding of relational databases and data warehouses. Hands-on experience with SQL database design.
Experience with Microsoft SQL stack (SSIS, SSRS, SSAS, etc); Experience with cloud-based data technologies, Azure preferred.
Experience working in a SharePoint environment; Experience with Python, R or other programming languages.
Experience in non-traditional SQL (noSQL, etc.) solutions.
Experience with machine learning and predictive analytics.
Experience with other ETL tools such as Alteryx.
Job Type: Full-time",glassdoor
32,"Tesla
3.6
Data Engineer
Fremont, CA

 What to Expect
The Data Engineer is responsible for processing structured and unstructured data, validating data quality, and developing and supporting data products. We are looking for someone with strong hands on experience in all layers of data Integration and analytics! We especially need experience in using Python as an ETL tool. The Data Engineer plays a significant role in Agile planning, providing advice and guidance, and monitoring emerging technologies. Some of the technology we use: * Python * Informatica * SQL Server and MySQL * Vertica * Kafka

What You’ll Do
* Design, code, test, correct and document programs and scripts using agreed standards and tools to achieve a well-engineered result * Derive an overall strategy of data management, within an established information architecture that supports the development and secure operation of existing and new information and digital services * Plan effective data storage, security, sharing and publishing within the organization * Gathers and processes raw, structured, semi-structured, and unstructured data using batch and real-time data processing frameworks * Ensures data quality and implements tools and frameworks for automating the identification of data quality issues * Collaborate with internal and external data providers on data validation providing feedback and making customized changes to data feeds and data mappings * Mentor and lead data engineers providing technical guidance and oversight * Provides ongoing support, monitoring, and maintenance of deployed products

What You’ll Bring

* Strong experience with relational databases like SQL Server, MySQL and Vertica. NoSQL databases experience is a plus! * Strong background in data modeling, data access, and data storage techniques * Experience with design, development, and implementation of highly scalable, high-volume software systems and components, source of truth systems for different business areas, developing and maintaining web services in an agile environment * Working experience with Kafka Streaming layer * Experience in Spark Framework on both batch and real-time data processing is a plus * Experience in Big Data Integration & Analytics is a plus * Experience in Supply Chain and Logistics data is a plus",glassdoor
33,"Triumph Tech
5.0
Data Engineer
Remote

 Posted 7 months ago
Job Features
Location100% Remote
DescriptionTriumph Tech is an Advanced Tier AWS Partner, based in Philadelphia, Pennsylvania, Naples Florida, Seattle, Washington, and New Jersey. We specialize in Migrations, DevOps, Containers, server-less, data & analytics, and ML/AI. We are looking for a brilliant person to join our team. Receive great benefits, company profit share, and salary.

Triumph Tech is an Advanced Tier AWS Partner. We are based out of Philadelphia, PA , Naples Florida, Seattle, Washington, and South New Jersey. We specialize in Migrations, DevOps, Containers, server-less, data & analytics, and ML/AI. We are looking for a brilliant individual to join our growing team. We have great benefits, company profit share and salary.
The successful candidate will build data solutions using state of the art technologies to acquire, ingest and transform big datasets.
Job Responsibilities
Partner with our users and other data product teams to understand their needs and build impactful data/analytics solutions.
You will design and build data pipelines to support applications and data science projects following software engineering best practice.
Design and develop data applications using big data technologies (Hadoop, AWS) to ingest, process, and analyze large disparate datasets.
Build robust data pipelines on Cloud using Airflow, Spark/EMR, Kinesis, Kafka, Lambda or other technologies.
Build the infrastructure required for optimal extraction, transformation, and loading of data from various data sources using SQL and AWS ‘big data’ technologies.
Qualifications
Experience delivering Data migration projects in AWS (preferably) but other cloud solutions will work too
SQL / ETL experience and understanding
Hadoop
Some ELT tool – Informatica, Airflow, AWS Glue etc
Must have experience writing core data transformations in Python.",glassdoor
34,"Blue Cross and Blue Shield of North Carolina
4.1
Data Engineer
Remote

 Additional Locations:
Full Time Remote - Alabama, Full Time Remote - Alabama, Full Time Remote - Arizona, Full Time Remote - Arkansas, Full Time Remote - Florida, Full Time Remote - Georgia, Full Time Remote - Idaho, Full Time Remote - Indiana, Full Time Remote - Iowa, Full Time Remote - Kansas, Full Time Remote - Kentucky, Full Time Remote - Louisiana, Full Time Remote - Maryland, Full Time Remote - Michigan, Full Time Remote - Mississippi, Full Time Remote - Missouri, Full Time Remote - Ohio, Full Time Remote - Oklahoma, Full Time Remote - Pennsylvania, Full Time Remote - South Carolina, Full Time Remote - South Dakota, Full Time Remote - Tennessee, Full Time Remote - Texas, Full Time Remote - Utah, Full Time Remote - Virginia {+ 1 more}
Job Description
IT is different here. Our work as technology specialists pushes the boundaries of what’s possible in health care. You will build solutions that make a real difference in people’s lives. Driven by the importance of their work, our team members innovate to elevate. We’re encouraged to be curious, collaborate, and turn ideas into solutions that transform this space.

In this role you will work closely with senior engineers, data scientists and other stakeholders to design and maintain moderate to advanced data models. The Data Engineer is responsible for developing and supporting advanced reports that provide accurate and timely data for internal and external clients. The Data Engineer will design and grow a data infrastructure that powers our ability to make timely and data-driven decisions. You will support Membership Operations, Customer Service Operations, Digital & Consumer Experience teams.

If you are ready to make a career out of making a difference, then you are the person for this team.
What You’ll Do
Define and extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes
Document, and test moderate data systems that bring together data from disparate sources, making it available to data scientists, and other users using scripting and/or programming languages
Write and refine code to ensure performance and reliability of data extraction and processing
Participate in requirements gathering sessions with business and technical staff to distill technical requirement from business requests
Develop SQL queries to extract data for analysis and model construction
Own delivery of moderately sized data engineering projects
Design and develop scalable, efficient data pipeline processes to handle data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets to analysts and data scientists
Ensure performance and reliability of data processes
Document and test data processes including performance of through data validation and verification
Collaborate with cross functional team to resolve data quality and operational issues and ensure timely delivery of products
Develop and implement scripts for database and data process maintenance, monitoring, and performance tuning
Analyze and evaluate databases in order to identify and recommend improvements and optimization
Design eye-catching visualizations to convey information to users
What You Will Bring
Bachelor’s degree and 3 years of experience with Oracle, Data Warehouses and Data Lakes, Big Data platforms and programming in Python, R or other related language.
In lieu of degree, 5 years of the experience as stated above.
SQL and Python scripting
Experience in a cloud environment
Experience with Ab Initio or other ETL tools",glassdoor
35,"Netflix
4.3
Data Engineer (L5) - Games
Los Gatos, CA
$108K - $193K (Glassdoor est.)

 Los Gatos, California
Data Science and Engineering
Now is an amazing time to join Netflix as we seek to entertain the world. We have over 200 million paid members in over 190 countries, and we won’t stop there. Games are our next big frontier and an incredible opportunity for us to deliver new experiences to delight and entertain our quickly growing membership. You will be jumping in at the very beginning of this adventure and be in a position to help us redefine what a Netflix subscription means for our members around the world.
Data Science and Engineering (‘DSE’) at Netflix is aimed at using data, analytics, and sciences to improve various aspects of our business. We are looking for a Data Engineer to join our Games DSE team, supporting end-to-end analytics & data needs for our games portfolio. This role will be partnering closely with our Game stakeholders to develop software and data solutions that enable analysis across the entire library of games.
As part of this team, you will work on diverse data technologies such as Spark, Presto, Flink, Kafka, and others to build insightful, scalable, and robust data pipelines that feed directly into our key gaming dashboards; write ETL jobs to collect and aggregate data; and build high-quality data models that represent how games are performing on Netflix.
The ideal candidate will also have a background in games, with a solid knowledge of how standard industry metrics are computed.
Who You Are:
7+ years of software/data engineering experience working with video game analytics (i.e you are familiar with how key metrics such as DAU, MAU and retention rates are computed in an ETL).
Passionate about building intuitive data models and an expert in distributed data processing patterns.
Highly proficient in at least one of these programming languages: Java, Python, or Scala.
Comfortable with complex SQL.
Expert in engineering data pipelines using big data technologies (Hive, Presto, Spark, Flink) on large-scale data sets demonstrated through years of experience.
Conceptually familiar with AWS cloud resources (S3, EC2, RDS etc).
Excel at taking vague requirements and crystallizing them into scalable data solutions.
Excited about operating independently, demonstrating excellence, and learning new technologies and frameworks.
What will you do?
Engineer efficient, adaptable, and scalable data pipelines in Spark and Python/Scala to process structured data into aggregate datasets that feed all games portfolio dashboards.
Become an expert in games metrics at Netflix - act as a thought partner to the games analytics team, understand their challenges, and help them to put the right data in front of our stakeholders.
Maintain and rethink existing datasets and pipelines to service a wider variety of use cases.
Join a stunning team of data engineers with diverse skill sets, partnering closely with analytics engineering and data science counterparts.
Netflix Culture
Our culture is unique, and we live by our values. For more information on what it's like to work at Netflix, please take a look at our culture memo.",glassdoor
36,"VSP Global
3.5
Data Engineer
California

 The Data Engineer creates and maintains data pipelines for key data and analytics capabilities in the enterprise. This position works in collaboration with analytics and data warehousing staff, DBAs, and subject matter experts to create reliable processes that load targeted data with integrity and quality, enabling it for strategic use by the business.
Collaborate within an agile, multi-disciplinary team to develop optimal data integration and transformation solutions.
Document and analyze data requirements (functional and non-functional) to develop scalable, automated, fault-tolerant data pipeline solutions for business and technology initiatives.
Profile data to assess the accuracy and completeness of data sources and work with business partners to mitigate issues.
Build and maintain data pipelines for using appropriate tools and practices in development, test, and production environments. Design with modularity to leverage the reuse of code wherever possible.
Create data mappings, programs, routines, and SQL to acquire data from legacy, web, cloud, and purchased package environments into the analytics environment.
Use a mix of ELT, ETL, data virtualization, and other methods to optimize the balance of minimal data movement against performance.
Maintain metadata management processes and documentation.
Monitor data quality to detect emerging issues and consult with the team to create transformation rules to cleanse against defined rules and standards.
Participate in code reviews and unit testing to optimize performance and minimize issues.
Job Specifications
Typically has the following skills or abilities:
Bachelor’s degree in computer science, data science, statistics, economics, or related functional area; or equivalent experience
Effective written and verbal communication skills with the ability to gather requirements and effectively collaborate with teammates and business partners
4+ years experience working in a development team providing analytical capabilities
4+ years of hands-on experience in the data space spanning data preparation, SQL, integration tools, ETL/ELT/data pipeline design
SQL coding experience
Familiarity with agile development environments (Scrum, Kanban) with a focus on Continuous Integration and Delivery
Previous experience using a data integration platform (IBM InfoSphere DataStage, Oracle Data Integrator, Informatica PowerCenter, MS SSIS, AWS Glue, Denodo), and familiarity with data warehouse MPP platforms such Snowflake, Netezza, Teradata, Redshift, etc.
Familiarity with event store and stream processing (Apache Kafka and platforms like Confluent) and with API development and management platforms (MuleSoft, Axway) is also beneficial
Capable of focusing on a specific set of tasks while also ensuring alignment to a broader strategic design
Exhibits the traits of a pro-active, self-driven contributor, who values continual learning and the adoption of new technology
#LI-REMOTE
#LI-VISIONCARE
Compensation range for the role is listed below. Applicable salary ranges may differ across markets. Actual pay will be determined based on experience and other job-related factors permitted by law. As a part of the compensation package, this role may include eligible bonuses, equity and commissions. For more information regarding VSP Vision benefits, please
click here
.
Salary Range:
0
0
VSP Vision is an equal opportunity employer and gives consideration for employment to qualified applicants without regard to age, gender, race, color, religion, sex, national origin, gender identity, sexual orientation, disability or protected veteran status. We maintain a drug-free workplace and perform pre-employment substance abuse testing.",glassdoor
37,"Mastercard
4.3
Data Engineer - Launch 2023
Arlington, VA

 Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a
culture of inclusion
for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Job Title
Data Engineer - Launch 2023
The Mastercard Launch program is aimed at early career talent, to help you develop skills and gain cross-functional work experience. Over a period of 18 months, Launch participants will be assigned to a business unit, learn and develop skills, and gain valuable on the job experience.

Be part of the Data & Services Technology Team at Mastercard, Data and Services

Data Engineers are fundamental to the success of our client engagements by acting as the bridge between raw client data and Mastercard's software. Data Engineers work closely with both Consultants while working on consulting engagements and Software Development Engineers while working to develop internal capabilities. Data Engineers are responsible for:
Designing processes to extract, transform, and load (ETL) terabytes of data into Mastercard's analytics platform
Sourcing data from clients, government and other third party data sources, and Mastercard's transaction data warehouse
Working across multiple teams, both internal and external, in order to determine the data requirements and business logic applicable to each data set
Tackling big data problems across various industries

Make an Impact as a Data Engineer
Here are just a few of the benefits that you will get to experience during your first year as a Data Engineer:
Strategic problem solving with exceptional peers who are also passionate about data
Creative freedom to innovate with new technologies and to explore a variety of solutions
Staffing on external-facing consulting projects where you will have the opportunity to work directly with clients
Flexibility to work on many new and challenging projects across diverse industries
A dynamic environment where you will have an impact and make an immediate difference
An immediate opportunity for increased responsibility, leadership, and professional growth
Committed mentoring and training by an experienced and driven leadership team
Cross-functional collaboration with others throughout Mastercard
Bring your passion and expertise

We recruit for and value the following core competencies:
Currently enrolled student pursuing a Bachelor's or Master's degree studying Computer Science, Data Engineering, or a related field
Desire to work with data and help businesses make better data-driven decisions
Understanding of relational databases, SQL, and database management
Excellent written and verbal communication skills
Strong troubleshooting and problem-solving capabilities
Demonstrated analytical and quantitative skills
The role also involves these skills. We don't require them, but it's helpful if you already have them:
Hands-on experience with the ETL process and SSIS
Knowledge of at least one programming language
COVID-19 Considerations
In many locations, we’ve implemented a virtual hiring process and continue to interview candidates by video or phone. In addition, in our NYC offices, as required by law, only individuals who have been fully vaccinated against COVID-19 will be permitted inside Mastercard offices unless a reasonable accommodation has been approved in advance.
In the US, Mastercard is an inclusive Equal Employment Opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. If you require accommodations or assistance to complete the online application process, please contact reasonable_accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.
Corporate Security Responsibility
All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.",glassdoor
38,"Auction Edge Inc
4.2
Data Engineer
Remote

 Auction Edge is the automotive remarketing industry’s leading provider of technology and services to independent auctions, dealers, and corporate remarketers. With 230 independent auction customers and millions of cars processed a year, Auction Edge is uniquely positioned to serve the competitive needs of the independent auction community. We currently have offices located in Franklin, TN, Pensacola, FL, and Statesville, NC. For more, visit www.auctionedge.com.
We are currently seeking a Data Engineer to join our team in Franklin, TN to work in several aspects of our Cloud Data ecosystem. This position will design, build, document and maintain data pipelines stretching from multiple on-premise databases to multi-tenant, cloud-based data stores, including operational data stores and data warehouses. In addition we are seeking someone that could design, build, document and maintain “predictive models” for a variety of applications. The ideal candidate will have experience as a programmer, sql, schema design and techniques to create predictive models. Company values broad technical experience along with excellent communication skills, written and oral.
Responsibilities
Develop reliable and performant programs that migrate data collected in near-realtime from on-premise systems to a centralized cloud based data store.
Develop reliable and performant programs that predict future behaviors, such as buyer behavior, based on past behavior. Accuracy of models versus cost to run are key.
Monitor and maintain multiple data pipelines reaching from on-premise sites to the cloud.
Maintain and enhance documentation on both on-premise and cloud-hosted data stores.
Maintain and develop standards for how data is coded and described both in source systems as well as how it's transformed as it's stored in the target system.
Ensure the security of critical data.
Understand data schemas for multiple on-premise, line-of-business applications as well as multi-tenant, cloud-hosted data stores
Required Qualifications
3+ years of database development experience
Excellent knowledge of SQL, plpgsql
Advanced ability to perform exploratory data analysis
Exceptional technical writing skills
2+ years of experience with PostgreSQL
Ability to communicate complex data in a simple and actionable way.
Analytical and problem solving skills.
Excellent skills in high performance query optimization.
Ability to work independently and with team members from different backgrounds
Excellent attention to detail
Preferred qualifications
2+ years of experience programming in JavaScript, Java, Python, Ruby, C# or other equivalent languages
1+ years of experience with ETL tools such as Talend, Informatica, Clover, Pentaho, etc.
1+ years experience as a database administrator / system administrator a plus
Experience with systems with high levels of concurrent transactions preferred
Experience with source control systems such as Subversion or Git
Experience with ElasticSearch / OpenSearch is a big plus
Knowledge of test driven database development preferred
Experience with continuous integration / deployment
Knowledge of Database statistics when / where / why
Knowledge of Database architecture
Experience with AWS cloud environment
RDS, Aurora, Lambda, DynamoDB etc.
1+ years of experience working with, developing, administering a data warehouse
Relocation assistance is not offered.
Auction Edge offers competitive pay, excellent benefits, a culture of continuous improvement and opportunity for career advancement through continued company growth.
Auction Edge is an Equal Opportunity Employer (EOE) and supports diversity in the workplace.",glassdoor
39,"Pinterest
4.1
Data Engineer
Remote

 About Pinterest:
Millions of people across the world come to Pinterest to find new ideas every day. It's where they get inspiration, dream about new possibilities and plan for what matters most. Our mission is to help those people find their inspiration and create a life they love. In your role, you'll be challenged to take on work that upholds this mission and pushes Pinterest forward. You'll grow as a person and leader in your field, all the while helping Pinners make their lives better in the positive corner of the internet.
Our new progressive work model is called PinFlex, a term that's uniquely Pinterest to describe our flexible approach to living and working. Visit our PinFlex landing page to learn more.
The Enterprise Data Platform team is looking for a Data Engineer who has experience with Building Data Pipelines and Managing/Developing on any Cloud Data Warehouse. In this role you will also advise other Data Analysts and Data Engineers from the Business teams at Pinterest on the best practices for handling data and deriving insights using Snowflake. You will gradually become the Subject Matter Expert on Snowflake and also help build out the Modern Data Stack at Pinterest.
What you'll do:
Build Data Pipelines using Python on either Airflow or AWS Lambda to ingest data into Snowflake
Build Scripts in Python to manage Data Access on Snowflake
Define and advocate the best practices for storing and analyzing data inside Snowflake
Review the Data Modeling practices of other teams
What we're looking for:
Strong skills in Python and SQL
Experience with Building Data Pipelines in Python
Experience with any Cloud Data Warehouse either as an Administrator or a Developer
Strong Data Modeling skills
#LI-BB1
#LI-Remote
Our Commitment to Diversity:
At Pinterest, our mission is to bring everyone the inspiration to create a life they love—and that includes our employees. We’re taking on the most exciting challenges of our working lives, and we succeed with a team that represents an inclusive and diverse set of identities and backgrounds.

Not Specified
0",glassdoor
40,"Qualtrics
4.2
Data Engineer
Provo, UT
$83K - $125K (Glassdoor est.)

 The Qualtrics XM Platform™ is a system of action that helps businesses to attract customers who stay longer and buy more, to engage and empower employees to do the best work of their lives, to develop breakthrough products people love, and to build a brand people can’t imagine living without.

Joining Qualtrics means becoming part of a team bold enough to chase breakthrough experiences - like building a technology that will be a force for good. A team committed to diversity, equity, and inclusion because of a conviction that every voice holds value, with a vision for representation that matches the world around us and inclusion that far exceeds it. You could belong to a team whose values center on transparency, being all in, having customer obsession, acting as one team, and operating with scrappiness. All so you can do the best work of your career.

We believe every interaction is an opportunity. Are we yours?
The Team
Our team is a collection of deeply passionate engineers who are riding the groundbreaking of cloud computing and web scalability. We built data analytics applications that help company leaders gain insights about technology spends, make sound decision on technology investments, and drive innovation in resource utilization and efficiency optimizations. Our environment is primarily TypeScript, Node.js, React, MySQL NoSQL, AWS, Python, PHP, and Docker. In our collaborative culture, you find plenty of opportunities to impact our full-stack products; from Web & mobile UI to data visualization & analysis to data ingestion, storage and processing.
Job Responsibilities
Developing scalable, fast, robust, and simple web-based solutions to solve complex business problems
Close collaboration with your team to collect and incorporate feedback into your feature design
Drive operational excellence by investigating production issues, driving root cause analysis and follow-up actions for mitigation
Improve performance, availability, reliability, scale, throughput and latency
Work with your team in order to meet customer work you're doing, understand the decisions that are being made and make your voice heard.
Qualifications
Bachelor's degree in Computer Science or related field
Coding experience with any programming language (Prefer experience in TypeScript/JavaScript/React/Python)
Experience with web infrastructure and distributed systems
Experience with software engineering best practices (e.g. unit testing, code reviews, design, continuous delivery, git, test automation and build\deploy systems)
Ability to work in a fast-paced and agile development environment and to learn new frameworks/stacks
Passionate about building products that help customers easily and effectively get their job done
Enthusiastic person, who communicates effectively and is easy to work with
Curious and constantly learning on your own and from others
You get satisfaction from helping others succeed, and you constantly seek ways to improve
You can identify gaps, propose solutions to important problems, then take it to resolution
Preferred Qualifications
Shown ability to troubleshoot and identify the root cause of issues
Demonstrated skill and passion for operational excellence
Experience in a 24/7 production environment is a plus
Ability to retain composure under stressful conditions, communicate effectively with wide array of individuals at Qualtrics, and get the right things done
Confirmed ability to understand large systems, drilling down to code level",glassdoor
41,"Eargo
4.2
Data Engineer
Remote

 We’re Eargo and we’re on a mission to disrupt, innovate, and reimage the hearing industry. If you believe fun at work is non-negotiable and want to experience the joy of being a part of helping someone hear life to the fullest again— expect tears of joy— then this is the place for you! Our passionate, fast-paced, energetic team is driven by the belief that people shouldn’t feel like they need a hearing aid—they should want one. So, if working with some of the coolest, most talented folks around and making an impact every single day sounds like a dream gig, then we want to hear from you!

We are looking for a Data Engineer to join our growing team of analytics experts. You will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts, and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.
Essential Job Duties and Responsibilities
Maintain daily activity of servers and support day-to-day needs of the company from a data engineering standpoint
Work closely with the Staff Data Engineer to unpack ETL of existing processes and help create a mapping of current ingestion system
Close all the outstanding issues with the ETL and removing/enabling that we get rid of the existing, limiting tools
Support exploring new technologies for ingestion and ETL framework
Create and maintain optimal data pipeline architecture.
Assemble complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.
Work with stakeholders including the Product, Data, and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Requirements
3+ years of experience in a Data Engineer role
BS degree in Computer Science, Statistics, Informatics, Information Systems, or another quantitative field
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures, and data sets.
Experience with programming languages such as Python, Java, and R (Optional).
Experience with AWS cloud services: EC2, EMR, RDS, and Redshift.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
A successful history of manipulating, processing, and extracting value from large, disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
Experience in using the following software/tools: Experience with relational SQL and NoSQL databases, including Postgres, MySQL, and DynamoDB.
Experience with data pipeline and workflow management tools.
Experience with object-oriented/object-function scripting languages.
Eargo is an equal opportunity employer that is committed to hiring a diverse workforce. We welcome all applicants and employees without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status. We value unique contributions and openly welcome individuals of all perspectives, experience and backgrounds to apply!",glassdoor
42,"ArchsystemInc
3.9
Data Engineer
Remote
Employer Provided Salary:$100K

 Experience using Azure Databricks platform;
Experience with Python programming;
Experience using pandas and numpy for data engineering and data cleansing;
Ability to troubleshoot the job scheduler and compute clusters;
Experience with databricks CLI and secrets module;
Experience with Azure Blob storage access configuration.
Job Type: Full-time
Salary: From $100,000.00 per year
Schedule:
8 hour shift
Application Question(s):
Do you have pandas and numpy experience?
Are you US citizen or GC?
Do you have Azure DataBricks experience?
Work Location: Remote",glassdoor
43,"Pixoul
5.0
Data Engineer
Remote

 We are looking for a Data Engineer who is experienced working with Dell NetWorker.
Responsibilities
Develop an integrated data strategy for maximizing value derived from internal data assets
Align data products and pipelines with the enterprise data strategy and architecture
Implement process improvements opportunity by automating manual processes and optimizing data delivery
Documenting Data lineage, usage and flow of data across from the point of data capture through the lifecycle to data usage
Will manage the day-to-day operations


Requirements
Requirements:

Experience using NetWorker
Ability to clearly and accurately define problems by collecting data, facts and the ability to develop and implement solutions to those problems
Experience working in an agile environment
Understanding of data regulation and best practices in data management
Experience with AWS or Microsoft Azure",glassdoor
44,"GenSpark
4.1
Data Engineer
Remote

 Position: Data Engineer
Location: Remote/ Atlanta
** Only US Citizens and GreenCard Holders eligible**
Requirements:
1. 3+ years of working experience on Python on Data side, NymPy, Pandas
2. Should have working experience on SQL
3. Data Engineer mindset
Job Type: Full-time
Salary: $75.00 - $90.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Paid time off
Vision insurance
Schedule:
8 hour shift
Monday to Friday
No weekends
Education:
Bachelor's (Preferred)
Experience:
python: 3 years (Preferred)
Work Location: Remote",glassdoor
45,"JPMorgan Chase Bank, N.A.
3.8
SQL Data Engineer
Chicago, IL
$79K - $106K (Glassdoor est.)

 As a member of our Software Engineering Group, we look first and foremost for people who are passionate around solving business problems through innovation and engineering practices. You'll be required to apply your depth of knowledge and expertise to all aspects of the software development lifecycle, as well as partner continuously with your many stakeholders on a daily basis to stay focused on common goals. We embrace a culture of experimentation and constantly strive for improvement and learning. You'll work in a collaborative, trusting, thought-provoking environment-one that encourages diversity of thought and creative solutions that are in the best interests of our customers globally.

This role requires a wide variety of strengths and capabilities, including:
BS/BA degree or equivalent experience
Advanced knowledge of application, data, and infrastructure architecture disciplines
Understanding of architecture and design across all systems
Working proficiency in developmental toolsets
Knowledge of industry-wide technology trends and best practices
Ability to work in large, collaborative teams to achieve organizational goals
Passionate about building an innovative culture
Proficiency in one or more modern programming languages
Understanding of software skills such as business analysis, development, maintenance, and software improvement
Experience performing data analysis ensuring technical delivery meets business requirements
Experience with Loan IQ and/or Financial knowledge or willingness to learn
1+ years' experience in Java
Minimum 2+ years' experience - SQL, Windows admin, JIRA/Bitbucket/Oracle
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.
We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs.
The health and safety of our colleagues, candidates, clients and communities has been a top priority in light of the COVID-19 pandemic. JPMorgan Chase was awarded the ""WELL Health-Safety Rating"" for all of our 6,200 locations globally based on our operational policies, maintenance protocols, stakeholder engagement and emergency plans to address a post-COVID-19 environment.
As a part of our commitment to health and safety, we have implemented various COVID-related health and safety requirements for our workforce. Employees are expected to follow the Firm's current COVID-19 or other infectious disease health and safety requirements, including local requirements. Requirements include sharing information including your vaccine card in the firm's vaccine record tool, and may include mask wearing. Requirements may change in the future with the evolving public health landscape. JPMorgan Chase will consider accommodation requests as required by applicable law.
Equal Opportunity Employer/Disability/Veterans",glassdoor
46,"National Research Group
3.7
Data Engineer
San Francisco, CA
$88K - $128K (Glassdoor est.)

 Who We Are
National Research Group (NRG) is a leader in data driven insights and strategic consultation to the global entertainment and technology industries. Working at the confluence of technology, content, and culture, NRG offers bold insights for storytellers everywhere. Our consultants have experience working across all facets of media and technology.
Why You'll Love It Here
We are inspired by working with storytellers that challenge us to think differently and see the world in new ways. As a result, our business is driven by creative, curious, and inventive people who have a passion for pop culture. We work as a collective across disciplines and geographies to bring together the best thinking for every assignment, delivering insights to bold storytellers everywhere.
The Opportunity
We are looking for a data engineer with a background in building and maintaining data pipelines to integrate and process diverse data sources and data formats. This candidate should have a minimum of 1-year experience for a full-time position within our fast paced and growing company.
If you feel that you can make an impact through innovation and collaboration and come to work with a passion to facilitate in delivering high quality data to our teams and clients, this is a great role for you.
The Role
Build, test, orchestrate, and maintain data pipelines that support the data sciences team and customer-facing client teams.
Assist in ad-hoc data deliveries by querying data from various SQL relational databases stored in multiple data models.
Track and manage pipeline efficiency and stability.
Evaluate, parse, clean, and integrate raw data sets including third party APIs. Help build sophisticated ETL processes around first party data such as survey data, second and third-party data sources such as IP addresses, clickstream data, movie meta data.
Provide recommendations for data storage, configurations, data access tools and new technologies/architectures.
Develop code-based data transformation/aggregation in data lakes, relational databases (primary use cases) and possibly non-relational databases, as well as for the purpose of BI tools such as Power BI and Tableau.
Participate in developing data APIs for data ingestion of NRG data into client-side applications or client-side data systems.
Assist application developers in the effective use of database query and programming languages.
Contribute to managing data integrity, data storage efficiency and data ecosystem efficiency.
Who You Are
Team asset who can describe data structures, relationships, and flows behind organization database servers and applications.
Up to date on the latest data-related best practices and technologies and always looking to learn more.
Internally motivated self-starter who continuously strives to get things done, regardless of challenges encountered.
Critical thinker, able to understand and respond to complex questions or issues that may arise, and able to demonstrate willingness to experiment with new technologies.
Successfully manages time and multiple competing priorities in order to ensure deadlines are always met.
Team player who is able to work collaboratively and initiate and drive projects to completion with minimal oversight.
Ideal Candidate
BS/BA in Computer Science or related field.
1+ year experience in building data pipelines or ETL.
1+ year experience with SQL (we use Snowflake but other experience with relational databases is welcome).
1+ year experience with AWS technologies/infrastructure.
Working knowledge with Python.
A solid foundation with end-to-end development and the desire to further their technical knowledge.
Knowledge of PII (personally identifiable information) data security standards is a plus.
dbt experience is a plus.
Terraform experience is a plus.
Dagster experience is a plus.
Experience in databases structured against survey data is a big plus.
Position Type
This is a full-time, exempt position.
Work Environment
This position is expected to be fully remote. However, NRG offers flexible work options if an employee happens to live near a dedicated office (Playa Vista or New York) and wants a hybrid work model. This role routinely uses standard office equipment.
Required Application Materials:
CV/Resume
Cover Letter which should include:
Why do you want to work at NRG?
Why are you interested in working in the entertainment industry?",glassdoor
47,"Dataquestcorp
Data Science Engineer
Branchburg, NJ
Employer Provided Salary:$75K - $80K

 Job Role: Data Science
Note: Please don't apply C2C profiles. its only w2 positions
Benefits:
Free Training and placement.
Training provided by highly qualified, industry-experienced & certified instructors.
We do provide free accommodations & Relocation charges.
H1B Sponsorship
We do support for STEM OPT and GC processing.
Health Insurance
Relocation Assistance any where in USA.
Free accommodation.
Location: Branchburg, NJ
Job Types: Full-time, Contract
Job Types: Full-time, Contract
Salary: $75,000.00 - $80,000.00 per year
Benefits:
Health insurance
Schedule:
8 hour shift
Ability to commute/relocate:
Branchburg, NJ: Reliably commute or planning to relocate before starting work (Required)
Experience:
Python: 1 year (Preferred)
SQL: 1 year (Preferred)
Work Location: One location
Speak with the employer
+91 9089927715",glassdoor
48,"Medicom
3.2
Data Engineer
Raleigh, NC
$76K - $107K (Glassdoor est.)

 MEDICOM
Medicom Technologies is a high-growth, healthcare technology company dedicated to creating innovative solutions for patients, health systems, and life sciences companies. We have a focused passion to improve patient outcomes by eliminating health data silos and facilitating data curation.
With over 3,500 connections and 1,000 participating organizations, the Medicom Network connects disparate silos of health information so health records can be easily and securely searched and shared amongst healthcare providers.
The Medicom deepMed Marketplace serves healthcare data consumers at life science, pharmaceutical, and AI companies by facilitating curation of individual or longitudinal data sets.
Every member of our team embodies our core values to ensure every network participant from patient to physician can collaborate in our mission.
Fresh off the completion of Series B funding (see press release), Medicom is developing a culture that strives for transparency, compassion and progress.
We are growing our team by seeking individuals with a growth mindset who share a high-level of passion, drive, and commitment to serve the variety of Medicom stakeholders.
To learn more about Medicom visit our website medicom.us
Position: Data Engineer
The Data Engineer will work with the deepMed business unit to collect and de-identify medical images for research, machine learning, and AI applications. This position will be responsible for analyzing and documenting business data and processes as well as recommending technical solutions and creating reports or other solutions as needed to support the deepMed business unit needs.
Responsibilities
Writing SQL queries, procedures, and reports on both ad-hoc and production basis for analysis of clinical data.
Proactively defines, identifies, develops, and implements processes and procedures to support business strategy and operational planning.
Develop and participate in presentations to existing and prospective customers and internal business areas.
Candidate must be SQL power user, able to review results, conduct root cause analysis, identify next steps, and put them into action.
Should have the ability to move multiple projects forward simultaneously and be responsible for the results; even when others are directly accountable for the outcome.
Aide in building the relationship with our data provider teams to work with their staff on data curation.
Package and deliver high-quality longitudinal data sets to our customers.
Assist and coordinate with implementation teams on new deepMed installations.Assist in contractual and compliance-related responsibilities with your clients.
Qualifications
Knowledge of analytic programming tools and methods (SQL).
2+ years of experience working within the health care industry in any of the following areas: Hospital research, predictive modeling, case-mix, risk adjustment methods, and tools, or supporting Clinical information systems.
5+ years of experience working in a data warehouse environment.
The ability to work with large data sets from multiple data sources.
Demonstrates strong ability to prioritize work, excellent organizational skills, and initiative to improve processes.
Bachelor’s degree in a related field.
Preferred Qualifications
Clinical Certification in the medical imaging space (CIIP, CNMT, RT, etc.).
Clinical radiology workflow experience.
Experience with JavaScript, TypeScript, Python R.
AWS, Amazon Web Services, or Google Cloud.",glassdoor
49,"Notion
4.9
Data Engineer
San Francisco, CA
$104K - $152K (Glassdoor est.)

 About Us:
We're on a mission to make it possible for every person, team, and company to be able to tailor their software to solve any problem and take on any challenge. Computers may be our most powerful tools, but most of us can't build or modify the software we use on them every day. At Notion, we want to change this with focus, design, and craft.
We've been working on this together since 2016, and have customers like Pixar, Mitsubishi, Figma, Plaid, Match Group, and thousands more on this journey with us. Today, we're growing fast and excited for new teammates to join us who are the best at what they do. We're passionate about building a company as diverse and creative as the millions of people Notion reaches worldwide.
About The Role:
Since the launch of Notion, the company has been on a mission to make toolmaking ubiquitous - from wikis to documents, notes, tasks, databases, etc. A strong product intuition and focus on users have helped the company achieve adoption across businesses of all sizes. Today, millions of users rely on Notion's building blocks to get their work done.
As Notion continues to grow quickly, there is a unique opportunity to build the foundations of data and help the product and company reach their full potential. This is where you come in — to design and build reliable, trusted and timely datasets that accelerate the decision-making process of key product and business functions. You will have a strong impact on the roadmap and the growth trajectory of the company.
What You'll Achieve:
You'll define the processes and ETL infrastructure to transform and make data readily available across the company
You'll build core datasets to serve as unique sources of truth for product and business functions (product, marketing, sales, finance, customer experience, data science, business operations, IT, engineering)
You'll partner with data scientists and other internal stakeholders to understand their needs and then design, build and monitor pipelines that meet today's requirements but can gracefully scale with our growing data size
You'll implement automated workflows that lower manual/operational cost for stakeholders, define and uphold SLAs for timely delivery of data, move the company closer to democratizing data and a self-serve model (query exploration, dashboards, data catalog, data discovery)
Skills You'll Need to Bring:
You are a self-starter and continuously gather and synthesize high-impact needs from business partners, design and implementing the appropriate technical solutions, and effectively communicating about deliverables, timelines and tradeoffs
You've spent 3+ years as a data engineer building core datasets and supporting business verticals as needed. You are passionate about analytics use cases, data models and solving complex data problems
You have hands-on experience shipping scalable data solutions in the cloud (e.g AWS, GCP, Azure), across multiple data stores (e.g Snowflake, Redshift, Hive, SQL/NoSQL, columnar storage formats) and methodologies (e.g dimensional modeling, data marts, star/snowflake schemas)
You are an SQL expert. You intimately understand aggregation functions, window functions, UDFs, self-joins, partitioning and clustering approaches to run correct and highly-performant queries
You are highly comfortable with object-oriented programming paradigms (e.g Python, Java, Scala)
Nice to Haves:
You have worked at a fast-growing start-up, a SaaS company or are eager to contribute in such an environment (being a current Notion user would be great!)
You have hands-on experience in designing and building highly scalable and reliable data pipelines using BigData stack (e.g Airflow, DBT, Spark, Hive, Parquet/ORC, Protobuf/Thrift, etc)
We hire talented and passionate people from a variety of backgrounds because we want our global employee base to represent the wide diversity of our customers. If you're excited about a role but your past experience doesn't align perfectly with every bullet point listed in the job description, we still encourage you to apply. If you're a builder at heart, share our company values, and enthusiastic about making software toolmaking ubiquitous, we want to hear from you.
Notion is proud to be an equal opportunity employer. We do not discriminate in hiring or any employment decision based on race, color, religion, national origin, age, sex (including pregnancy, childbirth, or related medical conditions), marital status, ancestry, physical or mental disability, genetic information, veteran status, gender identity or expression, sexual orientation, or other applicable legally protected characteristic. Notion considers qualified applicants with criminal histories, consistent with applicable federal, state and local law. Notion is also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation made due to a disability, please let your recruiter know.
#LI-Onsite",glassdoor
50,"Pepsico
3.9
Junior Data Engineer
Remote
Employer Provided Salary:$90K - $100K

 Compensation: $80k - $90k
Benefits: Medical, Dental, Vision, 401k match and Arc
This role can be performed remote in any of our headquarter locations including Plano, Texas; Purchase, New York; Chicago, Illinois.
What PepsiCo Data Management and Operations does:
Maintain a predictable, transparent, global operating rhythm that ensures always-on access to high-quality data for stakeholders across the company
Responsible for day-to-day data collection, transportation, maintenance/curation and access to the PepsiCo corporate data asset
Work cross-functionally across the enterprise to centralize data and standardize it for use by business, data science or other stakeholders
Increase awareness about available data and democratize access to it across the company.
As a member of the data engineering team, you will be the key technical expert developing and overseeing PepsiCo's data product build & operations and drive a strong vision for how data engineering can proactively create a positive impact on the business. You'll be an empowered member of a team of data engineers who build data pipelines into various source systems, rest data on the PepsiCo Data Lake, and enable exploration and access for analytics, visualization, machine learning, and product development efforts across the company. As a member of the data engineering team, you will help lead the development of very large and complex data applications into public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. You will work closely with process owners, product owners and business users. You'll be working in a hybrid environment with in-house, on-premise data sources as well as cloud and remote systems.
Key Accountabilities:
Active contributor to code development in projects and services
Manage and scale data pipelines from internal and external data sources to support new product launches and drive data quality across data products
Build and own the automation and monitoring frameworks that capture metrics and operational KPIs for data pipeline quality and performance
Responsible for implementing best practices around systems integration, security, performance and data management
Empower the business by creating value through the increased adoption of data, data science and business intelligence landscape
Collaborate with internal clients (data science and product teams) to drive solutioning and POC discussions.
Develop and optimize procedures to “productionalize” data science models
Define and manage SLA’s for data products and processes running in production
Support large-scale experimentation done by data scientists
Prototype new approaches and build solutions at scale
Research in state-of-the-art methodologies
Create documentation for learnings and knowledge transfer
Create and audit reusable packages or libraries
COVID-19 vaccination is a condition of employment for this role. Please note that all such company vaccine requirements provide the opportunity to request an approved accommodation or exemption under applicable law
Qualifications / Requirements :
BA/BS in Computer Science, Math, Physics is mandatory.
2+ years of overall technology experience that includes hands-on building data engineering pipelines
2+ years of experience in SQL optimization and performance tuning, and development experience in programming languages like Python, PySpark, Scala etc.)
1+ years in cloud data engineering experience in Azure or AWS
1+ Years in building data engineering pipelines in Azure (ADF and databricks)
Job Type: Full-time
Pay: $90,000.00 - $100,000.00 per year
Benefits:
401(k) matching
Dental insurance
Health insurance
Retirement plan
Vision insurance
Schedule:
8 hour shift
Education:
Bachelor's (Required)
Experience:
SQL: 2 years (Required)
Cloud: 2 years (Required)
Work Location: Remote",glassdoor
51,"Ivy Tech Solutions inc
3.6
Data Engineer
Remote

 Remote Position

Data Engineer

Only w2

Please send the resume to sowmya.g@ivytechsol.us

Job Description:

DataStage Data Engineer US/GC/Certain EADs – 6 month remote contract.

Together we are building a culture that values diversity and creates a space of belonging for all our team members. We believe that investing in your success is an investment in our customers and our business. Our people are what sets us apart and make us great. As a Data Engineer, you’ll provide your talents in contributing to the success of the client’s team by delivering the following:

Serve in the goalie rotation to support the Production environment.

Responsible for maintaining enterprise-grade platforms that enable data-driven solutions.

Search for ways to automate and maintain scalable infrastructure.

Ensure delivery of highly available and scalable systems.

Monitor all systems and applications and ensure optimal performance.

Analyzes and designs technical solutions to address production problems.

Participate in troubleshooting applications and systems issues.

Identifies, investigates, and proposes solutions to technical problems.

While providing technical support for issues, develop, test, and modify software to improve efficiency of data platforms and applications.

Monitors system performance to maintain consistent up time.

Prepares and maintains necessary documentation.

Participate in daily standups, team backlog grooming, and iteration retrospectives.

Coordinate with data operations teams to deploy changes into production.

Highest level may function as a lead.

Other duties as assigned.

Qualifications:

Requires a Bachelor's in Computer Science, Computer Engineering or related field and experience with ETL development, SQL, UNIX/Linux scripting, Big Data distributed systems. Prefer experience with IBM DataStage.

Various programming languages like Java and Python, orchestration tools and processes or other directly related experience.

A combination of education and experience may meet qualifications.

Excellent analytical, organizational, and problem-solving skills.

Ability and desire to learn new technologies quickly.

Ability to work independently and collaborate with others at all levels of technical understanding.

Able to meet deadlines.

Good judgment and project management skills.

Ability to communicate both verbally and in writing with both technical and non-technical staff.

Ability to work in a team environment and have good interpersonal skills.

Ability to adapt to changing technology and priorities.

Must be able to work independently, handle multiple concurrent tasks, with an ability to prioritize and manage tasks effectively
gDX0uvPo7F",glassdoor
52,"VSP Global
3.5
Data Engineer
California

 The Data Engineer creates and maintains data pipelines for key data and analytics capabilities in the enterprise. This position works in collaboration with analytics and data warehousing staff, DBAs, and subject matter experts to create reliable processes that load targeted data with integrity and quality, enabling it for strategic use by the business.
Collaborate within an agile, multi-disciplinary team to develop optimal data integration and transformation solutions.
Document and analyze data requirements (functional and non-functional) to develop scalable, automated, fault-tolerant data pipeline solutions for business and technology initiatives.
Profile data to assess the accuracy and completeness of data sources and work with business partners to mitigate issues.
Build and maintain data pipelines for using appropriate tools and practices in development, test, and production environments. Design with modularity to leverage the reuse of code wherever possible.
Create data mappings, programs, routines, and SQL to acquire data from legacy, web, cloud, and purchased package environments into the analytics environment.
Use a mix of ELT, ETL, data virtualization, and other methods to optimize the balance of minimal data movement against performance.
Maintain metadata management processes and documentation.
Monitor data quality to detect emerging issues and consult with the team to create transformation rules to cleanse against defined rules and standards.
Participate in code reviews and unit testing to optimize performance and minimize issues.
Job Specifications
Typically has the following skills or abilities:
Bachelor’s degree in computer science, data science, statistics, economics, or related functional area; or equivalent experience
Effective written and verbal communication skills with the ability to gather requirements and effectively collaborate with teammates and business partners
4+ years experience working in a development team providing analytical capabilities
4+ years of hands-on experience in the data space spanning data preparation, SQL, integration tools, ETL/ELT/data pipeline design
SQL coding experience
Familiarity with agile development environments (Scrum, Kanban) with a focus on Continuous Integration and Delivery
Previous experience using a data integration platform (IBM InfoSphere DataStage, Oracle Data Integrator, Informatica PowerCenter, MS SSIS, AWS Glue, Denodo), and familiarity with data warehouse MPP platforms such Snowflake, Netezza, Teradata, Redshift, etc.
Familiarity with event store and stream processing (Apache Kafka and platforms like Confluent) and with API development and management platforms (MuleSoft, Axway) is also beneficial
Capable of focusing on a specific set of tasks while also ensuring alignment to a broader strategic design
Exhibits the traits of a pro-active, self-driven contributor, who values continual learning and the adoption of new technology
#LI-REMOTE
#LI-VISIONCARE
Compensation range for the role is listed below. Applicable salary ranges may differ across markets. Actual pay will be determined based on experience and other job-related factors permitted by law. As a part of the compensation package, this role may include eligible bonuses, equity and commissions. For more information regarding VSP Vision benefits, please
click here
.
Salary Range:
0
0
VSP Vision is an equal opportunity employer and gives consideration for employment to qualified applicants without regard to age, gender, race, color, religion, sex, national origin, gender identity, sexual orientation, disability or protected veteran status. We maintain a drug-free workplace and perform pre-employment substance abuse testing.",glassdoor
53,"Realign LLC
4.5
Data Engineer
California

 Job Type: Contract
Job Category: IT
Job Description
Write and optimize queries, provide input on peer code reviews and data modeling, deploy data
updates via continuous integration / deployment (CI/CD) practices.

Collaborate with software developers, other data engineers, and database architects on projects to
ensure optimal data delivery following appropriate change management guidelines.

Collaborate with software and reliability engineers to automate repeatable data tasks.

Work with development and production support teams to troubleshoot data, application, and service
deployment issues.

Develop detailed, shared technical procedure documentation, including processes for contingency
operations.

Research, provide technical input, document, and implement new technology solutions.

Implement necessary patches, hotfixes, service packs, cumulative updates, upgrades, and
configuration change to maintain security compliance and application integrity.

Required Skills
Big Data Engineer",glassdoor
54,"Dataquestcorp
Data Science Engineer
Branchburg, NJ
Employer Provided Salary:$75K - $80K

 Job Role: Data Science
Note: Please don't apply C2C profiles. its only w2 positions
Benefits:
Free Training and placement.
Training provided by highly qualified, industry-experienced & certified instructors.
We do provide free accommodations & Relocation charges.
H1B Sponsorship
We do support for STEM OPT and GC processing.
Health Insurance
Relocation Assistance any where in USA.
Free accommodation.
Location: Branchburg, NJ
Job Types: Full-time, Contract
Job Types: Full-time, Contract
Salary: $75,000.00 - $80,000.00 per year
Benefits:
Schedule:
8 hour shift
Ability to commute/relocate:
Branchburg, NJ: Reliably commute or planning to relocate before starting work (Required)
Experience:
Python: 1 year (Preferred)
SQL: 1 year (Preferred)
Work Location: One location
Speak with the employer
+91 9089927715",glassdoor
55,"Pixoul
5.0
Data Engineer
Remote

 We are looking for a Data Engineer who is experienced working with Dell NetWorker.
Responsibilities
Develop an integrated data strategy for maximizing value derived from internal data assets
Align data products and pipelines with the enterprise data strategy and architecture
Implement process improvements opportunity by automating manual processes and optimizing data delivery
Documenting Data lineage, usage and flow of data across from the point of data capture through the lifecycle to data usage
Will manage the day-to-day operations


Requirements
Requirements:

Experience using NetWorker
Ability to clearly and accurately define problems by collecting data, facts and the ability to develop and implement solutions to those problems
Experience working in an agile environment
Understanding of data regulation and best practices in data management
Experience with AWS or Microsoft Azure",glassdoor
56,"Qualtrics
4.2
Data Engineer
Provo, UT
$83K - $125K (Glassdoor est.)

 The Qualtrics XM Platform™ is a system of action that helps businesses to attract customers who stay longer and buy more, to engage and empower employees to do the best work of their lives, to develop breakthrough products people love, and to build a brand people can’t imagine living without.

Joining Qualtrics means becoming part of a team bold enough to chase breakthrough experiences - like building a technology that will be a force for good. A team committed to diversity, equity, and inclusion because of a conviction that every voice holds value, with a vision for representation that matches the world around us and inclusion that far exceeds it. You could belong to a team whose values center on transparency, being all in, having customer obsession, acting as one team, and operating with scrappiness. All so you can do the best work of your career.

We believe every interaction is an opportunity. Are we yours?
The Team
Our team is a collection of deeply passionate engineers who are riding the groundbreaking of cloud computing and web scalability. We built data analytics applications that help company leaders gain insights about technology spends, make sound decision on technology investments, and drive innovation in resource utilization and efficiency optimizations. Our environment is primarily TypeScript, Node.js, React, MySQL NoSQL, AWS, Python, PHP, and Docker. In our collaborative culture, you find plenty of opportunities to impact our full-stack products; from Web & mobile UI to data visualization & analysis to data ingestion, storage and processing.
Job Responsibilities
Developing scalable, fast, robust, and simple web-based solutions to solve complex business problems
Close collaboration with your team to collect and incorporate feedback into your feature design
Drive operational excellence by investigating production issues, driving root cause analysis and follow-up actions for mitigation
Improve performance, availability, reliability, scale, throughput and latency
Work with your team in order to meet customer work you're doing, understand the decisions that are being made and make your voice heard.
Qualifications
Bachelor's degree in Computer Science or related field
Coding experience with any programming language (Prefer experience in TypeScript/JavaScript/React/Python)
Experience with web infrastructure and distributed systems
Experience with software engineering best practices (e.g. unit testing, code reviews, design, continuous delivery, git, test automation and build\deploy systems)
Ability to work in a fast-paced and agile development environment and to learn new frameworks/stacks
Passionate about building products that help customers easily and effectively get their job done
Enthusiastic person, who communicates effectively and is easy to work with
Curious and constantly learning on your own and from others
You get satisfaction from helping others succeed, and you constantly seek ways to improve
You can identify gaps, propose solutions to important problems, then take it to resolution
Preferred Qualifications
Shown ability to troubleshoot and identify the root cause of issues
Demonstrated skill and passion for operational excellence
Experience in a 24/7 production environment is a plus
Ability to retain composure under stressful conditions, communicate effectively with wide array of individuals at Qualtrics, and get the right things done
Confirmed ability to understand large systems, drilling down to code level",glassdoor
57,"Eargo
4.2
Data Engineer
Remote

 We’re Eargo and we’re on a mission to disrupt, innovate, and reimage the hearing industry. If you believe fun at work is non-negotiable and want to experience the joy of being a part of helping someone hear life to the fullest again— expect tears of joy— then this is the place for you! Our passionate, fast-paced, energetic team is driven by the belief that people shouldn’t feel like they need a hearing aid—they should want one. So, if working with some of the coolest, most talented folks around and making an impact every single day sounds like a dream gig, then we want to hear from you!

We are looking for a Data Engineer to join our growing team of analytics experts. You will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts, and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.
Essential Job Duties and Responsibilities
Maintain daily activity of servers and support day-to-day needs of the company from a data engineering standpoint
Work closely with the Staff Data Engineer to unpack ETL of existing processes and help create a mapping of current ingestion system
Close all the outstanding issues with the ETL and removing/enabling that we get rid of the existing, limiting tools
Support exploring new technologies for ingestion and ETL framework
Create and maintain optimal data pipeline architecture.
Assemble complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.
Work with stakeholders including the Product, Data, and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Requirements
3+ years of experience in a Data Engineer role
BS degree in Computer Science, Statistics, Informatics, Information Systems, or another quantitative field
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures, and data sets.
Experience with programming languages such as Python, Java, and R (Optional).
Experience with AWS cloud services: EC2, EMR, RDS, and Redshift.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
A successful history of manipulating, processing, and extracting value from large, disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
Experience in using the following software/tools: Experience with relational SQL and NoSQL databases, including Postgres, MySQL, and DynamoDB.
Experience with data pipeline and workflow management tools.
Experience with object-oriented/object-function scripting languages.
Eargo is an equal opportunity employer that is committed to hiring a diverse workforce. We welcome all applicants and employees without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status. We value unique contributions and openly welcome individuals of all perspectives, experience and backgrounds to apply!",glassdoor
58,"Blue Cross and Blue Shield of North Carolina
4.1
Data Engineer
Remote

 Additional Locations:
Full Time Remote - Alabama, Full Time Remote - Alabama, Full Time Remote - Arizona, Full Time Remote - Arkansas, Full Time Remote - Florida, Full Time Remote - Georgia, Full Time Remote - Idaho, Full Time Remote - Indiana, Full Time Remote - Iowa, Full Time Remote - Kansas, Full Time Remote - Kentucky, Full Time Remote - Louisiana, Full Time Remote - Maryland, Full Time Remote - Michigan, Full Time Remote - Mississippi, Full Time Remote - Missouri, Full Time Remote - Ohio, Full Time Remote - Oklahoma, Full Time Remote - Pennsylvania, Full Time Remote - South Carolina, Full Time Remote - South Dakota, Full Time Remote - Tennessee, Full Time Remote - Texas, Full Time Remote - Utah, Full Time Remote - Virginia {+ 1 more}
Job Description
IT is different here. Our work as technology specialists pushes the boundaries of what’s possible in health care. You will build solutions that make a real difference in people’s lives. Driven by the importance of their work, our team members innovate to elevate. We’re encouraged to be curious, collaborate, and turn ideas into solutions that transform this space.

In this role you will work closely with senior engineers, data scientists and other stakeholders to design and maintain moderate to advanced data models. The Data Engineer is responsible for developing and supporting advanced reports that provide accurate and timely data for internal and external clients. The Data Engineer will design and grow a data infrastructure that powers our ability to make timely and data-driven decisions. You will support Membership Operations, Customer Service Operations, Digital & Consumer Experience teams.

If you are ready to make a career out of making a difference, then you are the person for this team.
What You’ll Do
Define and extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes
Document, and test moderate data systems that bring together data from disparate sources, making it available to data scientists, and other users using scripting and/or programming languages
Write and refine code to ensure performance and reliability of data extraction and processing
Participate in requirements gathering sessions with business and technical staff to distill technical requirement from business requests
Develop SQL queries to extract data for analysis and model construction
Own delivery of moderately sized data engineering projects
Design and develop scalable, efficient data pipeline processes to handle data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets to analysts and data scientists
Ensure performance and reliability of data processes
Document and test data processes including performance of through data validation and verification
Collaborate with cross functional team to resolve data quality and operational issues and ensure timely delivery of products
Develop and implement scripts for database and data process maintenance, monitoring, and performance tuning
Analyze and evaluate databases in order to identify and recommend improvements and optimization
Design eye-catching visualizations to convey information to users
What You Will Bring
Bachelor’s degree and 3 years of experience with Oracle, Data Warehouses and Data Lakes, Big Data platforms and programming in Python, R or other related language.
In lieu of degree, 5 years of the experience as stated above.
SQL and Python scripting
Experience in a cloud environment
Experience with Ab Initio or other ETL tools",glassdoor
59,"Notion
4.9
Data Engineer
San Francisco, CA
$104K - $152K (Glassdoor est.)

 About Us:
We're on a mission to make it possible for every person, team, and company to be able to tailor their software to solve any problem and take on any challenge. Computers may be our most powerful tools, but most of us can't build or modify the software we use on them every day. At Notion, we want to change this with focus, design, and craft.
We've been working on this together since 2016, and have customers like Pixar, Mitsubishi, Figma, Plaid, Match Group, and thousands more on this journey with us. Today, we're growing fast and excited for new teammates to join us who are the best at what they do. We're passionate about building a company as diverse and creative as the millions of people Notion reaches worldwide.
About The Role:
Since the launch of Notion, the company has been on a mission to make toolmaking ubiquitous - from wikis to documents, notes, tasks, databases, etc. A strong product intuition and focus on users have helped the company achieve adoption across businesses of all sizes. Today, millions of users rely on Notion's building blocks to get their work done.
As Notion continues to grow quickly, there is a unique opportunity to build the foundations of data and help the product and company reach their full potential. This is where you come in — to design and build reliable, trusted and timely datasets that accelerate the decision-making process of key product and business functions. You will have a strong impact on the roadmap and the growth trajectory of the company.
What You'll Achieve:
You'll define the processes and ETL infrastructure to transform and make data readily available across the company
You'll build core datasets to serve as unique sources of truth for product and business functions (product, marketing, sales, finance, customer experience, data science, business operations, IT, engineering)
You'll partner with data scientists and other internal stakeholders to understand their needs and then design, build and monitor pipelines that meet today's requirements but can gracefully scale with our growing data size
You'll implement automated workflows that lower manual/operational cost for stakeholders, define and uphold SLAs for timely delivery of data, move the company closer to democratizing data and a self-serve model (query exploration, dashboards, data catalog, data discovery)
Skills You'll Need to Bring:
You are a self-starter and continuously gather and synthesize high-impact needs from business partners, design and implementing the appropriate technical solutions, and effectively communicating about deliverables, timelines and tradeoffs
You've spent 3+ years as a data engineer building core datasets and supporting business verticals as needed. You are passionate about analytics use cases, data models and solving complex data problems
You have hands-on experience shipping scalable data solutions in the cloud (e.g AWS, GCP, Azure), across multiple data stores (e.g Snowflake, Redshift, Hive, SQL/NoSQL, columnar storage formats) and methodologies (e.g dimensional modeling, data marts, star/snowflake schemas)
You are an SQL expert. You intimately understand aggregation functions, window functions, UDFs, self-joins, partitioning and clustering approaches to run correct and highly-performant queries
You are highly comfortable with object-oriented programming paradigms (e.g Python, Java, Scala)
Nice to Haves:
You have worked at a fast-growing start-up, a SaaS company or are eager to contribute in such an environment (being a current Notion user would be great!)
You have hands-on experience in designing and building highly scalable and reliable data pipelines using BigData stack (e.g Airflow, DBT, Spark, Hive, Parquet/ORC, Protobuf/Thrift, etc)
We hire talented and passionate people from a variety of backgrounds because we want our global employee base to represent the wide diversity of our customers. If you're excited about a role but your past experience doesn't align perfectly with every bullet point listed in the job description, we still encourage you to apply. If you're a builder at heart, share our company values, and enthusiastic about making software toolmaking ubiquitous, we want to hear from you.
Notion is proud to be an equal opportunity employer. We do not discriminate in hiring or any employment decision based on race, color, religion, national origin, age, sex (including pregnancy, childbirth, or related medical conditions), marital status, ancestry, physical or mental disability, genetic information, veteran status, gender identity or expression, sexual orientation, or other applicable legally protected characteristic. Notion considers qualified applicants with criminal histories, consistent with applicable federal, state and local law. Notion is also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation made due to a disability, please let your recruiter know.
#LI-Onsite",glassdoor
60,"Accenture
4.1
Data Engineer
San Francisco, CA

 Accenture Flex offers you the flexibility of local fixed-duration project-based work powered by Accenture, a leading global professional services company. Accenture is consistently recognized on FORTUNE's 100 Best Companies to Work For and Diversity Inc's Top 50 Companies For Diversity lists.
As an Accenture Flex employee, you will apply your skills and experience to help drive business transformation for leading organizations and communities. In addition to delivering innovative solutions for Accenture's clients, you will work with a highly skilled, diverse network of people across Accenture businesses who are using the latest emerging technologies to address today's biggest business challenges.
You will receive competitive rewards and access to benefits programs and world-class learning resources. Accenture Flex employees work in their local metro area onsite at the project, significantly reducing and/or eliminating the demands to travel.
Job Description:
As a Data Engineer, you will:
Utilize strong SQL & Python expertise to engineer sound data pipelines and conduct routine and ad hoc analysis to assess the performance of legacy products and the saliency of new features
Build reporting dashboards and visualizations to design, create, and track campaign/program KPIs
Perform analyses on large data sets to understand drivers of marketing engagement and provide recommendations on campaign and product optimization

Basic Qualifications:
Minimum 2 years of experience in Data Engineering
Minimum 2 years of experience with SQL
Minimum 2 years of experience with Python
High School Diploma or GED
Preferred Qualifications:
Experience with Data Analytics
As required by Colorado Law under the Equal Pay for Equal Work Act, Accenture provides a reasonable range of compensation for roles that may be hired in Colorado. Actual compensation is influenced by a wide array of factors including but not limited to skill set, level of experience, and specific office location. For the state of Colorado only, the starting range of pay for this role is $86.82 - $96.82 per hour, and information on benefits is here.

COVID-19 update:

The safety and well-being of our candidates, our people and their families continues to be a top priority. Until travel restrictions change, interviews will continue to be conducted virtually.

Subject to applicable law, please be aware that Accenture requires all employees to be fully vaccinated as a condition of employment. Accenture will consider requests for accommodation to this vaccination requirement during the recruiting process.

What We Believe

We have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture has the responsibility to create and sustain an inclusive environment.

Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more here

Equal Employment Opportunity Statement

Accenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation.

All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.

Accenture is committed to providing veteran employment opportunities to our service men and women.

For details, view a copy of the Accenture Equal Opportunity and Affirmative Action Policy Statement.

Requesting An Accommodation

Accenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.

If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.

Other Employment Statements

Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States.

Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.

Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.

The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.",glassdoor
61,"Apple
4.2
ML Data Collection and Data Science Engineer (TDG)
Cupertino, CA

 Summary
Posted: May 16, 2022
Role Number:200380146
Do you want to push the limits of the best Augmented Reality platform in the world? Apple's Technology Development Group (TDG) delivers algorithms that drive revolutionary Apple products, including the augmented reality (AR) platform ARKit to create ground-breaking new products. In this position, you will have the opportunity to be part of our extraordinary data team to discover and build solutions to previously-unsolved challenges and push the state of the art in AR algorithms that will change the way people experience the world! We are looking for a driven Machine Learning Data Collection Engineer that enjoys getting into the details to collect valuable data that feeds our machine learning models. As a member of the fast-paced data team, you have the rewarding opportunity to shape upcoming products that will delight and inspire millions of people every day. To succeed within this role, you should have shown experience in several of the following areas:
Key Qualifications
Ability to define/design/develop data collection efforts that focus on the end-to-end user experience, including anticipating potential failure modes, edge cases, and anomalies
Proficiency in programming languages including Python, C++, or similar
Capacity to multitask and manage several projects in parallel while meeting deadlines and providing access to clients and partners
Problem solving & critical thinking capacities, thinking outside the box in order to gain in speed, efficiency, and quality.
Excellent project management, communication, interpersonal, analytical, and organizational skills
Experience with industrial software development, a plus
Experience with CVML, a plus
Description
As a Machine Learning Data Collection Engineer, you'll be collaborating with multi-functional teams to work on CVML data collection projects, from collecting data collection requirements, designing protocols, testing software and hardwares, executing data collection, to analyzing and curating collected data. Your job responsibilities will include -Contribute to the design of CVML data collection, including hardware, software, user interface specifications, and collection protocols. -Define, implement, maintain SW and HW solutions to test data collection hardware, software and protocols. -Design, implement and maintain SW platforms to monitor date life cycle -Work with CVML engineers to design and implement data evaluation and curation process -Analyze data and build data analysis tools -Collaborate with multi-functional teams including algorithm, hardware, software, product design, project management, legal, procurement, security, logistics and vendors to define and deliver necessary study elements -Write technical documents including study instructions, operating procedures and training documents for study personnel -Drive process improvements across the organization to continuously improve the way we work
Education & Experience
B.S., M.S., or Ph.D. in Computer Science, Computer Engineering, or equivalent practical experience.
Additional Requirements",glassdoor
62,"CGI Group, Inc.
3.9
Data Engineer (JR)
Salt Lake City, UT
$75K - $106K (Glassdoor est.)

 Data Engineer (JR)

Position Description
CGI's Enterprise Technology and Operations (ETO) team is transforming what it means to work for a financial institution. We operate in a fast-paced, information-driven environment, which means we need people who bring diverse experiences, perspectives, and expertise to meet the ever-changing demands of a technology-driven world. We are grounded in the belief that ""improving the work is the work"" as we drive to create simple, easy, and fast solutions for our customers. Your ability to adapt, learn, and innovate helps increase revenue, reduce operational costs, and mitigates risk. ETO provides opportunities for you to own your career growth through Diversity, Equity, and Inclusion, Women in Technology, and Workforce of the Future initiatives that allow you to network across the organization, volunteer in our community, and build your technical and soft skills. Together we are building a culture that values diversity and creates a space of belonging for all our team members. We believe that investing in your success is an investment in our customers and our business. Our people are what sets us apart and make us great.

Your future duties and responsibilities
As a Data Engineer, you'll provide your talents in contributing to the success of the team by delivering the following:
Serve in the goalie rotation to support the Production environment.
Responsible for maintaining enterprise-grade platforms that enable data-driven solutions.
Search for ways to automate and maintain scalable infrastructure.
Ensure delivery of highly available and scalable systems.
Monitor all systems and applications and ensure optimal performance.
Analyzes and designs technical solutions to address production problems.
Participate in troubleshooting applications and systems issues.
Identifies, investigates, and proposes solutions to technical problems.
While providing technical support for issues, develop, test, and modify software to improve efficiency of data platforms and applications.
Monitors system performance to maintain consistent up time.
Prepares and maintains necessary documentation.
Participate in daily standups, team backlog grooming, and iteration retrospectives.
Coordinate with data operations teams to deploy changes into production.
Highest level may function as a lead.
Other duties as assigned.

Required qualifications to be successful in this role
Qualifications:
Requires a Bachelor's in Computer Science, Computer Engineering or related field and experience with ETL development, SQL, UNIX/Linux scripting, Big Data distributed systems. Prefer experience with IBM DataStage.
Various programming languages like Java and Python, orchestration tools and processes or other directly related experience.
A combination of education and experience may meet qualifications.
Excellent analytical, organizational, and problem-solving skills.
Ability and desire to learn new technologies quickly.
Ability to work independently and collaborate with others at all levels of technical understanding.
Able to meet deadlines.
Good judgment and project management skills.
Ability to communicate both verbally and in writing with both technical and non-technical staff.
Ability to work in a team environment and have good interpersonal skills.
Ability to adapt to changing technology and priorities.
Must be able to work independently, handle multiple concurrent tasks, with an ability to prioritize and manage tasks effectively.

Skill Set/Years of experience/Proficiency level

ETL
3-5 years
Expert

Linux
3-5 years
Expert

SQL
3-5 years
Expert

Microsoft Word, Excel, PowerPoint, Visio, and ADO
3-5 years
Expert

Python or Java
1-3 years
Expert

DESIRED QUALIFICATIONS/NON-ESSENTIAL SKILLS REQUIRED

Skill Set/Years of experience/Proficiency level

DataStage, Python
1 year
Professional

Minimum Education Required: Bachelor's degree

Colorado Equal Pay for Equal Work Act

Est. Salary Range (Colorado Only): $84,000-$107,000*

Disclaimer: In accordance with Colorado's Equal Pay for Equal Work Act, effective January 1, 2021, a good faith hourly or base salary range must be posted for all positions where the work may be performed in the state of Colorado. Therefore, this good faith salary range will only apply where this described position will be performed in the state,and should not be considered the compensation range in other locations or for other positions.

At CGI we call our professionals ""members"" to reinforce that all who join our team are, as owners, empowered to participate in the challenges and rewards that come from building a world-class company. CGI's benefits include:
Competitive base salaries
Eligibility to participate in an attractive Share Purchase Plan (SPP) in which the company matches dollar-for-dollar contributions made by eligible employees, up to a maximum, for their job category
401(k) Plan and Profit Participation for eligible members
Generous holidays, vacation, and sick leave plans
Comprehensive insurance plans that include, among other benefits, medical, dental, vision, life, disability, out-of-county emergency coverage in all countries of employment;
Back-up child care, Pet insurance, a Member Assistance Program, a 529 college savings program, a personal financial management tool, lifestyle management programs and more

Insights you can act on

While technology is at the heart of our clients' digital transformation, we understand that people are at the heart of business success.

When you join CGI, you become a trusted advisor, collaborating with colleagues and clients to bring forward actionable insights that deliver meaningful and sustainable outcomes. We call our employees ""members"" because they are CGI shareholders and owners and owners who enjoy working and growing together to build a company we are proud of. This has been our Dream since 1976, and it has brought us to where we are today - one of the world's largest independent providers of IT and business consulting services.

At CGI, we recognize the richness that diversity brings. We strive to create a work culture where all belong and collaborate with clients in building more inclusive communities. As an equal-opportunity employer, we want to empower all our members to succeed and grow. If you require an accommodation at any point during the recruitment process, please let us know. We will be happy to assist.

Ready to become part of our success story? Join CGI - where your ideas and actions make a difference.

Qualified applicants will receive consideration for employment without regard to their race, ethnicity, ancestry, color, sex, religion, creed, age, national origin, citizenship status, disability, pregnancy, medical condition, military and veteran status, marital status, sexual orientation or perceived sexual orientation, gender, gender identity, and gender expression, familial status, political affiliation, genetic information, or any other legally protected status or characteristics.

CGI provides reasonable accommodations to qualified individuals with disabilities. If you need an accommodation to apply for a job in the U.S., please email the CGI U.S. Employment Compliance mailbox at US_Employment_Compliance@cgi.com . You will need to reference the requisition number of the position in which you are interested. Your message will be routed to the appropriate recruiter who will assist you. Please note, this email address is only to be used for those individuals who need an accommodation to apply for a job. Emails for any other reason or those that do not include a requisition number will not be returned.

We make it easy to translate military experience and skills! Click here to be directed to our site that is dedicated to veterans and transitioning service members.

All CGI offers of employment in the U.S. are contingent upon the ability to successfully complete a background investigation. Background investigation components can vary dependent upon specific assignment and/or level of US government security clearance held. CGI will consider for employment qualified applicants with arrests and conviction records in accordance with all local regulations and ordinances.

CGI will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with CGI's legal duty to furnish information.

Skills
Data Engineering
ETL
Linux
SQL
DataStage
Python",glassdoor
63,"Netflix
4.3
Data Engineer (L5) - Games
Los Gatos, CA
$108K - $193K (Glassdoor est.)

 Los Gatos, California
Data Science and Engineering
Now is an amazing time to join Netflix as we seek to entertain the world. We have over 200 million paid members in over 190 countries, and we won’t stop there. Games are our next big frontier and an incredible opportunity for us to deliver new experiences to delight and entertain our quickly growing membership. You will be jumping in at the very beginning of this adventure and be in a position to help us redefine what a Netflix subscription means for our members around the world.
Data Science and Engineering (‘DSE’) at Netflix is aimed at using data, analytics, and sciences to improve various aspects of our business. We are looking for a Data Engineer to join our Games DSE team, supporting end-to-end analytics & data needs for our games portfolio. This role will be partnering closely with our Game stakeholders to develop software and data solutions that enable analysis across the entire library of games.
As part of this team, you will work on diverse data technologies such as Spark, Presto, Flink, Kafka, and others to build insightful, scalable, and robust data pipelines that feed directly into our key gaming dashboards; write ETL jobs to collect and aggregate data; and build high-quality data models that represent how games are performing on Netflix.
The ideal candidate will also have a background in games, with a solid knowledge of how standard industry metrics are computed.
Who You Are:
7+ years of software/data engineering experience working with video game analytics (i.e you are familiar with how key metrics such as DAU, MAU and retention rates are computed in an ETL).
Passionate about building intuitive data models and an expert in distributed data processing patterns.
Highly proficient in at least one of these programming languages: Java, Python, or Scala.
Comfortable with complex SQL.
Expert in engineering data pipelines using big data technologies (Hive, Presto, Spark, Flink) on large-scale data sets demonstrated through years of experience.
Conceptually familiar with AWS cloud resources (S3, EC2, RDS etc).
Excel at taking vague requirements and crystallizing them into scalable data solutions.
Excited about operating independently, demonstrating excellence, and learning new technologies and frameworks.
What will you do?
Engineer efficient, adaptable, and scalable data pipelines in Spark and Python/Scala to process structured data into aggregate datasets that feed all games portfolio dashboards.
Become an expert in games metrics at Netflix - act as a thought partner to the games analytics team, understand their challenges, and help them to put the right data in front of our stakeholders.
Maintain and rethink existing datasets and pipelines to service a wider variety of use cases.
Join a stunning team of data engineers with diverse skill sets, partnering closely with analytics engineering and data science counterparts.
Netflix Culture
Our culture is unique, and we live by our values. For more information on what it's like to work at Netflix, please take a look at our culture memo.",glassdoor
64,"Apple
4.2
Machine Learning Data Collection Engineer, Technology Development Group (TDG)
Cupertino, CA

 Summary
Posted: Mar 15, 2022
Role Number:200356922
Do you want to push the limits of the best Augmented Reality platform in the world? Apple's Technology Development Group (TDG) delivers algorithms that drive revolutionary Apple products, including the augmented reality (AR) platform ARKit to create ground-breaking new products. In this position, you will have the opportunity to be part of our extraordinary data team to discover and build solutions to previously-unsolved challenges and push the state of the art in AR algorithms that will change the way people experience the world! We are looking for a driven Machine Learning Data Collection Engineer that enjoys getting into the details to collect valuable data that feeds our machine learning models. As a member of the fast-paced data team, you have the rewarding opportunity to shape upcoming products that will delight and inspire millions of people every day. To succeed within this role, you should have shown experience in several of the following areas:
Key Qualifications
Ability to define/design/develop data collection efforts that focus on the end-to-end user experience, including anticipating potential failure modes, edge cases, and anomalies
Capacity to multitask and manage several projects in parallel while meeting deadlines and providing access to clients and partners
Problem solving & critical thinking capacities, thinking outside the box in order to gain in speed, efficiency, and quality.
Ability to re-construct ill-defined data needs into concrete project deliverables
Ability to maintain and develop relationships with multi-functional teams
Excellent project management, communication, interpersonal, analytical, and organizational skills
Description
As a Machine Learning Data Collection Engineer, you'll be working with our customers to understand their data collection requirements, assisting them in defining their protocols, and executing on the data collection. Your job responsibilities will include: -Collaborate with algorithm teams and understand data collection requirements in order to define collection protocols -Define and design the collection requirements and lead the collection effort from start to finish -Coordinate the efforts between internal teams (Legal, privacy, security, etc) guaranteeing compliance with applicable rules, laws, and best practices -Create documents and procedures needed to run data collections -Managing and track progress of externally run data collections
Education & Experience
Bachelors degree or related practical experience
Additional Requirements",glassdoor
65,"Tesla
3.6
Data Engineer
Fremont, CA

 What to Expect
The Data Engineer is responsible for processing structured and unstructured data, validating data quality, and developing and supporting data products. We are looking for someone with strong hands on experience in all layers of data Integration and analytics! We especially need experience in using Python as an ETL tool. The Data Engineer plays a significant role in Agile planning, providing advice and guidance, and monitoring emerging technologies. Some of the technology we use: * Python * Informatica * SQL Server and MySQL * Vertica * Kafka

What You’ll Do
* Design, code, test, correct and document programs and scripts using agreed standards and tools to achieve a well-engineered result * Derive an overall strategy of data management, within an established information architecture that supports the development and secure operation of existing and new information and digital services * Plan effective data storage, security, sharing and publishing within the organization * Gathers and processes raw, structured, semi-structured, and unstructured data using batch and real-time data processing frameworks * Ensures data quality and implements tools and frameworks for automating the identification of data quality issues * Collaborate with internal and external data providers on data validation providing feedback and making customized changes to data feeds and data mappings * Mentor and lead data engineers providing technical guidance and oversight * Provides ongoing support, monitoring, and maintenance of deployed products

What You’ll Bring

* Strong experience with relational databases like SQL Server, MySQL and Vertica. NoSQL databases experience is a plus! * Strong background in data modeling, data access, and data storage techniques * Experience with design, development, and implementation of highly scalable, high-volume software systems and components, source of truth systems for different business areas, developing and maintaining web services in an agile environment * Working experience with Kafka Streaming layer * Experience in Spark Framework on both batch and real-time data processing is a plus * Experience in Big Data Integration & Analytics is a plus * Experience in Supply Chain and Logistics data is a plus",glassdoor
66,"National Research Group
3.7
Data Engineer
San Francisco, CA
$88K - $128K (Glassdoor est.)

 Who We Are
National Research Group (NRG) is a leader in data driven insights and strategic consultation to the global entertainment and technology industries. Working at the confluence of technology, content, and culture, NRG offers bold insights for storytellers everywhere. Our consultants have experience working across all facets of media and technology.
Why You'll Love It Here
We are inspired by working with storytellers that challenge us to think differently and see the world in new ways. As a result, our business is driven by creative, curious, and inventive people who have a passion for pop culture. We work as a collective across disciplines and geographies to bring together the best thinking for every assignment, delivering insights to bold storytellers everywhere.
The Opportunity
We are looking for a data engineer with a background in building and maintaining data pipelines to integrate and process diverse data sources and data formats. This candidate should have a minimum of 1-year experience for a full-time position within our fast paced and growing company.
If you feel that you can make an impact through innovation and collaboration and come to work with a passion to facilitate in delivering high quality data to our teams and clients, this is a great role for you.
The Role
Build, test, orchestrate, and maintain data pipelines that support the data sciences team and customer-facing client teams.
Assist in ad-hoc data deliveries by querying data from various SQL relational databases stored in multiple data models.
Track and manage pipeline efficiency and stability.
Evaluate, parse, clean, and integrate raw data sets including third party APIs. Help build sophisticated ETL processes around first party data such as survey data, second and third-party data sources such as IP addresses, clickstream data, movie meta data.
Provide recommendations for data storage, configurations, data access tools and new technologies/architectures.
Develop code-based data transformation/aggregation in data lakes, relational databases (primary use cases) and possibly non-relational databases, as well as for the purpose of BI tools such as Power BI and Tableau.
Participate in developing data APIs for data ingestion of NRG data into client-side applications or client-side data systems.
Assist application developers in the effective use of database query and programming languages.
Contribute to managing data integrity, data storage efficiency and data ecosystem efficiency.
Who You Are
Team asset who can describe data structures, relationships, and flows behind organization database servers and applications.
Up to date on the latest data-related best practices and technologies and always looking to learn more.
Internally motivated self-starter who continuously strives to get things done, regardless of challenges encountered.
Critical thinker, able to understand and respond to complex questions or issues that may arise, and able to demonstrate willingness to experiment with new technologies.
Successfully manages time and multiple competing priorities in order to ensure deadlines are always met.
Team player who is able to work collaboratively and initiate and drive projects to completion with minimal oversight.
Ideal Candidate
BS/BA in Computer Science or related field.
1+ year experience in building data pipelines or ETL.
1+ year experience with SQL (we use Snowflake but other experience with relational databases is welcome).
1+ year experience with AWS technologies/infrastructure.
Working knowledge with Python.
A solid foundation with end-to-end development and the desire to further their technical knowledge.
Knowledge of PII (personally identifiable information) data security standards is a plus.
dbt experience is a plus.
Terraform experience is a plus.
Dagster experience is a plus.
Experience in databases structured against survey data is a big plus.
Position Type
This is a full-time, exempt position.
Work Environment
This position is expected to be fully remote. However, NRG offers flexible work options if an employee happens to live near a dedicated office (Playa Vista or New York) and wants a hybrid work model. This role routinely uses standard office equipment.
Required Application Materials:
CV/Resume
Cover Letter which should include:
Why do you want to work at NRG?
Why are you interested in working in the entertainment industry?",glassdoor
67,"Pinterest
4.1
Data Engineer
Remote

 About Pinterest:
Millions of people across the world come to Pinterest to find new ideas every day. It's where they get inspiration, dream about new possibilities and plan for what matters most. Our mission is to help those people find their inspiration and create a life they love. In your role, you'll be challenged to take on work that upholds this mission and pushes Pinterest forward. You'll grow as a person and leader in your field, all the while helping Pinners make their lives better in the positive corner of the internet.
Our new progressive work model is called PinFlex, a term that's uniquely Pinterest to describe our flexible approach to living and working. Visit our PinFlex landing page to learn more.
The Enterprise Data Platform team is looking for a Data Engineer who has experience with Building Data Pipelines and Managing/Developing on any Cloud Data Warehouse. In this role you will also advise other Data Analysts and Data Engineers from the Business teams at Pinterest on the best practices for handling data and deriving insights using Snowflake. You will gradually become the Subject Matter Expert on Snowflake and also help build out the Modern Data Stack at Pinterest.
What you'll do:
Build Data Pipelines using Python on either Airflow or AWS Lambda to ingest data into Snowflake
Build Scripts in Python to manage Data Access on Snowflake
Define and advocate the best practices for storing and analyzing data inside Snowflake
Review the Data Modeling practices of other teams
What we're looking for:
Strong skills in Python and SQL
Experience with Building Data Pipelines in Python
Experience with any Cloud Data Warehouse either as an Administrator or a Developer
Strong Data Modeling skills
#LI-BB1
#LI-Remote
Our Commitment to Diversity:
At Pinterest, our mission is to bring everyone the inspiration to create a life they love—and that includes our employees. We’re taking on the most exciting challenges of our working lives, and we succeed with a team that represents an inclusive and diverse set of identities and backgrounds.

Not Specified
0",glassdoor
68,"Zscaler
4.5
Data Engineer
San Francisco, CA
$99K - $143K (Glassdoor est.)

 Company Description

Zscaler (NASDAQ: ZS) accelerates digital transformation so that customers can be more agile, efficient, resilient, and secure. The Zscaler Zero Trust Exchange is the company’s cloud-native platform that protects thousands of customers from cyberattacks and data loss by securely connecting users, devices, and applications in any location.
With more than 10 years of experience developing, operating, and scaling the cloud, Zscaler serves thousands of enterprise customers around the world, including 450 of the Forbes Global 2000 organizations. In addition to protecting customers from damaging threats, such as ransomware and data exfiltration, it helps them slash costs, reduce complexity, and improve the user experience by eliminating stacks of latency-creating gateway appliances.
Zscaler was founded in 2007 with a mission to make the cloud a safe place to do business and a more enjoyable experience for enterprise users. Zscaler’s purpose-built security platform puts a company’s defenses and controls where the connections occur—the internet—so that every connection is fast and secure, no matter how or where users connect or where their applications and workloads reside

Job Description

Position: Data Engineer
Location: Remote within United States
About the team: As part of the IT group, we are responsible for executing our enterprise data strategy which emphasizes data management maturity, fosters a robust data culture, and architects a best-in-class enterprise data platform. We have the ultimate goal to provide trusted data and insights at scale which enable corporate and functional data-driven decision making. We are fueled by organic innovation, internal collaboration and adoption of data visualization, data management, reporting automation, AI/ML and integration tools. We leverage best practices and alignment through our Enterprise Data Community to deliver speed to insight, scale, control and enablement. The team is distributed across the United States and India and is composed of data engineers, data analysts, visualization developers, and infrastructure specialists.
Responsibilities/What You’ll Do:
Collaborate with Data & Technical architects, integration and engineering teams to capture inbound/outbound data pipeline requirements, conceptualize and develop solutions
Support the evaluation and implementation of the current and future data applications/technologies to support the evolving Zscaler business needs
Collaborate with IT business engagement & applications engineer teams, enterprise data engineering and business data partner teams to identify data source requirements
Profile and quantify quality of data sources, develop tools to prepare data and build data pipelines for integrating into Zscaler’s data warehouse in Snowflake
Continuously optimize existing data integrations, data models and views while developing new features and capabilities to meet our business partners needs
Work with Principal Engineer/ Data Platform Lead to design and implement data management standards and best practices
Continue to learn and develop next generation technology/ data capabilities that enhance our data engineering solutions
Develop large scale and mission-critical data pipelines using modern cloud and big data architectures

Qualifications

Qualifications/Your Background:
3+ years of experience in data warehouse design & development
Strong experience in integrating internal and external business applications (salesforce, netsuite, google analytics etc) with cloud data platforms like Snowflake
Proficiency in SQL and ability to perform complex modeling with large volumes of data
Experience with Big Data technologies like Hadoop
Required Experience with any industry standard ETL & data integration platforms like Matillion, Workato, Dell Boomi
Experience with data orchestration to like Apache Airflow a plus
Experience with resolving workflow and data quality issues associated with production grade large scale cloud systems
Strong capacity to manage multiple projects simultaneously
Experience with Python, Dbt or similar a plus

Additional Information

All your information will be kept confidential according to EEO guidelines.
#LI-YC2
#LI-Remote
What You Can Expect From Us:
An environment where you will be working on cutting edge technologies and architectures
A fun, passionate and collaborative workplace
Competitive salary and benefits, including equity
Why Zscaler?

People who excel at Zscaler are smart, motivated and share our values. Ask yourself: Do you want to team with the best talent in the industry? Do you want to work on disruptive technology? Do you thrive in a fluid work environment? Do you appreciate a company culture that enables individual and group success and celebrates achievement? If you said yes, we’d love to talk to you about joining our award-winning team.

Additional information about Zscaler (NASDAQ: ZS ) is available at https://www.zscaler.com.
Zscaler is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.",glassdoor
69,"Spokeo
3.8
Data Engineer, Analytics
Pasadena, CA
$113K - $164K (Glassdoor est.)

 Spokeo is a people search engine that both enlightens and empowers our customers. With over 12 billion records and 14 million visitors per month, we reconnect friends, reunite families, prevent fraud, and more.

We are looking for a Data Engineer, Analytics to join our team and help build our NextGen customer data management, analytics, and ML platform. This role will work as part of the larger data science and analytics team to build and maintain business-critical data pipelines and infrastructure.

Responsibilities:
Design and build maintainable and scalable infrastructure for data extraction, preparation, and loading of data from backend services and web browser clients to our data lake and other reporting databases
Build and manage tools to monitor pipeline performance and provide deeper insight into pipeline metrics
Monitor data pipelines and services for issues and ensure identified bugs are routed and resolved
Work with large, complex SQL and NoSQL databases
Create and maintain technical documentation and write well-abstracted, reusable, and efficient code
Essential Requirements:
2+ years of experience in data engineering or software development
Strong competency in SQL
Strong programming skills in languages such as Python, Ruby, etc.
Experience with AWS eco-system and working with services like EMR, RDS, Redshift, Kinesis, etc.
Experience working with large data sets in a Hadoop or Spark environment
Strong organizational skills and detail-oriented mindset
BS in Computer Science or equivalent skills and experience

Privacy Notice for Candidates: https://www.spokeo.com/recruiting-policy

Spokeo is an equal opportunity employer. Applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Spokeo fosters a business culture where ideas and decisions from all people help us grow, innovate, create the best products, and be relevant in a rapidly changing world.

Recruiters or staffing agencies: Spokeo is not obligated to compensate any external recruiter or search firm who presents a candidate or their resume or profile to a Spokeo employee without 1) a current, fully-executed agreement on file and 2) being assigned to the open position (as a search) via our applicant tracking solution.

This is a remote position.",glassdoor
70,"Hasbro
3.8
Data Engineer
East Providence, RI
$72K - $106K (Glassdoor est.)

 At Hasbro we’re changing the face of play and entertainment. We’re looking for people who want to explore, experiment and innovate to come up with the best ideas. Our culture of community, passion, integrity, creativity and inclusion has inspired our diverse team of highly skilled, highly creative and highly committed individuals for 90+ years and we believe the best is yet to come.

Do you have a passion for data? Then we are looking for you! We have an opportunity for a Data Engineer to join our high-visibility Analytics team which is helping Hasbro better reach consumers with compelling products and entertainment! The Data Engineer will expand the pool of data available for conducting analytics.

A day in the life as a Data Engineer:
Work on large scale data processing and analysis to improve the efficacy of our business strategies.
Develop, scale, and optimize the data pipelines and platform components to enable analytics insights.
Participate in the design, architecture, and implementation of data-engineering infrastructure.
Practice engineering excellence, including software design patterns, code reviews, and automated unit/functional testing.
Collaborate with product managers, data scientists, and analysts in an open, creative, and agile environment.

What you'll bring:
1-4 years of experience in Data Engineering, Analytics, consulting, or a related quantitative field.
Bachelor’s or Master’s Degree in Computer Science, Information Systems or related field.
Intermediate experience with object-oriented programming languages (Python preferred) and intermediate to advanced SQL skills; familiarity with git, CI/CD and the command-line interface (CLI)
Experience developing in AWS, Google cloud, or Azure (Azure preferred).
Good interpersonal, oral, visual, and written communication skills for communicating with technical and non-technical staff. Ability to work within a customer oriented, positive team environment.
Experience in an Agile delivery team using tools like JIRA, Confluence is a plus.

This position may be based in our office in East Providence, Rhode Island or may be fully remote.

Hasbro’s world-class brands and talented people are our greatest assets. One of the ways we invest in you is through a competitive and contemporary benefits package. Your particular benefits package will depend on your position, location, local legal requirements and years with the company. Here’s a look at what your benefits package may include: Medical, Dental & Vision Insurance, Half-day Fridays year round, Paid Vacation Time & Holidays, Generous 401(k) match, Paid Parental Leave, Team Hasbro Volunteer Program, Employee Giving & Matching Gifts Programs, Tuition Reimbursement, Toy Discounts and more!

Hasbro is committed to equality of opportunity in all aspects of employment. We are committed to making all employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity or expression, national origin, age, marital status, or any other legally protected status.
#LI-GA1 #LI-Remote",glassdoor
71,"Mercury
3.7
Data Engineer
San Francisco, CA
$104K - $152K (Glassdoor est.)

 SF, NY, Toronto, Portland, or remote
Full-time
Mercury
In the 1880s, Herman Hollerith noticed the US Census was taking over 8 years to calculate. To solve this, he invented a tabulating machine using punch cards that dramatically sped up the process and served as the foundation for innovation in high quality data gathering.
We’re looking for our first Data Engineer who can help us build our high quality data engine that informs how we invest in and build Mercury’s future. You’ll be early to building a data-informed culture across Mercury so that we can all determine what’s happening, react quickly, and invest intelligently.
Here are some things you’ll do on the job:
Partner with leadership, engineers, and data scientists to understand data needs and build systems that deliver high quality and reliable data.
Own and maintain the data systems that extract, transform, and load data into internal and external tooling.
Apply proven expertise and build high-performance scalable data warehouses.
Design, build, and launch efficient & reliable data pipelines to move and transform data (both large and small amounts).
Design and develop new systems in partnership with software engineers to enable quick and easy consumption of data.
You should:
Have 2+ years of experience working with analytics teams on building high quality and reliable data infrastructure.
Be able to navigate from architecture and implementation decisions related to data infrastructure to guide teams towards building reliable and accurate pipelines and company-critical data sets.
Have familiarity with postgres backend data, Snowflake, and data transformation tools like dbt.
Value quality in data tools, testing, and innovation.",glassdoor
72,"The Coca-Cola Company
4.1
Data Engineer
Atlanta, GA
$82K - $119K (Glassdoor est.)

 Data Engineer Job Description
Job Overview
We are looking for a savvy Data Engineer to join our growing team of data engineering experts. The right candidate will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is a passionate data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.
Responsibilities for Data Engineer
Create and maintain optimal data pipeline architecture,
Azure Synapse or Azure Data Factory is a plus
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AZURE ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AZURE regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Qualifications for Data Engineer
Working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large, disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
Minimum Requirements:
University Degree (Bachelor) or equivalent experience
At least 5 years of prior relevant experience
Has specialized depth and/or breadth of expertise in own discipline or function
Skills:
Microsoft Azure Synapse Analytics

Our Purpose and Growth Culture:
We are taking deliberate action to nurture an inclusive culture that is grounded in our company purpose, to refresh the world and make a difference. We act with a growth mindset, take an expansive approach to what’s possible and believe in continuous learning to improve our business and ourselves. We focus on four key behaviors – curious, empowered, inclusive and agile – and value how we work as much as what we achieve. We believe that our culture is one of the reasons our company continues to thrive after 130+ years. Visit Our Purpose and Vision to learn more about these behaviors and how you can bring them to life in your next role at Coca-Cola.

We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity and/or expression, status as a veteran, and basis of disability or any other federal, state or local protected class. When we collect your personal information as part of a job application or offer of employment, we do so in accordance with industry standards and best practices and in compliance with applicable privacy laws.",glassdoor
73,"Miracle Software Systems
3.5
Data Engineer
Arizona

 USA-Arizona
Exp 5 - 10 Years
Key Skills
Hadoop
Spark
SQL
Python
BigQuery
Responsibilities
The candidate should have minimum 3+ years of working experience as a Data Engineer
Ability to understand data frameworks that collect, manage, transform, and store data to derive business insights
Must have 2+Data Engineer years of experience within the Big Data ecosystem(Hadoop, SqoopHive, Spark, Pig, etc.)
Must have 2+ years of strong experience with SQL and Python(Data Engineering focused)
Preferred to have experience with Google Cloud data services such as BigQuery, Dataflow, Dataproc, etc.
Any prior experience in ETL tools such as DataStage, Informatica, DBT, Talend, etc., will be an added advantage
Should have SQL skills that include performance-tuning, clustering, indexing, modeling, database optimizing, etc.
Ability to handle huge datasets and perform quick data analysis to extract insights from raw data for sharing with clients
Should be able to code (Python preferred) for developing new applications (cloud functions, dataflow, etc.) and also a lot of existing workloads needs to be updated frequently
Advanced knowledge in data visualization tools with a grasp of effective data modeling and visualization practices
Domain-specific knowledge infrastructure, VMWare space (VMs, Datastore, and Hosting servers)
Good team player, quick learner, capable to work in high-demand work environments, and ready to accept and take on challenges
Ability to quickly adapt to new tools and evolving technologies
Good communication skills with the ability to work in large teams and interact with technical teams",glassdoor
74,"Koddi
4.6
Data Engineer
Fort Worth, TX
$81K - $116K (Glassdoor est.)

 Koddi, Inc. Seeks Data Engineer in Ft. Worth, TX: work with robust data systems and develop custom solutions while consulting with external customers. Telecommuting permitted from anywhere in the U.S. (Job ID JT0004). Please send resume with Job ID through web link: https://koddi.com/careers/.
If you are passionate about big data, want to be part of a great team, and love building new technology, we want to speak with you. As a Data Engineer, you will work with our technology team to build and maintain our suite of data pipelines, stores, and databases that power sophisticated marketing products used by many of the world’s largest advertisers. We are looking for smart and hardworking individuals who love to build world-class software. The right candidates will be creative thinkers who can design and deploy professional applications using the newest technologies to solve real business problems.
What You'll Do
Work within robust data systems and develop custom solutions while consulting with external customers
Recommend and implement improvements to data processes and warehouses that improve supportability, usability, and scalability
Optimize and refactor existing code
Improve the efficiency, scalability, and reliability of applications
Who You Are
Bachelor's or Master's degree in CS or other technical, science, or math fields
3+ years of experience as a data or software engineer
High level of experience with SQL, with ability to design and optimize objects
Experience with Extract, Transform, and Load(ETL)
Basic command line knowledge and Git
Outstanding work ethic and drive
Strong communication and teamwork skills
Willingness to learn and utilize emerging technologies
Relational Databases: MS SQL Server, Postgres, MySQL
Preferred Languages: Scala, Java, GoLang, Python
Luxury Experience: Spark, AWS Technologies
ABOUT KODDI
Koddi's award-winning ad technology platform provides a robust network for brands to connect with consumers and drive revenue through native sponsored placements, metasearch, and programmatic media campaigns.
Based in Fort Worth, Texas, Koddi has additional office locations in New York, Ann Arbor, Austin, San Francisco, and Düsseldorf. We embrace all ways of working inclusive of remote work, in-office work or hybrid work - we want your best self and will support your work preference based on your needs and Koddi’s need.
Koddi has been ranked by Forbes, Deloitte, and the Inc. 5000 as one of the fastest-growing companies in the nation. We’re on a mission to forge a better path to discovery through integrity, insights, inclusivity, and innovation. Come join us!
Job Type: Full-time",glassdoor
75,"Medicom
3.2
Data Engineer
Raleigh, NC
$76K - $107K (Glassdoor est.)

 MEDICOM
Medicom Technologies is a high-growth, healthcare technology company dedicated to creating innovative solutions for patients, health systems, and life sciences companies. We have a focused passion to improve patient outcomes by eliminating health data silos and facilitating data curation.
With over 3,500 connections and 1,000 participating organizations, the Medicom Network connects disparate silos of health information so health records can be easily and securely searched and shared amongst healthcare providers.
The Medicom deepMed Marketplace serves healthcare data consumers at life science, pharmaceutical, and AI companies by facilitating curation of individual or longitudinal data sets.
Every member of our team embodies our core values to ensure every network participant from patient to physician can collaborate in our mission.
Fresh off the completion of Series B funding (see press release), Medicom is developing a culture that strives for transparency, compassion and progress.
We are growing our team by seeking individuals with a growth mindset who share a high-level of passion, drive, and commitment to serve the variety of Medicom stakeholders.
To learn more about Medicom visit our website medicom.us
Position: Data Engineer
The Data Engineer will work with the deepMed business unit to collect and de-identify medical images for research, machine learning, and AI applications. This position will be responsible for analyzing and documenting business data and processes as well as recommending technical solutions and creating reports or other solutions as needed to support the deepMed business unit needs.
Responsibilities
Writing SQL queries, procedures, and reports on both ad-hoc and production basis for analysis of clinical data.
Proactively defines, identifies, develops, and implements processes and procedures to support business strategy and operational planning.
Develop and participate in presentations to existing and prospective customers and internal business areas.
Candidate must be SQL power user, able to review results, conduct root cause analysis, identify next steps, and put them into action.
Should have the ability to move multiple projects forward simultaneously and be responsible for the results; even when others are directly accountable for the outcome.
Aide in building the relationship with our data provider teams to work with their staff on data curation.
Package and deliver high-quality longitudinal data sets to our customers.
Assist and coordinate with implementation teams on new deepMed installations.Assist in contractual and compliance-related responsibilities with your clients.
Qualifications
Knowledge of analytic programming tools and methods (SQL).
2+ years of experience working within the health care industry in any of the following areas: Hospital research, predictive modeling, case-mix, risk adjustment methods, and tools, or supporting Clinical information systems.
5+ years of experience working in a data warehouse environment.
The ability to work with large data sets from multiple data sources.
Demonstrates strong ability to prioritize work, excellent organizational skills, and initiative to improve processes.
Bachelor’s degree in a related field.
Preferred Qualifications
Clinical Certification in the medical imaging space (CIIP, CNMT, RT, etc.).
Clinical radiology workflow experience.
Experience with JavaScript, TypeScript, Python R.
AWS, Amazon Web Services, or Google Cloud.",glassdoor
76,"Apple
4.2
Data Engineer
Cupertino, CA

 Summary
Posted: Aug 10, 2022
Weekly Hours: 40
Role Number:200406892
Are you a big-picture thinker who loves setting ambitious goals? Do you have a passion for understanding how each line of code affects all the others? In the Core Operating Systems group, you’ll ensure the OS is inseparable from each device’s identity as a whole. That’s because this group is committed to building fully integrated operating systems that combine hardware, software, and apps into a single Apple experience. Your dedication to cross-disciplinary collaboration will help develop groundbreaking technologies, such as iOS, macOS, watchOS, and tvOS. By crafting these distinct, holistic user experiences, you’ll continue to uphold and advance the excellence people expect from Apple devices. The Platform Services & Operations team in Core OS is looking for a Data Engineer to inform and develop essential workflow tooling at scale. The Workflow Engineering team enable teams to deliver high quality software through best in class engineering experiences, efficient workflow, data driven insights, and a culture of continuous improvement. Your focus is building the backend data pipelines that enables visualization of data across the organization in user intuitive and configurable formats.
Key Qualifications
3 +proven experience in a Data focused posistion
Proficient in Python; data access and retrieval. Quantitative data preparation. Regular expressions and text analysis
Highly Proficient in Database Language and Design; querying large stores of data (APIs, SQL, etc.).
Access, retrieval, and storage of information. Data Structures, modeling for speed and efficiency
Software Development; understanding of build pipelines, branching and merging, Agile methods, and the delivery of code. Fluency in Git (or comparable source control tool)
Description
- Replicate data from source system into data warehouse; retrieve data through various protocols and land it in a central store - Automate data pipelines; write programs to periodically update warehouse data from source systems - Design for scale; flexible infrastructure for common enhancements including: expanding the volume of captured data, adding fields to the user-facing views, and recompiling archived data - Work with a team of data scientists and full stack engineers, to derive and develop targeted insights through centrally managed interactive dashboards
Education & Experience
B.S. in Data Science, Computer Science, or equivalent experience.
Additional Requirements
Experience as an Analyst; worked in the delivery of visual information (dashboards, reports, web-apps)
An understanding of how data can be used and applied in context (what is useful to capture and how it can be communicated)
Full Stack Development; ability to maintain back-end systems and visualize front-end data for users (with a web-kit framework like Angular, React)
Experience with Snowflake and/or other data store technologies",glassdoor
77,"Triumph Tech
5.0
Data Engineer
Remote

 Posted 7 months ago
Job Features
Location100% Remote
DescriptionTriumph Tech is an Advanced Tier AWS Partner, based in Philadelphia, Pennsylvania, Naples Florida, Seattle, Washington, and New Jersey. We specialize in Migrations, DevOps, Containers, server-less, data & analytics, and ML/AI. We are looking for a brilliant person to join our team. Receive great benefits, company profit share, and salary.

Triumph Tech is an Advanced Tier AWS Partner. We are based out of Philadelphia, PA , Naples Florida, Seattle, Washington, and South New Jersey. We specialize in Migrations, DevOps, Containers, server-less, data & analytics, and ML/AI. We are looking for a brilliant individual to join our growing team. We have great benefits, company profit share and salary.
The successful candidate will build data solutions using state of the art technologies to acquire, ingest and transform big datasets.
Job Responsibilities
Partner with our users and other data product teams to understand their needs and build impactful data/analytics solutions.
You will design and build data pipelines to support applications and data science projects following software engineering best practice.
Design and develop data applications using big data technologies (Hadoop, AWS) to ingest, process, and analyze large disparate datasets.
Build robust data pipelines on Cloud using Airflow, Spark/EMR, Kinesis, Kafka, Lambda or other technologies.
Build the infrastructure required for optimal extraction, transformation, and loading of data from various data sources using SQL and AWS ‘big data’ technologies.
Qualifications
Experience delivering Data migration projects in AWS (preferably) but other cloud solutions will work too
SQL / ETL experience and understanding
Hadoop
Some ELT tool – Informatica, Airflow, AWS Glue etc
Must have experience writing core data transformations in Python.",glassdoor
78,"Wikimedia Foundation
4.0
Data Engineer
Los Angeles, CA
$91K - $139K (Glassdoor est.)

 Summary
The Wikimedia Foundation is looking for a Data Engineer to join our team, reporting to the Director of Data Engineering. As a Data Engineer, you will be responsible for building, maintaining and expanding the shared data infrastructure that powers a big part of decision making in the Foundation as well as the Wiki Movement. This includes everything from building scalable pipelines using big data technology to defining and creating a suite of datasets which adhere to our privacy principles.
We are a fully remote, internationally distributed team. We see each other in person 1-2 times a year during one of our off-sites (the last few have been in places like Copenhagen, Majorca and New York) or Wikimania, the annual international conference for the Wiki community.
Open to candidates located in timezones UTC-8 to UTC+2, daily team stand ups occur at 9am UTC-8.
You are responsible for:
Integrating data from multiple sources to gain insights in areas such as content, traffic, editors, readership and fundraising
Building scalable data pipelines in collaboration with other data engineers as well as teams across the foundation including product analytics, platform engineering, survey, research and machine learning teams
Designing the shared data platform that supports use cases for critical aspects of the Wikimedia mission: harassment prevention, image classification, bot detection, DDoS attacks flagging and many more
Building and maintaining public metrics and datasets
Implementing data quality monitoring that alerts the team of possible data issues
Implementing a data governance and lineage solution for all Wikimedia data
Skills and Experience:
2+ years of relevant industry experience
Advanced working knowledge of SQL, relational databases, query authoring, ideally in a variety of flavors (in our team alone we deal with MariaDB, HiveQL, CassandraQL, Spark SQL and Presto)
Experience with one or more programming languages such as Python, Scala, and Java
Experience building data pipelines using tools such as Airflow, Spark, Gobblin, Oozie, Yarn
Familiarity with stream processing systems using Kafka, Spark streaming and/or Flink
Excellent written and verbal communication skills
Strong interpersonal and collaboration skills
BS or MS degree, preferably in Computer Science, or equivalent work experience
Qualities that are important to us:
Commitment to the mission of the organization and our values
Commitment to our guiding principles
Commitment to diversity, equity, and inclusion
Cross-cultural sensitivity and awareness
Collaborative working experience
Additionally, we'd love it if you have:
Experience with Hadoop
Understanding of related disciplines including Machine Learning, Statistics, Privacy and Algorithms
Experience working with site reliability engineers
About the Wikimedia Foundation
The Wikimedia Foundation is the nonprofit organization that operates Wikipedia and the other Wikimedia free knowledge projects. Our vision is a world in which every single human can freely share in the sum of all knowledge. We believe that everyone has the potential to contribute something to our shared knowledge, and that everyone should be able to access that knowledge freely. We host Wikipedia and the Wikimedia projects, build software experiences for reading, contributing, and sharing Wikimedia content, support the volunteer communities and partners who make Wikimedia possible, and advocate for policies that enable Wikimedia and free knowledge to thrive.
The Wikimedia Foundation is a charitable, not-for-profit organization that relies on donations. We receive donations from millions of individuals around the world, with an average donation of about $15. We also receive donations through institutional grants and gifts. The Wikimedia Foundation is a United States 501(c)(3) tax-exempt organization with offices in San Francisco, California, USA.
As an equal opportunity employer, the Wikimedia Foundation values having a diverse workforce and continuously strives to maintain an inclusive and equitable workplace. We encourage people with a diverse range of backgrounds to apply. We do not discriminate against any person based upon their race, traits historically associated with race, religion, color, national origin, sex, pregnancy or related medical conditions, parental status, sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, or any other legally protected characteristics.
If you are a qualified applicant requiring assistance or an accommodation to complete any step of the application process due to a disability, you may contact us at recruiting@wikimedia.org or +1 (415) 839-6885.
More information
U.S. Benefits & Perks
Wikimedia Foundation
Applicant Privacy Policy
News from across the Wikimedia movement
Blog
Wikimedia 2030
Our Commitment to Equity
This is Wikimedia Foundation
Facts Matter
Our Projects
Our Tech Stack",glassdoor
79,"Lucid Motors
3.5
Data Engineer
Newark, CA
$112K - $163K (Glassdoor est.)

 Leading the future in luxury electric and mobility
At Lucid, we set out to introduce the most captivating, luxury electric vehicles that elevate the human experience and transcend the perceived limitations of space, performance, and intelligence. Vehicles that are intuitive, liberating, and designed for the future of mobility.
We plan to lead in this new era of luxury electric by returning to the fundamentals of great design – where every decision we make is in service of the individual and environment. Because when you are no longer bound by convention, you are free to define your own experience.
Come work alongside some of the most accomplished minds in the industry. Beyond providing competitive salaries, we’re providing a community for innovators who want to make an immediate and significant impact. If you are driven to create a better, more sustainable future, then this is the right place for you.

We are looking for a Senior Data Engineer, Big Data who is looking for a challenge, enjoys thinking big and looking to make their mark on an extremely fast growing company. If you have hands-on experience designing and developing streaming and IoT data pipelines this role is for you. Be part of a group who will be building large and building fast, working with a very talented team of engineers, and collaborating with the brightest mind in the Automotive industry.
The Role
Hands-on design and develop streaming and IoT data pipelines.
Developing streaming pipeline Kafka, Spark, Scala and Python
Python scripting for automation and application development
Developing streaming pipeline using FluentD, Elasticsearch, Kibana
Design ETL in Apache Airflow and other dependency enforcement and scheduling tools.
Hands-on data modeling and data warehousing
Deploy solution using AWS, S3, Redshift and Docker/Kubernetes
Develop storage and retrieval system using Presto and Parquet/ORC
Scripting with Apache Spark and data frame.
Qualifications
Bachelor or Masters in Software Engineering or Computer Science
2+ years of experience in Data Engineering and Business Intelligence
Excellent coding, scripting and problem solving skills
Experience in tools such as Spark, Kafka, S3, Hive, Data Lake
Experienced in Log Collection and processing using tools such FluentD and Elastic Search
Experience with AWS, S3, Redshift
Experience with Presto and Parquet/ORC
Proficient with Apache Spark and data frames
Experienced in containerization, including Docker and Kubernetes
Expert in tools such as Apache Spark, Apache Airflow, Presto, and Kubeflow
Expert in design and implement reliable, scalable, and performant distributed systems and data pipelines
Extensive programming and software engineering experience, especially with Scala, Java or Python
Experience with a columnar database such as Redshift or Vertica
Great verbal and written communication skills
At Lucid, we don’t just welcome diversity - we celebrate it! Lucid Motors is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, national or ethnic origin, age, religion, disability, sexual orientation, gender, gender identity and expression, marital status, and any other characteristic protected under applicable State or Federal laws and regulations.

Notice regarding COVID-19 protocols
At Lucid, we prioritize the health and wellbeing of our employees, families, and friends above all else. In response to the novel Coronavirus all new Lucid employees, whose job will be based in the United States may or may not be required to provide original documentation confirming status as having received the prescribed inoculation (doses). Vaccination requirements are dependent upon location and position, please refer to the job description for more details.
Individuals in positions requiring vaccinations may seek a medical and/or religious exemption from this requirement and may be granted such an accommodation after submitting a formal request to and the subsequent review and approval thereof by our dedicated Covid-19 Response team.
To all recruitment agencies: Lucid Motors does not accept agency resumes. Please do not forward resumes to our careers alias or other Lucid Motors employees. Lucid Motors is not responsible for any fees related to unsolicited resumes.",glassdoor
80,"Autodesk
4.2
Data Engineer
San Francisco, CA
$116K - $169K (Glassdoor est.)

 Job Requisition ID #
22WD64738
Position Overview
Autodesk is looking for a talented Data Engineer to join our Observability Analytics team to create robust and scalable data pipelines using and improving existing platforms.

A successful candidate has a strong sense of ownership and will use their expertise to build extensible data models, provide meaningful recommendations and actionable strategies to partnering data scientists. They will drive performance enhancements, development best practices and collaborate with other Data Engineering teams throughout Autodesk.

Responsibilities
Create, automate, and support reliable data pipelines
Gather customer requirements, sequence work and document technical solutions
Interface with data engineers, data scientists, product managers and internal stakeholders
Cross-train and mentor teammates

Minimum Qualifications
3+ years of data processing experience in large cloud-based infrastructure (AWS preferred)
Familiar with SQL, dimensional modeling, and analytical data warehouses, like Snowflake
Understanding of Data Engineering best practices for medium to large scale production workloads
Hands-on software development experience in Python
Experience with data pipeline orchestration tools, like Airflow
Customer-facing and service-oriented person
Team player with great communication skills
Problem solver with excellent written and interpersonal skills
Experience consuming REST APIs

Preferred Qualifications
Experience with ELT pipelines - DBT
REST API design and implementation
Familiarity with containers and infrastructure-as-code principles
Experience with automation frameworks - Git, Jenkins, and Terraform
#LI-POST
At Autodesk, we're building a diverse workplace and an inclusive culture to give more people the chance to imagine, design, and make a better world. Autodesk is proud to be an equal opportunity employer and considers all qualified applicants for employment without regard to race, color, religion, age, sex, sexual orientation, gender, gender identity, national origin, disability, veteran status or any other legally protected characteristic. We also consider for employment all qualified applicants regardless of criminal histories, consistent with applicable law.
Are you an existing contractor or consultant with Autodesk? Please search for open jobs and apply internally (not on this external site). If you have any questions or require support, contact
Autodesk Careers
.",glassdoor
81,"GovDocs
4.4
Data Engineer
Remote
Employer Provided Salary:$90K - $120K

 Flexible Work Model:
We believe that the best way for us to grow, is through a work environment that allows us more flexibility whereby employees can be together in the office where interactions can happen with higher frequency and effectiveness (collaboration and team-engagement) – especially when dealing with complex problems and business innovation, balanced with work-from-home where we have more focused, uninterrupted time with minimal distractions for dedicated project/productive work.
Best Places to Work 2021:
GovDocs was named one of the 2021 Best Places to Work by the Minneapolis/St. Paul Business Journal!
Being named an honoree was no easy feat, as they received over 300 nominations for this year’s award. GovDocs was one of the top-scoring Minnesota businesses honored in the medium company category (50-250 employees) for creating a fun, challenging, and rewarding workplace.
Read more about GovDocs as Best Places to Work 2021 here: https://bizj.us/1qbeau
Position Summary:
We are looking for a savvy Data Engineer to join our growing engineering team. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, and business systems team on data analytics and reporting initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.
Responsibilities:
Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Azure Data Lake technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Qualifications:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Understanding of non-relational databases such as MongoDB desired
Experience building and optimizing ‘big data’ data pipelines, architectures, and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Ability to build processes supporting data transformation, data structures, metadata, dependency, and workload management.
A successful history of manipulating, processing, and extracting value from large, disconnected datasets.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
Strong critical thinking, decision making, troubleshooting and problem-solving skills
Excellent oral and written communication skills
We are looking for a candidate with 3+ years of experience in a Data Engineer role. Bachelor’s Degree in Computer Science, Statistics, Informatics, Information Systems, or another quantitative field a plus.
Technical Experience/Skills Required:
Experience in Azure Ecosystem (Azure Data lake, Azure Data Factory, Azure Data Bricks, Azure Storage, Cosmos DB, ADO)
Understanding and experience working with Microsoft Azure DevOps (work items, build/release, CICD)
Experience in Database Analysis and modern warehousing technologies
Understanding of code development best practices, process design and automation, security concepts, Agile concepts, tools, and technologies
Knowledge on Data Ingestion/ streaming tooling such as Kafka, Spark, or similar technologies
Familiarity with DevOps landscape, processes, standards, and tools
Experience in Agile frameworks and methodologies (Atlassian, Azure DevOps), Software Development Lifecycle (SDLC) experience is a plus.
Strong understanding of data Ingestion, data transformation, data management, data quality, and data lineage services and technologies
Compensation
This position is critical to the success of our business and the compensation package will be commensurate with candidate's experience and skills. Compensation will include base salary and performance-based incentives. Benefits include paid vacation, paid volunteer time and paid holidays, medical and dental, and matching 401(k).
Company Description
GovDocs serves companies in building and executing their employment law compliance programs in two primary ways:
Employment Law Posting Service: We manage all the complexities of identifying and providing the required set of employment law postings from the 1,700+ potential postings across the U.S. and Canada. Using proprietary technology, we allow companies to manage, track and verify postings at each of their locations – including our patent pending PosterCheck technology. Our Employment Law Posting Update service is used by almost 22% of the Fortune 500 and 30% of the Fortune 100.
Employment Law Compliance Software Solutions: This is a first to market Software-as-a-Service starting with our Minimum Wage product and Paid Leave products, which allow companies to identify and track which laws apply to their locations and employees, then provides all relevant data to make decisions. This service was created in response to requests from some of our largest customers who recognized that employment law expansion across and variances between jurisdictions (Federal, State and Local) were too difficult to manually track.
GovDocs has grown revenue annually by 18% since 2008 with a 96% customer retention rate, primarily due to our Postings Update Program both obtaining and retaining customers – as employment law postings are required by law, every company has an existing provider. Our Software Solutions are an entirely new line of business that gives us great growth potential to create a full Employment Law Compliance (ELC) platform of solutions, it is also challenging us to reinvent how we view urgency, innovation and teamwork.
You must be authorized to work in the United States. Immigration or work visa sponsorship will not be provided. In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire
Job Type: Full-time
Pay: $90,000.00 - $120,000.00 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Employee assistance program
Flexible schedule
Flexible spending account
Health insurance
Health savings account
Life insurance
Paid time off
Vision insurance
Schedule:
8 hour shift
Day shift
Monday to Friday
Supplemental pay types:
Bonus pay
COVID-19 considerations:
Flexible work model with working from home options. We take action to protect the health and well-being of our colleagues by regular review of Covid-19 statistics and health guidelines.
Application Question(s):
Will you now or in the future require sponsorship for employment visa status?
What are your compensation requirements?
Experience:
Data Engineering: 5 years (Preferred)
Work Location: Remote",glassdoor
82,"Pinterest
4.1
Data Engineer
Remote

 About Pinterest:
Millions of people across the world come to Pinterest to find new ideas every day. It's where they get inspiration, dream about new possibilities and plan for what matters most. Our mission is to help those people find their inspiration and create a life they love. In your role, you'll be challenged to take on work that upholds this mission and pushes Pinterest forward. You'll grow as a person and leader in your field, all the while helping Pinners make their lives better in the positive corner of the internet.
Our new progressive work model is called PinFlex, a term that's uniquely Pinterest to describe our flexible approach to living and working. Visit our PinFlex landing page to learn more.
The Enterprise Data Platform team is looking for a Data Engineer who has experience with Building Data Pipelines and Managing/Developing on any Cloud Data Warehouse. In this role you will also advise other Data Analysts and Data Engineers from the Business teams at Pinterest on the best practices for handling data and deriving insights using Snowflake. You will gradually become the Subject Matter Expert on Snowflake and also help build out the Modern Data Stack at Pinterest.
What you'll do:
Build Data Pipelines using Python on either Airflow or AWS Lambda to ingest data into Snowflake
Build Scripts in Python to manage Data Access on Snowflake
Define and advocate the best practices for storing and analyzing data inside Snowflake
Review the Data Modeling practices of other teams
What we're looking for:
Strong skills in Python and SQL
Experience with Building Data Pipelines in Python
Experience with any Cloud Data Warehouse either as an Administrator or a Developer
Strong Data Modeling skills
#LI-BB1
#LI-Remote
Our Commitment to Diversity:
At Pinterest, our mission is to bring everyone the inspiration to create a life they love—and that includes our employees. We’re taking on the most exciting challenges of our working lives, and we succeed with a team that represents an inclusive and diverse set of identities and backgrounds.

Not Specified
0",glassdoor
83,"Dataquestcorp
Data Science Engineer
Branchburg, NJ
Employer Provided Salary:$75K - $80K

 Job Role: Data Science
Note: Please don't apply C2C profiles. its only w2 positions
Benefits:
Free Training and placement.
Training provided by highly qualified, industry-experienced & certified instructors.
We do provide free accommodations & Relocation charges.
H1B Sponsorship
We do support for STEM OPT and GC processing.
Health Insurance
Relocation Assistance any where in USA.
Free accommodation.
Location: Branchburg, NJ
Job Types: Full-time, Contract
Job Types: Full-time, Contract
Salary: $75,000.00 - $80,000.00 per year
Benefits:
Schedule:
8 hour shift
Ability to commute/relocate:
Branchburg, NJ: Reliably commute or planning to relocate before starting work (Required)
Experience:
Python: 1 year (Preferred)
SQL: 1 year (Preferred)
Work Location: One location
Speak with the employer
+91 9089927715",glassdoor
84,"Apple
4.2
Machine Learning Data Collection Engineer, Technology Development Group (TDG)
Cupertino, CA

 Summary
Posted: Mar 15, 2022
Role Number:200356922
Do you want to push the limits of the best Augmented Reality platform in the world? Apple's Technology Development Group (TDG) delivers algorithms that drive revolutionary Apple products, including the augmented reality (AR) platform ARKit to create ground-breaking new products. In this position, you will have the opportunity to be part of our extraordinary data team to discover and build solutions to previously-unsolved challenges and push the state of the art in AR algorithms that will change the way people experience the world! We are looking for a driven Machine Learning Data Collection Engineer that enjoys getting into the details to collect valuable data that feeds our machine learning models. As a member of the fast-paced data team, you have the rewarding opportunity to shape upcoming products that will delight and inspire millions of people every day. To succeed within this role, you should have shown experience in several of the following areas:
Key Qualifications
Ability to define/design/develop data collection efforts that focus on the end-to-end user experience, including anticipating potential failure modes, edge cases, and anomalies
Capacity to multitask and manage several projects in parallel while meeting deadlines and providing access to clients and partners
Problem solving & critical thinking capacities, thinking outside the box in order to gain in speed, efficiency, and quality.
Ability to re-construct ill-defined data needs into concrete project deliverables
Ability to maintain and develop relationships with multi-functional teams
Excellent project management, communication, interpersonal, analytical, and organizational skills
Description
As a Machine Learning Data Collection Engineer, you'll be working with our customers to understand their data collection requirements, assisting them in defining their protocols, and executing on the data collection. Your job responsibilities will include: -Collaborate with algorithm teams and understand data collection requirements in order to define collection protocols -Define and design the collection requirements and lead the collection effort from start to finish -Coordinate the efforts between internal teams (Legal, privacy, security, etc) guaranteeing compliance with applicable rules, laws, and best practices -Create documents and procedures needed to run data collections -Managing and track progress of externally run data collections
Education & Experience
Bachelors degree or related practical experience
Additional Requirements",glassdoor
85,"Realign LLC
4.5
Data Engineer
California

 Job Type: Contract
Job Category: IT
Job Description
Write and optimize queries, provide input on peer code reviews and data modeling, deploy data
updates via continuous integration / deployment (CI/CD) practices.

Collaborate with software developers, other data engineers, and database architects on projects to
ensure optimal data delivery following appropriate change management guidelines.

Collaborate with software and reliability engineers to automate repeatable data tasks.

Work with development and production support teams to troubleshoot data, application, and service
deployment issues.

Develop detailed, shared technical procedure documentation, including processes for contingency
operations.

Research, provide technical input, document, and implement new technology solutions.

Implement necessary patches, hotfixes, service packs, cumulative updates, upgrades, and
configuration change to maintain security compliance and application integrity.

Required Skills
Big Data Engineer",glassdoor
86,"Accenture
4.1
Data Engineer
San Francisco, CA

 Accenture Flex offers you the flexibility of local fixed-duration project-based work powered by Accenture, a leading global professional services company. Accenture is consistently recognized on FORTUNE's 100 Best Companies to Work For and Diversity Inc's Top 50 Companies For Diversity lists.
As an Accenture Flex employee, you will apply your skills and experience to help drive business transformation for leading organizations and communities. In addition to delivering innovative solutions for Accenture's clients, you will work with a highly skilled, diverse network of people across Accenture businesses who are using the latest emerging technologies to address today's biggest business challenges.
You will receive competitive rewards and access to benefits programs and world-class learning resources. Accenture Flex employees work in their local metro area onsite at the project, significantly reducing and/or eliminating the demands to travel.
Job Description:
As a Data Engineer, you will:
Utilize strong SQL & Python expertise to engineer sound data pipelines and conduct routine and ad hoc analysis to assess the performance of legacy products and the saliency of new features
Build reporting dashboards and visualizations to design, create, and track campaign/program KPIs
Perform analyses on large data sets to understand drivers of marketing engagement and provide recommendations on campaign and product optimization

Basic Qualifications:
Minimum 2 years of experience in Data Engineering
Minimum 2 years of experience with SQL
Minimum 2 years of experience with Python
High School Diploma or GED
Preferred Qualifications:
Experience with Data Analytics
As required by Colorado Law under the Equal Pay for Equal Work Act, Accenture provides a reasonable range of compensation for roles that may be hired in Colorado. Actual compensation is influenced by a wide array of factors including but not limited to skill set, level of experience, and specific office location. For the state of Colorado only, the starting range of pay for this role is $86.82 - $96.82 per hour, and information on benefits is here.

COVID-19 update:

The safety and well-being of our candidates, our people and their families continues to be a top priority. Until travel restrictions change, interviews will continue to be conducted virtually.

Subject to applicable law, please be aware that Accenture requires all employees to be fully vaccinated as a condition of employment. Accenture will consider requests for accommodation to this vaccination requirement during the recruiting process.

What We Believe

We have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture has the responsibility to create and sustain an inclusive environment.

Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more here

Equal Employment Opportunity Statement

Accenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation.

All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.

Accenture is committed to providing veteran employment opportunities to our service men and women.

For details, view a copy of the Accenture Equal Opportunity and Affirmative Action Policy Statement.

Requesting An Accommodation

Accenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.

If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.

Other Employment Statements

Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States.

Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.

Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.

The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.",glassdoor
87,"National Research Group
3.7
Data Engineer
San Francisco, CA
$88K - $128K (Glassdoor est.)

 Who We Are
National Research Group (NRG) is a leader in data driven insights and strategic consultation to the global entertainment and technology industries. Working at the confluence of technology, content, and culture, NRG offers bold insights for storytellers everywhere. Our consultants have experience working across all facets of media and technology.
Why You'll Love It Here
We are inspired by working with storytellers that challenge us to think differently and see the world in new ways. As a result, our business is driven by creative, curious, and inventive people who have a passion for pop culture. We work as a collective across disciplines and geographies to bring together the best thinking for every assignment, delivering insights to bold storytellers everywhere.
The Opportunity
We are looking for a data engineer with a background in building and maintaining data pipelines to integrate and process diverse data sources and data formats. This candidate should have a minimum of 1-year experience for a full-time position within our fast paced and growing company.
If you feel that you can make an impact through innovation and collaboration and come to work with a passion to facilitate in delivering high quality data to our teams and clients, this is a great role for you.
The Role
Build, test, orchestrate, and maintain data pipelines that support the data sciences team and customer-facing client teams.
Assist in ad-hoc data deliveries by querying data from various SQL relational databases stored in multiple data models.
Track and manage pipeline efficiency and stability.
Evaluate, parse, clean, and integrate raw data sets including third party APIs. Help build sophisticated ETL processes around first party data such as survey data, second and third-party data sources such as IP addresses, clickstream data, movie meta data.
Provide recommendations for data storage, configurations, data access tools and new technologies/architectures.
Develop code-based data transformation/aggregation in data lakes, relational databases (primary use cases) and possibly non-relational databases, as well as for the purpose of BI tools such as Power BI and Tableau.
Participate in developing data APIs for data ingestion of NRG data into client-side applications or client-side data systems.
Assist application developers in the effective use of database query and programming languages.
Contribute to managing data integrity, data storage efficiency and data ecosystem efficiency.
Who You Are
Team asset who can describe data structures, relationships, and flows behind organization database servers and applications.
Up to date on the latest data-related best practices and technologies and always looking to learn more.
Internally motivated self-starter who continuously strives to get things done, regardless of challenges encountered.
Critical thinker, able to understand and respond to complex questions or issues that may arise, and able to demonstrate willingness to experiment with new technologies.
Successfully manages time and multiple competing priorities in order to ensure deadlines are always met.
Team player who is able to work collaboratively and initiate and drive projects to completion with minimal oversight.
Ideal Candidate
BS/BA in Computer Science or related field.
1+ year experience in building data pipelines or ETL.
1+ year experience with SQL (we use Snowflake but other experience with relational databases is welcome).
1+ year experience with AWS technologies/infrastructure.
Working knowledge with Python.
A solid foundation with end-to-end development and the desire to further their technical knowledge.
Knowledge of PII (personally identifiable information) data security standards is a plus.
dbt experience is a plus.
Terraform experience is a plus.
Dagster experience is a plus.
Experience in databases structured against survey data is a big plus.
Position Type
This is a full-time, exempt position.
Work Environment
This position is expected to be fully remote. However, NRG offers flexible work options if an employee happens to live near a dedicated office (Playa Vista or New York) and wants a hybrid work model. This role routinely uses standard office equipment.
Required Application Materials:
CV/Resume
Cover Letter which should include:
Why do you want to work at NRG?
Why are you interested in working in the entertainment industry?",glassdoor
88,"Tesla
3.6
Data Engineer
Fremont, CA

 What to Expect
The Data Engineer is responsible for processing structured and unstructured data, validating data quality, and developing and supporting data products. We are looking for someone with strong hands on experience in all layers of data Integration and analytics! We especially need experience in using Python as an ETL tool. The Data Engineer plays a significant role in Agile planning, providing advice and guidance, and monitoring emerging technologies. Some of the technology we use: * Python * Informatica * SQL Server and MySQL * Vertica * Kafka

What You’ll Do
* Design, code, test, correct and document programs and scripts using agreed standards and tools to achieve a well-engineered result * Derive an overall strategy of data management, within an established information architecture that supports the development and secure operation of existing and new information and digital services * Plan effective data storage, security, sharing and publishing within the organization * Gathers and processes raw, structured, semi-structured, and unstructured data using batch and real-time data processing frameworks * Ensures data quality and implements tools and frameworks for automating the identification of data quality issues * Collaborate with internal and external data providers on data validation providing feedback and making customized changes to data feeds and data mappings * Mentor and lead data engineers providing technical guidance and oversight * Provides ongoing support, monitoring, and maintenance of deployed products

What You’ll Bring

* Strong experience with relational databases like SQL Server, MySQL and Vertica. NoSQL databases experience is a plus! * Strong background in data modeling, data access, and data storage techniques * Experience with design, development, and implementation of highly scalable, high-volume software systems and components, source of truth systems for different business areas, developing and maintaining web services in an agile environment * Working experience with Kafka Streaming layer * Experience in Spark Framework on both batch and real-time data processing is a plus * Experience in Big Data Integration & Analytics is a plus * Experience in Supply Chain and Logistics data is a plus",glassdoor
89,"Blue Cross and Blue Shield of North Carolina
4.1
Data Engineer
Remote

 Additional Locations:
Full Time Remote - Alabama, Full Time Remote - Alabama, Full Time Remote - Arizona, Full Time Remote - Arkansas, Full Time Remote - Florida, Full Time Remote - Georgia, Full Time Remote - Idaho, Full Time Remote - Indiana, Full Time Remote - Iowa, Full Time Remote - Kansas, Full Time Remote - Kentucky, Full Time Remote - Louisiana, Full Time Remote - Maryland, Full Time Remote - Michigan, Full Time Remote - Mississippi, Full Time Remote - Missouri, Full Time Remote - Ohio, Full Time Remote - Oklahoma, Full Time Remote - Pennsylvania, Full Time Remote - South Carolina, Full Time Remote - South Dakota, Full Time Remote - Tennessee, Full Time Remote - Texas, Full Time Remote - Utah, Full Time Remote - Virginia {+ 1 more}
Job Description
IT is different here. Our work as technology specialists pushes the boundaries of what’s possible in health care. You will build solutions that make a real difference in people’s lives. Driven by the importance of their work, our team members innovate to elevate. We’re encouraged to be curious, collaborate, and turn ideas into solutions that transform this space.

In this role you will work closely with senior engineers, data scientists and other stakeholders to design and maintain moderate to advanced data models. The Data Engineer is responsible for developing and supporting advanced reports that provide accurate and timely data for internal and external clients. The Data Engineer will design and grow a data infrastructure that powers our ability to make timely and data-driven decisions. You will support Membership Operations, Customer Service Operations, Digital & Consumer Experience teams.

If you are ready to make a career out of making a difference, then you are the person for this team.
What You’ll Do
Define and extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes
Document, and test moderate data systems that bring together data from disparate sources, making it available to data scientists, and other users using scripting and/or programming languages
Write and refine code to ensure performance and reliability of data extraction and processing
Participate in requirements gathering sessions with business and technical staff to distill technical requirement from business requests
Develop SQL queries to extract data for analysis and model construction
Own delivery of moderately sized data engineering projects
Design and develop scalable, efficient data pipeline processes to handle data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets to analysts and data scientists
Ensure performance and reliability of data processes
Document and test data processes including performance of through data validation and verification
Collaborate with cross functional team to resolve data quality and operational issues and ensure timely delivery of products
Develop and implement scripts for database and data process maintenance, monitoring, and performance tuning
Analyze and evaluate databases in order to identify and recommend improvements and optimization
Design eye-catching visualizations to convey information to users
What You Will Bring
Bachelor’s degree and 3 years of experience with Oracle, Data Warehouses and Data Lakes, Big Data platforms and programming in Python, R or other related language.
In lieu of degree, 5 years of the experience as stated above.
SQL and Python scripting
Experience in a cloud environment
Experience with Ab Initio or other ETL tools",glassdoor
90,"Apple
4.2
Data Engineer
Cupertino, CA

 Summary
Posted: Aug 10, 2022
Weekly Hours: 40
Role Number:200406892
Are you a big-picture thinker who loves setting ambitious goals? Do you have a passion for understanding how each line of code affects all the others? In the Core Operating Systems group, you’ll ensure the OS is inseparable from each device’s identity as a whole. That’s because this group is committed to building fully integrated operating systems that combine hardware, software, and apps into a single Apple experience. Your dedication to cross-disciplinary collaboration will help develop groundbreaking technologies, such as iOS, macOS, watchOS, and tvOS. By crafting these distinct, holistic user experiences, you’ll continue to uphold and advance the excellence people expect from Apple devices. The Platform Services & Operations team in Core OS is looking for a Data Engineer to inform and develop essential workflow tooling at scale. The Workflow Engineering team enable teams to deliver high quality software through best in class engineering experiences, efficient workflow, data driven insights, and a culture of continuous improvement. Your focus is building the backend data pipelines that enables visualization of data across the organization in user intuitive and configurable formats.
Key Qualifications
3 +proven experience in a Data focused posistion
Proficient in Python; data access and retrieval. Quantitative data preparation. Regular expressions and text analysis
Highly Proficient in Database Language and Design; querying large stores of data (APIs, SQL, etc.).
Access, retrieval, and storage of information. Data Structures, modeling for speed and efficiency
Software Development; understanding of build pipelines, branching and merging, Agile methods, and the delivery of code. Fluency in Git (or comparable source control tool)
Description
- Replicate data from source system into data warehouse; retrieve data through various protocols and land it in a central store - Automate data pipelines; write programs to periodically update warehouse data from source systems - Design for scale; flexible infrastructure for common enhancements including: expanding the volume of captured data, adding fields to the user-facing views, and recompiling archived data - Work with a team of data scientists and full stack engineers, to derive and develop targeted insights through centrally managed interactive dashboards
Education & Experience
B.S. in Data Science, Computer Science, or equivalent experience.
Additional Requirements
Experience as an Analyst; worked in the delivery of visual information (dashboards, reports, web-apps)
An understanding of how data can be used and applied in context (what is useful to capture and how it can be communicated)
Full Stack Development; ability to maintain back-end systems and visualize front-end data for users (with a web-kit framework like Angular, React)
Experience with Snowflake and/or other data store technologies",glassdoor
91,"Zscaler
4.5
Data Engineer
San Francisco, CA
$99K - $143K (Glassdoor est.)

 Company Description

Zscaler (NASDAQ: ZS) accelerates digital transformation so that customers can be more agile, efficient, resilient, and secure. The Zscaler Zero Trust Exchange is the company’s cloud-native platform that protects thousands of customers from cyberattacks and data loss by securely connecting users, devices, and applications in any location.
With more than 10 years of experience developing, operating, and scaling the cloud, Zscaler serves thousands of enterprise customers around the world, including 450 of the Forbes Global 2000 organizations. In addition to protecting customers from damaging threats, such as ransomware and data exfiltration, it helps them slash costs, reduce complexity, and improve the user experience by eliminating stacks of latency-creating gateway appliances.
Zscaler was founded in 2007 with a mission to make the cloud a safe place to do business and a more enjoyable experience for enterprise users. Zscaler’s purpose-built security platform puts a company’s defenses and controls where the connections occur—the internet—so that every connection is fast and secure, no matter how or where users connect or where their applications and workloads reside

Job Description

Position: Data Engineer
Location: Remote within United States
About the team: As part of the IT group, we are responsible for executing our enterprise data strategy which emphasizes data management maturity, fosters a robust data culture, and architects a best-in-class enterprise data platform. We have the ultimate goal to provide trusted data and insights at scale which enable corporate and functional data-driven decision making. We are fueled by organic innovation, internal collaboration and adoption of data visualization, data management, reporting automation, AI/ML and integration tools. We leverage best practices and alignment through our Enterprise Data Community to deliver speed to insight, scale, control and enablement. The team is distributed across the United States and India and is composed of data engineers, data analysts, visualization developers, and infrastructure specialists.
Responsibilities/What You’ll Do:
Collaborate with Data & Technical architects, integration and engineering teams to capture inbound/outbound data pipeline requirements, conceptualize and develop solutions
Support the evaluation and implementation of the current and future data applications/technologies to support the evolving Zscaler business needs
Collaborate with IT business engagement & applications engineer teams, enterprise data engineering and business data partner teams to identify data source requirements
Profile and quantify quality of data sources, develop tools to prepare data and build data pipelines for integrating into Zscaler’s data warehouse in Snowflake
Continuously optimize existing data integrations, data models and views while developing new features and capabilities to meet our business partners needs
Work with Principal Engineer/ Data Platform Lead to design and implement data management standards and best practices
Continue to learn and develop next generation technology/ data capabilities that enhance our data engineering solutions
Develop large scale and mission-critical data pipelines using modern cloud and big data architectures

Qualifications

Qualifications/Your Background:
3+ years of experience in data warehouse design & development
Strong experience in integrating internal and external business applications (salesforce, netsuite, google analytics etc) with cloud data platforms like Snowflake
Proficiency in SQL and ability to perform complex modeling with large volumes of data
Experience with Big Data technologies like Hadoop
Required Experience with any industry standard ETL & data integration platforms like Matillion, Workato, Dell Boomi
Experience with data orchestration to like Apache Airflow a plus
Experience with resolving workflow and data quality issues associated with production grade large scale cloud systems
Strong capacity to manage multiple projects simultaneously
Experience with Python, Dbt or similar a plus

Additional Information

All your information will be kept confidential according to EEO guidelines.
#LI-YC2
#LI-Remote
What You Can Expect From Us:
An environment where you will be working on cutting edge technologies and architectures
A fun, passionate and collaborative workplace
Competitive salary and benefits, including equity
Why Zscaler?

People who excel at Zscaler are smart, motivated and share our values. Ask yourself: Do you want to team with the best talent in the industry? Do you want to work on disruptive technology? Do you thrive in a fluid work environment? Do you appreciate a company culture that enables individual and group success and celebrates achievement? If you said yes, we’d love to talk to you about joining our award-winning team.

Additional information about Zscaler (NASDAQ: ZS ) is available at https://www.zscaler.com.
Zscaler is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.",glassdoor
92,"Netflix
4.3
Data Engineer (L5) - Games
Los Gatos, CA
$108K - $193K (Glassdoor est.)

 Los Gatos, California
Data Science and Engineering
Now is an amazing time to join Netflix as we seek to entertain the world. We have over 200 million paid members in over 190 countries, and we won’t stop there. Games are our next big frontier and an incredible opportunity for us to deliver new experiences to delight and entertain our quickly growing membership. You will be jumping in at the very beginning of this adventure and be in a position to help us redefine what a Netflix subscription means for our members around the world.
Data Science and Engineering (‘DSE’) at Netflix is aimed at using data, analytics, and sciences to improve various aspects of our business. We are looking for a Data Engineer to join our Games DSE team, supporting end-to-end analytics & data needs for our games portfolio. This role will be partnering closely with our Game stakeholders to develop software and data solutions that enable analysis across the entire library of games.
As part of this team, you will work on diverse data technologies such as Spark, Presto, Flink, Kafka, and others to build insightful, scalable, and robust data pipelines that feed directly into our key gaming dashboards; write ETL jobs to collect and aggregate data; and build high-quality data models that represent how games are performing on Netflix.
The ideal candidate will also have a background in games, with a solid knowledge of how standard industry metrics are computed.
Who You Are:
7+ years of software/data engineering experience working with video game analytics (i.e you are familiar with how key metrics such as DAU, MAU and retention rates are computed in an ETL).
Passionate about building intuitive data models and an expert in distributed data processing patterns.
Highly proficient in at least one of these programming languages: Java, Python, or Scala.
Comfortable with complex SQL.
Expert in engineering data pipelines using big data technologies (Hive, Presto, Spark, Flink) on large-scale data sets demonstrated through years of experience.
Conceptually familiar with AWS cloud resources (S3, EC2, RDS etc).
Excel at taking vague requirements and crystallizing them into scalable data solutions.
Excited about operating independently, demonstrating excellence, and learning new technologies and frameworks.
What will you do?
Engineer efficient, adaptable, and scalable data pipelines in Spark and Python/Scala to process structured data into aggregate datasets that feed all games portfolio dashboards.
Become an expert in games metrics at Netflix - act as a thought partner to the games analytics team, understand their challenges, and help them to put the right data in front of our stakeholders.
Maintain and rethink existing datasets and pipelines to service a wider variety of use cases.
Join a stunning team of data engineers with diverse skill sets, partnering closely with analytics engineering and data science counterparts.
Netflix Culture
Our culture is unique, and we live by our values. For more information on what it's like to work at Netflix, please take a look at our culture memo.",glassdoor
93,"Twitch
4.0
Data Engineer
San Francisco, CA
Employer Provided Salary:$140K - $171K

 About Us
Twitch is the world's biggest live streaming service, with global communities built around gaming, entertainment, music, sports, cooking, and more. It's where millions of people come together to chat, interact, and make their own entertainment.
We're about community, inside and out. You'll find coworkers who are eager to team up, collaborate, and smash (or elegantly solve) problems together. We're on a quest to empower live communities, so if this sounds good to you, see what we're up to on LinkedIn and Twitter, get interviewing tips on Instagram, and discover projects we're solving on our Blog.
About the Role
Reporting to the Head of Global Talent Acquisition, the Data Engineer will expand the reach and role of data among leaders and managers at Twitch. You will empower the business to integrate data into their daily workflow by creating/maintaining data pipelines, producing reporting, and automating our processes.
You can work in San Francisco, CA or remotely across the US.
This role is for you if:
You love automating processes and developing efficient scalable solutions
You're excited about contributing to the success, efficiency, and happiness of Twitch staff
You're excited to jump into a diverse array of data work to support the team
You enjoy working with autonomy and shaping a new function

You Will:
Delight consumers of people-related data by ensuring they have the data they need to inform decisions, where and when they need it
Build and own data pipelines, SQL queries/views, and apps
Automate processes through the use of JavaScript and other languages
Improve business, engineering, and data processes through data architecture, engineering, testing, and operational excellence best practices
Ensure the integrity of People and Places data in analyses and tools through regular audits
Partner to develop analytics products and recommend opportunities
Develop ongoing metrics, analyses, and dashboards to guide important decisions
You Have:
Experience writing SQL and a procedural language (Python, R, etc.) for data handling
Experience owning systems that collect, transform, and visualize data
Experience implementing data analytics, visualization tools and programs for HR working with Workday, Greenhouse, Tableau, Google Workspace, Google Data Studio, and Google Sheets
Experience implementing software solutions to automate data source, visualization and analytics products
Bachelors in related field, or equivalent experience
Bonus Points
Experience handling People-related data including compensation, performance, hiring, and engagement data.
Experience automating Google services (Sheets, Docs, Data Studio) with Javascript
Experience with Workday, Greenhouse, and Tableau
Demonstrated net positive contributor to company community and culture above and beyond the core job
Perks
Medical, Dental, Vision & Disability Insurance
401(k), Maternity & Parental Leave
Flexible PTO
Commuter Benefits
Amazon Employee Discount
Monthly Contribution & Discounts for Wellness Related Activities & Programs (e.g., gym memberships, off-site massages, etc.),
Breakfast, Lunch & Dinner Served Daily
Free Snacks & Beverages
We are an equal opportunity employer and value diversity at Twitch. We do not discriminate on the basis of race, religion, color, national origin, gender, gender identity, sexual orientation, age, marital status, veteran status, or disability status, or other legally protected status.
Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
Pursuant to the Los Angeles Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
The base pay range for this position in Colorado, Connecticut and Washington is $139,860 - $170,940 yr and in New York City is $153,900 - $188,100 yr. Pay is based on market location and may vary depending on job-related knowledge, skills, and experience. A sign-on payment and restricted stock units may be provided as part of the compensation package, in addition to a full range of medical, financial, and/or other benefits, dependent on the position offered. Applicants should apply via Twitch's internal or external careers site.
Workers in New York City who perform in-person work or interact with the public in the course of business must show proof they have been fully vaccinated against COVID or request and receive approval for a reasonable accommodation, including medical or religious accommodation.
Twitch values your privacy. Please consult our Candidate Privacy Notice, for information about how we collect, use, and disclose personal information of our candidates.
Job ID: TW7236
#LI-Remote #RemoteFriendly",glassdoor
94,"IDEXX
3.6
Data Engineer
Westbrook, ME
Employer Provided Salary:$95K - $105K

 As a Data Engineer , you will create data pipelines on our next-generation database build. You will assist with building robust, fault-tolerant data pipelines that collect, assemble, transform and aggregate distributed data into databases, operational data stores, data integration hubs, and data lakes. You will compile and install scalable cloud-based database systems and prepare data for analytical and operational uses. You will work to lay the groundwork for data consumers to easily retrieve and examine data sets to glean knowledge and insights.

IT Data Engineering is responsible for designing and developing enterprise data collection, aggregation, and access systems for IDEXX's global business environment. We work with traditional data architectures such as enterprise data warehousing and larger cloud-based data centralization systems like data integration hubs. Our products are used to synchronize billions of data points between enterprise applications such as global ERP and CRM applications, collect and normalize reference lab results and clinical utilization, and create easy-to-access data sources for enterprise analytics, sales enablement tools, and data science initiatives.
Our team includes a range of data engineers, data architects, and data-centric business system analysts, with a heavy focus on cloud-based ""big data"" projects. Some team members provide knowledge and support over our traditional data warehouse applications, building upon these environments with SQL and traditional ETL methods. At the same time, our newest technology addition expands our data models via Snowflake, bringing the best of cloud scale and compute capabilities, along with long-lived data engineering practices.

Our stack: AWS, Snowflake, Oracle, MySQL, Python, Informatica

In this role:
Using multiple technologies, you will design and implement scalable, reliable distributed data processing frameworks and analytical infrastructure.
You will define, design, and implement data integration, management, storage, consumption, backup, and recovery solutions that ensure the high performance of the organization's enterprise data.
You will develop Structured Query Language (SQL), Data Definition Language (DDL), and Python or equivalent programming scripts to support data pipeline development, problem-solving, data validation, and performance tuning.
You will adhere to and contribute to naming conventions, data governance practices, and thourough testing standards.
You will document data design tasks or project requirements.
You will implement measures to ensure data accuracy and accessibility.
You will identify and resolve data-oriented problems, such as missing, duplicate or incorrect data.
You will monitor performance and utilization.
You will guide data design and requirements to other development and business teams.
You will propose or develop semantic layer features for the enterprise model.
You will provide ongoing maintenance and process improvements for data initiatives.

What you will need to succeed:
You have a bachelor's degree or equivalent combination of education and relevant experience.
You have experience with relational databases such as Oracle, MySQL, and Snowflake.
You are proficient in coding and programming languages such as Structured Query Language (SQL) and Python.
You have experience with data integration/ETL tools such as Informatica PowerCenter or Sesame Relational Junction.
You are familiar with cloud platforms such as Amazon Web Services (AWS).
You understand data warehousing solutions and relational database theory.
You have good verbal and written communication skills and can translate technical subject matter to non-technical audiences (both as a speaker and listener).
You take the initiative in resolving problems and can balance conflicting requirements in partnership with others.
You excel at customer service and building relationships with businesses.
You excel at planning and organizing your work and can prioritize and be flexible with changing business needs.
You are a self-starter and can work on your own and in teams.
You can solve problems and draw conclusions, in some cases, with limited information.
You worked with Agile software development methodology.

What you can expect from us:
Base annual salary target: $95000 -$105000 (yes, we do have flexibility if needed)
Opportunity for annual cash bonus
Health / Dental / Vision Benefits Day-One
5% matching 401k
Additional benefits include but are not limited to financial support, pet insurance, mental health resources, volunteer paid days off, employee stock program, foundation donation matching, and much more!

Why IDEXX
We’re proud of the work we do, because our work matters. An innovation leader in every industry we serve, we follow our Purpose and Guiding Principles to help pet owners worldwide
keep their companion animals healthy and happy, to ensure safe drinking water for billions, and to help farmers protect livestock and poultry from disease. We have customers in over 175 countries and a global workforce of over 9,000 talented people.
So, what does that mean for you? We enrich the livelihoods of our employees with a positive and respectful work culture that embraces challenges and encourages learning and discovery. At IDEXX, you will be supported by competitive compensation, incentives, and benefits while enjoying purposeful work that drives improvement.
Let’s pursue what matters together.

IDEXX values a diverse workforce and workplace and strongly encourages women, people of color, LGBT individuals, people with disabilities, members of ethnic minorities, foreign-born residents, and veterans to apply.
IDEXX is an equal opportunity employer. Applicants will not be discriminated against because of race, color, creed, sex, sexual orientation, gender identity or expression, age, religion, national origin, citizenship status, disability, ancestry, marital status, veteran status, medical condition, or any protected category prohibited by local, state, or federal laws.

EOE/Minority/Female/Disabled/Veteran

#LI-REMOTE",glassdoor
95,"Resideo
3.9
Junior Data Engineer
Austin, TX
$75K - $113K (Glassdoor est.)

 Resideo is seeking a Junior Data Engineer to join our AI team. Resideo engineers strive to provide peace of mind to millions of homeowners through a robust and capable set of products that safeguard the home and simplify everyday life.
Unusual compared to most data engineering roles, the AI team is dealing with millions of unstructured data events per day. We need to build robust ETL and data pipelines to continuously improve our ML models. Those ML models enable a range of next-generation of Resideo home security products, including video doorbells, outdoor cameras, and other security sensors.
As part of this initiative, we are looking for a junior data engineer who is excited to work with cloud unstructured data pipelines and the challenges associated with them . You will be taking POC pipelines and expanding them to work with big data, helping build out MLOps for Resideo. Work with a cross-functional team of embedded engineers, data scientists, and cloud developers to deliver a best-in-class solution.
This role will have the opportunity to impact newly developed consumer products with high business visibility.
JOB DUTIES:
As a Data Engineer, you will be tasked with building data acquisition and processing to building video machine-learning products
Unstructured data comes with unique challenges and problems that you will be responsible for researching and helping solve
You will work closely with engineers and scientists contributing to the ongoing development and monitoring of ML products
Decompose complex problems and pipelines into simple, straight-forward solutions
Work with a geographically and culturally dispersed team
YOU MUST HAVE:
Bachelor's degree in Computer Science, Engineering, Mathematics or a related field or equivalent professional or military experience
One or more in each of these categories:
Python, PySpark, SQL, etc.
Experience manipulating and curating large image and video datasets
Experience with CI/CD workflows, including Github and Terraform
Technial exposure across video/image topics including image processing, ML/DL, encodings
Excellent written and oral communication skills
Demonstrated ability to achieve goals in a fast-paced environment
WE VALUE:
Computer vision , CNNs, and Machine learning workflows
Domain knowledge of security cameras or home IOT devices
Understanding with embedded SoC devices and edge deployment
Experience with a variety of vision, depth or audio sensors
Knowledge and experience with Azure cloud environments, Databricks, Azure Data Factory
WHAT'S IN IT FOR YOU:
Life and health insurance
Life assistance program
Accidental death and dismemberment insurance
Disability insurance
Retirement plan (Immediate eligibility for 401K)
Vacation & holidays. (Enjoy work-life balance)
#LI-CT1
#SWE

About Us: Resideo is a leading global provider of critical comfort and security solutions primarily in residential environments and distributor of low-voltage electronic and security products. Building on a 130-year heritage, Resideo has a presence in more than 150 million homes, with 15 million systems installed in homes each year. We continue to serve more than 110,000 professionals through leading distributors, including our ADI Global Distribution business, which exports to more than 100 countries from more than 200 stocking locations around the world. Resideo is a $5.0 billion company with approximately 13,000 global employees. For more information about Resideo, please visit www.resideo.com .
At Resideo, we bring together diverse individuals to build the future of homes. Resideo is an equal opportunity employer. Qualified applicants will be considered without regard to age, race, creed, color, national origin, ancestry, marital status, affectional or sexual orientation, gender identity or expression, disability, nationality, sex, religion, or veteran status.",glassdoor
96,"Autodesk
4.2
Data Engineer
San Francisco, CA
$116K - $169K (Glassdoor est.)

 Job Requisition ID #
22WD64738
Position Overview
Autodesk is looking for a talented Data Engineer to join our Observability Analytics team to create robust and scalable data pipelines using and improving existing platforms.

A successful candidate has a strong sense of ownership and will use their expertise to build extensible data models, provide meaningful recommendations and actionable strategies to partnering data scientists. They will drive performance enhancements, development best practices and collaborate with other Data Engineering teams throughout Autodesk.

Responsibilities
Create, automate, and support reliable data pipelines
Gather customer requirements, sequence work and document technical solutions
Interface with data engineers, data scientists, product managers and internal stakeholders
Cross-train and mentor teammates

Minimum Qualifications
3+ years of data processing experience in large cloud-based infrastructure (AWS preferred)
Familiar with SQL, dimensional modeling, and analytical data warehouses, like Snowflake
Understanding of Data Engineering best practices for medium to large scale production workloads
Hands-on software development experience in Python
Experience with data pipeline orchestration tools, like Airflow
Customer-facing and service-oriented person
Team player with great communication skills
Problem solver with excellent written and interpersonal skills
Experience consuming REST APIs

Preferred Qualifications
Experience with ELT pipelines - DBT
REST API design and implementation
Familiarity with containers and infrastructure-as-code principles
Experience with automation frameworks - Git, Jenkins, and Terraform
#LI-POST
At Autodesk, we're building a diverse workplace and an inclusive culture to give more people the chance to imagine, design, and make a better world. Autodesk is proud to be an equal opportunity employer and considers all qualified applicants for employment without regard to race, color, religion, age, sex, sexual orientation, gender, gender identity, national origin, disability, veteran status or any other legally protected characteristic. We also consider for employment all qualified applicants regardless of criminal histories, consistent with applicable law.
Are you an existing contractor or consultant with Autodesk? Please search for open jobs and apply internally (not on this external site). If you have any questions or require support, contact
Autodesk Careers
.",glassdoor
97,"Intrado
3.7
Data Engineer
Remote
Employer Provided Salary:$90K - $97K

 Job Description
For this opening we will consider candidates from the following locations: , United States |


Intrado is looking to hire a Data Engineer to join our Life & Safety business segment. This role is a fully remote and work from home opportunity anywhere in the USA.
Essential Duties:
Responsible for creating standardized documentation to be utilized by team members to process cases.
Analyzes and evaluates applications/tasks and determines areas that need improvement within the scope of departmental responsibility
Serves as primary escalation point for assigned area of responsibility
Process cases that were not resolved at lower level due to the cases being undocumented
Create documentation to be entered into a centralized knowledgebase for case resolutions to be utilized by department staff
Maintain and update centralized knowledgebase to ensure information is accurate and relevant
Develop basic reports for use by management in an accurate and timely manner
Analyze and evaluate applications and tasks and determine areas that need improvement within the scope of departmental responsibility
Collaborate with internal teams to complete design phase and initiate implementation
Participate in large-scale projects, completing tasks under the guidance of senior staff (e.g. Sr. Data Engineer, etc.)
Serve as subject-matter-expert (SME) for smaller projects requiring knowledge of specific systems or methods
Provide assistance to senior staff when conducting complex data analysis to resolve management inquiries
Applicant for this job will be expected to meet the following minimum qualifications:
Education:
Bachelor's degree from an accredited college or university with major course work in computer science, MIS, or a related field is required
Equivalent work experience in a similar position may be substituted for education requirements
Experience:
Minimum 3 years of experience with data analysis and migration to include experience in the analysis or design of applications or systems to store and extract data
Minimum 1 year of experience writing detailed test plans for small to medium sized projects preferred
Minimum 2 years of experience with SQL required
Minimum 1 year experience with requirements analysis and the software development life cycle required
Intermediate knowledge of Word, Excel, and PowerPoint required
Technical:
Proficiency in Python, Spark, Tableau, ELK preferred
Proficiency in Power BI preferred
Experience in Azure or AWS Cloud applications preferred
Experience with databricks preferred
Compensation:
Want to love where you work? At Intrado, we offer a comprehensive benefits package that includes what you’d expect (medical, dental, vision, life and disability coverage, paid time off, a 401(k) retirement plan with company match and flexible spending accounts), and several that go above and beyond (tuition reimbursement paid parental leave, access to a robust library of personal and professional training resources, employee discounts, critical illness, hospital indemnity and pet insurances, identity protection and more)! Apply today to join us in work worth doing!
The starting salary for this position is between $90-97,000 a year and will be commensurate with experience.

ABOUT US
Connecting people with each other and the right information is mission critical. Our Company develops innovative cloud-based technology to make it easier, more effective and more efficient to make the right connections. Our solutions put people in sync with each other and the right information, so they gain the insight needed to reach better decisions on the issues that matter most. We do it with a laser focus on reliability.

The Company is a leading provider of technology-driven, communication services, serving Fortune 1000 companies and other clients in a variety of industries, including telecommunications, retail, financial services, public safety, technology and healthcare. For more than 30 years, we have been leading the way in hosted and cloud-based solutions.

Our solutions connect people with each other and the information needed to gain insights for better decisions on the issues that matter most – Information to Insight.

Our Company has sales and/or operations in the United States, Canada, Europe, the Middle East, Asia Pacific, Latin and South America and is an Equal Opportunity Employer – Veterans/Disabled and Other Protected Categories. Our Company welcomes and encourages applications of individuals with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process.

ABOUT THE TEAM
Intrado’s Life & Safety division is responsible for some critical parts of our everyday life. Our solutions are responsible for everything that happens after a 9-1-1 call is placed – call routing, delivery, location determination and data management. Whether you call from a landline, cell phone or text 9-1-1, we make sure first responders get the right information at the right time so they can save lives.


Intrado also provides notifications to the utilities, healthcare and educational sectors. Our platform provides multi-modal communications that meet an individual’s contact preference and routes over 4 billion notifications each year. At the end of the day, Intrado believes that keeping people in our communities safe, connected and healthy is a top priority.",glassdoor
98,"MHS
5.0
Data Engineer
Remote

 Founded in 1999, MHS is a full-service provider of innovative material handling systems that solve the challenges of distribution and fulfillment operations. We build, engineer and maintain systems for some of the biggest companies in the world, including UPS, FedEx, Walmart, Amazon and others. MHS is already one of the 10 largest material handling system suppliers worldwide, and we only expect to continue growing. We’re looking for top talent to be part of the journey.

The Data Engineer is a key member of the Fortna Warehouse Execution System (WES) data team that design usable data models and build robust & dependable data pipelines where both batch & streaming process are leveraged to meet the latency requirements for the business. This position plays a vital role in building the Data Platform, Business Intelligence and Data product capability of the FortnaWES software product.
Evaluate business and technical domains to produce representative logical and physical data models
Build data models with the flexibility to change when business requirements change
Reconcile multiple logical source models into a single, logically consistent enterprise model
Develop and automate large scale, high-performance data processing systems (batch and/or streaming) to drive business growth and improve the product experience
Develop data stores, including warehouses, data lakes, data marts, etc., to support the BI and operational research initiatives
Build scalable data pipelines leveraging orchestration framework
Improve data quality by researching, using, and improving tools to automatically detect issues
Employ initiative, professionalism, and self-discipline in daily interactions
Qualifications:
Two to three years of relevant industry experience
Bachelor’s and/or master’s degree, preferably in Computer Science, or equivalent experience
Proven capability for managing data migrations between software products and custom apps
Experience with pipeline tools such as Nifi, Airflow
Experienced with Extract-Transform-Load (ETL), Extract-Load-Transform (ELT), and Discover-Access-Distill (DAD) processes
Experience in multidimensional data modeling, start schemas, snowflakes, normalized and de-normalized modes, and Kimball methodologies
Ability to communicate in a written, spoken, or visual manner at all personnel levels
Experience in deploying dbt/airflow workflow is a plus

DESIRED QUALIFICATIONS:
Demonstrated real-world execution implementing data warehouses and data lakes
Familiarity working with open-source Linux-based technologies
Verifiable record of building an enterprise analytics capability from greenfield",glassdoor
99,"Mercury
3.7
Data Engineer
San Francisco, CA
$104K - $152K (Glassdoor est.)

 SF, NY, Toronto, Portland, or remote
Full-time
Mercury
In the 1880s, Herman Hollerith noticed the US Census was taking over 8 years to calculate. To solve this, he invented a tabulating machine using punch cards that dramatically sped up the process and served as the foundation for innovation in high quality data gathering.
We’re looking for our first Data Engineer who can help us build our high quality data engine that informs how we invest in and build Mercury’s future. You’ll be early to building a data-informed culture across Mercury so that we can all determine what’s happening, react quickly, and invest intelligently.
Here are some things you’ll do on the job:
Partner with leadership, engineers, and data scientists to understand data needs and build systems that deliver high quality and reliable data.
Own and maintain the data systems that extract, transform, and load data into internal and external tooling.
Apply proven expertise and build high-performance scalable data warehouses.
Design, build, and launch efficient & reliable data pipelines to move and transform data (both large and small amounts).
Design and develop new systems in partnership with software engineers to enable quick and easy consumption of data.
You should:
Have 2+ years of experience working with analytics teams on building high quality and reliable data infrastructure.
Be able to navigate from architecture and implementation decisions related to data infrastructure to guide teams towards building reliable and accurate pipelines and company-critical data sets.
Have familiarity with postgres backend data, Snowflake, and data transformation tools like dbt.
Value quality in data tools, testing, and innovation.",glassdoor
100,"CGI Group, Inc.
3.9
Data Engineer (JR)
Salt Lake City, UT
$75K - $106K (Glassdoor est.)

 Data Engineer (JR)

Position Description
CGI's Enterprise Technology and Operations (ETO) team is transforming what it means to work for a financial institution. We operate in a fast-paced, information-driven environment, which means we need people who bring diverse experiences, perspectives, and expertise to meet the ever-changing demands of a technology-driven world. We are grounded in the belief that ""improving the work is the work"" as we drive to create simple, easy, and fast solutions for our customers. Your ability to adapt, learn, and innovate helps increase revenue, reduce operational costs, and mitigates risk. ETO provides opportunities for you to own your career growth through Diversity, Equity, and Inclusion, Women in Technology, and Workforce of the Future initiatives that allow you to network across the organization, volunteer in our community, and build your technical and soft skills. Together we are building a culture that values diversity and creates a space of belonging for all our team members. We believe that investing in your success is an investment in our customers and our business. Our people are what sets us apart and make us great.

Your future duties and responsibilities
As a Data Engineer, you'll provide your talents in contributing to the success of the team by delivering the following:
Serve in the goalie rotation to support the Production environment.
Responsible for maintaining enterprise-grade platforms that enable data-driven solutions.
Search for ways to automate and maintain scalable infrastructure.
Ensure delivery of highly available and scalable systems.
Monitor all systems and applications and ensure optimal performance.
Analyzes and designs technical solutions to address production problems.
Participate in troubleshooting applications and systems issues.
Identifies, investigates, and proposes solutions to technical problems.
While providing technical support for issues, develop, test, and modify software to improve efficiency of data platforms and applications.
Monitors system performance to maintain consistent up time.
Prepares and maintains necessary documentation.
Participate in daily standups, team backlog grooming, and iteration retrospectives.
Coordinate with data operations teams to deploy changes into production.
Highest level may function as a lead.
Other duties as assigned.

Required qualifications to be successful in this role
Qualifications:
Requires a Bachelor's in Computer Science, Computer Engineering or related field and experience with ETL development, SQL, UNIX/Linux scripting, Big Data distributed systems. Prefer experience with IBM DataStage.
Various programming languages like Java and Python, orchestration tools and processes or other directly related experience.
A combination of education and experience may meet qualifications.
Excellent analytical, organizational, and problem-solving skills.
Ability and desire to learn new technologies quickly.
Ability to work independently and collaborate with others at all levels of technical understanding.
Able to meet deadlines.
Good judgment and project management skills.
Ability to communicate both verbally and in writing with both technical and non-technical staff.
Ability to work in a team environment and have good interpersonal skills.
Ability to adapt to changing technology and priorities.
Must be able to work independently, handle multiple concurrent tasks, with an ability to prioritize and manage tasks effectively.

Skill Set/Years of experience/Proficiency level

ETL
3-5 years
Expert

Linux
3-5 years
Expert

SQL
3-5 years
Expert

Microsoft Word, Excel, PowerPoint, Visio, and ADO
3-5 years
Expert

Python or Java
1-3 years
Expert

DESIRED QUALIFICATIONS/NON-ESSENTIAL SKILLS REQUIRED

Skill Set/Years of experience/Proficiency level

DataStage, Python
1 year
Professional

Minimum Education Required: Bachelor's degree

Colorado Equal Pay for Equal Work Act

Est. Salary Range (Colorado Only): $84,000-$107,000*

Disclaimer: In accordance with Colorado's Equal Pay for Equal Work Act, effective January 1, 2021, a good faith hourly or base salary range must be posted for all positions where the work may be performed in the state of Colorado. Therefore, this good faith salary range will only apply where this described position will be performed in the state,and should not be considered the compensation range in other locations or for other positions.

At CGI we call our professionals ""members"" to reinforce that all who join our team are, as owners, empowered to participate in the challenges and rewards that come from building a world-class company. CGI's benefits include:
Competitive base salaries
Eligibility to participate in an attractive Share Purchase Plan (SPP) in which the company matches dollar-for-dollar contributions made by eligible employees, up to a maximum, for their job category
401(k) Plan and Profit Participation for eligible members
Generous holidays, vacation, and sick leave plans
Comprehensive insurance plans that include, among other benefits, medical, dental, vision, life, disability, out-of-county emergency coverage in all countries of employment;
Back-up child care, Pet insurance, a Member Assistance Program, a 529 college savings program, a personal financial management tool, lifestyle management programs and more

Insights you can act on

While technology is at the heart of our clients' digital transformation, we understand that people are at the heart of business success.

When you join CGI, you become a trusted advisor, collaborating with colleagues and clients to bring forward actionable insights that deliver meaningful and sustainable outcomes. We call our employees ""members"" because they are CGI shareholders and owners and owners who enjoy working and growing together to build a company we are proud of. This has been our Dream since 1976, and it has brought us to where we are today - one of the world's largest independent providers of IT and business consulting services.

At CGI, we recognize the richness that diversity brings. We strive to create a work culture where all belong and collaborate with clients in building more inclusive communities. As an equal-opportunity employer, we want to empower all our members to succeed and grow. If you require an accommodation at any point during the recruitment process, please let us know. We will be happy to assist.

Ready to become part of our success story? Join CGI - where your ideas and actions make a difference.

Qualified applicants will receive consideration for employment without regard to their race, ethnicity, ancestry, color, sex, religion, creed, age, national origin, citizenship status, disability, pregnancy, medical condition, military and veteran status, marital status, sexual orientation or perceived sexual orientation, gender, gender identity, and gender expression, familial status, political affiliation, genetic information, or any other legally protected status or characteristics.

CGI provides reasonable accommodations to qualified individuals with disabilities. If you need an accommodation to apply for a job in the U.S., please email the CGI U.S. Employment Compliance mailbox at US_Employment_Compliance@cgi.com . You will need to reference the requisition number of the position in which you are interested. Your message will be routed to the appropriate recruiter who will assist you. Please note, this email address is only to be used for those individuals who need an accommodation to apply for a job. Emails for any other reason or those that do not include a requisition number will not be returned.

We make it easy to translate military experience and skills! Click here to be directed to our site that is dedicated to veterans and transitioning service members.

All CGI offers of employment in the U.S. are contingent upon the ability to successfully complete a background investigation. Background investigation components can vary dependent upon specific assignment and/or level of US government security clearance held. CGI will consider for employment qualified applicants with arrests and conviction records in accordance with all local regulations and ordinances.

CGI will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with CGI's legal duty to furnish information.

Skills
Data Engineering
ETL
Linux
SQL
DataStage
Python",glassdoor
101,"Lucid Motors
3.5
Data Engineer
Newark, CA
$112K - $163K (Glassdoor est.)

 Leading the future in luxury electric and mobility
At Lucid, we set out to introduce the most captivating, luxury electric vehicles that elevate the human experience and transcend the perceived limitations of space, performance, and intelligence. Vehicles that are intuitive, liberating, and designed for the future of mobility.
We plan to lead in this new era of luxury electric by returning to the fundamentals of great design – where every decision we make is in service of the individual and environment. Because when you are no longer bound by convention, you are free to define your own experience.
Come work alongside some of the most accomplished minds in the industry. Beyond providing competitive salaries, we’re providing a community for innovators who want to make an immediate and significant impact. If you are driven to create a better, more sustainable future, then this is the right place for you.

We are looking for a Senior Data Engineer, Big Data who is looking for a challenge, enjoys thinking big and looking to make their mark on an extremely fast growing company. If you have hands-on experience designing and developing streaming and IoT data pipelines this role is for you. Be part of a group who will be building large and building fast, working with a very talented team of engineers, and collaborating with the brightest mind in the Automotive industry.
The Role
Hands-on design and develop streaming and IoT data pipelines.
Developing streaming pipeline Kafka, Spark, Scala and Python
Python scripting for automation and application development
Developing streaming pipeline using FluentD, Elasticsearch, Kibana
Design ETL in Apache Airflow and other dependency enforcement and scheduling tools.
Hands-on data modeling and data warehousing
Deploy solution using AWS, S3, Redshift and Docker/Kubernetes
Develop storage and retrieval system using Presto and Parquet/ORC
Scripting with Apache Spark and data frame.
Qualifications
Bachelor or Masters in Software Engineering or Computer Science
2+ years of experience in Data Engineering and Business Intelligence
Excellent coding, scripting and problem solving skills
Experience in tools such as Spark, Kafka, S3, Hive, Data Lake
Experienced in Log Collection and processing using tools such FluentD and Elastic Search
Experience with AWS, S3, Redshift
Experience with Presto and Parquet/ORC
Proficient with Apache Spark and data frames
Experienced in containerization, including Docker and Kubernetes
Expert in tools such as Apache Spark, Apache Airflow, Presto, and Kubeflow
Expert in design and implement reliable, scalable, and performant distributed systems and data pipelines
Extensive programming and software engineering experience, especially with Scala, Java or Python
Experience with a columnar database such as Redshift or Vertica
Great verbal and written communication skills
At Lucid, we don’t just welcome diversity - we celebrate it! Lucid Motors is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, national or ethnic origin, age, religion, disability, sexual orientation, gender, gender identity and expression, marital status, and any other characteristic protected under applicable State or Federal laws and regulations.

Notice regarding COVID-19 protocols
At Lucid, we prioritize the health and wellbeing of our employees, families, and friends above all else. In response to the novel Coronavirus all new Lucid employees, whose job will be based in the United States may or may not be required to provide original documentation confirming status as having received the prescribed inoculation (doses). Vaccination requirements are dependent upon location and position, please refer to the job description for more details.
Individuals in positions requiring vaccinations may seek a medical and/or religious exemption from this requirement and may be granted such an accommodation after submitting a formal request to and the subsequent review and approval thereof by our dedicated Covid-19 Response team.
To all recruitment agencies: Lucid Motors does not accept agency resumes. Please do not forward resumes to our careers alias or other Lucid Motors employees. Lucid Motors is not responsible for any fees related to unsolicited resumes.",glassdoor
102,"John Deere
4.1
Analytics Data Engineer
East Moline, IL

 There are over 7 billion people on this planet. And by 2050, there will be 2 billion more... many moving into urban centers at an unprecedented rate. Making sure there is enough food, fiber and infrastructure for our rapidly growing world is what we're all about at John Deere. And it's why we're investing in our people and our technology like never before! Here the world's brightest minds are tackling the world's biggest challenges. If you believe one person can make the world a better place, we'll put you to work. RIGHT NOW.

John Deere is an equal opportunity employer. All qualified applicants will receive consideration for employment without regards to, among other things, race, religion, color, national origin, sex, age, sexual orientation, gender identity or expression, status as a protected veteran, or status as a qualified individual with disability.

Primary Location: United States (US) - Illinois - East Moline
Function: Data & Analytics (CA)
Title: Analytics Data Engineer - 91351
Onsite/Remote:Onsite Position

This is an Onsite position, located in East Moline IL.
Visa sponsorship is NOT available for this position.
Your Responsibilities
Lead expert in identifying and prioritizing actionable insights for manufacturing and quality through a deep understanding of manufacturing data and analytic techniques.
Collaborate with a team of analytics professionals to design, build, and continuously improve meaningful factory-based analytics.
Acquires and connects data attributes to be used to develop analytic products (using Machine Learning methods).
Innovates and experiments with new data processing and transformation methods to enable the analytics development process.
Transforms data in alignment with data science needs and governance parameters and provides recommendations and testing for production environments.
What Skills You Need
2-4 years experience of advanced data gathering and analysis techniques, including statistical analysis or equivalent
2-4 years experience with tools used for data management or data warehousing
2-4 years - Proficiency with programming for data analysis, ideally Python, SQL, R, or SAS
2-4 years - Experience with analytics/bigdata platforms and/or technologies (e.g. AWS, DataBricks, Spark)
2-4 years - Experience in data visualization tools or application development (e.g. PowerBI, Tableau, R Shiny)
What Makes You Stand Out
Experience working in a manufacturing related function (Operations, Manufacturing or Quality Engineering, Factory Automation, or Robotics)
Experience managing large data migration or data transformation projects
Experience with machine learning models and/or supporting infastructure.
Education
Degree in an Information Technology discipline or equivalent experience. - University Degree (4 years or equivalent)
Degree in a Math discipline or equivalent experience. - University Degree (4 years or equivalent)
Statistics - University Degree (4 years or equivalent)
What You'll Get
At John Deere, you are empowered to create a career that will take you to where you want to go while working in an inclusive team environment. Here, you'll enjoy the freedom to explore new projects, the support to think outside the box and the advanced tools and technology that foster innovation and achievement. Additionally, we offer a comprehensive reward package to help you get started on your new career path, including:
Flexible work arrangements
Highly competitive base pay and performance bonuses
Savings & Retirement benefits (401K and Defined Benefit Pension)
Healthcare benefits with a generous company contribution in the Health Savings Account
Adoption assistance
Employee Assistance Programs
Tuition assistance
Fitness subsidies and on-site gyms at specific Deere locations
Charitable contribution match
Employee Purchase Plan & numerous discount programs for personal use

Click Here to find out more about our Total Rewards Package.

The information contained herein is not intended to be an exhaustive list of all responsibilities and qualifications required of individuals performing the job. The qualifications detailed in this job description are not considered the minimum requirements necessary to perform the job, but rather as guidelines.

The terms of the applicable benefit plans, and all company actions administering or interpreting these plans, continue to control. Deere & Company reserves the right to suspend, amend, modify, or terminate the Plan(s) in any manner at any time, including the right to modify or eliminate any cost-sharing between the company and participants. Changes, which can be made at any time, are made by action of the company's board of directors, or to the extent authorized by resolution of its board of directors, or by the Deere & Company Compensation Committee. In the event of a conflict between the language of the official Plan Documents and this document, the language of the official Plan Documents will control.

ACA Section 1557 Nondiscrimination Notice
The John Deere Health Benefit Plans for Salaried Employees and The John Deere Benefit Plan for Wage Employees comply with applicable Federal civil rights laws and do not discriminate on the basis of race, color, national origin, age, disability, or sex.",glassdoor
103,"Vimeo
4.1
Data Engineer II, Analytics
New York, NY
$107K - $150K (Glassdoor est.)

 Vimeo is looking for an experienced Data Engineer II, Analytics to join our Data Architecture and Analytics Engineering team and work closely with Data Analysts and Data Scientists to create and maintain robust, scalable, and sustainable data models that provide decision-making insights for senior leadership including executives. The ideal candidate is a self-starter with a bias for action and results, with experience in a fast-paced, data-driven environment.
What you'll do:
Build data models that can support dynamic and efficient data analysis, and collaborate with other teams to maintain and evolve those models over time
Ensure alignment to coding standard methodologies and development of reusable code
Partner with Data Analysts to understand business processes and identify opportunities to build scalable and efficient data models that can be used for scalable, refreshable analysis and reporting
Create and enable the generation of ad-hoc / on-demand data sets for use by analysts and data scientists
Work with Engineering teams to set up monitoring and alerting systems for business and product KPIs
Skills and knowledge you should possess:
BS/MS in Computer Science or a related technical field.
2+ years working with Analytics and Data Engineering teams with a mixed data engineering and analytics background
2+ years of experience in scalable data architecture, fault-tolerant ETL, and monitoring of data quality in the cloud
Experience working on or leading initiatives around data governance, master data management, data catalogs, and enterprise data warehouse architecture
Strong analytical skills, data sensibility, and an able communicator
Open to working on multiple projects simultaneously
Proficiency in:
SQL
Python
Dimensional Modeling
Data pipeline development, workflow management, and orchestration tools
ETL optimization and best practices
Snowflake or other column-oriented and cloud-based databases
Looker or any similar Business Intelligence tool
Relational Databases
Bonus Points (Nice Skills to Have, but Not Needed):
DBT
Git / Github
Looker/Tableau is a big plus
large data sets (terabyte scale)
Apache Airflow
#LI-JS1
Vimeo (NASDAQ: VMEO) is the world's leading all-in-one video software solution. Our platform enables any professional, team, and organization to unlock the power of video to create, collaborate and communicate. We proudly serve our growing community of over 260 million users — from creatives to entrepreneurs to the world's largest companies.
Vimeo is headquartered in New York City with offices around the world. At Vimeo, we believe our impact is greatest when our workforce of passionate, dedicated people, represents our diverse and global community. We're proud to be an equal opportunity employer where diversity, equity, and inclusion is championed in how we build our products, develop our leaders, and strengthen our culture.
Learn more at www.vimeo.com
Learn more at www.vimeo.com/jobs",glassdoor
104,"Hazel Health
4.3
Data Engineer
San Francisco, CA
$111K - $154K (Glassdoor est.)

 About Hazel Health
Hazel Health, the national leader in school-based telehealth, was founded in 2015 to address systemic inequities in healthcare access, and ensure all children can get the quality care they need and deserve. We leverage digital health technology to provide on-demand physical and mental health care services to over 2 million students in school districts across the country.
Physical and mental telehealth has become more relevant in the lives of children than ever before. Hazel is experiencing tremendous company growth as we respond to our nation's call for equitable, affordable, and safe virtual access to healthcare.
We are a mission-driven team of healthcare and business leaders, educators, and tech innovators, bringing together our unique skills in a meaningful way to do good in the world. Please consider joining us to share your gifts and talents with a growing and diverse organization, working to make healthcare available to all students.
Job Summary
We are looking for a dynamic, empathetic, and action-oriented individual to join our exciting Engineering team.
As Data Engineer at Hazel, you will have significant responsibility in shaping Hazel's strategic direction as you build our data environment from end-to-end. As Hazel sits at the intersection of three data-rich industries (education, healthcare, and tech), this work is vital to Hazel's near- and long-term success.
Your primary responsibilities will be to:
Architect and build new data infrastructure for efficient storage, retrieval, and analytics
Innovating on current systems and processes
Designing, building, and scaling data pipelines
Monitoring database performance and tuning
Supporting data access and querying / visualization needs
Understand and translate ambiguous business needs by partnering with cross-functional teams to ultimately craft solutions aligned with Hazel's strategy
Spearheading the implementation of data governance and security policies within the company
Empower business leaders across product, clinical, and operations teams to adopt more innovative approaches to data collection and utilization
Champion and advise on on data strategy across the organization, supporting the buildout of data-oriented teams and advising on key external partnerships
Job Skills and Qualifications
5+ years of experience in data engineering and data architecture, at least part of which in a startup environment
Passion for our mission
Excitement for architecting an up-and-coming data ecosystem
Deep experience independently building and maintaining data warehouses and ETL pipelines
Familiarity with data governance frameworks
Advanced SQL coding and query optimization experience
Experience with data security and privacy concerns, ideally with healthcare data
A natural ownership mindset and entrepreneurial approach
Comfort with ambiguity and getting scrappy in a humble, fast-paced environment
This is an exciting position in a fast-paced organization. We offer a highly competitive compensation package.
Our Stance On Diversity:
At Hazel, we don't just accept differences—we thrive on them. We recognize that having diverse perspectives and backgrounds among our teammates makes our company, our solutions, and our service to families and schools stronger. We are committed to making Hazel an inclusive work environment and helping all staff grow professionally.
Hazel is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, national origin, sex, gender identity, sexual orientation, age, marital status, disability status, or Veteran status.
All offers of employment are conditioned on a candidate's consent to a background check and our satisfaction with the results. Qualified candidates with arrest and conviction records will be considered for employment in accordance with the San Francisco Fair Chance Ordinance.",glassdoor
105,"Curie
Data Engineer
Remote

 About Curie
Virtual showrooms save lives and the environment. We believe the Metaverse is a more sustainable way to support e-commerce, and we're looking for smart, driven people to help us populate the Metaverse.
Curie is a Seattle-based startup focused on supplying the growing need for 3D, from retail to online experiences, by creating AI-powered tools at the forefront of technology to generate 3D assets.
Work in a remote-work environment with room for autonomy and self-direction. You are self-motivated, work at the forefront of AI-powered tools, and have a passion for high-quality experiences of the future.
We offer competitive salaries and stock options.
*
Description*
The Data Engineer will be responsible for data capture. That means harnessing and ensuring the availability of the data which should be used by both the Machine Learning team and the Back-end engineers for a 2D to 3D product pipeline. Duties may include scraping data from websites, storing and versioning the data. Setting up and maintaining any databases relational or non-relational functions.
Role also will evolve to include data capture for Site Reliability Engineering (SRE) and other service performance and insights functions.
Requirements
Mandatory
Expert-level experience with writing scrapers in any language (Python or JavaScript are preferred)
Expert text import, manipulation, parsing and refinement skills (fast, accurate and iterative) and/or mastery of text manipulation toolsets that work well for a startup environment.
Experience with one of AWS, GCP, or Azure for storing and querying large quantities of data (preferably 3D realted)
Experience with at least one relational or non-relational database (PostgreSQL, MySQL, SQL, MongoDB, SQL Server, etc.)
Experience with Linux
Experience and broad understanding of current 3D model marketplaces.
Job Type: Contract",glassdoor
106,"2am.
Data Engineer
Remote

 Our ongoing desire to evolve took us on a journey #beyondsoftware. We are 2am.tech, a team of builders and problem solvers with a core belief in delivering excellence. This value has bred a company culture of providing solutions and products that exceed expectations every time. We are a fully remote company based in Miami, FL. If you're based in LATAM, the Balkans, and Europe, we'll be happy to hear from you.

As Data Engineer you are responsible for:
Communicate complex concepts verbally in English.
Be able to significantly overlap or fully work in North American time zones. These are the times the clients’ teams are working, and you need to share some hours to be part of those teams.
Respect deadlines and work in a team-oriented environment.
Assess new technologies and trends correctly.
Extensive experience with Data warehousing methodologies and modeling techniques.
Minimum three years of experience with the Snowflake architecture including using features such as Zero Copy Clone, Time Travel, User defined functions, etc.
Experience managing security in Snowflake including the creation of custom Roles to control access to Data, Databases, Warehouses, etc.
Experience in designing Compute Clusters (Warehouse) in Snowflake.
Good knowledge of Snowpipe (whatever ETL or ELT we will be using) for handling Streaming data.
Advanced understanding of migration, and methods to cloud data solutions.
Extensive experience in handling semi-structured data (JSON, XML) using the VARIANT attribute in Snowflake.
Experience in re-clustering the data in Snowflake with a good understanding of how Micro-Partition works inside Snowflake.
More than five years in creating master data datasets.
Design Tableau KPIs style dashboards and embed those in web applications.
Designing Tableau reports. Minimum of 3 years.
High English level is a must.",glassdoor
107,"Bloom Insurance
3.3
Jr. Data Engineer I
Remote

 Data Engineer I
To support internal and external clients via processing and handling of data. To generate data solutions for ongoing immediate day to day business needs.

Essential Functions
Day to day functions include the following:
Design data models and develop database structures in Microsoft SQL server.
Write various database objects like stored procedures, functions, views, triggers for various front end applications.
Write SQL scripts, create SQL agent jobs to automate tasks like data importing, exporting, cleansing tasks.
Create database deployment packages for deploying changes.
Identify & repair inconsistencies in data, database tuning, query optimization.
Able to generate ad hoc data on demand.
Able to identify best practices, documentation, communicate all aspects of projects in a clear, concise manner
Develop simple SSIS packages to perform various ETL functions including data cleansing, manipulating, importing, exporting.
Develop & maintain client facing reports by using various data manipulation techniques in SSRS and Visual Studio.
Documentation
Optimization recommendations
Day to day troubleshooting
.NET Programming as needed

Education/Experience
BA, BS, or Masters in computer science/related field preferred or an equivalent combination of education and experience derived from at least 2 years of professional work experience
Solid experience with various versions of MS SQL Server and TSQL programming
Microsoft Certified DBA a plus

Skills/Knowledge
Strong experience in writing efficient SQL code
Working knowledge of SQL Server Management Studio (SSMS)
Knowledge of SQL Server Reporting Services (SSRS)
Knowledge of SQL Server Integration Services (SSIS)
Knowledge of Red Gate DBA Tool Belt (SQL Compare, SQL Data Compare, SQL Source Control) a plus
Knowledge of data science technologies is a plus
Clear, concise communication skills, excellent organizational skills
Highly self-motivated and directed
Keen attention to detail
High level of work intensity in a team environment
High integrity and values-driven
Eager for professional development
Experience and understanding of source control management a plus

What We Offer

At Advise / Bloom, we offer an engaging, supportive work environment, great benefits, and the opportunity to build the career you always wanted. Benefits of working for Advise / Bloom include:
Competitive compensation
Comprehensive health benefits
Long-term career growth and mentoring

About Advise
Advise Insurance is a licensed Medicare agency that aims to preserve the patient–physician relationship and help build a better healthcare experience. We provide education that explains how Medicare works and helps beneficiaries select a plan that meets their healthcare needs and includes their trusted doctor.

About Bloom
As an insurance services company licensed in 48 contiguous U.S. states, Bloom focuses on enabling health plans to increase membership and improve the enrollee experience while reducing costs. We concentrate on two areas of service: technology services and call center services and are committed to ensuring our state-of-the-art software products and services provide greater efficiency and cost savings to clients.

Ascend Technology ™
Advise / Bloom provides advanced sales and enrollment automation technology to the insurance industry through our Ascend ™. Our Ascend™ technology platform focuses on sales automation efficiencies and optimizing the member experience from the first moment a prospect considers a health plan membership.

Advise / Bloom is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.",glassdoor
108,"Lincoln Financial
3.6
Data Engineer (REMOTE)
Radnor, PA
Employer Provided Salary:$63K - $138K

 Date: Oct 9, 2022
Primary Location: Radnor, PA, US
Company: Lincoln Financial
Alternate Locations: Work from Home

Work Arrangement: Work from Home

Relocation assistance:: is not available for this opportunity.

Pay Range: $63,100 - $137,900

Bonus Potential: 5%

Requisition #: 69444

The Role at a Glance

This is an exciting opportunity within Lincoln’s Work Place Solutions IT Data Team for a Data Engineer/ETL Developer to help build solutions for Lincoln’s Work Place Solutions business. This position will assist Analytic Teams with the design and implementation of Data solutions and systems, including integration with databases and data warehouses, both on-Premise and in AWS Cloud. This candidate must be able to develop, enhance, and support Informatica workflows and processes using Informatica Power Center and Dataiku for the extraction and transformation of data in a UNIX and Oracle database environment. They must also have experience working within BI tools such as Tableau and Microstrategy. Experience working in the cloud using AWS native services such as Glue, Athena, Aurora, Redshift, and/or Snowflake is needed. The candidate must have experience participating in and beginning to lead teams within a Data Organization by suggesting new and innovative ways of gaining data processing efficiencies and participating in architectural and modeling discussions.

What you'll be doing

Participates in defining architecture and modeling best practices within the team
Develop tools and work on integrating disparate systems using ETL
Work on transformation of data into Facts and Dims in a Kimball and/or relational model
Works with Sr. Technical Professionals to implement data development best practices
Develop, enhance and support Informatica workflows and processes using Informatica Power Center for the extraction and translation of data in a UNIX and Oracle database environment
Develop, enhance and support Dataiku workflows and processes for transforming data into Kimball model Facts/Dims
Creates partnerships with stakeholders, POs, BSAs and Analytic teams in requirement, design and coding walkthroughs to ensure the development of quality solutions and understand complex business/technical problems and opportunities and identify potential application solutions.
Demonstrates expertise in a variety of the data warehouse concepts, practices, and procedures. Relies on extensive experience and judgment to plan and accomplish goals
Analyzes operational and analytical data requirements by working with cross functional business and application development teams
Maintains knowledge on current and emerging developments/trends for assigned area(s) of responsibility, assess the impact, and collaborates with senior management to incorporate new trends and developments in current and future solutions.
Participate with collaboration efforts with development teams to review, update and approve the data portion of project designs, participate in cost/benefit analysis and preparation of project plans.
Participate in the design, development and delivery data centric IT solutions, including large scale data staging and orchestration, integration and provisioning mechanisms
Works with business partners to prioritize business and information needs
Provides input and validates increasingly complex project plans, test plans and implementation plans
Creates increasingly complex technical specifications from business requirements/business specifications
Proactively identifies problems and presents/develops solutions
Communicates effectively with internal stakeholders and management
Defines detailed development tasks, task dependencies and estimates to complete work
What we're looking for

4 Year/Bachelor's degree or equivalent work experience (4 years of experience in lieu of Bachelor's) in Computer Science, Computer Information Systems, Information Systems, Information Technology or Computer Engineering or equivalent work experience (Minimum Required
3 - 5+ Years’ experience in application development that directly aligns with the specific responsibilities for this position (Required)
Experience with ETL development
Must have experience with Informatica; Dataiku is a plus
Must have experience with BI tools such as Tableau and Microstrategy
Experience with AWS cloud native services, such as: Glue, Athena, Aurora, Redshift
Must have a proven track record working closely with business stakeholders, BSAs, and POs, Solution Architects to understand requirements and expectations to achieve quality technical solutions
What’s it like to work here?
At Lincoln Financial Group, we love what we do. We make meaningful contributions each and every day to empower our customers to take charge of their lives. Working alongside dedicated and talented colleagues, we build fulfilling careers and stronger communities through a company that values our unique perspectives, insights and contributions and invests in programs that empower each of us to take charge of our own future.

What’s in it for YOU:
A clearly defined career framework to help you successfully manage your career
Leadership development and virtual training opportunities
PTO/parental leave
Competitive 401K and employee benefits
Free financial counseling, health coaching and employee assistance program
Tuition assistance program
A leadership team that prioritizes your health and well-being; offering a remote work environment and flexible work hybrid situations
Effective productivity/technology tools and training

Work Arrangement
Work from Home : Employees will work from home and are not required to work in a Lincoln office on a regular basis.

Lincoln will evaluate the following when setting the successful candidate's wage rate:
Prior work or industry experience.
Education level to the extent education is relevant to the position.
Unique skills

About The Company
Lincoln Financial Group, a Fortune 200 company with over 10,000 employees, provides advice and solutions that help empower Americans to take charge of their financial lives with confidence. Our core business areas — Life Insurance, Annuities, Retirement Plan Services and Group Protection — focus on supporting, preserving and enhancing over 17 million customer’s lifestyles and retirement outcomes.

Headquartered in Radnor, Pennsylvania, Lincoln Financial Group is the marketing name for Lincoln National Corporation (NYSE: LNC) and its affiliates. The company had $324 billion in end-of-period account values as of June 30, 2021.

Ranked one of the Best Large Employers in America and Best Employers for Women by Forbes magazine as well as one of Newsweek’s Most Responsible Companies, Lincoln Financial Group makes a serious investment in our employees’ futures through a broad range of wealth accumulation and protection plans, health and wellness programs, and career development resources designed to help each individual reach their personal and professional goals.

Lincoln is committed to creating a diverse and inclusive environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.

Lincoln Financial Group is a committed corporate citizen included on major sustainability indices including the Dow Jones Sustainability Index North America and FTSE4Good. Dedicated to diversity and inclusion, we earned perfect 100 percent scores on the Corporate Equality Index and the Disability Equality Index. Follow us on Facebook, Twitter, LinkedIn, and Instagram.

Be Aware of Fraudulent Recruiting Activities
If you are interested in a career at Lincoln, we encourage you to review our current openings and apply on our website. Lincoln values the privacy and security of every applicant and urges all applicants to diligently protect their sensitive personal information from scams targeting job seekers. These scams can take many forms including fake employment applications, bogus interviews and falsified offer letters.
Lincoln will not ask applicants to provide their social security numbers, date of birth, bank account information or other sensitive information in job applications. Additionally, our recruiters do not communicate with applicants through free e-mail accounts (Gmail, Yahoo, Hotmail) or conduct interviews utilizing video chat rooms. We will never ask applicants to provide payment during the hiring process or extend an offer without conducting a phone, live video or in-person interview. Please contact Lincoln's fraud team at fraudhotline@lfg.com if you encounter a recruiter or see a job opportunity that seems suspicious.

Additional Information
This position may be subject to Lincoln’s Political Contribution Policy. An offer of employment may be contingent upon disclosing to Lincoln the details of certain political contributions. Lincoln may decline to extend an offer or terminate employment for this role if it determines political contributions made could have an adverse impact on Lincoln’s current or future business interests, misrepresentations were made, or for failure to fully disclose applicable political contributions and or fundraising activities.

Any unsolicited resumes/candidate profiles submitted through our web site or to personal e-mail accounts of employees of Lincoln Financial Group are considered property of Lincoln Financial Group and are not subject to payment of agency fees.

Lincoln Financial Group (“LFG”) is an Equal Opportunity employer and, as such, is committed in policy and practice to recruit, hire, compensate, train and promote, in all job classifications, without regard to race, color, religion, sex (including pregnancy), age, national origin, disability, sexual orientation, gender identity and expression, Veteran status, or genetic information. Applicants are evaluated on the basis of job qualifications. If you are a person with a disability that impedes your ability to express your interest for a position through our online application process, or require TTY/TDD assistance, contact us by calling 260-455-2558.",glassdoor
109,"Nintendo of America Inc.
4.4
Data Engineer
Redmond, WA
$92K - $134K (Glassdoor est.)

 Nintendo of America Inc.

The worldwide pioneer in the creation of interactive entertainment, Nintendo Co., Ltd., of Kyoto, Japan, manufactures and markets hardware and software for its Nintendo Switch™ system and the Nintendo 3DS™ family of portable systems. Since 1983, when it launched the Nintendo Entertainment System™, Nintendo has sold billions of video games and hundreds of millions of hardware units globally, including Nintendo Switch and the Nintendo 3DS family of systems, as well as the Game Boy™, Game Boy Advance, Nintendo DS™ family of systems, Super NES™, Nintendo 64™, Nintendo GameCube™, Wii™, and Wii U™ systems. It has also created industry icons that have become well-known, household names, such as Mario, Donkey Kong, Metroid, Zelda and Pokémon. A wholly owned subsidiary, Nintendo of America Inc., based in Redmond, Wash., serves as headquarters for Nintendo’s operations in the Americas. For more information about Nintendo, please visit the company’s website at http://www.nintendo.com .

Nintendo is an equal opportunity employer. We offer a welcoming and inclusive environment in service to one another, our products, the diverse consumers we represent, and the communities we call home. We do all of this with kindness, empathy and respect for each other.
DESCRIPTION OF DUTIES
Design, implement and support stable, scalable data pipelines that cleanse, structure and integrate disparate big data sets into a readable and accessible format for end user analyses and targeting.
Develop quality framework to ensure delivery of high quality data and analyses to stakeholders.
Implement/improve version control, deployment strategies, notifications to ensure product quality, agility and recoverability.
Work with business customers in understanding the business requirements and implementing data solutions.
Manage small projects, hold stakeholder communication and ensure objectives are met.

SUMMARY OF REQUIREMENTS
3+ years of quantitative and qualitative experience in building fault tolerant ETL data flows in large scale data warehouses and BI reporting systems.
Hands-on knowledge on AWS or Google Cloud platform, Cloud Data warehouse such as Redshift or Google Big Query.
Hands-on knowledge in using advanced SQL queries (analytical functions), experience in writing and optimizing efficient SQL queries
1+ years of experience with scripting in Python .
Experienced in testing and monitoring data for anomalies and rectifying them.
Excellent communication skills to be able to work with business owners to develop and define key business uses and to build data sets that address them.
Experience in working with Data visualization tools such a Tableau is a plus.
Prior experience with marketing data is preferred.
Implement data structures using best practices in data modeling, ETL/ELT processes, and SQL
Bachelor’s degree or equivalent in an engineering or technical field such as Computer Science, Physics, Mathematics, Statistics, Engineering or similar.
This position is hybrid/onsite in Redmond, WA. Relocation assistance available.
#LI-HYBRID",glassdoor
110,"Apple
4.2
Biomedical Data Engineer - Health Technologies
Cupertino, CA

 Summary
Posted: Aug 8, 2022
Weekly Hours: 40
Role Number:200402289
The Health Technologies Team conceives and proves out innovative technology for Apple’s future products and features in health. We are seeking a highly capable Biomedical Data Engineer to join a multi-disciplinary team. Successful candidates will be able to integrate with our research study leads, data scientists and engineers to develop and support effective data analysis and machine learning workflows.
Key Qualifications
Experience with software engineering frameworks
Excellent coding skills in Python (e.g.,Pandas, Spark, Jupyter)
Workflow orchestrations (e.g., Airflow, Luigi)
Designing and maintaining (non-)relational databases (e.g. Postgres, Cassandra, MongoDB) and file systems (e.g. Parquet, CSV, JSON)
Great understanding of infrastructure designs
Linux, MacOS based development frameworks
iOS/ watchOS development (e.g., Swift, Objective-C)
Web Service APIs (e.g., AWS, REDCap, XNAT)
Version control frameworks (Git, virtualenv)
Familiarity with best practices for information security, including safe harbor privacy principles for sensitive data
Experience with biomedical sensors/platforms for measuring physiological signals in the health, wellness and/or fitness realms
Description
- Work closely with team members and study staff to design, build, launch and maintain systems for storing, aggregating and analyzing large amounts of data - Process, troubleshoot, and clean incoming data from human studies - Automate and monitor data ingestion and transformation pipelines, with hooks for QA, auditing, redaction and compliance checks per data management specifications - Create and maintain databases with existing and incoming clinical data - Architect data models and create tools to harmonize disparate data sources - Incorporate and comply with regulations as they pertain to electronic and clinical data and databases
Education & Experience
BS/MS in Computer Science, Engineering, Informatics, or equivalent with relevant 4+ years industry experience with biomedical, health or sensitive data.
Additional Requirements",glassdoor
111,"Discord
4.1
Software Engineer, Data Products
San Francisco, CA
Employer Provided Salary:$165K

 Part of the central Data Platform organization, the Data Products team seeks to make the petabytes of data at Discord easily accessible to everyone at the company. We build full-stack applications, tooling, and frameworks to improve the productivity of teams at Discord with strong data needs, in particular our product, analytics, and machine learning teams. Our work is foundational to company and product strategy — to learn more about Discord Engineering,read our engineering blog here! If that sounds exciting to you, read on! What you'll be doing Build applications, tooling, and frameworks to improve the productivity of Discord's product, analytics, and machine learning teams, using modern technologies such as BigQuery, Airflow, Kubernetes, etc. Work with our analytics and data science teams to optimize data models for performant storage/retrieval and fulfill critical product and business requirements Work to empower internal users via training and documentation. Contribute to and promote data engineering and governance standards across Discord. What you should have You have 2+ years of experience as a Software Engineer. Experience with at least one of the following languages: Python, Java, Scala. Experience building and deploying large-scale distributed systems Experience with and/or exposure to a variety of datastores (relational, NoSQL, data warehouse solutions). Good working knowledge of relational databases and query authoring (SQL). You thrive in ambiguous environments and get excited about figuring out solutions to complex problems, and then executing on them. You are a first principles thinker that can work with others to come up with pragmatic solutions — and then evolve and generalize them. You have the ability to take a high-level goal and deliver shippable code. You have a growth mindset — curious, eager to learn, and never afraid of asking questions. Bonus Points Experience working with very high-scale data infrastructure Experience with data products (discovery, quality checks, etc) on Google Cloud Platform, Kubernetes, or Airflow Full-stack development or product engineering experience New York City residents only: Minimum salary of $165,000/year + equity and benefits *Note: Disclosure as required by NYC Pay Transparency Law Colorado residents only: Minimum salary of $132,000/year + equity and benefits *Note: Disclosure as required by sb19-085(8-5-20). Benefits and Perks Comprehensive medical insurance including Health, Dental and Vision (plus up to $20,000 for gender affirmation procedures) Mental health resources and quarterly wellness stipends 16+ paid holidays, 4 weeks of PTO + use-what-you-need sick days Paid parental leave (plus fertility, adoption and other family planning benefits) Flexible long-term work options (remote and hybrid) Volunteer time off A diverse slate of Employee Resource Groups Plus commuter contributions and other perks for office-based employees About Us Discord is a voice, video and text app that helps friends and communities come together to hang out and explore their interests — from artists and activists, to study groups, sneakerheads, plant parents, and more. With 150 million monthly users across 19 million active communities, called servers, Discord has grown to become one of the most popular communications services in the world. Discord was built without selling ads or user data and instead, offers a premium subscription called Nitro that gives users special perks like higher quality streams and fun customizations. We’re working toward an inclusive world where no one feels like an outsider, where genuine human connection is a click, text chat, or voice call away. A place where everyone can find belonging. Challenging? Heck yes. Rewarding? Double heck yes. It’s a mission that gives us the chance to positively impact millions of people all over the world. So if this strikes a chord with you, come build belonging with us!",glassdoor
112,"Apple
4.2
Biomedical Data Engineer - Health Technologies
Cupertino, CA

 Summary
Posted: Aug 8, 2022
Weekly Hours: 40
Role Number:200402289
The Health Technologies Team conceives and proves out innovative technology for Apple’s future products and features in health. We are seeking a highly capable Biomedical Data Engineer to join a multi-disciplinary team. Successful candidates will be able to integrate with our research study leads, data scientists and engineers to develop and support effective data analysis and machine learning workflows.
Key Qualifications
Experience with software engineering frameworks
Excellent coding skills in Python (e.g.,Pandas, Spark, Jupyter)
Workflow orchestrations (e.g., Airflow, Luigi)
Designing and maintaining (non-)relational databases (e.g. Postgres, Cassandra, MongoDB) and file systems (e.g. Parquet, CSV, JSON)
Great understanding of infrastructure designs
Linux, MacOS based development frameworks
iOS/ watchOS development (e.g., Swift, Objective-C)
Web Service APIs (e.g., AWS, REDCap, XNAT)
Version control frameworks (Git, virtualenv)
Familiarity with best practices for information security, including safe harbor privacy principles for sensitive data
Experience with biomedical sensors/platforms for measuring physiological signals in the health, wellness and/or fitness realms
Description
- Work closely with team members and study staff to design, build, launch and maintain systems for storing, aggregating and analyzing large amounts of data - Process, troubleshoot, and clean incoming data from human studies - Automate and monitor data ingestion and transformation pipelines, with hooks for QA, auditing, redaction and compliance checks per data management specifications - Create and maintain databases with existing and incoming clinical data - Architect data models and create tools to harmonize disparate data sources - Incorporate and comply with regulations as they pertain to electronic and clinical data and databases
Education & Experience
BS/MS in Computer Science, Engineering, Informatics, or equivalent with relevant 4+ years industry experience with biomedical, health or sensitive data.
Additional Requirements",glassdoor
113,"Vimeo
4.1
Data Engineer II, Analytics
New York, NY
$107K - $150K (Glassdoor est.)

 Vimeo is looking for an experienced Data Engineer II, Analytics to join our Data Architecture and Analytics Engineering team and work closely with Data Analysts and Data Scientists to create and maintain robust, scalable, and sustainable data models that provide decision-making insights for senior leadership including executives. The ideal candidate is a self-starter with a bias for action and results, with experience in a fast-paced, data-driven environment.
What you'll do:
Build data models that can support dynamic and efficient data analysis, and collaborate with other teams to maintain and evolve those models over time
Ensure alignment to coding standard methodologies and development of reusable code
Partner with Data Analysts to understand business processes and identify opportunities to build scalable and efficient data models that can be used for scalable, refreshable analysis and reporting
Create and enable the generation of ad-hoc / on-demand data sets for use by analysts and data scientists
Work with Engineering teams to set up monitoring and alerting systems for business and product KPIs
Skills and knowledge you should possess:
BS/MS in Computer Science or a related technical field.
2+ years working with Analytics and Data Engineering teams with a mixed data engineering and analytics background
2+ years of experience in scalable data architecture, fault-tolerant ETL, and monitoring of data quality in the cloud
Experience working on or leading initiatives around data governance, master data management, data catalogs, and enterprise data warehouse architecture
Strong analytical skills, data sensibility, and an able communicator
Open to working on multiple projects simultaneously
Proficiency in:
SQL
Python
Dimensional Modeling
Data pipeline development, workflow management, and orchestration tools
ETL optimization and best practices
Snowflake or other column-oriented and cloud-based databases
Looker or any similar Business Intelligence tool
Relational Databases
Bonus Points (Nice Skills to Have, but Not Needed):
DBT
Git / Github
Looker/Tableau is a big plus
large data sets (terabyte scale)
Apache Airflow
#LI-JS1
Vimeo (NASDAQ: VMEO) is the world's leading all-in-one video software solution. Our platform enables any professional, team, and organization to unlock the power of video to create, collaborate and communicate. We proudly serve our growing community of over 260 million users — from creatives to entrepreneurs to the world's largest companies.
Vimeo is headquartered in New York City with offices around the world. At Vimeo, we believe our impact is greatest when our workforce of passionate, dedicated people, represents our diverse and global community. We're proud to be an equal opportunity employer where diversity, equity, and inclusion is championed in how we build our products, develop our leaders, and strengthen our culture.
Learn more at www.vimeo.com
Learn more at www.vimeo.com/jobs",glassdoor
114,"Apple
4.2
Data Engineer
Cupertino, CA

 Summary
Posted: Aug 10, 2022
Weekly Hours: 40
Role Number:200406892
Are you a big-picture thinker who loves setting ambitious goals? Do you have a passion for understanding how each line of code affects all the others? In the Core Operating Systems group, you’ll ensure the OS is inseparable from each device’s identity as a whole. That’s because this group is committed to building fully integrated operating systems that combine hardware, software, and apps into a single Apple experience. Your dedication to cross-disciplinary collaboration will help develop groundbreaking technologies, such as iOS, macOS, watchOS, and tvOS. By crafting these distinct, holistic user experiences, you’ll continue to uphold and advance the excellence people expect from Apple devices. The Platform Services & Operations team in Core OS is looking for a Data Engineer to inform and develop essential workflow tooling at scale. The Workflow Engineering team enable teams to deliver high quality software through best in class engineering experiences, efficient workflow, data driven insights, and a culture of continuous improvement. Your focus is building the backend data pipelines that enables visualization of data across the organization in user intuitive and configurable formats.
Key Qualifications
3 +proven experience in a Data focused posistion
Proficient in Python; data access and retrieval. Quantitative data preparation. Regular expressions and text analysis
Highly Proficient in Database Language and Design; querying large stores of data (APIs, SQL, etc.).
Access, retrieval, and storage of information. Data Structures, modeling for speed and efficiency
Software Development; understanding of build pipelines, branching and merging, Agile methods, and the delivery of code. Fluency in Git (or comparable source control tool)
Description
- Replicate data from source system into data warehouse; retrieve data through various protocols and land it in a central store - Automate data pipelines; write programs to periodically update warehouse data from source systems - Design for scale; flexible infrastructure for common enhancements including: expanding the volume of captured data, adding fields to the user-facing views, and recompiling archived data - Work with a team of data scientists and full stack engineers, to derive and develop targeted insights through centrally managed interactive dashboards
Education & Experience
B.S. in Data Science, Computer Science, or equivalent experience.
Additional Requirements
Experience as an Analyst; worked in the delivery of visual information (dashboards, reports, web-apps)
An understanding of how data can be used and applied in context (what is useful to capture and how it can be communicated)
Full Stack Development; ability to maintain back-end systems and visualize front-end data for users (with a web-kit framework like Angular, React)
Experience with Snowflake and/or other data store technologies",glassdoor
115,"Pinterest
4.1
Data Engineer
Remote

 About Pinterest:
Millions of people across the world come to Pinterest to find new ideas every day. It's where they get inspiration, dream about new possibilities and plan for what matters most. Our mission is to help those people find their inspiration and create a life they love. In your role, you'll be challenged to take on work that upholds this mission and pushes Pinterest forward. You'll grow as a person and leader in your field, all the while helping Pinners make their lives better in the positive corner of the internet.
Our new progressive work model is called PinFlex, a term that's uniquely Pinterest to describe our flexible approach to living and working. Visit our PinFlex landing page to learn more.
The Enterprise Data Platform team is looking for a Data Engineer who has experience with Building Data Pipelines and Managing/Developing on any Cloud Data Warehouse. In this role you will also advise other Data Analysts and Data Engineers from the Business teams at Pinterest on the best practices for handling data and deriving insights using Snowflake. You will gradually become the Subject Matter Expert on Snowflake and also help build out the Modern Data Stack at Pinterest.
What you'll do:
Build Data Pipelines using Python on either Airflow or AWS Lambda to ingest data into Snowflake
Build Scripts in Python to manage Data Access on Snowflake
Define and advocate the best practices for storing and analyzing data inside Snowflake
Review the Data Modeling practices of other teams
What we're looking for:
Strong skills in Python and SQL
Experience with Building Data Pipelines in Python
Experience with any Cloud Data Warehouse either as an Administrator or a Developer
Strong Data Modeling skills
#LI-BB1
#LI-Remote
Our Commitment to Diversity:
At Pinterest, our mission is to bring everyone the inspiration to create a life they love—and that includes our employees. We’re taking on the most exciting challenges of our working lives, and we succeed with a team that represents an inclusive and diverse set of identities and backgrounds.

Not Specified
0",glassdoor
116,"Qualtrics
4.2
Data Engineer
Provo, UT
$83K - $125K (Glassdoor est.)

 The Qualtrics XM Platform™ is a system of action that helps businesses to attract customers who stay longer and buy more, to engage and empower employees to do the best work of their lives, to develop breakthrough products people love, and to build a brand people can’t imagine living without.

Joining Qualtrics means becoming part of a team bold enough to chase breakthrough experiences - like building a technology that will be a force for good. A team committed to diversity, equity, and inclusion because of a conviction that every voice holds value, with a vision for representation that matches the world around us and inclusion that far exceeds it. You could belong to a team whose values center on transparency, being all in, having customer obsession, acting as one team, and operating with scrappiness. All so you can do the best work of your career.

We believe every interaction is an opportunity. Are we yours?
The Team
Our team is a collection of deeply passionate engineers who are riding the groundbreaking of cloud computing and web scalability. We built data analytics applications that help company leaders gain insights about technology spends, make sound decision on technology investments, and drive innovation in resource utilization and efficiency optimizations. Our environment is primarily TypeScript, Node.js, React, MySQL NoSQL, AWS, Python, PHP, and Docker. In our collaborative culture, you find plenty of opportunities to impact our full-stack products; from Web & mobile UI to data visualization & analysis to data ingestion, storage and processing.
Job Responsibilities
Developing scalable, fast, robust, and simple web-based solutions to solve complex business problems
Close collaboration with your team to collect and incorporate feedback into your feature design
Drive operational excellence by investigating production issues, driving root cause analysis and follow-up actions for mitigation
Improve performance, availability, reliability, scale, throughput and latency
Work with your team in order to meet customer work you're doing, understand the decisions that are being made and make your voice heard.
Qualifications
Bachelor's degree in Computer Science or related field
Coding experience with any programming language (Prefer experience in TypeScript/JavaScript/React/Python)
Experience with web infrastructure and distributed systems
Experience with software engineering best practices (e.g. unit testing, code reviews, design, continuous delivery, git, test automation and build\deploy systems)
Ability to work in a fast-paced and agile development environment and to learn new frameworks/stacks
Passionate about building products that help customers easily and effectively get their job done
Enthusiastic person, who communicates effectively and is easy to work with
Curious and constantly learning on your own and from others
You get satisfaction from helping others succeed, and you constantly seek ways to improve
You can identify gaps, propose solutions to important problems, then take it to resolution
Preferred Qualifications
Shown ability to troubleshoot and identify the root cause of issues
Demonstrated skill and passion for operational excellence
Experience in a 24/7 production environment is a plus
Ability to retain composure under stressful conditions, communicate effectively with wide array of individuals at Qualtrics, and get the right things done
Confirmed ability to understand large systems, drilling down to code level",glassdoor
117,"Accenture
4.1
Data Engineer
San Francisco, CA

 Accenture Flex offers you the flexibility of local fixed-duration project-based work powered by Accenture, a leading global professional services company. Accenture is consistently recognized on FORTUNE's 100 Best Companies to Work For and Diversity Inc's Top 50 Companies For Diversity lists.
As an Accenture Flex employee, you will apply your skills and experience to help drive business transformation for leading organizations and communities. In addition to delivering innovative solutions for Accenture's clients, you will work with a highly skilled, diverse network of people across Accenture businesses who are using the latest emerging technologies to address today's biggest business challenges.
You will receive competitive rewards and access to benefits programs and world-class learning resources. Accenture Flex employees work in their local metro area onsite at the project, significantly reducing and/or eliminating the demands to travel.
Job Description:
As a Data Engineer, you will:
Utilize strong SQL & Python expertise to engineer sound data pipelines and conduct routine and ad hoc analysis to assess the performance of legacy products and the saliency of new features
Build reporting dashboards and visualizations to design, create, and track campaign/program KPIs
Perform analyses on large data sets to understand drivers of marketing engagement and provide recommendations on campaign and product optimization

Basic Qualifications:
Minimum 2 years of experience in Data Engineering
Minimum 2 years of experience with SQL
Minimum 2 years of experience with Python
High School Diploma or GED
Preferred Qualifications:
Experience with Data Analytics
As required by Colorado Law under the Equal Pay for Equal Work Act, Accenture provides a reasonable range of compensation for roles that may be hired in Colorado. Actual compensation is influenced by a wide array of factors including but not limited to skill set, level of experience, and specific office location. For the state of Colorado only, the starting range of pay for this role is $86.82 - $96.82 per hour, and information on benefits is here.

COVID-19 update:

The safety and well-being of our candidates, our people and their families continues to be a top priority. Until travel restrictions change, interviews will continue to be conducted virtually.

Subject to applicable law, please be aware that Accenture requires all employees to be fully vaccinated as a condition of employment. Accenture will consider requests for accommodation to this vaccination requirement during the recruiting process.

What We Believe

We have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture has the responsibility to create and sustain an inclusive environment.

Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more here

Equal Employment Opportunity Statement

Accenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation.

All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.

Accenture is committed to providing veteran employment opportunities to our service men and women.

For details, view a copy of the Accenture Equal Opportunity and Affirmative Action Policy Statement.

Requesting An Accommodation

Accenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.

If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.

Other Employment Statements

Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States.

Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.

Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.

The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.",glassdoor
118,"Lincoln Financial
3.6
Data Engineer (REMOTE)
Radnor, PA
Employer Provided Salary:$63K - $138K

 Date: Oct 9, 2022
Primary Location: Radnor, PA, US
Company: Lincoln Financial
Alternate Locations: Work from Home

Work Arrangement: Work from Home

Relocation assistance:: is not available for this opportunity.

Pay Range: $63,100 - $137,900

Bonus Potential: 5%

Requisition #: 69444

The Role at a Glance

This is an exciting opportunity within Lincoln’s Work Place Solutions IT Data Team for a Data Engineer/ETL Developer to help build solutions for Lincoln’s Work Place Solutions business. This position will assist Analytic Teams with the design and implementation of Data solutions and systems, including integration with databases and data warehouses, both on-Premise and in AWS Cloud. This candidate must be able to develop, enhance, and support Informatica workflows and processes using Informatica Power Center and Dataiku for the extraction and transformation of data in a UNIX and Oracle database environment. They must also have experience working within BI tools such as Tableau and Microstrategy. Experience working in the cloud using AWS native services such as Glue, Athena, Aurora, Redshift, and/or Snowflake is needed. The candidate must have experience participating in and beginning to lead teams within a Data Organization by suggesting new and innovative ways of gaining data processing efficiencies and participating in architectural and modeling discussions.

What you'll be doing

Participates in defining architecture and modeling best practices within the team
Develop tools and work on integrating disparate systems using ETL
Work on transformation of data into Facts and Dims in a Kimball and/or relational model
Works with Sr. Technical Professionals to implement data development best practices
Develop, enhance and support Informatica workflows and processes using Informatica Power Center for the extraction and translation of data in a UNIX and Oracle database environment
Develop, enhance and support Dataiku workflows and processes for transforming data into Kimball model Facts/Dims
Creates partnerships with stakeholders, POs, BSAs and Analytic teams in requirement, design and coding walkthroughs to ensure the development of quality solutions and understand complex business/technical problems and opportunities and identify potential application solutions.
Demonstrates expertise in a variety of the data warehouse concepts, practices, and procedures. Relies on extensive experience and judgment to plan and accomplish goals
Analyzes operational and analytical data requirements by working with cross functional business and application development teams
Maintains knowledge on current and emerging developments/trends for assigned area(s) of responsibility, assess the impact, and collaborates with senior management to incorporate new trends and developments in current and future solutions.
Participate with collaboration efforts with development teams to review, update and approve the data portion of project designs, participate in cost/benefit analysis and preparation of project plans.
Participate in the design, development and delivery data centric IT solutions, including large scale data staging and orchestration, integration and provisioning mechanisms
Works with business partners to prioritize business and information needs
Provides input and validates increasingly complex project plans, test plans and implementation plans
Creates increasingly complex technical specifications from business requirements/business specifications
Proactively identifies problems and presents/develops solutions
Communicates effectively with internal stakeholders and management
Defines detailed development tasks, task dependencies and estimates to complete work
What we're looking for

4 Year/Bachelor's degree or equivalent work experience (4 years of experience in lieu of Bachelor's) in Computer Science, Computer Information Systems, Information Systems, Information Technology or Computer Engineering or equivalent work experience (Minimum Required
3 - 5+ Years’ experience in application development that directly aligns with the specific responsibilities for this position (Required)
Experience with ETL development
Must have experience with Informatica; Dataiku is a plus
Must have experience with BI tools such as Tableau and Microstrategy
Experience with AWS cloud native services, such as: Glue, Athena, Aurora, Redshift
Must have a proven track record working closely with business stakeholders, BSAs, and POs, Solution Architects to understand requirements and expectations to achieve quality technical solutions
What’s it like to work here?
At Lincoln Financial Group, we love what we do. We make meaningful contributions each and every day to empower our customers to take charge of their lives. Working alongside dedicated and talented colleagues, we build fulfilling careers and stronger communities through a company that values our unique perspectives, insights and contributions and invests in programs that empower each of us to take charge of our own future.

What’s in it for YOU:
A clearly defined career framework to help you successfully manage your career
Leadership development and virtual training opportunities
PTO/parental leave
Competitive 401K and employee benefits
Free financial counseling, health coaching and employee assistance program
Tuition assistance program
A leadership team that prioritizes your health and well-being; offering a remote work environment and flexible work hybrid situations
Effective productivity/technology tools and training

Work Arrangement
Work from Home : Employees will work from home and are not required to work in a Lincoln office on a regular basis.

Lincoln will evaluate the following when setting the successful candidate's wage rate:
Prior work or industry experience.
Education level to the extent education is relevant to the position.
Unique skills

About The Company
Lincoln Financial Group, a Fortune 200 company with over 10,000 employees, provides advice and solutions that help empower Americans to take charge of their financial lives with confidence. Our core business areas — Life Insurance, Annuities, Retirement Plan Services and Group Protection — focus on supporting, preserving and enhancing over 17 million customer’s lifestyles and retirement outcomes.

Headquartered in Radnor, Pennsylvania, Lincoln Financial Group is the marketing name for Lincoln National Corporation (NYSE: LNC) and its affiliates. The company had $324 billion in end-of-period account values as of June 30, 2021.

Ranked one of the Best Large Employers in America and Best Employers for Women by Forbes magazine as well as one of Newsweek’s Most Responsible Companies, Lincoln Financial Group makes a serious investment in our employees’ futures through a broad range of wealth accumulation and protection plans, health and wellness programs, and career development resources designed to help each individual reach their personal and professional goals.

Lincoln is committed to creating a diverse and inclusive environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.

Lincoln Financial Group is a committed corporate citizen included on major sustainability indices including the Dow Jones Sustainability Index North America and FTSE4Good. Dedicated to diversity and inclusion, we earned perfect 100 percent scores on the Corporate Equality Index and the Disability Equality Index. Follow us on Facebook, Twitter, LinkedIn, and Instagram.

Be Aware of Fraudulent Recruiting Activities
If you are interested in a career at Lincoln, we encourage you to review our current openings and apply on our website. Lincoln values the privacy and security of every applicant and urges all applicants to diligently protect their sensitive personal information from scams targeting job seekers. These scams can take many forms including fake employment applications, bogus interviews and falsified offer letters.
Lincoln will not ask applicants to provide their social security numbers, date of birth, bank account information or other sensitive information in job applications. Additionally, our recruiters do not communicate with applicants through free e-mail accounts (Gmail, Yahoo, Hotmail) or conduct interviews utilizing video chat rooms. We will never ask applicants to provide payment during the hiring process or extend an offer without conducting a phone, live video or in-person interview. Please contact Lincoln's fraud team at fraudhotline@lfg.com if you encounter a recruiter or see a job opportunity that seems suspicious.

Additional Information
This position may be subject to Lincoln’s Political Contribution Policy. An offer of employment may be contingent upon disclosing to Lincoln the details of certain political contributions. Lincoln may decline to extend an offer or terminate employment for this role if it determines political contributions made could have an adverse impact on Lincoln’s current or future business interests, misrepresentations were made, or for failure to fully disclose applicable political contributions and or fundraising activities.

Any unsolicited resumes/candidate profiles submitted through our web site or to personal e-mail accounts of employees of Lincoln Financial Group are considered property of Lincoln Financial Group and are not subject to payment of agency fees.

Lincoln Financial Group (“LFG”) is an Equal Opportunity employer and, as such, is committed in policy and practice to recruit, hire, compensate, train and promote, in all job classifications, without regard to race, color, religion, sex (including pregnancy), age, national origin, disability, sexual orientation, gender identity and expression, Veteran status, or genetic information. Applicants are evaluated on the basis of job qualifications. If you are a person with a disability that impedes your ability to express your interest for a position through our online application process, or require TTY/TDD assistance, contact us by calling 260-455-2558.",glassdoor
119,"Zscaler
4.5
Data Engineer
San Francisco, CA
$99K - $143K (Glassdoor est.)

 Company Description

Zscaler (NASDAQ: ZS) accelerates digital transformation so that customers can be more agile, efficient, resilient, and secure. The Zscaler Zero Trust Exchange is the company’s cloud-native platform that protects thousands of customers from cyberattacks and data loss by securely connecting users, devices, and applications in any location.
With more than 10 years of experience developing, operating, and scaling the cloud, Zscaler serves thousands of enterprise customers around the world, including 450 of the Forbes Global 2000 organizations. In addition to protecting customers from damaging threats, such as ransomware and data exfiltration, it helps them slash costs, reduce complexity, and improve the user experience by eliminating stacks of latency-creating gateway appliances.
Zscaler was founded in 2007 with a mission to make the cloud a safe place to do business and a more enjoyable experience for enterprise users. Zscaler’s purpose-built security platform puts a company’s defenses and controls where the connections occur—the internet—so that every connection is fast and secure, no matter how or where users connect or where their applications and workloads reside

Job Description

Position: Data Engineer
Location: Remote within United States
About the team: As part of the IT group, we are responsible for executing our enterprise data strategy which emphasizes data management maturity, fosters a robust data culture, and architects a best-in-class enterprise data platform. We have the ultimate goal to provide trusted data and insights at scale which enable corporate and functional data-driven decision making. We are fueled by organic innovation, internal collaboration and adoption of data visualization, data management, reporting automation, AI/ML and integration tools. We leverage best practices and alignment through our Enterprise Data Community to deliver speed to insight, scale, control and enablement. The team is distributed across the United States and India and is composed of data engineers, data analysts, visualization developers, and infrastructure specialists.
Responsibilities/What You’ll Do:
Collaborate with Data & Technical architects, integration and engineering teams to capture inbound/outbound data pipeline requirements, conceptualize and develop solutions
Support the evaluation and implementation of the current and future data applications/technologies to support the evolving Zscaler business needs
Collaborate with IT business engagement & applications engineer teams, enterprise data engineering and business data partner teams to identify data source requirements
Profile and quantify quality of data sources, develop tools to prepare data and build data pipelines for integrating into Zscaler’s data warehouse in Snowflake
Continuously optimize existing data integrations, data models and views while developing new features and capabilities to meet our business partners needs
Work with Principal Engineer/ Data Platform Lead to design and implement data management standards and best practices
Continue to learn and develop next generation technology/ data capabilities that enhance our data engineering solutions
Develop large scale and mission-critical data pipelines using modern cloud and big data architectures

Qualifications

Qualifications/Your Background:
3+ years of experience in data warehouse design & development
Strong experience in integrating internal and external business applications (salesforce, netsuite, google analytics etc) with cloud data platforms like Snowflake
Proficiency in SQL and ability to perform complex modeling with large volumes of data
Experience with Big Data technologies like Hadoop
Required Experience with any industry standard ETL & data integration platforms like Matillion, Workato, Dell Boomi
Experience with data orchestration to like Apache Airflow a plus
Experience with resolving workflow and data quality issues associated with production grade large scale cloud systems
Strong capacity to manage multiple projects simultaneously
Experience with Python, Dbt or similar a plus

Additional Information

All your information will be kept confidential according to EEO guidelines.
#LI-YC2
#LI-Remote
What You Can Expect From Us:
An environment where you will be working on cutting edge technologies and architectures
A fun, passionate and collaborative workplace
Competitive salary and benefits, including equity
Why Zscaler?

People who excel at Zscaler are smart, motivated and share our values. Ask yourself: Do you want to team with the best talent in the industry? Do you want to work on disruptive technology? Do you thrive in a fluid work environment? Do you appreciate a company culture that enables individual and group success and celebrates achievement? If you said yes, we’d love to talk to you about joining our award-winning team.

Additional information about Zscaler (NASDAQ: ZS ) is available at https://www.zscaler.com.
Zscaler is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.",glassdoor
120,"Twitch
4.0
Data Engineer
San Francisco, CA
Employer Provided Salary:$140K - $171K

 About Us
Twitch is the world's biggest live streaming service, with global communities built around gaming, entertainment, music, sports, cooking, and more. It's where millions of people come together to chat, interact, and make their own entertainment.
We're about community, inside and out. You'll find coworkers who are eager to team up, collaborate, and smash (or elegantly solve) problems together. We're on a quest to empower live communities, so if this sounds good to you, see what we're up to on LinkedIn and Twitter, get interviewing tips on Instagram, and discover projects we're solving on our Blog.
About the Role
Reporting to the Head of Global Talent Acquisition, the Data Engineer will expand the reach and role of data among leaders and managers at Twitch. You will empower the business to integrate data into their daily workflow by creating/maintaining data pipelines, producing reporting, and automating our processes.
You can work in San Francisco, CA or remotely across the US.
This role is for you if:
You love automating processes and developing efficient scalable solutions
You're excited about contributing to the success, efficiency, and happiness of Twitch staff
You're excited to jump into a diverse array of data work to support the team
You enjoy working with autonomy and shaping a new function

You Will:
Delight consumers of people-related data by ensuring they have the data they need to inform decisions, where and when they need it
Build and own data pipelines, SQL queries/views, and apps
Automate processes through the use of JavaScript and other languages
Improve business, engineering, and data processes through data architecture, engineering, testing, and operational excellence best practices
Ensure the integrity of People and Places data in analyses and tools through regular audits
Partner to develop analytics products and recommend opportunities
Develop ongoing metrics, analyses, and dashboards to guide important decisions
You Have:
Experience writing SQL and a procedural language (Python, R, etc.) for data handling
Experience owning systems that collect, transform, and visualize data
Experience implementing data analytics, visualization tools and programs for HR working with Workday, Greenhouse, Tableau, Google Workspace, Google Data Studio, and Google Sheets
Experience implementing software solutions to automate data source, visualization and analytics products
Bachelors in related field, or equivalent experience
Bonus Points
Experience handling People-related data including compensation, performance, hiring, and engagement data.
Experience automating Google services (Sheets, Docs, Data Studio) with Javascript
Experience with Workday, Greenhouse, and Tableau
Demonstrated net positive contributor to company community and culture above and beyond the core job
Perks
Medical, Dental, Vision & Disability Insurance
401(k), Maternity & Parental Leave
Flexible PTO
Commuter Benefits
Amazon Employee Discount
Monthly Contribution & Discounts for Wellness Related Activities & Programs (e.g., gym memberships, off-site massages, etc.),
Breakfast, Lunch & Dinner Served Daily
Free Snacks & Beverages
We are an equal opportunity employer and value diversity at Twitch. We do not discriminate on the basis of race, religion, color, national origin, gender, gender identity, sexual orientation, age, marital status, veteran status, or disability status, or other legally protected status.
Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
Pursuant to the Los Angeles Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
The base pay range for this position in Colorado, Connecticut and Washington is $139,860 - $170,940 yr and in New York City is $153,900 - $188,100 yr. Pay is based on market location and may vary depending on job-related knowledge, skills, and experience. A sign-on payment and restricted stock units may be provided as part of the compensation package, in addition to a full range of medical, financial, and/or other benefits, dependent on the position offered. Applicants should apply via Twitch's internal or external careers site.
Workers in New York City who perform in-person work or interact with the public in the course of business must show proof they have been fully vaccinated against COVID or request and receive approval for a reasonable accommodation, including medical or religious accommodation.
Twitch values your privacy. Please consult our Candidate Privacy Notice, for information about how we collect, use, and disclose personal information of our candidates.
Job ID: TW7236
#LI-Remote #RemoteFriendly",glassdoor
121,"National Research Group
3.7
Data Engineer
San Francisco, CA
$88K - $128K (Glassdoor est.)

 Who We Are
National Research Group (NRG) is a leader in data driven insights and strategic consultation to the global entertainment and technology industries. Working at the confluence of technology, content, and culture, NRG offers bold insights for storytellers everywhere. Our consultants have experience working across all facets of media and technology.
Why You'll Love It Here
We are inspired by working with storytellers that challenge us to think differently and see the world in new ways. As a result, our business is driven by creative, curious, and inventive people who have a passion for pop culture. We work as a collective across disciplines and geographies to bring together the best thinking for every assignment, delivering insights to bold storytellers everywhere.
The Opportunity
We are looking for a data engineer with a background in building and maintaining data pipelines to integrate and process diverse data sources and data formats. This candidate should have a minimum of 1-year experience for a full-time position within our fast paced and growing company.
If you feel that you can make an impact through innovation and collaboration and come to work with a passion to facilitate in delivering high quality data to our teams and clients, this is a great role for you.
The Role
Build, test, orchestrate, and maintain data pipelines that support the data sciences team and customer-facing client teams.
Assist in ad-hoc data deliveries by querying data from various SQL relational databases stored in multiple data models.
Track and manage pipeline efficiency and stability.
Evaluate, parse, clean, and integrate raw data sets including third party APIs. Help build sophisticated ETL processes around first party data such as survey data, second and third-party data sources such as IP addresses, clickstream data, movie meta data.
Provide recommendations for data storage, configurations, data access tools and new technologies/architectures.
Develop code-based data transformation/aggregation in data lakes, relational databases (primary use cases) and possibly non-relational databases, as well as for the purpose of BI tools such as Power BI and Tableau.
Participate in developing data APIs for data ingestion of NRG data into client-side applications or client-side data systems.
Assist application developers in the effective use of database query and programming languages.
Contribute to managing data integrity, data storage efficiency and data ecosystem efficiency.
Who You Are
Team asset who can describe data structures, relationships, and flows behind organization database servers and applications.
Up to date on the latest data-related best practices and technologies and always looking to learn more.
Internally motivated self-starter who continuously strives to get things done, regardless of challenges encountered.
Critical thinker, able to understand and respond to complex questions or issues that may arise, and able to demonstrate willingness to experiment with new technologies.
Successfully manages time and multiple competing priorities in order to ensure deadlines are always met.
Team player who is able to work collaboratively and initiate and drive projects to completion with minimal oversight.
Ideal Candidate
BS/BA in Computer Science or related field.
1+ year experience in building data pipelines or ETL.
1+ year experience with SQL (we use Snowflake but other experience with relational databases is welcome).
1+ year experience with AWS technologies/infrastructure.
Working knowledge with Python.
A solid foundation with end-to-end development and the desire to further their technical knowledge.
Knowledge of PII (personally identifiable information) data security standards is a plus.
dbt experience is a plus.
Terraform experience is a plus.
Dagster experience is a plus.
Experience in databases structured against survey data is a big plus.
Position Type
This is a full-time, exempt position.
Work Environment
This position is expected to be fully remote. However, NRG offers flexible work options if an employee happens to live near a dedicated office (Playa Vista or New York) and wants a hybrid work model. This role routinely uses standard office equipment.
Required Application Materials:
CV/Resume
Cover Letter which should include:
Why do you want to work at NRG?
Why are you interested in working in the entertainment industry?",glassdoor
122,"State Farm
3.7
Data Analytics Engineer (REMOTE)
Dunwoody, GA
Employer Provided Salary:$85K - $135K

 Overview:
We are not just offering a job but a meaningful career! Come join our passionate team!
As a Fortune 50 company, we hire the best employees to serve our customers, making us a leader in the insurance and financial services industry. State Farm embraces diversity and inclusion to ensure a workforce that is engaged, builds on the strengths and talents of all associates, and creates a Good Neighbor culture.
We offer competitive benefits and pay with the potential for an annual financial award based on both individual and enterprise performance. Our employees have an opportunity to participate in volunteer events within the community and engage in a learning culture. We offer programs to assist with tuition reimbursement, professional designations, employee development, wellness initiatives, and more!
Visit our Careers page for more information on our benefits, locations and the process of joining the State Farm team!
REMOTE: Qualified candidates (outside of hub locations listed below) may be considered for 100% remote work arrangements based on where a candidate currently resides or is currently located.
HYBRID: Qualified candidates (in or near hub locations listed below) should plan to spend time working from home and some time working in the office as part of our hybrid work environment.
Responsibilities:
A Day In The Life Of A Data Analytic Engineer
As a data engineer, you will play in integral role supporting the Data Science team by helping build and support solutions to drive results for the enterprise. Data analytic engineers are responsible for developing and maintaining data feature stores, accountable for maintaining and enhancing the compute environment for our Data Science teams and assisting with analytic research requests. Through this role, your work is essential for helping increase the use of analytics for decision making across the company.
What You Can Expect
Being part of our team will help facilitate your professional growth across multiple development areas. First, you will strengthen your communication skills through interactions with key business partners that require you to articulate technical concepts in a non-technical way. Additionally, the variety of projects that you work on will allow you to refine your knowledge for data pipelines, tool development, and data analysis. Finally, to help keep your skills sharp, this role includes an opportunity for practical research and continued professional development with opportunities to learn and leverage cutting edge tools and many different programming languages.
Qualifications:
Preferred Skills and Work Experiences

Computer Science background (Bachelor’s degree or higher) with a minimum of 2 years of experience in an IT related field
Ability to support multiple efforts and work closely with roles such as Data Scientist, Machine Learning Engineers, and Data Analysts to support internal data pipelines
Possess strong business acumen and the technical ability to acquire, transform and interpret complex data in order to answer ad hoc questions often coming from top executives
Experience with gathering and creating analytic business requirements, researching potential data sources (both internal and external sources), designing, developing, and maintaining data assets
Experience with data governance policies, including the implementation of data security strategies
Excellent communication skills and the ability to work with multiple, diverse stakeholders across business areas and leadership levels
Technical expertise with multiple compute environments, including at least two of the following: Linux, Hadoop, Mainframe, and AWS
Experience with building and maintaining data pipelines
Proficiency with technologies such as – CI/CD, Terraform, AWS (Lambda, Athena, Glue, S3, IAM, Redshift), Feature Store
Familiarity with building SQL and No-SQL queries
Proficiency with at least one of the following languages: Python, R, or SAS
Knowledge of version control and DevOps tools, such as GitLab
Knowledge of work prioritization using the Agile framework
****Applicants are required to be eligible to lawfully work in the U.S. immediately; employer will not sponsor applicants for U.S. work authorization (e.g., H-1B visa) for this opportunity*****

For Los Angeles candidates: Pursuant to the Los Angeles Fair Chance Initiative for Hiring, we will consider for employment qualified applicants with criminal histories.
For San Francisco candidates: Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
For Colorado candidates:
Salary Range: $84,620.00 - $135,400.00
Competitive Benefits, including:
401k Plan
Health Insurance
Dental/Vision plans
Life Insurance
Paid Time Off
Annual Merit Increases
Tuition Reimbursement
Health Initiatives
For more details visit our benefits summary page

SFARM
#LI-LP1
#LI-Remote

SFARM
#LI-LP1",glassdoor
123,"Resideo
3.9
Junior Data Engineer
Austin, TX
$75K - $113K (Glassdoor est.)

 Resideo is seeking a Junior Data Engineer to join our AI team. Resideo engineers strive to provide peace of mind to millions of homeowners through a robust and capable set of products that safeguard the home and simplify everyday life.
Unusual compared to most data engineering roles, the AI team is dealing with millions of unstructured data events per day. We need to build robust ETL and data pipelines to continuously improve our ML models. Those ML models enable a range of next-generation of Resideo home security products, including video doorbells, outdoor cameras, and other security sensors.
As part of this initiative, we are looking for a junior data engineer who is excited to work with cloud unstructured data pipelines and the challenges associated with them . You will be taking POC pipelines and expanding them to work with big data, helping build out MLOps for Resideo. Work with a cross-functional team of embedded engineers, data scientists, and cloud developers to deliver a best-in-class solution.
This role will have the opportunity to impact newly developed consumer products with high business visibility.
JOB DUTIES:
As a Data Engineer, you will be tasked with building data acquisition and processing to building video machine-learning products
Unstructured data comes with unique challenges and problems that you will be responsible for researching and helping solve
You will work closely with engineers and scientists contributing to the ongoing development and monitoring of ML products
Decompose complex problems and pipelines into simple, straight-forward solutions
Work with a geographically and culturally dispersed team
YOU MUST HAVE:
Bachelor's degree in Computer Science, Engineering, Mathematics or a related field or equivalent professional or military experience
One or more in each of these categories:
Python, PySpark, SQL, etc.
Experience manipulating and curating large image and video datasets
Experience with CI/CD workflows, including Github and Terraform
Technial exposure across video/image topics including image processing, ML/DL, encodings
Excellent written and oral communication skills
Demonstrated ability to achieve goals in a fast-paced environment
WE VALUE:
Computer vision , CNNs, and Machine learning workflows
Domain knowledge of security cameras or home IOT devices
Understanding with embedded SoC devices and edge deployment
Experience with a variety of vision, depth or audio sensors
Knowledge and experience with Azure cloud environments, Databricks, Azure Data Factory
WHAT'S IN IT FOR YOU:
Life and health insurance
Life assistance program
Accidental death and dismemberment insurance
Disability insurance
Retirement plan (Immediate eligibility for 401K)
Vacation & holidays. (Enjoy work-life balance)
#LI-CT1
#SWE

About Us: Resideo is a leading global provider of critical comfort and security solutions primarily in residential environments and distributor of low-voltage electronic and security products. Building on a 130-year heritage, Resideo has a presence in more than 150 million homes, with 15 million systems installed in homes each year. We continue to serve more than 110,000 professionals through leading distributors, including our ADI Global Distribution business, which exports to more than 100 countries from more than 200 stocking locations around the world. Resideo is a $5.0 billion company with approximately 13,000 global employees. For more information about Resideo, please visit www.resideo.com .
At Resideo, we bring together diverse individuals to build the future of homes. Resideo is an equal opportunity employer. Qualified applicants will be considered without regard to age, race, creed, color, national origin, ancestry, marital status, affectional or sexual orientation, gender identity or expression, disability, nationality, sex, religion, or veteran status.",glassdoor
124,"Autodesk
4.2
Data Engineer
San Francisco, CA
$116K - $169K (Glassdoor est.)

 Job Requisition ID #
22WD64738
Position Overview
Autodesk is looking for a talented Data Engineer to join our Observability Analytics team to create robust and scalable data pipelines using and improving existing platforms.

A successful candidate has a strong sense of ownership and will use their expertise to build extensible data models, provide meaningful recommendations and actionable strategies to partnering data scientists. They will drive performance enhancements, development best practices and collaborate with other Data Engineering teams throughout Autodesk.

Responsibilities
Create, automate, and support reliable data pipelines
Gather customer requirements, sequence work and document technical solutions
Interface with data engineers, data scientists, product managers and internal stakeholders
Cross-train and mentor teammates

Minimum Qualifications
3+ years of data processing experience in large cloud-based infrastructure (AWS preferred)
Familiar with SQL, dimensional modeling, and analytical data warehouses, like Snowflake
Understanding of Data Engineering best practices for medium to large scale production workloads
Hands-on software development experience in Python
Experience with data pipeline orchestration tools, like Airflow
Customer-facing and service-oriented person
Team player with great communication skills
Problem solver with excellent written and interpersonal skills
Experience consuming REST APIs

Preferred Qualifications
Experience with ELT pipelines - DBT
REST API design and implementation
Familiarity with containers and infrastructure-as-code principles
Experience with automation frameworks - Git, Jenkins, and Terraform
#LI-POST
At Autodesk, we're building a diverse workplace and an inclusive culture to give more people the chance to imagine, design, and make a better world. Autodesk is proud to be an equal opportunity employer and considers all qualified applicants for employment without regard to race, color, religion, age, sex, sexual orientation, gender, gender identity, national origin, disability, veteran status or any other legally protected characteristic. We also consider for employment all qualified applicants regardless of criminal histories, consistent with applicable law.
Are you an existing contractor or consultant with Autodesk? Please search for open jobs and apply internally (not on this external site). If you have any questions or require support, contact
Autodesk Careers
.",glassdoor
125,"Apple
4.2
Biomedical Data Engineer - Health Technologies
Cupertino, CA

 Summary
Posted: Aug 8, 2022
Weekly Hours: 40
Role Number:200402289
The Health Technologies Team conceives and proves out innovative technology for Apple’s future products and features in health. We are seeking a highly capable Biomedical Data Engineer to join a multi-disciplinary team. Successful candidates will be able to integrate with our research study leads, data scientists and engineers to develop and support effective data analysis and machine learning workflows.
Key Qualifications
Experience with software engineering frameworks
Excellent coding skills in Python (e.g.,Pandas, Spark, Jupyter)
Workflow orchestrations (e.g., Airflow, Luigi)
Designing and maintaining (non-)relational databases (e.g. Postgres, Cassandra, MongoDB) and file systems (e.g. Parquet, CSV, JSON)
Great understanding of infrastructure designs
Linux, MacOS based development frameworks
iOS/ watchOS development (e.g., Swift, Objective-C)
Web Service APIs (e.g., AWS, REDCap, XNAT)
Version control frameworks (Git, virtualenv)
Familiarity with best practices for information security, including safe harbor privacy principles for sensitive data
Experience with biomedical sensors/platforms for measuring physiological signals in the health, wellness and/or fitness realms
Description
- Work closely with team members and study staff to design, build, launch and maintain systems for storing, aggregating and analyzing large amounts of data - Process, troubleshoot, and clean incoming data from human studies - Automate and monitor data ingestion and transformation pipelines, with hooks for QA, auditing, redaction and compliance checks per data management specifications - Create and maintain databases with existing and incoming clinical data - Architect data models and create tools to harmonize disparate data sources - Incorporate and comply with regulations as they pertain to electronic and clinical data and databases
Education & Experience
BS/MS in Computer Science, Engineering, Informatics, or equivalent with relevant 4+ years industry experience with biomedical, health or sensitive data.
Additional Requirements",glassdoor
126,"2am.
Data Engineer
Remote

 Our ongoing desire to evolve took us on a journey #beyondsoftware. We are 2am.tech, a team of builders and problem solvers with a core belief in delivering excellence. This value has bred a company culture of providing solutions and products that exceed expectations every time. We are a fully remote company based in Miami, FL. If you're based in LATAM, the Balkans, and Europe, we'll be happy to hear from you.

As Data Engineer you are responsible for:
Communicate complex concepts verbally in English.
Be able to significantly overlap or fully work in North American time zones. These are the times the clients’ teams are working, and you need to share some hours to be part of those teams.
Respect deadlines and work in a team-oriented environment.
Assess new technologies and trends correctly.
Extensive experience with Data warehousing methodologies and modeling techniques.
Minimum three years of experience with the Snowflake architecture including using features such as Zero Copy Clone, Time Travel, User defined functions, etc.
Experience managing security in Snowflake including the creation of custom Roles to control access to Data, Databases, Warehouses, etc.
Experience in designing Compute Clusters (Warehouse) in Snowflake.
Good knowledge of Snowpipe (whatever ETL or ELT we will be using) for handling Streaming data.
Advanced understanding of migration, and methods to cloud data solutions.
Extensive experience in handling semi-structured data (JSON, XML) using the VARIANT attribute in Snowflake.
Experience in re-clustering the data in Snowflake with a good understanding of how Micro-Partition works inside Snowflake.
More than five years in creating master data datasets.
Design Tableau KPIs style dashboards and embed those in web applications.
Designing Tableau reports. Minimum of 3 years.
High English level is a must.",glassdoor
127,"Discord
4.1
Software Engineer, Data Products
San Francisco, CA
Employer Provided Salary:$165K

 Part of the central Data Platform organization, the Data Products team seeks to make the petabytes of data at Discord easily accessible to everyone at the company. We build full-stack applications, tooling, and frameworks to improve the productivity of teams at Discord with strong data needs, in particular our product, analytics, and machine learning teams. Our work is foundational to company and product strategy — to learn more about Discord Engineering,read our engineering blog here! If that sounds exciting to you, read on! What you'll be doing Build applications, tooling, and frameworks to improve the productivity of Discord's product, analytics, and machine learning teams, using modern technologies such as BigQuery, Airflow, Kubernetes, etc. Work with our analytics and data science teams to optimize data models for performant storage/retrieval and fulfill critical product and business requirements Work to empower internal users via training and documentation. Contribute to and promote data engineering and governance standards across Discord. What you should have You have 2+ years of experience as a Software Engineer. Experience with at least one of the following languages: Python, Java, Scala. Experience building and deploying large-scale distributed systems Experience with and/or exposure to a variety of datastores (relational, NoSQL, data warehouse solutions). Good working knowledge of relational databases and query authoring (SQL). You thrive in ambiguous environments and get excited about figuring out solutions to complex problems, and then executing on them. You are a first principles thinker that can work with others to come up with pragmatic solutions — and then evolve and generalize them. You have the ability to take a high-level goal and deliver shippable code. You have a growth mindset — curious, eager to learn, and never afraid of asking questions. Bonus Points Experience working with very high-scale data infrastructure Experience with data products (discovery, quality checks, etc) on Google Cloud Platform, Kubernetes, or Airflow Full-stack development or product engineering experience New York City residents only: Minimum salary of $165,000/year + equity and benefits *Note: Disclosure as required by NYC Pay Transparency Law Colorado residents only: Minimum salary of $132,000/year + equity and benefits *Note: Disclosure as required by sb19-085(8-5-20). Benefits and Perks Comprehensive medical insurance including Health, Dental and Vision (plus up to $20,000 for gender affirmation procedures) Mental health resources and quarterly wellness stipends 16+ paid holidays, 4 weeks of PTO + use-what-you-need sick days Paid parental leave (plus fertility, adoption and other family planning benefits) Flexible long-term work options (remote and hybrid) Volunteer time off A diverse slate of Employee Resource Groups Plus commuter contributions and other perks for office-based employees About Us Discord is a voice, video and text app that helps friends and communities come together to hang out and explore their interests — from artists and activists, to study groups, sneakerheads, plant parents, and more. With 150 million monthly users across 19 million active communities, called servers, Discord has grown to become one of the most popular communications services in the world. Discord was built without selling ads or user data and instead, offers a premium subscription called Nitro that gives users special perks like higher quality streams and fun customizations. We’re working toward an inclusive world where no one feels like an outsider, where genuine human connection is a click, text chat, or voice call away. A place where everyone can find belonging. Challenging? Heck yes. Rewarding? Double heck yes. It’s a mission that gives us the chance to positively impact millions of people all over the world. So if this strikes a chord with you, come build belonging with us!",glassdoor
128,"Mint Mobile
3.6
Digital Data Engineer I - Remote
Costa Mesa, CA
Employer Provided Salary:$90K - $103K

 MINT MOBILE is seeking a talented Digital Data Engineer I to join the Data Management Team! Individual reports to Customer Data Manager. Role is remote; must reside in the United States.
ABOUT THE ROLE
Provide direct data engineering development to data pipelines for ETL establishment and enhancements to and from data warehouses to customer management platform (Braze). Work collaboratively with cross-functional teams to determine digital data needs, establish data collection requirements, and deploy & maintain accurate data to ensure metrics & dimensions are addressed for analytics/reporting requirements.
Your usual day of awesomeness includes:
Transform required data conditions into performance code logic.
Develop high-performance code in SQL and Python.
Develop, automate, and enhance ELT processes for continuous data flow.
Create, modify, and deploy code to production via AWS resources including Lambda, S3, Glue, Redshift, etc.
Partner with stakeholders to support the implementation and development of data requirements.
Troubleshoot data anomalies and provide applicable solutions.
Build, test and maintain database pipeline architectures.
WHAT YOU BRING
Advanced level in SQL and Python for data engineering and backend development.
Understanding of popular code development approaches:
Test-driven development
Continuous Integration/Continuous Deployment (CI/CD)
Experienced working with AWS services (Lambda, S3, Glue, Redshift etc.) and Cloud Data Warehouse.
Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
Define digital data collection methods and implementations to DWH and customer management platforms.
Experienced with QA testing process to verify data is collected & rendered as expected.
Ability to excel in a fast-paced, cross-functional environment.
Ability to work autonomously.
Excellent written and verbal communication skills.
Proactive problem-solving and critical thinking skills.
Ability to manage time effectively and consistently meet deadlines.
NICE TO HAVE
Prior working knowledge of Braze or other Customer Management Platforms
Snowflake Cloud Data Warehouse
Terraform/Bitbucket/Airflow/Jenkins
Looker, Tableau, Power BI
WE ARE MINT MOBILE
We connect people to what's most important in their lives: Easily, affordably and reliably. We strive to be California's Preeminent Destination Employer. Oh yeah, we get it too! We understand what matters to you most. You're an individual with unique needs, and we're prepared to exceed any expectations you have for an ideal employer.
We're smart, strategic, and get things done without a lot of red tape or unnecessary politics. Everyone matters here and everyone has a voice. Expect to spend your time contributing to projects that really matter. We obsess over the employee experience. To start, we provide some of the most competitive salary, benefits, family leave, vacation, retirement and equity options in Southern California. We believe in you and invest in you. Not just your career aspirations, but your life.
In addition, we've got a laundry list of perks you'll brag about on insta - Lunch every day prepared by our very own chef, healthy snacks, onsite gym, free massages, car wash services, and most importantly, a team atmosphere. We even raise the bar on well bars, including Espresso/Cappuccino/Nitro/Cold Brew/Kombucha Bar, Froyo Bar, Breakfast Bar, Snack Bar and a, well, you know, bar (after 5 pm).
And if you feel intrigued right now reading, imagine the co-workers we have already attracted. This is the kind of team you'll want to take home to mom or invite to your kid's next birthday party. This is the kind of close-knit community happening here. Come check out how you can be part of Mint!
OUR VALUES – LET'S MAKE LIFE ULTRA TOGETHER!
Ownership: We are all owners; be the outcome and get the job done.
Action Biased: Be brilliant, proactive, and act with urgency.
Embrace the Adventure: Be agile, adaptive, and thrive on change.
Invent and Simplify: Never accept good enough.
$1,000 REFERRAL BONUS
Take a look at this job description, if you are the right person, please apply. If Mint Mobile doesn't appear to be a fit for you, refer a friend or colleague and get $1,000. Let your friend or colleague know to provide your full name and email when applying to the job. If we hire them and they stay for 90 days, you get $1000. For more details of restrictions and rules, please email recruiting@ultra.me.

Covid-19 Vaccination Requirement
UVNV, Inc. has adopted a mandated vaccination policy to support the health and safety of our team members and our community. The Company requires all employees to be fully vaccinated. The Company will provide accommodations based on medical condition or sincerely held religious beliefs or practices. Please let us know if you'd like to discuss the policy or available accommodations before proceeding with our recruitment process.
We are committed to equal employment opportunities regardless of race, color, genetic information, creed, religion, sex, sexual orientation, gender identity, lawful alien status, national origin, age, marital status, or protected veteran status. We support an inclusive workplace where associates excel based on personal merit, qualification, experience, ability, and job performance.
In support of the Equal Pay for Equal Work Act, the range of starting pay for this role is $90,000 - $103,000. This is not a guarantee of compensation or salary, actual compensation is influenced by a wide range of factors including but not limited to skill set, level of experience, education, certifications, responsibility, and geographic location. We also offer a variety of benefits including health, disability insurance, 401 (k), flexible spending accounts, EAP, education reimbursement, parental leave, unlimited vacation, bonuses, incentive stock options and company paid holidays. The specific programs and options available will vary depending on state, start date, and employment type. Our recruitment team will be happy to answer any questions you may have.
#LI-Remote",glassdoor
129,"Spokeo
3.8
Data Engineer, Analytics
Pasadena, CA
$113K - $164K (Glassdoor est.)

 Spokeo is a people search engine that both enlightens and empowers our customers. With over 12 billion records and 14 million visitors per month, we reconnect friends, reunite families, prevent fraud, and more.

We are looking for a Data Engineer, Analytics to join our team and help build our NextGen customer data management, analytics, and ML platform. This role will work as part of the larger data science and analytics team to build and maintain business-critical data pipelines and infrastructure.

Responsibilities:
Design and build maintainable and scalable infrastructure for data extraction, preparation, and loading of data from backend services and web browser clients to our data lake and other reporting databases
Build and manage tools to monitor pipeline performance and provide deeper insight into pipeline metrics
Monitor data pipelines and services for issues and ensure identified bugs are routed and resolved
Work with large, complex SQL and NoSQL databases
Create and maintain technical documentation and write well-abstracted, reusable, and efficient code
Essential Requirements:
2+ years of experience in data engineering or software development
Strong competency in SQL
Strong programming skills in languages such as Python, Ruby, etc.
Experience with AWS eco-system and working with services like EMR, RDS, Redshift, Kinesis, etc.
Experience working with large data sets in a Hadoop or Spark environment
Strong organizational skills and detail-oriented mindset
BS in Computer Science or equivalent skills and experience

Privacy Notice for Candidates: https://www.spokeo.com/recruiting-policy

Spokeo is an equal opportunity employer. Applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Spokeo fosters a business culture where ideas and decisions from all people help us grow, innovate, create the best products, and be relevant in a rapidly changing world.

Recruiters or staffing agencies: Spokeo is not obligated to compensate any external recruiter or search firm who presents a candidate or their resume or profile to a Spokeo employee without 1) a current, fully-executed agreement on file and 2) being assigned to the open position (as a search) via our applicant tracking solution.

This is a remote position.",glassdoor
130,"Mercury
3.7
Data Engineer
San Francisco, CA
$104K - $152K (Glassdoor est.)

 SF, NY, Toronto, Portland, or remote
Full-time
Mercury
In the 1880s, Herman Hollerith noticed the US Census was taking over 8 years to calculate. To solve this, he invented a tabulating machine using punch cards that dramatically sped up the process and served as the foundation for innovation in high quality data gathering.
We’re looking for our first Data Engineer who can help us build our high quality data engine that informs how we invest in and build Mercury’s future. You’ll be early to building a data-informed culture across Mercury so that we can all determine what’s happening, react quickly, and invest intelligently.
Here are some things you’ll do on the job:
Partner with leadership, engineers, and data scientists to understand data needs and build systems that deliver high quality and reliable data.
Own and maintain the data systems that extract, transform, and load data into internal and external tooling.
Apply proven expertise and build high-performance scalable data warehouses.
Design, build, and launch efficient & reliable data pipelines to move and transform data (both large and small amounts).
Design and develop new systems in partnership with software engineers to enable quick and easy consumption of data.
You should:
Have 2+ years of experience working with analytics teams on building high quality and reliable data infrastructure.
Be able to navigate from architecture and implementation decisions related to data infrastructure to guide teams towards building reliable and accurate pipelines and company-critical data sets.
Have familiarity with postgres backend data, Snowflake, and data transformation tools like dbt.
Value quality in data tools, testing, and innovation.",glassdoor
131,"Apple
4.2
Keystone Big Data Software Engineer, Global Business Intelligence
Cupertino, CA

 Summary
Posted: Jul 18, 2022
Role Number:200399924
Imagine what you could do here! At Apple, great minds come together to build products, services, and solutions that amaze the world. Imagine how your contributions could transform the world and there is no limit to what you could accomplish here. Apple's Global Business Intelligence (GBI) team is seeking an experienced Software Engineer to build high quality, scalable and resilient distributed systems that power Apple's analytics platforms and data pipelines. Apple's Enterprise Data Warehouse landscape caters to a wide variety of real-time, near real-time and batch analytical solutions. These solutions are an integral part of business functions like Sales, Operations, Finance, AppleCare, Marketing, and Internet Services, enabling business drivers to make critical decisions. If you enjoy learning new technologies, and are comfortable proposing and implementing solutions, demonstrating Software Engineering standard methodologies, you will find it rewarding to work in GBI! The ideal candidate for this position will be able to think outside of the box and should have passion for building engineering solutions to enable business in making time sensitive and critical decisions.
Key Qualifications
Strong fundamentals in data structures, algorithms, and software system design
Strong hands-on programming skills (Scala / Java / Python preferred)
Proficiency in developing applications in Spark & deep understanding of Spark is essential for this role
Proven track record of building jobs processing high-volume data using Spark
Experience with real time data processing with Spark Streaming, Flink is a huge plus
Committed to test driven development paradigm
Strong analytical and interpersonal skills and demonstrated ability to code & collaborate
Self-starter, highly motivated and ability to research, learn, prototype quickly
Sound experience in Cloud technologies such as AWS or GCP
Experience on Cloud with databases like SnowFlake and Singlestore is a plus
Prior experience in the areas of AI/ML/Data Sciences will be a strong plus
Curiosity to explore and understand data is a plus
Description
The Frameworks team in GBI build and support critical infrastructural systems which provide services for numerous organizations within Apple and we are looking for a strong, enthusiastic developer to join as a member of this group. You are someone with ideas and real passion for software delivered as a service to improve reuse, efficiency, and simplicity. This engineer’s work will affect multiple data teams within Apple and enable our partners to derive insights and help execute their goals.
Education & Experience
BS/MS in Computer Science, Computer Engineering or similar field
Additional Requirements
Apple is an Equal Opportunity Employer that is committed to inclusion and diversity. We also take affirmative action to offer employment and advancement opportunities to all applicants, including minorities, women, protected veterans, and individuals with disabilities. Apple will not discriminate or retaliate against applicants who inquire about, disclose, or discuss their compensation or that of other applicants.
We at Apple we are committed to working with and providing reasonable accommodation to applicants with physical and mental disabilities. Learn more.",glassdoor
132,"Intrado
3.7
Data Engineer
Remote
Employer Provided Salary:$90K - $97K

 Job Description
For this opening we will consider candidates from the following locations: , United States |


Intrado is looking to hire a Data Engineer to join our Life & Safety business segment. This role is a fully remote and work from home opportunity anywhere in the USA.
Essential Duties:
Responsible for creating standardized documentation to be utilized by team members to process cases.
Analyzes and evaluates applications/tasks and determines areas that need improvement within the scope of departmental responsibility
Serves as primary escalation point for assigned area of responsibility
Process cases that were not resolved at lower level due to the cases being undocumented
Create documentation to be entered into a centralized knowledgebase for case resolutions to be utilized by department staff
Maintain and update centralized knowledgebase to ensure information is accurate and relevant
Develop basic reports for use by management in an accurate and timely manner
Analyze and evaluate applications and tasks and determine areas that need improvement within the scope of departmental responsibility
Collaborate with internal teams to complete design phase and initiate implementation
Participate in large-scale projects, completing tasks under the guidance of senior staff (e.g. Sr. Data Engineer, etc.)
Serve as subject-matter-expert (SME) for smaller projects requiring knowledge of specific systems or methods
Provide assistance to senior staff when conducting complex data analysis to resolve management inquiries
Applicant for this job will be expected to meet the following minimum qualifications:
Education:
Bachelor's degree from an accredited college or university with major course work in computer science, MIS, or a related field is required
Equivalent work experience in a similar position may be substituted for education requirements
Experience:
Minimum 3 years of experience with data analysis and migration to include experience in the analysis or design of applications or systems to store and extract data
Minimum 1 year of experience writing detailed test plans for small to medium sized projects preferred
Minimum 2 years of experience with SQL required
Minimum 1 year experience with requirements analysis and the software development life cycle required
Intermediate knowledge of Word, Excel, and PowerPoint required
Technical:
Proficiency in Python, Spark, Tableau, ELK preferred
Proficiency in Power BI preferred
Experience in Azure or AWS Cloud applications preferred
Experience with databricks preferred
Compensation:
Want to love where you work? At Intrado, we offer a comprehensive benefits package that includes what you’d expect (medical, dental, vision, life and disability coverage, paid time off, a 401(k) retirement plan with company match and flexible spending accounts), and several that go above and beyond (tuition reimbursement paid parental leave, access to a robust library of personal and professional training resources, employee discounts, critical illness, hospital indemnity and pet insurances, identity protection and more)! Apply today to join us in work worth doing!
The starting salary for this position is between $90-97,000 a year and will be commensurate with experience.

ABOUT US
Connecting people with each other and the right information is mission critical. Our Company develops innovative cloud-based technology to make it easier, more effective and more efficient to make the right connections. Our solutions put people in sync with each other and the right information, so they gain the insight needed to reach better decisions on the issues that matter most. We do it with a laser focus on reliability.

The Company is a leading provider of technology-driven, communication services, serving Fortune 1000 companies and other clients in a variety of industries, including telecommunications, retail, financial services, public safety, technology and healthcare. For more than 30 years, we have been leading the way in hosted and cloud-based solutions.

Our solutions connect people with each other and the information needed to gain insights for better decisions on the issues that matter most – Information to Insight.

Our Company has sales and/or operations in the United States, Canada, Europe, the Middle East, Asia Pacific, Latin and South America and is an Equal Opportunity Employer – Veterans/Disabled and Other Protected Categories. Our Company welcomes and encourages applications of individuals with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process.

ABOUT THE TEAM
Intrado’s Life & Safety division is responsible for some critical parts of our everyday life. Our solutions are responsible for everything that happens after a 9-1-1 call is placed – call routing, delivery, location determination and data management. Whether you call from a landline, cell phone or text 9-1-1, we make sure first responders get the right information at the right time so they can save lives.


Intrado also provides notifications to the utilities, healthcare and educational sectors. Our platform provides multi-modal communications that meet an individual’s contact preference and routes over 4 billion notifications each year. At the end of the day, Intrado believes that keeping people in our communities safe, connected and healthy is a top priority.",glassdoor
133,"Home Depot / THD
3.8
Data Engineer II (Remote)
Atlanta, GA
Employer Provided Salary:$170K

 Position Purpose:
Data Engineer's map source system data to warehouse models. In addition, develop and test ETL processes, define and capture metadata and rules associated with ETL processes, adapt ETL processes to accommodate changes in source systems and new business user requirements and to demonstrate work ethic that motivates and encourages others on their team. BI Data Engineers are encouraged to bring fresh ideas, new perspectives, and an eagerness to learn new technologies. Responsible for the scripts required to extract, transform, clean, and move data and metadata so they can be loaded into the appropriate data mart. Map source system data to data mart models. Experience with column-oriented databases (e.g, Big Query). Creating views in BQ Work with business requirements to identify and understand source data systems. Helping with solution design and architecture.

Responsible for:
Creating programmatic artifacts to extract, clean, transform, move, and load data into data lake, data warehouse and appropriate data mart. Work with various stakeholders to identify and understand source data, source systems. Integrate with different source and sink systems.
Developing and testing ETL jobs/pipelines, configuring orchestration, configuring automated CI/CD, writing automation scripts, and supporting the pipelines in production.
Defining and capturing metadata and rules associated with ETL processes.
Adapting ETL processes to accommodate changes in source systems and new business user requirements.
Major Tasks, Responsibilities and Key Accountabilities

20%- Implement a real time streaming data ingestion and processing pipeline using Google Data flow (Apache Beam)
20%- Interface with business intelligence analysts and others in IT (i.e. data engineers, architects, WebOps) in frequent whiteboard sessions to discuss the design, implementation, and testing of data pipelines
20%- Maintain data architecture standards and ETL/ELT best practices consistent with a column oriented data store in an analytic use case
20%- Active and engaged participation in the Scrum delivery process
20%- Support solutions in production

Nature and Scope:
This position reports to the Manager, Data Engineering & Data Platforms

This position has no direct reports

Environmental Job Requirements:
Environment:
1. Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Travel:
Typically requires overnight travel less than 10% of the time.

Additional Environmental Job Requirements:
Standard Minimum Qualifications:
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.

Additional Minimum Qualifications:

Education Required:
The knowledge, skills and abilities typically acquired through the completion of a high school diploma and/or GED.

Years of Relevant Work Experience:
2 years

Certifications & Licenses:

Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.

Additional Qualifications:
Familiarity with Agile methodologies
Experience with data warehousing and dimensional modeling Experience in building real time streaming data ingestion and processing pipeline Experience with data processing tools (e.g. Hadoop, Spark, Data flow, etc.)
Experience building ETL/ELT pipelines Experience with column-oriented databases (e.g Redhift, Big Query, Vertica)
Ability to effectively communicate with technical and non-technical audiences Strong programming ability
Success in a highly dynamic environment and ability to shift priorities with agility
Ability to act independently with minimal supervision
Willingness to explore and implement new ideas and technologies
Experience working directly with subject matter experts in both business and technology domains
Experience with data science technologies (optional)
Familiarity with Contact Center Data Management
Knowledge of Python or equivalent programming languages and ETL products

This information indicates the general nature and level of work performed by associates in this role. It is not designed to contain a comprehensive inventory of all duties, responsibilities, and qualifications required of associates assigned to this role. This description super cedes any previous or undated descriptions for this role. Management has the right to add or change the duties of the position at any time.",glassdoor
134,"Serenity Healthcare
3.0
Junior Data Engineer
Lehi, UT
$61K - $93K (Glassdoor est.)

 Junior Data Engineer
Serenity Healthcare is hiring a Junior Data Engineer for our Lehi, UT headquarters. (Remote availability for residents of Utah or Colorado) While previous ETL experience is preferred, we are open to exceptional entry-level talent for this role.
We intend to provide on the job training in data-skills: SQL, BI (PowerBI), ETL (SSIS), Warehousing (SQL Stored Procedures), Exploratory Data Analysis, etc. It’s our intention to train you in Microsoft’s new tool: PowerApps.
Desired skill sets:
Must be a quick learner
SSIS experience strongly preferred
Skills used in the role:
SQL 20%
SSIS 40%
PowerApps 40%
Day-to-day work description:
The Junior Data Engineer will be responsible for keeping the data flowing, building new data pipelines, and creating business applications using MS-PowerApps. You’ll need to be comfortable with SQL, SQL Server, and SSIS. You’ll be reading API documentation to establish new ETL flows, as well as automating report delivery.
Job Fit:
Capable of “Deep Work”
Problem Solver
Reliable and consistent
Attention to detail
What We Offer to You:
Competitive pay (DOE), including additional target compensation
Opportunity to work and grow your career in a fast-paced environment
Medical, Dental, Vision Insurance (90% coverage for you and codependents)
Life Insurance
Flexible spending account
Paid time off
Vision insurance
401k
Open and friendly, professional office environment
Who We Are:
We have helped thousands of patients take back their lives from mental illness with specialized clinical expertise and the foremost cutting-edge technology available in mental health today. Serenity’s approach to treating mental illnesses is to offer holistic options and treat the whole person by providing an atmosphere of positivity, support, and healing in an outpatient setting.
We believe people should live their best lives, and mental health is a substantial segment of total well-being. We bring the same passion we have for improving our patient’s lives to providing a work experience that will help you do your best work, enjoy the time you invest at work, and succeed in life outside of work. We take our people and culture seriously and make it a priority to invest in both.
Serenity Mental Health Centers is an equal opportunity employer. This position is contingent on successfully completing a criminal background check and drug screen upon hire.",glassdoor
135,"John Deere
4.1
Analytics Data Engineer
East Moline, IL

 There are over 7 billion people on this planet. And by 2050, there will be 2 billion more... many moving into urban centers at an unprecedented rate. Making sure there is enough food, fiber and infrastructure for our rapidly growing world is what we're all about at John Deere. And it's why we're investing in our people and our technology like never before! Here the world's brightest minds are tackling the world's biggest challenges. If you believe one person can make the world a better place, we'll put you to work. RIGHT NOW.

John Deere is an equal opportunity employer. All qualified applicants will receive consideration for employment without regards to, among other things, race, religion, color, national origin, sex, age, sexual orientation, gender identity or expression, status as a protected veteran, or status as a qualified individual with disability.

Primary Location: United States (US) - Illinois - East Moline
Function: Data & Analytics (CA)
Title: Analytics Data Engineer - 91351
Onsite/Remote:Onsite Position

This is an Onsite position, located in East Moline IL.
Visa sponsorship is NOT available for this position.
Your Responsibilities
Lead expert in identifying and prioritizing actionable insights for manufacturing and quality through a deep understanding of manufacturing data and analytic techniques.
Collaborate with a team of analytics professionals to design, build, and continuously improve meaningful factory-based analytics.
Acquires and connects data attributes to be used to develop analytic products (using Machine Learning methods).
Innovates and experiments with new data processing and transformation methods to enable the analytics development process.
Transforms data in alignment with data science needs and governance parameters and provides recommendations and testing for production environments.
What Skills You Need
2-4 years experience of advanced data gathering and analysis techniques, including statistical analysis or equivalent
2-4 years experience with tools used for data management or data warehousing
2-4 years - Proficiency with programming for data analysis, ideally Python, SQL, R, or SAS
2-4 years - Experience with analytics/bigdata platforms and/or technologies (e.g. AWS, DataBricks, Spark)
2-4 years - Experience in data visualization tools or application development (e.g. PowerBI, Tableau, R Shiny)
What Makes You Stand Out
Experience working in a manufacturing related function (Operations, Manufacturing or Quality Engineering, Factory Automation, or Robotics)
Experience managing large data migration or data transformation projects
Experience with machine learning models and/or supporting infastructure.
Education
Degree in an Information Technology discipline or equivalent experience. - University Degree (4 years or equivalent)
Degree in a Math discipline or equivalent experience. - University Degree (4 years or equivalent)
Statistics - University Degree (4 years or equivalent)
What You'll Get
At John Deere, you are empowered to create a career that will take you to where you want to go while working in an inclusive team environment. Here, you'll enjoy the freedom to explore new projects, the support to think outside the box and the advanced tools and technology that foster innovation and achievement. Additionally, we offer a comprehensive reward package to help you get started on your new career path, including:
Flexible work arrangements
Highly competitive base pay and performance bonuses
Savings & Retirement benefits (401K and Defined Benefit Pension)
Healthcare benefits with a generous company contribution in the Health Savings Account
Adoption assistance
Employee Assistance Programs
Tuition assistance
Fitness subsidies and on-site gyms at specific Deere locations
Charitable contribution match
Employee Purchase Plan & numerous discount programs for personal use

Click Here to find out more about our Total Rewards Package.

The information contained herein is not intended to be an exhaustive list of all responsibilities and qualifications required of individuals performing the job. The qualifications detailed in this job description are not considered the minimum requirements necessary to perform the job, but rather as guidelines.

The terms of the applicable benefit plans, and all company actions administering or interpreting these plans, continue to control. Deere & Company reserves the right to suspend, amend, modify, or terminate the Plan(s) in any manner at any time, including the right to modify or eliminate any cost-sharing between the company and participants. Changes, which can be made at any time, are made by action of the company's board of directors, or to the extent authorized by resolution of its board of directors, or by the Deere & Company Compensation Committee. In the event of a conflict between the language of the official Plan Documents and this document, the language of the official Plan Documents will control.

ACA Section 1557 Nondiscrimination Notice
The John Deere Health Benefit Plans for Salaried Employees and The John Deere Benefit Plan for Wage Employees comply with applicable Federal civil rights laws and do not discriminate on the basis of race, color, national origin, age, disability, or sex.",glassdoor
136,"Bloom Insurance
3.3
Jr. Data Engineer I
Remote

 Data Engineer I
To support internal and external clients via processing and handling of data. To generate data solutions for ongoing immediate day to day business needs.

Essential Functions
Day to day functions include the following:
Design data models and develop database structures in Microsoft SQL server.
Write various database objects like stored procedures, functions, views, triggers for various front end applications.
Write SQL scripts, create SQL agent jobs to automate tasks like data importing, exporting, cleansing tasks.
Create database deployment packages for deploying changes.
Identify & repair inconsistencies in data, database tuning, query optimization.
Able to generate ad hoc data on demand.
Able to identify best practices, documentation, communicate all aspects of projects in a clear, concise manner
Develop simple SSIS packages to perform various ETL functions including data cleansing, manipulating, importing, exporting.
Develop & maintain client facing reports by using various data manipulation techniques in SSRS and Visual Studio.
Documentation
Optimization recommendations
Day to day troubleshooting
.NET Programming as needed

Education/Experience
BA, BS, or Masters in computer science/related field preferred or an equivalent combination of education and experience derived from at least 2 years of professional work experience
Solid experience with various versions of MS SQL Server and TSQL programming
Microsoft Certified DBA a plus

Skills/Knowledge
Strong experience in writing efficient SQL code
Working knowledge of SQL Server Management Studio (SSMS)
Knowledge of SQL Server Reporting Services (SSRS)
Knowledge of SQL Server Integration Services (SSIS)
Knowledge of Red Gate DBA Tool Belt (SQL Compare, SQL Data Compare, SQL Source Control) a plus
Knowledge of data science technologies is a plus
Clear, concise communication skills, excellent organizational skills
Highly self-motivated and directed
Keen attention to detail
High level of work intensity in a team environment
High integrity and values-driven
Eager for professional development
Experience and understanding of source control management a plus

What We Offer

At Advise / Bloom, we offer an engaging, supportive work environment, great benefits, and the opportunity to build the career you always wanted. Benefits of working for Advise / Bloom include:
Competitive compensation
Comprehensive health benefits
Long-term career growth and mentoring

About Advise
Advise Insurance is a licensed Medicare agency that aims to preserve the patient–physician relationship and help build a better healthcare experience. We provide education that explains how Medicare works and helps beneficiaries select a plan that meets their healthcare needs and includes their trusted doctor.

About Bloom
As an insurance services company licensed in 48 contiguous U.S. states, Bloom focuses on enabling health plans to increase membership and improve the enrollee experience while reducing costs. We concentrate on two areas of service: technology services and call center services and are committed to ensuring our state-of-the-art software products and services provide greater efficiency and cost savings to clients.

Ascend Technology ™
Advise / Bloom provides advanced sales and enrollment automation technology to the insurance industry through our Ascend ™. Our Ascend™ technology platform focuses on sales automation efficiencies and optimizing the member experience from the first moment a prospect considers a health plan membership.

Advise / Bloom is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.",glassdoor
137,"Lucid Motors
3.5
Data Engineer
Newark, CA
$112K - $163K (Glassdoor est.)

 Leading the future in luxury electric and mobility
At Lucid, we set out to introduce the most captivating, luxury electric vehicles that elevate the human experience and transcend the perceived limitations of space, performance, and intelligence. Vehicles that are intuitive, liberating, and designed for the future of mobility.
We plan to lead in this new era of luxury electric by returning to the fundamentals of great design – where every decision we make is in service of the individual and environment. Because when you are no longer bound by convention, you are free to define your own experience.
Come work alongside some of the most accomplished minds in the industry. Beyond providing competitive salaries, we’re providing a community for innovators who want to make an immediate and significant impact. If you are driven to create a better, more sustainable future, then this is the right place for you.

We are looking for a Senior Data Engineer, Big Data who is looking for a challenge, enjoys thinking big and looking to make their mark on an extremely fast growing company. If you have hands-on experience designing and developing streaming and IoT data pipelines this role is for you. Be part of a group who will be building large and building fast, working with a very talented team of engineers, and collaborating with the brightest mind in the Automotive industry.
The Role
Hands-on design and develop streaming and IoT data pipelines.
Developing streaming pipeline Kafka, Spark, Scala and Python
Python scripting for automation and application development
Developing streaming pipeline using FluentD, Elasticsearch, Kibana
Design ETL in Apache Airflow and other dependency enforcement and scheduling tools.
Hands-on data modeling and data warehousing
Deploy solution using AWS, S3, Redshift and Docker/Kubernetes
Develop storage and retrieval system using Presto and Parquet/ORC
Scripting with Apache Spark and data frame.
Qualifications
Bachelor or Masters in Software Engineering or Computer Science
2+ years of experience in Data Engineering and Business Intelligence
Excellent coding, scripting and problem solving skills
Experience in tools such as Spark, Kafka, S3, Hive, Data Lake
Experienced in Log Collection and processing using tools such FluentD and Elastic Search
Experience with AWS, S3, Redshift
Experience with Presto and Parquet/ORC
Proficient with Apache Spark and data frames
Experienced in containerization, including Docker and Kubernetes
Expert in tools such as Apache Spark, Apache Airflow, Presto, and Kubeflow
Expert in design and implement reliable, scalable, and performant distributed systems and data pipelines
Extensive programming and software engineering experience, especially with Scala, Java or Python
Experience with a columnar database such as Redshift or Vertica
Great verbal and written communication skills
At Lucid, we don’t just welcome diversity - we celebrate it! Lucid Motors is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, national or ethnic origin, age, religion, disability, sexual orientation, gender, gender identity and expression, marital status, and any other characteristic protected under applicable State or Federal laws and regulations.

Notice regarding COVID-19 protocols
At Lucid, we prioritize the health and wellbeing of our employees, families, and friends above all else. In response to the novel Coronavirus all new Lucid employees, whose job will be based in the United States may or may not be required to provide original documentation confirming status as having received the prescribed inoculation (doses). Vaccination requirements are dependent upon location and position, please refer to the job description for more details.
Individuals in positions requiring vaccinations may seek a medical and/or religious exemption from this requirement and may be granted such an accommodation after submitting a formal request to and the subsequent review and approval thereof by our dedicated Covid-19 Response team.
To all recruitment agencies: Lucid Motors does not accept agency resumes. Please do not forward resumes to our careers alias or other Lucid Motors employees. Lucid Motors is not responsible for any fees related to unsolicited resumes.",glassdoor
138,"Apple
4.2
Biomedical Data Engineer - Health Technologies
Cupertino, CA

 Summary
Posted: Aug 8, 2022
Weekly Hours: 40
Role Number:200402289
The Health Technologies Team conceives and proves out innovative technology for Apple’s future products and features in health. We are seeking a highly capable Biomedical Data Engineer to join a multi-disciplinary team. Successful candidates will be able to integrate with our research study leads, data scientists and engineers to develop and support effective data analysis and machine learning workflows.
Key Qualifications
Experience with software engineering frameworks
Excellent coding skills in Python (e.g.,Pandas, Spark, Jupyter)
Workflow orchestrations (e.g., Airflow, Luigi)
Designing and maintaining (non-)relational databases (e.g. Postgres, Cassandra, MongoDB) and file systems (e.g. Parquet, CSV, JSON)
Great understanding of infrastructure designs
Linux, MacOS based development frameworks
iOS/ watchOS development (e.g., Swift, Objective-C)
Web Service APIs (e.g., AWS, REDCap, XNAT)
Version control frameworks (Git, virtualenv)
Familiarity with best practices for information security, including safe harbor privacy principles for sensitive data
Experience with biomedical sensors/platforms for measuring physiological signals in the health, wellness and/or fitness realms
Description
- Work closely with team members and study staff to design, build, launch and maintain systems for storing, aggregating and analyzing large amounts of data - Process, troubleshoot, and clean incoming data from human studies - Automate and monitor data ingestion and transformation pipelines, with hooks for QA, auditing, redaction and compliance checks per data management specifications - Create and maintain databases with existing and incoming clinical data - Architect data models and create tools to harmonize disparate data sources - Incorporate and comply with regulations as they pertain to electronic and clinical data and databases
Education & Experience
BS/MS in Computer Science, Engineering, Informatics, or equivalent with relevant 4+ years industry experience with biomedical, health or sensitive data.
Additional Requirements",glassdoor
139,"Pinterest
4.1
Data Engineer
Remote

 About Pinterest:
Millions of people across the world come to Pinterest to find new ideas every day. It's where they get inspiration, dream about new possibilities and plan for what matters most. Our mission is to help those people find their inspiration and create a life they love. In your role, you'll be challenged to take on work that upholds this mission and pushes Pinterest forward. You'll grow as a person and leader in your field, all the while helping Pinners make their lives better in the positive corner of the internet.
Our new progressive work model is called PinFlex, a term that's uniquely Pinterest to describe our flexible approach to living and working. Visit our PinFlex landing page to learn more.
The Enterprise Data Platform team is looking for a Data Engineer who has experience with Building Data Pipelines and Managing/Developing on any Cloud Data Warehouse. In this role you will also advise other Data Analysts and Data Engineers from the Business teams at Pinterest on the best practices for handling data and deriving insights using Snowflake. You will gradually become the Subject Matter Expert on Snowflake and also help build out the Modern Data Stack at Pinterest.
What you'll do:
Build Data Pipelines using Python on either Airflow or AWS Lambda to ingest data into Snowflake
Build Scripts in Python to manage Data Access on Snowflake
Define and advocate the best practices for storing and analyzing data inside Snowflake
Review the Data Modeling practices of other teams
What we're looking for:
Strong skills in Python and SQL
Experience with Building Data Pipelines in Python
Experience with any Cloud Data Warehouse either as an Administrator or a Developer
Strong Data Modeling skills
#LI-BB1
#LI-Remote
Our Commitment to Diversity:
At Pinterest, our mission is to bring everyone the inspiration to create a life they love—and that includes our employees. We’re taking on the most exciting challenges of our working lives, and we succeed with a team that represents an inclusive and diverse set of identities and backgrounds.

Not Specified
0",glassdoor
140,"Qualtrics
4.2
Data Engineer
Provo, UT
$83K - $125K (Glassdoor est.)

 The Qualtrics XM Platform™ is a system of action that helps businesses to attract customers who stay longer and buy more, to engage and empower employees to do the best work of their lives, to develop breakthrough products people love, and to build a brand people can’t imagine living without.

Joining Qualtrics means becoming part of a team bold enough to chase breakthrough experiences - like building a technology that will be a force for good. A team committed to diversity, equity, and inclusion because of a conviction that every voice holds value, with a vision for representation that matches the world around us and inclusion that far exceeds it. You could belong to a team whose values center on transparency, being all in, having customer obsession, acting as one team, and operating with scrappiness. All so you can do the best work of your career.

We believe every interaction is an opportunity. Are we yours?
The Team
Our team is a collection of deeply passionate engineers who are riding the groundbreaking of cloud computing and web scalability. We built data analytics applications that help company leaders gain insights about technology spends, make sound decision on technology investments, and drive innovation in resource utilization and efficiency optimizations. Our environment is primarily TypeScript, Node.js, React, MySQL NoSQL, AWS, Python, PHP, and Docker. In our collaborative culture, you find plenty of opportunities to impact our full-stack products; from Web & mobile UI to data visualization & analysis to data ingestion, storage and processing.
Job Responsibilities
Developing scalable, fast, robust, and simple web-based solutions to solve complex business problems
Close collaboration with your team to collect and incorporate feedback into your feature design
Drive operational excellence by investigating production issues, driving root cause analysis and follow-up actions for mitigation
Improve performance, availability, reliability, scale, throughput and latency
Work with your team in order to meet customer work you're doing, understand the decisions that are being made and make your voice heard.
Qualifications
Bachelor's degree in Computer Science or related field
Coding experience with any programming language (Prefer experience in TypeScript/JavaScript/React/Python)
Experience with web infrastructure and distributed systems
Experience with software engineering best practices (e.g. unit testing, code reviews, design, continuous delivery, git, test automation and build\deploy systems)
Ability to work in a fast-paced and agile development environment and to learn new frameworks/stacks
Passionate about building products that help customers easily and effectively get their job done
Enthusiastic person, who communicates effectively and is easy to work with
Curious and constantly learning on your own and from others
You get satisfaction from helping others succeed, and you constantly seek ways to improve
You can identify gaps, propose solutions to important problems, then take it to resolution
Preferred Qualifications
Shown ability to troubleshoot and identify the root cause of issues
Demonstrated skill and passion for operational excellence
Experience in a 24/7 production environment is a plus
Ability to retain composure under stressful conditions, communicate effectively with wide array of individuals at Qualtrics, and get the right things done
Confirmed ability to understand large systems, drilling down to code level",glassdoor
141,"Twitch
4.0
Data Engineer
San Francisco, CA
Employer Provided Salary:$140K - $171K

 About Us
Twitch is the world's biggest live streaming service, with global communities built around gaming, entertainment, music, sports, cooking, and more. It's where millions of people come together to chat, interact, and make their own entertainment.
We're about community, inside and out. You'll find coworkers who are eager to team up, collaborate, and smash (or elegantly solve) problems together. We're on a quest to empower live communities, so if this sounds good to you, see what we're up to on LinkedIn and Twitter, get interviewing tips on Instagram, and discover projects we're solving on our Blog.
About the Role
Reporting to the Head of Global Talent Acquisition, the Data Engineer will expand the reach and role of data among leaders and managers at Twitch. You will empower the business to integrate data into their daily workflow by creating/maintaining data pipelines, producing reporting, and automating our processes.
You can work in San Francisco, CA or remotely across the US.
This role is for you if:
You love automating processes and developing efficient scalable solutions
You're excited about contributing to the success, efficiency, and happiness of Twitch staff
You're excited to jump into a diverse array of data work to support the team
You enjoy working with autonomy and shaping a new function

You Will:
Delight consumers of people-related data by ensuring they have the data they need to inform decisions, where and when they need it
Build and own data pipelines, SQL queries/views, and apps
Automate processes through the use of JavaScript and other languages
Improve business, engineering, and data processes through data architecture, engineering, testing, and operational excellence best practices
Ensure the integrity of People and Places data in analyses and tools through regular audits
Partner to develop analytics products and recommend opportunities
Develop ongoing metrics, analyses, and dashboards to guide important decisions
You Have:
Experience writing SQL and a procedural language (Python, R, etc.) for data handling
Experience owning systems that collect, transform, and visualize data
Experience implementing data analytics, visualization tools and programs for HR working with Workday, Greenhouse, Tableau, Google Workspace, Google Data Studio, and Google Sheets
Experience implementing software solutions to automate data source, visualization and analytics products
Bachelors in related field, or equivalent experience
Bonus Points
Experience handling People-related data including compensation, performance, hiring, and engagement data.
Experience automating Google services (Sheets, Docs, Data Studio) with Javascript
Experience with Workday, Greenhouse, and Tableau
Demonstrated net positive contributor to company community and culture above and beyond the core job
Perks
Medical, Dental, Vision & Disability Insurance
401(k), Maternity & Parental Leave
Flexible PTO
Commuter Benefits
Amazon Employee Discount
Monthly Contribution & Discounts for Wellness Related Activities & Programs (e.g., gym memberships, off-site massages, etc.),
Breakfast, Lunch & Dinner Served Daily
Free Snacks & Beverages
We are an equal opportunity employer and value diversity at Twitch. We do not discriminate on the basis of race, religion, color, national origin, gender, gender identity, sexual orientation, age, marital status, veteran status, or disability status, or other legally protected status.
Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
Pursuant to the Los Angeles Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
The base pay range for this position in Colorado, Connecticut and Washington is $139,860 - $170,940 yr and in New York City is $153,900 - $188,100 yr. Pay is based on market location and may vary depending on job-related knowledge, skills, and experience. A sign-on payment and restricted stock units may be provided as part of the compensation package, in addition to a full range of medical, financial, and/or other benefits, dependent on the position offered. Applicants should apply via Twitch's internal or external careers site.
Workers in New York City who perform in-person work or interact with the public in the course of business must show proof they have been fully vaccinated against COVID or request and receive approval for a reasonable accommodation, including medical or religious accommodation.
Twitch values your privacy. Please consult our Candidate Privacy Notice, for information about how we collect, use, and disclose personal information of our candidates.
Job ID: TW7236
#LI-Remote #RemoteFriendly",glassdoor
142,"Adobe
4.4
Software Development Engineer - Data Science & Analytics
Lehi, UT
$108K - $155K (Glassdoor est.)

 Our Company

Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.

We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!

Our Company
Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands— everything they need to design and deliver exceptional digital experiences. We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.

We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours.
The Opportunity
Adobe is seeking hardworking and passionate Cloud Software Engineer to plan, design, and develop internal analytical tools, dashboards and reporting to help Engineers to Executives make data driven decisions.

We’re on a mission to hire the very best and are committed to building exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!
What You’ll Do
Develop high-performance, reliable, testable and maintainable code.
Participating in all aspects of software development activities, including design, coding, code review, testing, bug fixing, and code/API documentation.
Collaborate with engineers and participate in daily or weekly stand ups and meetings.
Develop reporting dashboards and analytical tools to help Adobe teams manage their AWS & Azure Cloud resources.
Build and automate data sets to answer key business questions using data and data visualizations.
Grow with the support of your team and help others on the team grow by providing thoughtful feedback and uplifting those around you.
Work both independently and collaboratively within a fast-paced development team, with clear, positive, and constructive communication.
What You Need to Succeed
Bachelor's or Master’s in Computer Science, Information Systems, Data Science or equivalent experience required.
Proficient in programming languages such as JavaScript, Python & SQL.
Strong technical background with analytical and problem-solving skills.
Strong proficiency with Business Analytics tools like Power BI & Tableau.
Extensive experience with cloud hosting technology, including Azure and AWS infrastructure.
Experience developing web applications using ReactJS is helpful.
Excellent problem solving and debugging skills, and direct experience with DevOps in a public cloud environment.
Passion for quality and engineering excellence at scale, attention to details, and ability to multitask and meet deadlines.
Excellent communication and collaboration skills.

If you’re looking to make an impact, Adobe’s the place for you. Discover what our employees are saying about their career experiences on the Adobe Life blog and explore the meaningful benefits we offer.
Adobe is an equal opportunity employer. We welcome and encourage diversity in the workplace regardless of race, gender, sexual orientation, gender identity, disability or veteran status.",glassdoor
143,"Accenture
4.1
Data Engineer
San Francisco, CA

 Accenture Flex offers you the flexibility of local fixed-duration project-based work powered by Accenture, a leading global professional services company. Accenture is consistently recognized on FORTUNE's 100 Best Companies to Work For and Diversity Inc's Top 50 Companies For Diversity lists.
As an Accenture Flex employee, you will apply your skills and experience to help drive business transformation for leading organizations and communities. In addition to delivering innovative solutions for Accenture's clients, you will work with a highly skilled, diverse network of people across Accenture businesses who are using the latest emerging technologies to address today's biggest business challenges.
You will receive competitive rewards and access to benefits programs and world-class learning resources. Accenture Flex employees work in their local metro area onsite at the project, significantly reducing and/or eliminating the demands to travel.
Job Description:
As a Data Engineer, you will:
Utilize strong SQL & Python expertise to engineer sound data pipelines and conduct routine and ad hoc analysis to assess the performance of legacy products and the saliency of new features
Build reporting dashboards and visualizations to design, create, and track campaign/program KPIs
Perform analyses on large data sets to understand drivers of marketing engagement and provide recommendations on campaign and product optimization

Basic Qualifications:
Minimum 2 years of experience in Data Engineering
Minimum 2 years of experience with SQL
Minimum 2 years of experience with Python
High School Diploma or GED
Preferred Qualifications:
Experience with Data Analytics
As required by Colorado Law under the Equal Pay for Equal Work Act, Accenture provides a reasonable range of compensation for roles that may be hired in Colorado. Actual compensation is influenced by a wide array of factors including but not limited to skill set, level of experience, and specific office location. For the state of Colorado only, the starting range of pay for this role is $86.82 - $96.82 per hour, and information on benefits is here.

COVID-19 update:

The safety and well-being of our candidates, our people and their families continues to be a top priority. Until travel restrictions change, interviews will continue to be conducted virtually.

Subject to applicable law, please be aware that Accenture requires all employees to be fully vaccinated as a condition of employment. Accenture will consider requests for accommodation to this vaccination requirement during the recruiting process.

What We Believe

We have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture has the responsibility to create and sustain an inclusive environment.

Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more here

Equal Employment Opportunity Statement

Accenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation.

All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.

Accenture is committed to providing veteran employment opportunities to our service men and women.

For details, view a copy of the Accenture Equal Opportunity and Affirmative Action Policy Statement.

Requesting An Accommodation

Accenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.

If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.

Other Employment Statements

Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States.

Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.

Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.

The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.",glassdoor
144,"Apple
4.2
Data Engineer
Cupertino, CA

 Summary
Posted: Aug 10, 2022
Weekly Hours: 40
Role Number:200406892
Are you a big-picture thinker who loves setting ambitious goals? Do you have a passion for understanding how each line of code affects all the others? In the Core Operating Systems group, you’ll ensure the OS is inseparable from each device’s identity as a whole. That’s because this group is committed to building fully integrated operating systems that combine hardware, software, and apps into a single Apple experience. Your dedication to cross-disciplinary collaboration will help develop groundbreaking technologies, such as iOS, macOS, watchOS, and tvOS. By crafting these distinct, holistic user experiences, you’ll continue to uphold and advance the excellence people expect from Apple devices. The Platform Services & Operations team in Core OS is looking for a Data Engineer to inform and develop essential workflow tooling at scale. The Workflow Engineering team enable teams to deliver high quality software through best in class engineering experiences, efficient workflow, data driven insights, and a culture of continuous improvement. Your focus is building the backend data pipelines that enables visualization of data across the organization in user intuitive and configurable formats.
Key Qualifications
3 +proven experience in a Data focused posistion
Proficient in Python; data access and retrieval. Quantitative data preparation. Regular expressions and text analysis
Highly Proficient in Database Language and Design; querying large stores of data (APIs, SQL, etc.).
Access, retrieval, and storage of information. Data Structures, modeling for speed and efficiency
Software Development; understanding of build pipelines, branching and merging, Agile methods, and the delivery of code. Fluency in Git (or comparable source control tool)
Description
- Replicate data from source system into data warehouse; retrieve data through various protocols and land it in a central store - Automate data pipelines; write programs to periodically update warehouse data from source systems - Design for scale; flexible infrastructure for common enhancements including: expanding the volume of captured data, adding fields to the user-facing views, and recompiling archived data - Work with a team of data scientists and full stack engineers, to derive and develop targeted insights through centrally managed interactive dashboards
Education & Experience
B.S. in Data Science, Computer Science, or equivalent experience.
Additional Requirements
Experience as an Analyst; worked in the delivery of visual information (dashboards, reports, web-apps)
An understanding of how data can be used and applied in context (what is useful to capture and how it can be communicated)
Full Stack Development; ability to maintain back-end systems and visualize front-end data for users (with a web-kit framework like Angular, React)
Experience with Snowflake and/or other data store technologies",glassdoor
145,"Mint Mobile
3.6
Digital Data Engineer I - Remote
Costa Mesa, CA
Employer Provided Salary:$90K - $103K

 MINT MOBILE is seeking a talented Digital Data Engineer I to join the Data Management Team! Individual reports to Customer Data Manager. Role is remote; must reside in the United States.
ABOUT THE ROLE
Provide direct data engineering development to data pipelines for ETL establishment and enhancements to and from data warehouses to customer management platform (Braze). Work collaboratively with cross-functional teams to determine digital data needs, establish data collection requirements, and deploy & maintain accurate data to ensure metrics & dimensions are addressed for analytics/reporting requirements.
Your usual day of awesomeness includes:
Transform required data conditions into performance code logic.
Develop high-performance code in SQL and Python.
Develop, automate, and enhance ELT processes for continuous data flow.
Create, modify, and deploy code to production via AWS resources including Lambda, S3, Glue, Redshift, etc.
Partner with stakeholders to support the implementation and development of data requirements.
Troubleshoot data anomalies and provide applicable solutions.
Build, test and maintain database pipeline architectures.
WHAT YOU BRING
Advanced level in SQL and Python for data engineering and backend development.
Understanding of popular code development approaches:
Test-driven development
Continuous Integration/Continuous Deployment (CI/CD)
Experienced working with AWS services (Lambda, S3, Glue, Redshift etc.) and Cloud Data Warehouse.
Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
Define digital data collection methods and implementations to DWH and customer management platforms.
Experienced with QA testing process to verify data is collected & rendered as expected.
Ability to excel in a fast-paced, cross-functional environment.
Ability to work autonomously.
Excellent written and verbal communication skills.
Proactive problem-solving and critical thinking skills.
Ability to manage time effectively and consistently meet deadlines.
NICE TO HAVE
Prior working knowledge of Braze or other Customer Management Platforms
Snowflake Cloud Data Warehouse
Terraform/Bitbucket/Airflow/Jenkins
Looker, Tableau, Power BI
WE ARE MINT MOBILE
We connect people to what's most important in their lives: Easily, affordably and reliably. We strive to be California's Preeminent Destination Employer. Oh yeah, we get it too! We understand what matters to you most. You're an individual with unique needs, and we're prepared to exceed any expectations you have for an ideal employer.
We're smart, strategic, and get things done without a lot of red tape or unnecessary politics. Everyone matters here and everyone has a voice. Expect to spend your time contributing to projects that really matter. We obsess over the employee experience. To start, we provide some of the most competitive salary, benefits, family leave, vacation, retirement and equity options in Southern California. We believe in you and invest in you. Not just your career aspirations, but your life.
In addition, we've got a laundry list of perks you'll brag about on insta - Lunch every day prepared by our very own chef, healthy snacks, onsite gym, free massages, car wash services, and most importantly, a team atmosphere. We even raise the bar on well bars, including Espresso/Cappuccino/Nitro/Cold Brew/Kombucha Bar, Froyo Bar, Breakfast Bar, Snack Bar and a, well, you know, bar (after 5 pm).
And if you feel intrigued right now reading, imagine the co-workers we have already attracted. This is the kind of team you'll want to take home to mom or invite to your kid's next birthday party. This is the kind of close-knit community happening here. Come check out how you can be part of Mint!
OUR VALUES – LET'S MAKE LIFE ULTRA TOGETHER!
Ownership: We are all owners; be the outcome and get the job done.
Action Biased: Be brilliant, proactive, and act with urgency.
Embrace the Adventure: Be agile, adaptive, and thrive on change.
Invent and Simplify: Never accept good enough.
$1,000 REFERRAL BONUS
Take a look at this job description, if you are the right person, please apply. If Mint Mobile doesn't appear to be a fit for you, refer a friend or colleague and get $1,000. Let your friend or colleague know to provide your full name and email when applying to the job. If we hire them and they stay for 90 days, you get $1000. For more details of restrictions and rules, please email recruiting@ultra.me.

Covid-19 Vaccination Requirement
UVNV, Inc. has adopted a mandated vaccination policy to support the health and safety of our team members and our community. The Company requires all employees to be fully vaccinated. The Company will provide accommodations based on medical condition or sincerely held religious beliefs or practices. Please let us know if you'd like to discuss the policy or available accommodations before proceeding with our recruitment process.
We are committed to equal employment opportunities regardless of race, color, genetic information, creed, religion, sex, sexual orientation, gender identity, lawful alien status, national origin, age, marital status, or protected veteran status. We support an inclusive workplace where associates excel based on personal merit, qualification, experience, ability, and job performance.
In support of the Equal Pay for Equal Work Act, the range of starting pay for this role is $90,000 - $103,000. This is not a guarantee of compensation or salary, actual compensation is influenced by a wide range of factors including but not limited to skill set, level of experience, education, certifications, responsibility, and geographic location. We also offer a variety of benefits including health, disability insurance, 401 (k), flexible spending accounts, EAP, education reimbursement, parental leave, unlimited vacation, bonuses, incentive stock options and company paid holidays. The specific programs and options available will vary depending on state, start date, and employment type. Our recruitment team will be happy to answer any questions you may have.
#LI-Remote",glassdoor
146,"Vimeo
4.1
Data Engineer II, Analytics
New York, NY
$107K - $150K (Glassdoor est.)

 Vimeo is looking for an experienced Data Engineer II, Analytics to join our Data Architecture and Analytics Engineering team and work closely with Data Analysts and Data Scientists to create and maintain robust, scalable, and sustainable data models that provide decision-making insights for senior leadership including executives. The ideal candidate is a self-starter with a bias for action and results, with experience in a fast-paced, data-driven environment.
What you'll do:
Build data models that can support dynamic and efficient data analysis, and collaborate with other teams to maintain and evolve those models over time
Ensure alignment to coding standard methodologies and development of reusable code
Partner with Data Analysts to understand business processes and identify opportunities to build scalable and efficient data models that can be used for scalable, refreshable analysis and reporting
Create and enable the generation of ad-hoc / on-demand data sets for use by analysts and data scientists
Work with Engineering teams to set up monitoring and alerting systems for business and product KPIs
Skills and knowledge you should possess:
BS/MS in Computer Science or a related technical field.
2+ years working with Analytics and Data Engineering teams with a mixed data engineering and analytics background
2+ years of experience in scalable data architecture, fault-tolerant ETL, and monitoring of data quality in the cloud
Experience working on or leading initiatives around data governance, master data management, data catalogs, and enterprise data warehouse architecture
Strong analytical skills, data sensibility, and an able communicator
Open to working on multiple projects simultaneously
Proficiency in:
SQL
Python
Dimensional Modeling
Data pipeline development, workflow management, and orchestration tools
ETL optimization and best practices
Snowflake or other column-oriented and cloud-based databases
Looker or any similar Business Intelligence tool
Relational Databases
Bonus Points (Nice Skills to Have, but Not Needed):
DBT
Git / Github
Looker/Tableau is a big plus
large data sets (terabyte scale)
Apache Airflow
#LI-JS1
Vimeo (NASDAQ: VMEO) is the world's leading all-in-one video software solution. Our platform enables any professional, team, and organization to unlock the power of video to create, collaborate and communicate. We proudly serve our growing community of over 260 million users — from creatives to entrepreneurs to the world's largest companies.
Vimeo is headquartered in New York City with offices around the world. At Vimeo, we believe our impact is greatest when our workforce of passionate, dedicated people, represents our diverse and global community. We're proud to be an equal opportunity employer where diversity, equity, and inclusion is championed in how we build our products, develop our leaders, and strengthen our culture.
Learn more at www.vimeo.com
Learn more at www.vimeo.com/jobs",glassdoor
147,"Lincoln Financial
3.6
Data Engineer (REMOTE)
Radnor, PA
Employer Provided Salary:$63K - $138K

 Date: Oct 9, 2022
Primary Location: Radnor, PA, US
Company: Lincoln Financial
Alternate Locations: Work from Home

Work Arrangement: Work from Home

Relocation assistance:: is not available for this opportunity.

Pay Range: $63,100 - $137,900

Bonus Potential: 5%

Requisition #: 69444

The Role at a Glance

This is an exciting opportunity within Lincoln’s Work Place Solutions IT Data Team for a Data Engineer/ETL Developer to help build solutions for Lincoln’s Work Place Solutions business. This position will assist Analytic Teams with the design and implementation of Data solutions and systems, including integration with databases and data warehouses, both on-Premise and in AWS Cloud. This candidate must be able to develop, enhance, and support Informatica workflows and processes using Informatica Power Center and Dataiku for the extraction and transformation of data in a UNIX and Oracle database environment. They must also have experience working within BI tools such as Tableau and Microstrategy. Experience working in the cloud using AWS native services such as Glue, Athena, Aurora, Redshift, and/or Snowflake is needed. The candidate must have experience participating in and beginning to lead teams within a Data Organization by suggesting new and innovative ways of gaining data processing efficiencies and participating in architectural and modeling discussions.

What you'll be doing

Participates in defining architecture and modeling best practices within the team
Develop tools and work on integrating disparate systems using ETL
Work on transformation of data into Facts and Dims in a Kimball and/or relational model
Works with Sr. Technical Professionals to implement data development best practices
Develop, enhance and support Informatica workflows and processes using Informatica Power Center for the extraction and translation of data in a UNIX and Oracle database environment
Develop, enhance and support Dataiku workflows and processes for transforming data into Kimball model Facts/Dims
Creates partnerships with stakeholders, POs, BSAs and Analytic teams in requirement, design and coding walkthroughs to ensure the development of quality solutions and understand complex business/technical problems and opportunities and identify potential application solutions.
Demonstrates expertise in a variety of the data warehouse concepts, practices, and procedures. Relies on extensive experience and judgment to plan and accomplish goals
Analyzes operational and analytical data requirements by working with cross functional business and application development teams
Maintains knowledge on current and emerging developments/trends for assigned area(s) of responsibility, assess the impact, and collaborates with senior management to incorporate new trends and developments in current and future solutions.
Participate with collaboration efforts with development teams to review, update and approve the data portion of project designs, participate in cost/benefit analysis and preparation of project plans.
Participate in the design, development and delivery data centric IT solutions, including large scale data staging and orchestration, integration and provisioning mechanisms
Works with business partners to prioritize business and information needs
Provides input and validates increasingly complex project plans, test plans and implementation plans
Creates increasingly complex technical specifications from business requirements/business specifications
Proactively identifies problems and presents/develops solutions
Communicates effectively with internal stakeholders and management
Defines detailed development tasks, task dependencies and estimates to complete work
What we're looking for

4 Year/Bachelor's degree or equivalent work experience (4 years of experience in lieu of Bachelor's) in Computer Science, Computer Information Systems, Information Systems, Information Technology or Computer Engineering or equivalent work experience (Minimum Required
3 - 5+ Years’ experience in application development that directly aligns with the specific responsibilities for this position (Required)
Experience with ETL development
Must have experience with Informatica; Dataiku is a plus
Must have experience with BI tools such as Tableau and Microstrategy
Experience with AWS cloud native services, such as: Glue, Athena, Aurora, Redshift
Must have a proven track record working closely with business stakeholders, BSAs, and POs, Solution Architects to understand requirements and expectations to achieve quality technical solutions
What’s it like to work here?
At Lincoln Financial Group, we love what we do. We make meaningful contributions each and every day to empower our customers to take charge of their lives. Working alongside dedicated and talented colleagues, we build fulfilling careers and stronger communities through a company that values our unique perspectives, insights and contributions and invests in programs that empower each of us to take charge of our own future.

What’s in it for YOU:
A clearly defined career framework to help you successfully manage your career
Leadership development and virtual training opportunities
PTO/parental leave
Competitive 401K and employee benefits
Free financial counseling, health coaching and employee assistance program
Tuition assistance program
A leadership team that prioritizes your health and well-being; offering a remote work environment and flexible work hybrid situations
Effective productivity/technology tools and training

Work Arrangement
Work from Home : Employees will work from home and are not required to work in a Lincoln office on a regular basis.

Lincoln will evaluate the following when setting the successful candidate's wage rate:
Prior work or industry experience.
Education level to the extent education is relevant to the position.
Unique skills

About The Company
Lincoln Financial Group, a Fortune 200 company with over 10,000 employees, provides advice and solutions that help empower Americans to take charge of their financial lives with confidence. Our core business areas — Life Insurance, Annuities, Retirement Plan Services and Group Protection — focus on supporting, preserving and enhancing over 17 million customer’s lifestyles and retirement outcomes.

Headquartered in Radnor, Pennsylvania, Lincoln Financial Group is the marketing name for Lincoln National Corporation (NYSE: LNC) and its affiliates. The company had $324 billion in end-of-period account values as of June 30, 2021.

Ranked one of the Best Large Employers in America and Best Employers for Women by Forbes magazine as well as one of Newsweek’s Most Responsible Companies, Lincoln Financial Group makes a serious investment in our employees’ futures through a broad range of wealth accumulation and protection plans, health and wellness programs, and career development resources designed to help each individual reach their personal and professional goals.

Lincoln is committed to creating a diverse and inclusive environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.

Lincoln Financial Group is a committed corporate citizen included on major sustainability indices including the Dow Jones Sustainability Index North America and FTSE4Good. Dedicated to diversity and inclusion, we earned perfect 100 percent scores on the Corporate Equality Index and the Disability Equality Index. Follow us on Facebook, Twitter, LinkedIn, and Instagram.

Be Aware of Fraudulent Recruiting Activities
If you are interested in a career at Lincoln, we encourage you to review our current openings and apply on our website. Lincoln values the privacy and security of every applicant and urges all applicants to diligently protect their sensitive personal information from scams targeting job seekers. These scams can take many forms including fake employment applications, bogus interviews and falsified offer letters.
Lincoln will not ask applicants to provide their social security numbers, date of birth, bank account information or other sensitive information in job applications. Additionally, our recruiters do not communicate with applicants through free e-mail accounts (Gmail, Yahoo, Hotmail) or conduct interviews utilizing video chat rooms. We will never ask applicants to provide payment during the hiring process or extend an offer without conducting a phone, live video or in-person interview. Please contact Lincoln's fraud team at fraudhotline@lfg.com if you encounter a recruiter or see a job opportunity that seems suspicious.

Additional Information
This position may be subject to Lincoln’s Political Contribution Policy. An offer of employment may be contingent upon disclosing to Lincoln the details of certain political contributions. Lincoln may decline to extend an offer or terminate employment for this role if it determines political contributions made could have an adverse impact on Lincoln’s current or future business interests, misrepresentations were made, or for failure to fully disclose applicable political contributions and or fundraising activities.

Any unsolicited resumes/candidate profiles submitted through our web site or to personal e-mail accounts of employees of Lincoln Financial Group are considered property of Lincoln Financial Group and are not subject to payment of agency fees.

Lincoln Financial Group (“LFG”) is an Equal Opportunity employer and, as such, is committed in policy and practice to recruit, hire, compensate, train and promote, in all job classifications, without regard to race, color, religion, sex (including pregnancy), age, national origin, disability, sexual orientation, gender identity and expression, Veteran status, or genetic information. Applicants are evaluated on the basis of job qualifications. If you are a person with a disability that impedes your ability to express your interest for a position through our online application process, or require TTY/TDD assistance, contact us by calling 260-455-2558.",glassdoor
148,"Zscaler
4.5
Data Engineer
San Francisco, CA
$99K - $143K (Glassdoor est.)

 Company Description

Zscaler (NASDAQ: ZS) accelerates digital transformation so that customers can be more agile, efficient, resilient, and secure. The Zscaler Zero Trust Exchange is the company’s cloud-native platform that protects thousands of customers from cyberattacks and data loss by securely connecting users, devices, and applications in any location.
With more than 10 years of experience developing, operating, and scaling the cloud, Zscaler serves thousands of enterprise customers around the world, including 450 of the Forbes Global 2000 organizations. In addition to protecting customers from damaging threats, such as ransomware and data exfiltration, it helps them slash costs, reduce complexity, and improve the user experience by eliminating stacks of latency-creating gateway appliances.
Zscaler was founded in 2007 with a mission to make the cloud a safe place to do business and a more enjoyable experience for enterprise users. Zscaler’s purpose-built security platform puts a company’s defenses and controls where the connections occur—the internet—so that every connection is fast and secure, no matter how or where users connect or where their applications and workloads reside

Job Description

Position: Data Engineer
Location: Remote within United States
About the team: As part of the IT group, we are responsible for executing our enterprise data strategy which emphasizes data management maturity, fosters a robust data culture, and architects a best-in-class enterprise data platform. We have the ultimate goal to provide trusted data and insights at scale which enable corporate and functional data-driven decision making. We are fueled by organic innovation, internal collaboration and adoption of data visualization, data management, reporting automation, AI/ML and integration tools. We leverage best practices and alignment through our Enterprise Data Community to deliver speed to insight, scale, control and enablement. The team is distributed across the United States and India and is composed of data engineers, data analysts, visualization developers, and infrastructure specialists.
Responsibilities/What You’ll Do:
Collaborate with Data & Technical architects, integration and engineering teams to capture inbound/outbound data pipeline requirements, conceptualize and develop solutions
Support the evaluation and implementation of the current and future data applications/technologies to support the evolving Zscaler business needs
Collaborate with IT business engagement & applications engineer teams, enterprise data engineering and business data partner teams to identify data source requirements
Profile and quantify quality of data sources, develop tools to prepare data and build data pipelines for integrating into Zscaler’s data warehouse in Snowflake
Continuously optimize existing data integrations, data models and views while developing new features and capabilities to meet our business partners needs
Work with Principal Engineer/ Data Platform Lead to design and implement data management standards and best practices
Continue to learn and develop next generation technology/ data capabilities that enhance our data engineering solutions
Develop large scale and mission-critical data pipelines using modern cloud and big data architectures

Qualifications

Qualifications/Your Background:
3+ years of experience in data warehouse design & development
Strong experience in integrating internal and external business applications (salesforce, netsuite, google analytics etc) with cloud data platforms like Snowflake
Proficiency in SQL and ability to perform complex modeling with large volumes of data
Experience with Big Data technologies like Hadoop
Required Experience with any industry standard ETL & data integration platforms like Matillion, Workato, Dell Boomi
Experience with data orchestration to like Apache Airflow a plus
Experience with resolving workflow and data quality issues associated with production grade large scale cloud systems
Strong capacity to manage multiple projects simultaneously
Experience with Python, Dbt or similar a plus

Additional Information

All your information will be kept confidential according to EEO guidelines.
#LI-YC2
#LI-Remote
What You Can Expect From Us:
An environment where you will be working on cutting edge technologies and architectures
A fun, passionate and collaborative workplace
Competitive salary and benefits, including equity
Why Zscaler?

People who excel at Zscaler are smart, motivated and share our values. Ask yourself: Do you want to team with the best talent in the industry? Do you want to work on disruptive technology? Do you thrive in a fluid work environment? Do you appreciate a company culture that enables individual and group success and celebrates achievement? If you said yes, we’d love to talk to you about joining our award-winning team.

Additional information about Zscaler (NASDAQ: ZS ) is available at https://www.zscaler.com.
Zscaler is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.",glassdoor
149,"Autodesk
4.2
Data Engineer
San Francisco, CA
$116K - $169K (Glassdoor est.)

 Job Requisition ID #
22WD64738
Position Overview
Autodesk is looking for a talented Data Engineer to join our Observability Analytics team to create robust and scalable data pipelines using and improving existing platforms.

A successful candidate has a strong sense of ownership and will use their expertise to build extensible data models, provide meaningful recommendations and actionable strategies to partnering data scientists. They will drive performance enhancements, development best practices and collaborate with other Data Engineering teams throughout Autodesk.

Responsibilities
Create, automate, and support reliable data pipelines
Gather customer requirements, sequence work and document technical solutions
Interface with data engineers, data scientists, product managers and internal stakeholders
Cross-train and mentor teammates

Minimum Qualifications
3+ years of data processing experience in large cloud-based infrastructure (AWS preferred)
Familiar with SQL, dimensional modeling, and analytical data warehouses, like Snowflake
Understanding of Data Engineering best practices for medium to large scale production workloads
Hands-on software development experience in Python
Experience with data pipeline orchestration tools, like Airflow
Customer-facing and service-oriented person
Team player with great communication skills
Problem solver with excellent written and interpersonal skills
Experience consuming REST APIs

Preferred Qualifications
Experience with ELT pipelines - DBT
REST API design and implementation
Familiarity with containers and infrastructure-as-code principles
Experience with automation frameworks - Git, Jenkins, and Terraform
#LI-POST
At Autodesk, we're building a diverse workplace and an inclusive culture to give more people the chance to imagine, design, and make a better world. Autodesk is proud to be an equal opportunity employer and considers all qualified applicants for employment without regard to race, color, religion, age, sex, sexual orientation, gender, gender identity, national origin, disability, veteran status or any other legally protected characteristic. We also consider for employment all qualified applicants regardless of criminal histories, consistent with applicable law.
Are you an existing contractor or consultant with Autodesk? Please search for open jobs and apply internally (not on this external site). If you have any questions or require support, contact
Autodesk Careers
.",glassdoor
150,"Hazel Health
4.3
Data Engineer
San Francisco, CA
$111K - $154K (Glassdoor est.)

 About Hazel Health
Hazel Health, the national leader in school-based telehealth, was founded in 2015 to address systemic inequities in healthcare access, and ensure all children can get the quality care they need and deserve. We leverage digital health technology to provide on-demand physical and mental health care services to over 2 million students in school districts across the country.
Physical and mental telehealth has become more relevant in the lives of children than ever before. Hazel is experiencing tremendous company growth as we respond to our nation's call for equitable, affordable, and safe virtual access to healthcare.
We are a mission-driven team of healthcare and business leaders, educators, and tech innovators, bringing together our unique skills in a meaningful way to do good in the world. Please consider joining us to share your gifts and talents with a growing and diverse organization, working to make healthcare available to all students.
Job Summary
We are looking for a dynamic, empathetic, and action-oriented individual to join our exciting Engineering team.
As Data Engineer at Hazel, you will have significant responsibility in shaping Hazel's strategic direction as you build our data environment from end-to-end. As Hazel sits at the intersection of three data-rich industries (education, healthcare, and tech), this work is vital to Hazel's near- and long-term success.
Your primary responsibilities will be to:
Architect and build new data infrastructure for efficient storage, retrieval, and analytics
Innovating on current systems and processes
Designing, building, and scaling data pipelines
Monitoring database performance and tuning
Supporting data access and querying / visualization needs
Understand and translate ambiguous business needs by partnering with cross-functional teams to ultimately craft solutions aligned with Hazel's strategy
Spearheading the implementation of data governance and security policies within the company
Empower business leaders across product, clinical, and operations teams to adopt more innovative approaches to data collection and utilization
Champion and advise on on data strategy across the organization, supporting the buildout of data-oriented teams and advising on key external partnerships
Job Skills and Qualifications
5+ years of experience in data engineering and data architecture, at least part of which in a startup environment
Passion for our mission
Excitement for architecting an up-and-coming data ecosystem
Deep experience independently building and maintaining data warehouses and ETL pipelines
Familiarity with data governance frameworks
Advanced SQL coding and query optimization experience
Experience with data security and privacy concerns, ideally with healthcare data
A natural ownership mindset and entrepreneurial approach
Comfort with ambiguity and getting scrappy in a humble, fast-paced environment
This is an exciting position in a fast-paced organization. We offer a highly competitive compensation package.
Our Stance On Diversity:
At Hazel, we don't just accept differences—we thrive on them. We recognize that having diverse perspectives and backgrounds among our teammates makes our company, our solutions, and our service to families and schools stronger. We are committed to making Hazel an inclusive work environment and helping all staff grow professionally.
Hazel is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, national origin, sex, gender identity, sexual orientation, age, marital status, disability status, or Veteran status.
All offers of employment are conditioned on a candidate's consent to a background check and our satisfaction with the results. Qualified candidates with arrest and conviction records will be considered for employment in accordance with the San Francisco Fair Chance Ordinance.",glassdoor
151,"VSP Global
3.5
Data Engineer
California

 The Data Engineer creates and maintains data pipelines for key data and analytics capabilities in the enterprise. This position works in collaboration with analytics and data warehousing staff, DBAs, and subject matter experts to create reliable processes that load targeted data with integrity and quality, enabling it for strategic use by the business.
Collaborate within an agile, multi-disciplinary team to develop optimal data integration and transformation solutions.
Document and analyze data requirements (functional and non-functional) to develop scalable, automated, fault-tolerant data pipeline solutions for business and technology initiatives.
Profile data to assess the accuracy and completeness of data sources and work with business partners to mitigate issues.
Build and maintain data pipelines for using appropriate tools and practices in development, test, and production environments. Design with modularity to leverage the reuse of code wherever possible.
Create data mappings, programs, routines, and SQL to acquire data from legacy, web, cloud, and purchased package environments into the analytics environment.
Use a mix of ELT, ETL, data virtualization, and other methods to optimize the balance of minimal data movement against performance.
Maintain metadata management processes and documentation.
Monitor data quality to detect emerging issues and consult with the team to create transformation rules to cleanse against defined rules and standards.
Participate in code reviews and unit testing to optimize performance and minimize issues.
Job Specifications
Typically has the following skills or abilities:
Bachelor’s degree in computer science, data science, statistics, economics, or related functional area; or equivalent experience
Effective written and verbal communication skills with the ability to gather requirements and effectively collaborate with teammates and business partners
4+ years experience working in a development team providing analytical capabilities
4+ years of hands-on experience in the data space spanning data preparation, SQL, integration tools, ETL/ELT/data pipeline design
SQL coding experience
Familiarity with agile development environments (Scrum, Kanban) with a focus on Continuous Integration and Delivery
Previous experience using a data integration platform (IBM InfoSphere DataStage, Oracle Data Integrator, Informatica PowerCenter, MS SSIS, AWS Glue, Denodo), and familiarity with data warehouse MPP platforms such Snowflake, Netezza, Teradata, Redshift, etc.
Familiarity with event store and stream processing (Apache Kafka and platforms like Confluent) and with API development and management platforms (MuleSoft, Axway) is also beneficial
Capable of focusing on a specific set of tasks while also ensuring alignment to a broader strategic design
Exhibits the traits of a pro-active, self-driven contributor, who values continual learning and the adoption of new technology
#LI-REMOTE
#LI-VISIONCARE
Compensation range for the role is listed below. Applicable salary ranges may differ across markets. Actual pay will be determined based on experience and other job-related factors permitted by law. As a part of the compensation package, this role may include eligible bonuses, equity and commissions. For more information regarding VSP Vision benefits, please
click here
.
Salary Range:
0
0
VSP Vision is an equal opportunity employer and gives consideration for employment to qualified applicants without regard to age, gender, race, color, religion, sex, national origin, gender identity, sexual orientation, disability or protected veteran status. We maintain a drug-free workplace and perform pre-employment substance abuse testing.",glassdoor
152,"John Deere
4.1
Analytics Data Engineer
East Moline, IL

 There are over 7 billion people on this planet. And by 2050, there will be 2 billion more... many moving into urban centers at an unprecedented rate. Making sure there is enough food, fiber and infrastructure for our rapidly growing world is what we're all about at John Deere. And it's why we're investing in our people and our technology like never before! Here the world's brightest minds are tackling the world's biggest challenges. If you believe one person can make the world a better place, we'll put you to work. RIGHT NOW.

John Deere is an equal opportunity employer. All qualified applicants will receive consideration for employment without regards to, among other things, race, religion, color, national origin, sex, age, sexual orientation, gender identity or expression, status as a protected veteran, or status as a qualified individual with disability.

Primary Location: United States (US) - Illinois - East Moline
Function: Data & Analytics (CA)
Title: Analytics Data Engineer - 91351
Onsite/Remote:Onsite Position

This is an Onsite position, located in East Moline IL.
Visa sponsorship is NOT available for this position.
Your Responsibilities
Lead expert in identifying and prioritizing actionable insights for manufacturing and quality through a deep understanding of manufacturing data and analytic techniques.
Collaborate with a team of analytics professionals to design, build, and continuously improve meaningful factory-based analytics.
Acquires and connects data attributes to be used to develop analytic products (using Machine Learning methods).
Innovates and experiments with new data processing and transformation methods to enable the analytics development process.
Transforms data in alignment with data science needs and governance parameters and provides recommendations and testing for production environments.
What Skills You Need
2-4 years experience of advanced data gathering and analysis techniques, including statistical analysis or equivalent
2-4 years experience with tools used for data management or data warehousing
2-4 years - Proficiency with programming for data analysis, ideally Python, SQL, R, or SAS
2-4 years - Experience with analytics/bigdata platforms and/or technologies (e.g. AWS, DataBricks, Spark)
2-4 years - Experience in data visualization tools or application development (e.g. PowerBI, Tableau, R Shiny)
What Makes You Stand Out
Experience working in a manufacturing related function (Operations, Manufacturing or Quality Engineering, Factory Automation, or Robotics)
Experience managing large data migration or data transformation projects
Experience with machine learning models and/or supporting infastructure.
Education
Degree in an Information Technology discipline or equivalent experience. - University Degree (4 years or equivalent)
Degree in a Math discipline or equivalent experience. - University Degree (4 years or equivalent)
Statistics - University Degree (4 years or equivalent)
What You'll Get
At John Deere, you are empowered to create a career that will take you to where you want to go while working in an inclusive team environment. Here, you'll enjoy the freedom to explore new projects, the support to think outside the box and the advanced tools and technology that foster innovation and achievement. Additionally, we offer a comprehensive reward package to help you get started on your new career path, including:
Flexible work arrangements
Highly competitive base pay and performance bonuses
Savings & Retirement benefits (401K and Defined Benefit Pension)
Healthcare benefits with a generous company contribution in the Health Savings Account
Adoption assistance
Employee Assistance Programs
Tuition assistance
Fitness subsidies and on-site gyms at specific Deere locations
Charitable contribution match
Employee Purchase Plan & numerous discount programs for personal use

Click Here to find out more about our Total Rewards Package.

The information contained herein is not intended to be an exhaustive list of all responsibilities and qualifications required of individuals performing the job. The qualifications detailed in this job description are not considered the minimum requirements necessary to perform the job, but rather as guidelines.

The terms of the applicable benefit plans, and all company actions administering or interpreting these plans, continue to control. Deere & Company reserves the right to suspend, amend, modify, or terminate the Plan(s) in any manner at any time, including the right to modify or eliminate any cost-sharing between the company and participants. Changes, which can be made at any time, are made by action of the company's board of directors, or to the extent authorized by resolution of its board of directors, or by the Deere & Company Compensation Committee. In the event of a conflict between the language of the official Plan Documents and this document, the language of the official Plan Documents will control.

ACA Section 1557 Nondiscrimination Notice
The John Deere Health Benefit Plans for Salaried Employees and The John Deere Benefit Plan for Wage Employees comply with applicable Federal civil rights laws and do not discriminate on the basis of race, color, national origin, age, disability, or sex.",glassdoor
153,"2am.
Data Engineer
Remote

 Our ongoing desire to evolve took us on a journey #beyondsoftware. We are 2am.tech, a team of builders and problem solvers with a core belief in delivering excellence. This value has bred a company culture of providing solutions and products that exceed expectations every time. We are a fully remote company based in Miami, FL. If you're based in LATAM, the Balkans, and Europe, we'll be happy to hear from you.

As Data Engineer you are responsible for:
Communicate complex concepts verbally in English.
Be able to significantly overlap or fully work in North American time zones. These are the times the clients’ teams are working, and you need to share some hours to be part of those teams.
Respect deadlines and work in a team-oriented environment.
Assess new technologies and trends correctly.
Extensive experience with Data warehousing methodologies and modeling techniques.
Minimum three years of experience with the Snowflake architecture including using features such as Zero Copy Clone, Time Travel, User defined functions, etc.
Experience managing security in Snowflake including the creation of custom Roles to control access to Data, Databases, Warehouses, etc.
Experience in designing Compute Clusters (Warehouse) in Snowflake.
Good knowledge of Snowpipe (whatever ETL or ELT we will be using) for handling Streaming data.
Advanced understanding of migration, and methods to cloud data solutions.
Extensive experience in handling semi-structured data (JSON, XML) using the VARIANT attribute in Snowflake.
Experience in re-clustering the data in Snowflake with a good understanding of how Micro-Partition works inside Snowflake.
More than five years in creating master data datasets.
Design Tableau KPIs style dashboards and embed those in web applications.
Designing Tableau reports. Minimum of 3 years.
High English level is a must.",glassdoor
154,"GovDocs
4.4
Data Engineer
Remote
Employer Provided Salary:$90K - $120K

 Flexible Work Model:
We believe that the best way for us to grow, is through a work environment that allows us more flexibility whereby employees can be together in the office where interactions can happen with higher frequency and effectiveness (collaboration and team-engagement) – especially when dealing with complex problems and business innovation, balanced with work-from-home where we have more focused, uninterrupted time with minimal distractions for dedicated project/productive work.
Best Places to Work 2021:
GovDocs was named one of the 2021 Best Places to Work by the Minneapolis/St. Paul Business Journal!
Being named an honoree was no easy feat, as they received over 300 nominations for this year’s award. GovDocs was one of the top-scoring Minnesota businesses honored in the medium company category (50-250 employees) for creating a fun, challenging, and rewarding workplace.
Read more about GovDocs as Best Places to Work 2021 here: https://bizj.us/1qbeau
Position Summary:
We are looking for a savvy Data Engineer to join our growing engineering team. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, and business systems team on data analytics and reporting initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.
Responsibilities:
Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Azure Data Lake technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Qualifications:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Understanding of non-relational databases such as MongoDB desired
Experience building and optimizing ‘big data’ data pipelines, architectures, and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Ability to build processes supporting data transformation, data structures, metadata, dependency, and workload management.
A successful history of manipulating, processing, and extracting value from large, disconnected datasets.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
Strong critical thinking, decision making, troubleshooting and problem-solving skills
Excellent oral and written communication skills
We are looking for a candidate with 3+ years of experience in a Data Engineer role. Bachelor’s Degree in Computer Science, Statistics, Informatics, Information Systems, or another quantitative field a plus.
Technical Experience/Skills Required:
Experience in Azure Ecosystem (Azure Data lake, Azure Data Factory, Azure Data Bricks, Azure Storage, Cosmos DB, ADO)
Understanding and experience working with Microsoft Azure DevOps (work items, build/release, CICD)
Experience in Database Analysis and modern warehousing technologies
Understanding of code development best practices, process design and automation, security concepts, Agile concepts, tools, and technologies
Knowledge on Data Ingestion/ streaming tooling such as Kafka, Spark, or similar technologies
Familiarity with DevOps landscape, processes, standards, and tools
Experience in Agile frameworks and methodologies (Atlassian, Azure DevOps), Software Development Lifecycle (SDLC) experience is a plus.
Strong understanding of data Ingestion, data transformation, data management, data quality, and data lineage services and technologies
Compensation
This position is critical to the success of our business and the compensation package will be commensurate with candidate's experience and skills. Compensation will include base salary and performance-based incentives. Benefits include paid vacation, paid volunteer time and paid holidays, medical and dental, and matching 401(k).
Company Description
GovDocs serves companies in building and executing their employment law compliance programs in two primary ways:
Employment Law Posting Service: We manage all the complexities of identifying and providing the required set of employment law postings from the 1,700+ potential postings across the U.S. and Canada. Using proprietary technology, we allow companies to manage, track and verify postings at each of their locations – including our patent pending PosterCheck technology. Our Employment Law Posting Update service is used by almost 22% of the Fortune 500 and 30% of the Fortune 100.
Employment Law Compliance Software Solutions: This is a first to market Software-as-a-Service starting with our Minimum Wage product and Paid Leave products, which allow companies to identify and track which laws apply to their locations and employees, then provides all relevant data to make decisions. This service was created in response to requests from some of our largest customers who recognized that employment law expansion across and variances between jurisdictions (Federal, State and Local) were too difficult to manually track.
GovDocs has grown revenue annually by 18% since 2008 with a 96% customer retention rate, primarily due to our Postings Update Program both obtaining and retaining customers – as employment law postings are required by law, every company has an existing provider. Our Software Solutions are an entirely new line of business that gives us great growth potential to create a full Employment Law Compliance (ELC) platform of solutions, it is also challenging us to reinvent how we view urgency, innovation and teamwork.
You must be authorized to work in the United States. Immigration or work visa sponsorship will not be provided. In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire
Job Type: Full-time
Pay: $90,000.00 - $120,000.00 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Employee assistance program
Flexible schedule
Flexible spending account
Health insurance
Health savings account
Life insurance
Paid time off
Vision insurance
Schedule:
8 hour shift
Day shift
Monday to Friday
Supplemental pay types:
Bonus pay
COVID-19 considerations:
Flexible work model with working from home options. We take action to protect the health and well-being of our colleagues by regular review of Covid-19 statistics and health guidelines.
Application Question(s):
Will you now or in the future require sponsorship for employment visa status?
What are your compensation requirements?
Experience:
Data Engineering: 5 years (Preferred)
Work Location: Remote",glassdoor
155,"The Travelers Companies, Inc.
3.9
Data Engineer I - Data Products
Hartford, CT
Employer Provided Salary:$99K - $163K

 Who Are We?
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Job Category
Technology
Compensation Overview
The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.
Salary Range
$98,600.00 - $162,600.00
Target Openings
1
What Is the Opportunity?
Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate the stories found in data. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.
What Will You Do?
Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.
Design data solutions.
Analyze sources to determine value and recommend data to include in analytical processes.
Incorporate core data management competencies including data governance, data security and data quality.
Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.
Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.
Test data movement, transformation code, and data components.
Perform other duties as assigned.
What Will Our Ideal Candidate Have?
Bachelor’s Degree in STEM related field or equivalent
Six years of related experience
Proficient use of tools, techniques, and manipulation including Cloud platforms (AWS), programming languages (SQL, Python) and an understanding of software engineering practices.
The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.
Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.
Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.
Strong verbal and written communication skills with the ability to interact with team members and business partners.
Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities.
What is a Must Have?
Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
Four years of data engineering or equivalent experience.
What Is in It for You?
Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.
Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.
Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.
Wellness Program: The Travelers wellness program is comprised of tools and resources that empower you to achieve your wellness goals. In addition, our Life Balance program provides access to professional counseling services, life coaching and other resources to support your daily life needs. Through Life Balance, you’re eligible for five free counseling sessions with a licensed therapist.
Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.
Employment Practices
Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.

If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an
email
so we may assist you.

Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit
http://careers.travelers.com/life-at-travelers/benefits/
.",glassdoor
156,"Mercury
3.7
Data Engineer
San Francisco, CA
$104K - $152K (Glassdoor est.)

 SF, NY, Toronto, Portland, or remote
Full-time
Mercury
In the 1880s, Herman Hollerith noticed the US Census was taking over 8 years to calculate. To solve this, he invented a tabulating machine using punch cards that dramatically sped up the process and served as the foundation for innovation in high quality data gathering.
We’re looking for our first Data Engineer who can help us build our high quality data engine that informs how we invest in and build Mercury’s future. You’ll be early to building a data-informed culture across Mercury so that we can all determine what’s happening, react quickly, and invest intelligently.
Here are some things you’ll do on the job:
Partner with leadership, engineers, and data scientists to understand data needs and build systems that deliver high quality and reliable data.
Own and maintain the data systems that extract, transform, and load data into internal and external tooling.
Apply proven expertise and build high-performance scalable data warehouses.
Design, build, and launch efficient & reliable data pipelines to move and transform data (both large and small amounts).
Design and develop new systems in partnership with software engineers to enable quick and easy consumption of data.
You should:
Have 2+ years of experience working with analytics teams on building high quality and reliable data infrastructure.
Be able to navigate from architecture and implementation decisions related to data infrastructure to guide teams towards building reliable and accurate pipelines and company-critical data sets.
Have familiarity with postgres backend data, Snowflake, and data transformation tools like dbt.
Value quality in data tools, testing, and innovation.",glassdoor
157,"IDEXX
3.6
Data Engineer
Westbrook, ME
Employer Provided Salary:$95K - $105K

 As a Data Engineer , you will create data pipelines on our next-generation database build. You will assist with building robust, fault-tolerant data pipelines that collect, assemble, transform and aggregate distributed data into databases, operational data stores, data integration hubs, and data lakes. You will compile and install scalable cloud-based database systems and prepare data for analytical and operational uses. You will work to lay the groundwork for data consumers to easily retrieve and examine data sets to glean knowledge and insights.

IT Data Engineering is responsible for designing and developing enterprise data collection, aggregation, and access systems for IDEXX's global business environment. We work with traditional data architectures such as enterprise data warehousing and larger cloud-based data centralization systems like data integration hubs. Our products are used to synchronize billions of data points between enterprise applications such as global ERP and CRM applications, collect and normalize reference lab results and clinical utilization, and create easy-to-access data sources for enterprise analytics, sales enablement tools, and data science initiatives.
Our team includes a range of data engineers, data architects, and data-centric business system analysts, with a heavy focus on cloud-based ""big data"" projects. Some team members provide knowledge and support over our traditional data warehouse applications, building upon these environments with SQL and traditional ETL methods. At the same time, our newest technology addition expands our data models via Snowflake, bringing the best of cloud scale and compute capabilities, along with long-lived data engineering practices.

Our stack: AWS, Snowflake, Oracle, MySQL, Python, Informatica

In this role:
Using multiple technologies, you will design and implement scalable, reliable distributed data processing frameworks and analytical infrastructure.
You will define, design, and implement data integration, management, storage, consumption, backup, and recovery solutions that ensure the high performance of the organization's enterprise data.
You will develop Structured Query Language (SQL), Data Definition Language (DDL), and Python or equivalent programming scripts to support data pipeline development, problem-solving, data validation, and performance tuning.
You will adhere to and contribute to naming conventions, data governance practices, and thourough testing standards.
You will document data design tasks or project requirements.
You will implement measures to ensure data accuracy and accessibility.
You will identify and resolve data-oriented problems, such as missing, duplicate or incorrect data.
You will monitor performance and utilization.
You will guide data design and requirements to other development and business teams.
You will propose or develop semantic layer features for the enterprise model.
You will provide ongoing maintenance and process improvements for data initiatives.

What you will need to succeed:
You have a bachelor's degree or equivalent combination of education and relevant experience.
You have experience with relational databases such as Oracle, MySQL, and Snowflake.
You are proficient in coding and programming languages such as Structured Query Language (SQL) and Python.
You have experience with data integration/ETL tools such as Informatica PowerCenter or Sesame Relational Junction.
You are familiar with cloud platforms such as Amazon Web Services (AWS).
You understand data warehousing solutions and relational database theory.
You have good verbal and written communication skills and can translate technical subject matter to non-technical audiences (both as a speaker and listener).
You take the initiative in resolving problems and can balance conflicting requirements in partnership with others.
You excel at customer service and building relationships with businesses.
You excel at planning and organizing your work and can prioritize and be flexible with changing business needs.
You are a self-starter and can work on your own and in teams.
You can solve problems and draw conclusions, in some cases, with limited information.
You worked with Agile software development methodology.

What you can expect from us:
Base annual salary target: $95000 -$105000 (yes, we do have flexibility if needed)
Opportunity for annual cash bonus
Health / Dental / Vision Benefits Day-One
5% matching 401k
Additional benefits include but are not limited to financial support, pet insurance, mental health resources, volunteer paid days off, employee stock program, foundation donation matching, and much more!

Why IDEXX
We’re proud of the work we do, because our work matters. An innovation leader in every industry we serve, we follow our Purpose and Guiding Principles to help pet owners worldwide
keep their companion animals healthy and happy, to ensure safe drinking water for billions, and to help farmers protect livestock and poultry from disease. We have customers in over 175 countries and a global workforce of over 9,000 talented people.
So, what does that mean for you? We enrich the livelihoods of our employees with a positive and respectful work culture that embraces challenges and encourages learning and discovery. At IDEXX, you will be supported by competitive compensation, incentives, and benefits while enjoying purposeful work that drives improvement.
Let’s pursue what matters together.

IDEXX values a diverse workforce and workplace and strongly encourages women, people of color, LGBT individuals, people with disabilities, members of ethnic minorities, foreign-born residents, and veterans to apply.
IDEXX is an equal opportunity employer. Applicants will not be discriminated against because of race, color, creed, sex, sexual orientation, gender identity or expression, age, religion, national origin, citizenship status, disability, ancestry, marital status, veteran status, medical condition, or any protected category prohibited by local, state, or federal laws.

EOE/Minority/Female/Disabled/Veteran

#LI-REMOTE",glassdoor
158,"Ultra Mobile
4.4
Digital Data Engineer I - Remote
Costa Mesa, CA
Employer Provided Salary:$90K - $103K

 ULTRA MOBILE is seeking a talented Digital Data Engineer I to join the Data Management Team! Individual reports to Customer Data Manager. Role is remote; must reside in the United States.
ABOUT THE ROLE
Provide direct data engineering development to data pipelines for ETL establishment and enhancements to and from data warehouses to customer management platform (Braze). Work collaboratively with cross-functional teams to determine digital data needs, establish data collection requirements, and deploy & maintain accurate data to ensure metrics & dimensions are addressed for analytics/reporting requirements.
Your usual day of awesomeness includes:
Transform required data conditions into performance code logic.
Develop high-performance code in SQL and Python.
Develop, automate, and enhance ELT processes for continuous data flow.
Create, modify, and deploy code to production via AWS resources including Lambda, S3, Glue, Redshift, etc.
Partner with stakeholders to support the implementation and development of data requirements.
Troubleshoot data anomalies and provide applicable solutions.
Build, test and maintain database pipeline architectures.
WHAT YOU BRING
Advanced level in SQL and Python for data engineering and backend development.
Understanding of popular code development approaches:
Test-driven development
Continuous Integration/Continuous Deployment (CI/CD)
Experienced working with AWS services (Lambda, S3, Glue, Redshift etc.) and Cloud Data Warehouse.
Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
Define digital data collection methods and implementations to DWH and customer management platforms.
Experienced with QA testing process to verify data is collected & rendered as expected.
Ability to excel in a fast-paced, cross-functional environment.
Ability to work autonomously.
Excellent written and verbal communication skills.
Proactive problem-solving and critical thinking skills.
Ability to manage time effectively and consistently meet deadlines.
NICE TO HAVE
Prior working knowledge of Braze or other Customer Management Platforms
Snowflake Cloud Data Warehouse
Terraform/Bitbucket/Airflow/Jenkins
Looker, Tableau, Power BI
WE ARE ULTRA & MINT MOBILE
We connect people to what's most important in their lives: Easily, affordably and reliably. We strive to be California's Preeminent Destination Employer. Oh yeah, we get it too! We understand what matters to you most. You're an individual with unique needs, and we're prepared to exceed any expectations you have for an ideal employer.
We're smart, strategic, and get things done without a lot of red tape or unnecessary politics. Everyone matters here and everyone has a voice. Expect to spend your time contributing to projects that really matter. We obsess over the employee experience. To start, we provide some of the most competitive salary, benefits, family leave, vacation, retirement and equity options in Southern California. We believe in you and invest in you. Not just your career aspirations, but your life.
In addition, we've got a laundry list of perks you'll brag about on insta - Lunch every day prepared by our very own chef, healthy snacks, onsite gym, free massages, car wash services, and most importantly, a team atmosphere. We even raise the bar on well bars, including Espresso/Cappuccino/Nitro/Cold Brew/Kombucha Bar, Froyo Bar, Breakfast Bar, Snack Bar and a, well, you know, bar (after 5 pm).
And if you feel intrigued right now reading, imagine the co-workers we have already attracted. This is the kind of team you'll want to take home to mom or invite to your kid's next birthday party. This is the kind of close-knit community happening here. Come check out how you can be part of Ultra & Mint!
OUR VALUES – LET'S MAKE LIFE ULTRA TOGETHER!
Ownership: We are all owners; be the outcome and get the job done.
Action Biased: Be brilliant, proactive, and act with urgency.
Embrace the Adventure: Be agile, adaptive, and thrive on change.
Invent and Simplify: Never accept good enough.
$1,000 REFERRAL BONUS
Take a look at this job description, if you are the right person, please apply. If Ultra Mobile doesn't appear to be a fit for you, refer a friend or colleague and get $1,000. Let your friend or colleague know to provide your full name and email when applying to the job. If we hire them and they stay for 90 days, you get $1000. For more details of restrictions and rules, please email recruiting@ultra.me.

Covid-19 Vaccination Requirement
UVNV, Inc. has adopted a mandated vaccination policy to support the health and safety of our team members and our community. The Company requires all employees to be fully vaccinated. The Company will provide accommodations based on medical condition or sincerely held religious beliefs or practices. Please let us know if you'd like to discuss the policy or available accommodations before proceeding with our recruitment process.
We are committed to equal employment opportunities regardless of race, color, genetic information, creed, religion, sex, sexual orientation, gender identity, lawful alien status, national origin, age, marital status, or protected veteran status. We support an inclusive workplace where associates excel based on personal merit, qualification, experience, ability, and job performance.
In support of the Equal Pay for Equal Work Act, the range of starting pay for this role is $90,000 - $103,000. This is not a guarantee of compensation or salary, actual compensation is influenced by a wide range of factors including but not limited to skill set, level of experience, education, certifications, responsibility, and geographic location. We also offer a variety of benefits including health, disability insurance, 401 (k), flexible spending accounts, EAP, education reimbursement, parental leave, unlimited vacation, bonuses, incentive stock options and company paid holidays. The specific programs and options available will vary depending on state, start date, and employment type. Our recruitment team will be happy to answer any questions you may have.
#LI-Remote",glassdoor
159,"Ceribell, Inc
4.1
Clinical Data Engineer
Sunnyvale, CA
$91K - $142K (Glassdoor est.)

 About Ceribell
Ceribell Inc. is a rapidly growing venture capital backed medical technology startup based in Sunnyvale, CA. Ceribell deploys a cloud-linked, portable electroencephalogram (EEG) device to assess brain waves in minutes to identify the occurrence of seizures in emergency rooms and intensive care units. The Ceribell system is comprised of a brain stethoscope that converts brain waves into sound, enabling nurses and doctors to quickly diagnose seizures in order to more quickly administer live saving therapies. Ceribell received the first ever FDA 510(k) clearance for a digital seizure detection algorithm, and is growing its customer base and revenue rapidly. You can find more information at www.ceribell.com.
Position Overview
We are looking for a talented Clinical Data Engineer who is passionate about biomedical applications and has a strong background in clinical data management plus data annotation. The successful candidate will join the data science team and will contribute to the design and development of new state-of-the-art classification algorithms that will take the field of EEG neurodiagnostics to the next level.
This is a hybrid position. You will need to come into the office at least 4x per week
What you'll do:
Work with the team to build a research data infrastructure, including dataset management and collaboration with physicians to obtain data annotations, and developing innovative strategies to leverage research data to serve the R&D goals of the broader institution.
Understand what data and processes are needed for data science projects and participate in data collection and analysis.
Contribute to design, development and assessment of innovative machine learning classification algorithms.
What you need to be successful:
BS in Biomedical Engineering, Neuroscience, Computer Science, or equivalent Disciplines
Experience and interest in biomedical applications, biological signal processing, and algorithm development
Proficient in Matlab and/or Python and/or SQL or similar programming languages
Strong communication and analytical skills, detail-oriented and collaborative
A sense of urgency for anticipating/solving problems, the ability to manage multiple priorities at the same time.
Has an eye for detecting discrepancies – mistakes are inevitable in data handling and algorithm development. Should have an eye to detect them as early as possible before they propagate to next steps
Familiarity with signal processing and machine learning.
What we offer:
90-100K Base +Bonus + Ceribell Equity
100% Employer paid Health Benefits for the Employee
Life & Long-term disability insurance paid 100% by Ceribell
Flexible paid time off
11 Paid Holidays
Maternity and Paternity Leave
Fantastic culture with tremendous career advancement opportunities
Job Type: Full-time",glassdoor
160,"Cigna
3.8
BI Data Engineer-Work from home-eviCore
Hartford, CT
Employer Provided Salary:$96K - $160K

 Duties
Build ETL processes to allow data to flow seamlessly from source to target using tools like Databricks, Azure Data Factory, SSIS, SQL Stored Procedures and Powershell scripting
Load and enhance dimensional data models
Leverage code to apply business rules to ensure data is clean and is interpreted correctly by all business stakeholders, using tools like Databricks, SQL, Scala and Python
Perform code reviews and QA
Participate in sprint ceremonies
Provide on-call support to offshore operations team
Train operations teams on the ETL processes being developed
Troubleshoot and address issues with the data and/or the ETL process
Fine tune existing code to make processes more efficient
Maintain and create documentation to describe our data management processes
Analyze reports using various tools like Micro Strategy, Tableau and SSRS
Support user questions on data management processes and results

Minimum Required Skills
5+ Years building Big Data and Data Warehousing solutions
Knowledge of data modeling (including dimensional modeling), data architecture & data governance concepts
Experience in working with implementations of Azure cloud data solutions (ADLS, Data Bricks, Synapse, ADF)
Proficient in database concepts and technologies including MS SQ Server, DB2 and Oracle
Excellent written and oral communications skills
Must be able to effectively communicate complex technical topics to a variety of audiences
Experience with Healthcare data is a plus

Minimum Education, Licensure and Professional Certification requirement:
Bachelor’s degree with relevant experience required.
Master’s Degree is a plus.

If you will be working at home occasionally or permanently, the internet connection must be obtained through a cable broadband or fiber optic internet service provider with speeds of at least 10Mbps download/5Mbps upload.

For this position, we anticipate offering an annual salary of 95,900 - 159,800 USD / yearly, depending on relevant factors, including experience and geographic location.

This role is also anticipated to be eligible to participate in an annual bonus plan.

We want you to be healthy, balanced, and feel secure. That’s why you’ll enjoy a comprehensive range of benefits, with a focus on supporting your whole health. Starting on day one of your employment, you’ll be offered several health-related benefits including medical, vision, dental, and well-being and behavioral health programs. We also offer 401(k) with company match, company paid life insurance, tuition reimbursement, a minimum of 18 days of paid time off per year and paid holidays. For more details on our employee benefits programs, visit Life at Cigna .

About Cigna
Cigna Corporation exists to improve lives. We are a global health service company dedicated to improving the health, well-being and peace of mind of those we serve. Together, with colleagues around the world, we aspire to transform health services, making them more affordable and accessible to millions. Through our unmatched expertise, bold action, fresh ideas and an unwavering commitment to patient-centered care, we are a force of health services innovation. When you work with us, or one of our subsidiaries, you’ll enjoy meaningful career experiences that enrich people’s lives. What difference will you make?

Qualified applicants will be considered without regard to race, color, age, disability, sex, childbirth (including pregnancy) or related medical conditions including but not limited to lactation, sexual orientation, gender identity or expression, veteran or military status, religion, national origin, ancestry, marital or familial status, genetic information, status with regard to public assistance, citizenship status or any other characteristic protected by applicable equal employment opportunity laws.

If you require reasonable accommodation in completing the online application process, please email: SeeYourself@cigna.com for support. Do not email SeeYourself@cigna.com for an update on your application or to provide your resume as you will not receive a response.

Cigna has a tobacco-free policy and reserves the right not to hire tobacco/nicotine users in states where that is legally permissible. Candidates in such states who use tobacco/nicotine will not be considered for employment unless they enter a qualifying smoking cessation program prior to the start of their employment. These states include: Alabama, Alaska, Arizona, Arkansas, Delaware, Florida, Georgia, Hawaii, Idaho, Iowa, Kansas, Maryland, Massachusetts, Michigan, Nebraska, Ohio, Pennsylvania, Texas, Utah, Vermont, and Washington State.",glassdoor
161,"Colgate-Palmolive
4.2
Data Engineer
Piscataway, NJ
Employer Provided Salary:$97K - $135K

 No Relocation Assistance Offered
# 145263 - Piscataway, New Jersey, United States
Job Title: Data Engineer

Job Summary

We're looking for an experienced data and analytics professional to join our Global Supply
Analytics team. The ideal candidate will develop and automate data transformation pipelines
integrating data sources from various parts of the business to drive understanding and
operational efficiency for our Global Supply Organization. As an early member of the analytics
team, your role will influence the tech stack and frameworks we develop across the
organization. As an Analytics Engineer, you will collaborate with departments across the
organization and company, including Digital, eCommerce, Finance and IT.
Reporting:
Will report directly to the Data Integration and Visualization Lead.
What you will do:
Use SQL and Python to write production-quality code to meet the data transformation
needs of analysts and other business partners
Support the use of analytics platforms and data science workflows, while identifying
ways to strengthen and scale our data foundation
Help craft and develop transparent ELT pipelines that deliver timely and accurate data to
end users
Translate business requirements and logic into well-documented data models to drive
clarity and efficiency for end users
Collaborate cross functionally to understand and identify data needs and opportunities to
use data to drive business solutions
Communicate technical concepts to a non-technical audience in a compelling manner
Partner with IT to align on data architecture, analytics tools, and other technologies
Performs other duties as assigned
Align with all policies and standards
Required Qualifications:
Bachelor's Degree
At Least 6+ years of experience of professional experience as a data analyst, data
scientist, or data engineer
Demonstrated proficiency in the use of SQL and/or Python to wrangle, clean, and
integrate data from a variety of sources
Demonstrable understanding of modern data warehouse design principles and data
engineering standard methodologies
Practical experience using data visualization and/or BI tools (e.g., Domo, Tableau) to
analyze data
A commercially astute individual, with the ability to build strong cross-functional
relationships. Excited at the prospect of developing and implementing new tools and
processes that add organizational value & improve decision making capabilities.
A forward-thinking, high-reaching person, with strategic capabilities, able to lead change,
influence and collaborate both internally and externally, and with a clear dedication to
delivering business results in a timely manner.
Preferred Qualifications:
Master’s or PhD in a quantitative field
Proven experience with Git/GitHub, dbt Core/Cloud, and Airflow
Familiarity with SAP systems (ECC, C4C)
Salary Range $96,640 - $134,700 USD

Pay is based on several non discriminatory factors including but not limited to experience, education, skills and office location. In addition to your salary, Colgate-Palmolive offers a performance based bonus and competitive benefits package.

Equal Opportunity Employer
Colgate is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity, sexual orientation, national origin, ethnicity, age, disability, marital status, veteran status (United States positions), or any other characteristic protected by law.
Are you interested in working for Colgate-Palmolive? You can apply online and attach all relevant documents such as a cover letter and resume or CV. Applications received by e-mail are not considered in the selection process. Become part of our team. We look forward to your application.
Colgate-Palmolive is a leading global consumer products company, tightly focused on Oral Care, Personal Care, Home Care and Pet Nutrition. Colgate sells its products in over 200 countries and territories around the world under such internationally recognized brand names as Colgate, Palmolive, elmex, Tom’s of Maine, Sorriso, Speed Stick, Lady Speed Stick, Softsoap, Irish Spring, Protex, Sanex, Elta MD, PCA Skin, Ajax, Axion, Fabuloso, Soupline and Suavitel, as well as Hill’s Science Diet and Hill’s Prescription Diet.
For more information about Colgate’s global business, visit the Company’s web site at http://www.colgatepalmolive.com. To learn more about Colgate Bright Smiles, Bright Futures® oral health education program, please visit http://www.colgatebsbf.com. To learn more about Hill's and the Hill’s Food, Shelter & Love program please visit http://www.hillspet.com. To learn more about Tom’s of Maine please visit http://www.tomsofmaine.com.
Reasonable accommodation during the application process is available for persons with disabilities. Please contact Application_Accommodation@colpal.com with the subject ""Accommodation Request"" should you require accommodation.",glassdoor
162,"Twitch Interactive, Inc.
3.8
Data Engineer
San Francisco, CA
Employer Provided Salary:$140K - $171K

 You Have: • Experience writing SQL and a procedural language (Python, R, etc.) for data handling • Experience owning systems that collect, transform, and visualize data • Experience implementing data analytics, visualization tools and programs for HR working with Workday, Greenhouse, Tableau, Google Workspace, Google Data Studio, and Google Sheets • Experience implementing software solutions to automate data source, visualization and analytics products • Bachelors in related field, or equivalent experience
Job summary About Us: Twitch is the world's biggest live streaming service, with global communities built around gaming, entertainment, music, sports, cooking, and more. It's where millions of people come together to chat, interact, and make their own entertainment. We're about community, inside and out. You'll find coworkers who are eager to team up, collaborate, and smash (or elegantly solve) problems together. We're on a quest to empower live communities, so if this sounds good to you, see what we're up to on LinkedIn and Twitter, get interviewing tips on Instagram, and discover projects we're solving on our Blog. About the Role: Reporting to the Head of Global Talent Acquisition, the Data Engineer will expand the reach and role of data among leaders and managers at Twitch. You will empower the business to integrate data into their daily workflow by creating/maintaining data pipelines, producing reporting, and automating our processes. You can work in San Francisco, CA or remotely across the US. This role is for you if: • You love automating processes and developing efficient scalable solutions • You're excited about contributing to the success, efficiency, and happiness of Twitch staff • You're excited to jump into a diverse array of data work to support the team • You enjoy working with autonomy and shaping a new function You Will: • Delight consumers of people-related data by ensuring they have the data they need to inform decisions, where and when they need it • Build and own data pipelines, SQL queries/views, and apps • Automate processes through the use of JavaScript and other languages • Improve business, engineering, and data processes through data architecture, engineering, testing, and operational excellence best practices • Ensure the integrity of People and Places data in analyses and tools through regular audits • Partner to develop analytics products and recommend opportunities • Develop ongoing metrics, analyses, and dashboards to guide important decisions
Bonus Points

Experience handling People-related data including compensation, performance, hiring, and engagement data.
Experience automating Google services (Sheets, Docs, Data Studio) with Javascript
Experience with Workday, Greenhouse, and Tableau
Demonstrated net positive contributor to company community and culture above and beyond the core job

Perks:

Medical, Dental, Vision & Disability Insurance
401(k), Maternity & Parental Leave
Flexible PTO
Commuter Benefits
Amazon Employee Discount
Monthly Contribution & Discounts for Wellness Related Activities & Programs (e.g., gym memberships, off-site massages)
Breakfast, Lunch & Dinner Served Daily
Free Snacks & Beverages

Pursuant to the Los Angeles Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

The base pay range for this position in Colorado, Connecticut and Washington is $139,860 - $170,940 yr and in New York City is $153,900 - $188,100 yr. Pay is based on market location and may vary depending on job-related knowledge, skills, and experience. A sign-on payment and restricted stock units may be provided as part of the compensation package, in addition to a full range of medical, financial, and/or other benefits, dependent on the position offered. Applicants should apply via Twitch's internal or external careers site.

Workers in New York City who perform in-person work or interact with the public in the course of business must show proof they have been fully vaccinated against COVID or request and receive approval for a reasonable accommodation, including medical or religious accommodation.

Twitch values your privacy. Please consult our Candidate Privacy Notice, for information about how we collect, use, and disclose personal information of our candidates.

We are an equal opportunity employer and value diversity at Twitch. We do not discriminate on the basis of race, religion, color, national origin, gender, gender identity, sexual orientation, age, marital status, veteran status, or disability status, or other legally protected status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.",glassdoor
163,"Radcube LLC
3.7
Data Engineer
Remote
Employer Provided Salary:$116K - $130K

 Required:
Strong Python and R skills
Experience In Cloud
Experience using cloud technology - AWS/Snowflake/S3 (anyone)
Experience in Data Analytics and Machine Learning and NLP
Ability to research and solve problems independently
Strong written and verbal communication skills
Job Types: Full-time, Contract
Pay: $116,416.00 - $130,000.00 per year
Schedule:
8 hour shift
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: Remote",glassdoor
164,"Intrado
3.7
Data Engineer
Remote
Employer Provided Salary:$90K - $97K

 Job Description
For this opening we will consider candidates from the following locations: , United States |


Intrado is looking to hire a Data Engineer to join our Life & Safety business segment. This role is a fully remote and work from home opportunity anywhere in the USA.
Essential Duties:
Responsible for creating standardized documentation to be utilized by team members to process cases.
Analyzes and evaluates applications/tasks and determines areas that need improvement within the scope of departmental responsibility
Serves as primary escalation point for assigned area of responsibility
Process cases that were not resolved at lower level due to the cases being undocumented
Create documentation to be entered into a centralized knowledgebase for case resolutions to be utilized by department staff
Maintain and update centralized knowledgebase to ensure information is accurate and relevant
Develop basic reports for use by management in an accurate and timely manner
Analyze and evaluate applications and tasks and determine areas that need improvement within the scope of departmental responsibility
Collaborate with internal teams to complete design phase and initiate implementation
Participate in large-scale projects, completing tasks under the guidance of senior staff (e.g. Sr. Data Engineer, etc.)
Serve as subject-matter-expert (SME) for smaller projects requiring knowledge of specific systems or methods
Provide assistance to senior staff when conducting complex data analysis to resolve management inquiries
Applicant for this job will be expected to meet the following minimum qualifications:
Education:
Bachelor's degree from an accredited college or university with major course work in computer science, MIS, or a related field is required
Equivalent work experience in a similar position may be substituted for education requirements
Experience:
Minimum 3 years of experience with data analysis and migration to include experience in the analysis or design of applications or systems to store and extract data
Minimum 1 year of experience writing detailed test plans for small to medium sized projects preferred
Minimum 2 years of experience with SQL required
Minimum 1 year experience with requirements analysis and the software development life cycle required
Intermediate knowledge of Word, Excel, and PowerPoint required
Technical:
Proficiency in Python, Spark, Tableau, ELK preferred
Proficiency in Power BI preferred
Experience in Azure or AWS Cloud applications preferred
Experience with databricks preferred
Compensation:
Want to love where you work? At Intrado, we offer a comprehensive benefits package that includes what you’d expect (medical, dental, vision, life and disability coverage, paid time off, a 401(k) retirement plan with company match and flexible spending accounts), and several that go above and beyond (tuition reimbursement paid parental leave, access to a robust library of personal and professional training resources, employee discounts, critical illness, hospital indemnity and pet insurances, identity protection and more)! Apply today to join us in work worth doing!
The starting salary for this position is between $90-97,000 a year and will be commensurate with experience.

ABOUT US
Connecting people with each other and the right information is mission critical. Our Company develops innovative cloud-based technology to make it easier, more effective and more efficient to make the right connections. Our solutions put people in sync with each other and the right information, so they gain the insight needed to reach better decisions on the issues that matter most. We do it with a laser focus on reliability.

The Company is a leading provider of technology-driven, communication services, serving Fortune 1000 companies and other clients in a variety of industries, including telecommunications, retail, financial services, public safety, technology and healthcare. For more than 30 years, we have been leading the way in hosted and cloud-based solutions.

Our solutions connect people with each other and the information needed to gain insights for better decisions on the issues that matter most – Information to Insight.

Our Company has sales and/or operations in the United States, Canada, Europe, the Middle East, Asia Pacific, Latin and South America and is an Equal Opportunity Employer – Veterans/Disabled and Other Protected Categories. Our Company welcomes and encourages applications of individuals with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process.

ABOUT THE TEAM
Intrado’s Life & Safety division is responsible for some critical parts of our everyday life. Our solutions are responsible for everything that happens after a 9-1-1 call is placed – call routing, delivery, location determination and data management. Whether you call from a landline, cell phone or text 9-1-1, we make sure first responders get the right information at the right time so they can save lives.


Intrado also provides notifications to the utilities, healthcare and educational sectors. Our platform provides multi-modal communications that meet an individual’s contact preference and routes over 4 billion notifications each year. At the end of the day, Intrado believes that keeping people in our communities safe, connected and healthy is a top priority.",glassdoor
165,"MHS
5.0
Data Engineer
Remote

 Founded in 1999, MHS is a full-service provider of innovative material handling systems that solve the challenges of distribution and fulfillment operations. We build, engineer and maintain systems for some of the biggest companies in the world, including UPS, FedEx, Walmart, Amazon and others. MHS is already one of the 10 largest material handling system suppliers worldwide, and we only expect to continue growing. We’re looking for top talent to be part of the journey.

The Data Engineer is a key member of the Fortna Warehouse Execution System (WES) data team that design usable data models and build robust & dependable data pipelines where both batch & streaming process are leveraged to meet the latency requirements for the business. This position plays a vital role in building the Data Platform, Business Intelligence and Data product capability of the FortnaWES software product.
Evaluate business and technical domains to produce representative logical and physical data models
Build data models with the flexibility to change when business requirements change
Reconcile multiple logical source models into a single, logically consistent enterprise model
Develop and automate large scale, high-performance data processing systems (batch and/or streaming) to drive business growth and improve the product experience
Develop data stores, including warehouses, data lakes, data marts, etc., to support the BI and operational research initiatives
Build scalable data pipelines leveraging orchestration framework
Improve data quality by researching, using, and improving tools to automatically detect issues
Employ initiative, professionalism, and self-discipline in daily interactions
Qualifications:
Two to three years of relevant industry experience
Bachelor’s and/or master’s degree, preferably in Computer Science, or equivalent experience
Proven capability for managing data migrations between software products and custom apps
Experience with pipeline tools such as Nifi, Airflow
Experienced with Extract-Transform-Load (ETL), Extract-Load-Transform (ELT), and Discover-Access-Distill (DAD) processes
Experience in multidimensional data modeling, start schemas, snowflakes, normalized and de-normalized modes, and Kimball methodologies
Ability to communicate in a written, spoken, or visual manner at all personnel levels
Experience in deploying dbt/airflow workflow is a plus

DESIRED QUALIFICATIONS:
Demonstrated real-world execution implementing data warehouses and data lakes
Familiarity working with open-source Linux-based technologies
Verifiable record of building an enterprise analytics capability from greenfield",glassdoor
166,"CGI Group, Inc.
3.9
Data Engineer (JR)
Salt Lake City, UT
$75K - $106K (Glassdoor est.)

 Data Engineer (JR)

Position Description
CGI's Enterprise Technology and Operations (ETO) team is transforming what it means to work for a financial institution. We operate in a fast-paced, information-driven environment, which means we need people who bring diverse experiences, perspectives, and expertise to meet the ever-changing demands of a technology-driven world. We are grounded in the belief that ""improving the work is the work"" as we drive to create simple, easy, and fast solutions for our customers. Your ability to adapt, learn, and innovate helps increase revenue, reduce operational costs, and mitigates risk. ETO provides opportunities for you to own your career growth through Diversity, Equity, and Inclusion, Women in Technology, and Workforce of the Future initiatives that allow you to network across the organization, volunteer in our community, and build your technical and soft skills. Together we are building a culture that values diversity and creates a space of belonging for all our team members. We believe that investing in your success is an investment in our customers and our business. Our people are what sets us apart and make us great.

Your future duties and responsibilities
As a Data Engineer, you'll provide your talents in contributing to the success of the team by delivering the following:
Serve in the goalie rotation to support the Production environment.
Responsible for maintaining enterprise-grade platforms that enable data-driven solutions.
Search for ways to automate and maintain scalable infrastructure.
Ensure delivery of highly available and scalable systems.
Monitor all systems and applications and ensure optimal performance.
Analyzes and designs technical solutions to address production problems.
Participate in troubleshooting applications and systems issues.
Identifies, investigates, and proposes solutions to technical problems.
While providing technical support for issues, develop, test, and modify software to improve efficiency of data platforms and applications.
Monitors system performance to maintain consistent up time.
Prepares and maintains necessary documentation.
Participate in daily standups, team backlog grooming, and iteration retrospectives.
Coordinate with data operations teams to deploy changes into production.
Highest level may function as a lead.
Other duties as assigned.

Required qualifications to be successful in this role
Qualifications:
Requires a Bachelor's in Computer Science, Computer Engineering or related field and experience with ETL development, SQL, UNIX/Linux scripting, Big Data distributed systems. Prefer experience with IBM DataStage.
Various programming languages like Java and Python, orchestration tools and processes or other directly related experience.
A combination of education and experience may meet qualifications.
Excellent analytical, organizational, and problem-solving skills.
Ability and desire to learn new technologies quickly.
Ability to work independently and collaborate with others at all levels of technical understanding.
Able to meet deadlines.
Good judgment and project management skills.
Ability to communicate both verbally and in writing with both technical and non-technical staff.
Ability to work in a team environment and have good interpersonal skills.
Ability to adapt to changing technology and priorities.
Must be able to work independently, handle multiple concurrent tasks, with an ability to prioritize and manage tasks effectively.

Skill Set/Years of experience/Proficiency level

ETL
3-5 years
Expert

Linux
3-5 years
Expert

SQL
3-5 years
Expert

Microsoft Word, Excel, PowerPoint, Visio, and ADO
3-5 years
Expert

Python or Java
1-3 years
Expert

DESIRED QUALIFICATIONS/NON-ESSENTIAL SKILLS REQUIRED

Skill Set/Years of experience/Proficiency level

DataStage, Python
1 year
Professional

Minimum Education Required: Bachelor's degree

Colorado Equal Pay for Equal Work Act

Est. Salary Range (Colorado Only): $84,000-$107,000*

Disclaimer: In accordance with Colorado's Equal Pay for Equal Work Act, effective January 1, 2021, a good faith hourly or base salary range must be posted for all positions where the work may be performed in the state of Colorado. Therefore, this good faith salary range will only apply where this described position will be performed in the state,and should not be considered the compensation range in other locations or for other positions.

At CGI we call our professionals ""members"" to reinforce that all who join our team are, as owners, empowered to participate in the challenges and rewards that come from building a world-class company. CGI's benefits include:
Competitive base salaries
Eligibility to participate in an attractive Share Purchase Plan (SPP) in which the company matches dollar-for-dollar contributions made by eligible employees, up to a maximum, for their job category
401(k) Plan and Profit Participation for eligible members
Generous holidays, vacation, and sick leave plans
Comprehensive insurance plans that include, among other benefits, medical, dental, vision, life, disability, out-of-county emergency coverage in all countries of employment;
Back-up child care, Pet insurance, a Member Assistance Program, a 529 college savings program, a personal financial management tool, lifestyle management programs and more

Insights you can act on

While technology is at the heart of our clients' digital transformation, we understand that people are at the heart of business success.

When you join CGI, you become a trusted advisor, collaborating with colleagues and clients to bring forward actionable insights that deliver meaningful and sustainable outcomes. We call our employees ""members"" because they are CGI shareholders and owners and owners who enjoy working and growing together to build a company we are proud of. This has been our Dream since 1976, and it has brought us to where we are today - one of the world's largest independent providers of IT and business consulting services.

At CGI, we recognize the richness that diversity brings. We strive to create a work culture where all belong and collaborate with clients in building more inclusive communities. As an equal-opportunity employer, we want to empower all our members to succeed and grow. If you require an accommodation at any point during the recruitment process, please let us know. We will be happy to assist.

Ready to become part of our success story? Join CGI - where your ideas and actions make a difference.

Qualified applicants will receive consideration for employment without regard to their race, ethnicity, ancestry, color, sex, religion, creed, age, national origin, citizenship status, disability, pregnancy, medical condition, military and veteran status, marital status, sexual orientation or perceived sexual orientation, gender, gender identity, and gender expression, familial status, political affiliation, genetic information, or any other legally protected status or characteristics.

CGI provides reasonable accommodations to qualified individuals with disabilities. If you need an accommodation to apply for a job in the U.S., please email the CGI U.S. Employment Compliance mailbox at US_Employment_Compliance@cgi.com . You will need to reference the requisition number of the position in which you are interested. Your message will be routed to the appropriate recruiter who will assist you. Please note, this email address is only to be used for those individuals who need an accommodation to apply for a job. Emails for any other reason or those that do not include a requisition number will not be returned.

We make it easy to translate military experience and skills! Click here to be directed to our site that is dedicated to veterans and transitioning service members.

All CGI offers of employment in the U.S. are contingent upon the ability to successfully complete a background investigation. Background investigation components can vary dependent upon specific assignment and/or level of US government security clearance held. CGI will consider for employment qualified applicants with arrests and conviction records in accordance with all local regulations and ordinances.

CGI will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with CGI's legal duty to furnish information.

Skills
Data Engineering
ETL
Linux
SQL
DataStage
Python",glassdoor
167,"Enquizit Inc
4.3
DATA ENGINEER
Remote

 Enquizit, Inc. Achieves Virginia Business BEST Places to work 2021

https://enquizit.com/news/enquizit-inc-achieves-virginia-business-best-places-to-work-2021

Data Engineer
Enquizit Inc,

Enquizit is seeking Data Engineers with extensive experience in extract, transform and load of complex structured and semi-structured data from a variety of data sources to data destinations. This can range from Transactional, Search, Document or NoSql data stores. Ideal candidates will have multiple years of experience dealing with complex, large volume data with stringent quality control requirements using open-source software. The individual must be capable of working in a fast-paced Agile environment and working cooperatively within a multi-functional team. The individual would also have some familiarity with scheduler, orchestrator, background jobs and Data Ingestion techniques. Experience with Docker and Kubernetes environments is preferred.

Responsibilities
Aggregate data from both internal and external data sources to build a data processing system.
Create new pipelines and builds reusable components at scale to support reporting & analytics data products.
Develop complex queries to transform raw data sources into accessible models by coding.
Clean, prepare, transform, and optimize data at scale for integration and consumption.
Implement data management projects and restructures current web architecture.
Solve complex data issues and performs root cause analysis to proactively resolve product issues.
Own the data pipeline and supports systems failures.
Implement automated workflow using workflow scheduling processes like Apache airflow.
Has broad experience and knowledge of open source and proprietary cloud data pipeline tools.
Experienced at breaking down complex and large units of work, managing the work product of other engineers, and coaching more junior team members.

Qualifications
Bachelor’s degree in a related field or equivalent experience
The following attributes will be required to be successful:
A Bias for Action. Many decisions and actions are reversible and do not need extensive study. We value calculated risk taking
Excellent communication and interpersonal skills
Strong attention to detail
Self-motivated, proactive, energetic and tenacious
Excellent analytical, problem solving and resolution skills
Strong sense of ownership and responsibility
An interest in continuous improvement, innovation and simplification
The ability to translate business problems into practical, scalable technical solutions
Humility, integrity and the ability to be self-critical
Location:
100% remote
Employment type:
Fulltime/Contract C2C/1099/W2
WHAT WE OFFER:
Competitive annual salary and bonus
Paid Time off
Medical for employee with employer HSA -100% employer paid
Long term disability, Short term disability and Life Insurance/ AD&D - 100% employer paid
Low-cost 401K plan with 3% employer match
Relocation package
Career Growth
Training, Certification and Continuous Learning opportunities
Tech Conferences
What You’ll Find:
Everyone at Enquizit is driven by the pleasure of helping organizations who exist to do good, impacting our larger community.
Rewarding work – We aim to empower good, doing business with clients whose work makes our world better.
An open-door policy – We encourage feedback and transparency to enable trust and address issues proactively before they become larger.
Encouragement to fail fast – We have one rule about mistakes: learn from them. When mistakes happen, we bypass blame and work as a team to correct what went wrong.
Ongoing opportunities to learn – We have lunch and learns so we all learn, and as a company, we work smarter.
Work-life balance – Our work is thrilling and meaningful, but we know that balance in all things is key to living well.
A welcoming community – We work hard, but we take time to know each other, celebrate, and gather throughout the year.
Cooperation across disciplines – Our teams rely on and coach each other, building trust and knowledge that pays off in every project.

For more information about Enquizit visit https://enquizit.com/

We are an Equal Opportunity Employer.

To apply to the position, send a copy of your resume and cover letter.

Kumar Ramachandran | Senior Manager
Enquizit, Inc | www.enquizit.com",glassdoor
168,"Apple
4.2
Machine Learning Data Collection Engineer, Technology Development Group (TDG)
Cupertino, CA

 Summary
Posted: Mar 15, 2022
Role Number:200356922
Do you want to push the limits of the best Augmented Reality platform in the world? Apple's Technology Development Group (TDG) delivers algorithms that drive revolutionary Apple products, including the augmented reality (AR) platform ARKit to create ground-breaking new products. In this position, you will have the opportunity to be part of our extraordinary data team to discover and build solutions to previously-unsolved challenges and push the state of the art in AR algorithms that will change the way people experience the world! We are looking for a driven Machine Learning Data Collection Engineer that enjoys getting into the details to collect valuable data that feeds our machine learning models. As a member of the fast-paced data team, you have the rewarding opportunity to shape upcoming products that will delight and inspire millions of people every day. To succeed within this role, you should have shown experience in several of the following areas:
Key Qualifications
Ability to define/design/develop data collection efforts that focus on the end-to-end user experience, including anticipating potential failure modes, edge cases, and anomalies
Capacity to multitask and manage several projects in parallel while meeting deadlines and providing access to clients and partners
Problem solving & critical thinking capacities, thinking outside the box in order to gain in speed, efficiency, and quality.
Ability to re-construct ill-defined data needs into concrete project deliverables
Ability to maintain and develop relationships with multi-functional teams
Excellent project management, communication, interpersonal, analytical, and organizational skills
Description
As a Machine Learning Data Collection Engineer, you'll be working with our customers to understand their data collection requirements, assisting them in defining their protocols, and executing on the data collection. Your job responsibilities will include: -Collaborate with algorithm teams and understand data collection requirements in order to define collection protocols -Define and design the collection requirements and lead the collection effort from start to finish -Coordinate the efforts between internal teams (Legal, privacy, security, etc) guaranteeing compliance with applicable rules, laws, and best practices -Create documents and procedures needed to run data collections -Managing and track progress of externally run data collections
Education & Experience
Bachelors degree or related practical experience
Additional Requirements",glassdoor
169,"Apple
4.2
Biomedical Data Engineer - Health Technologies
Cupertino, CA

 Summary
Posted: Aug 8, 2022
Weekly Hours: 40
Role Number:200402289
The Health Technologies Team conceives and proves out innovative technology for Apple’s future products and features in health. We are seeking a highly capable Biomedical Data Engineer to join a multi-disciplinary team. Successful candidates will be able to integrate with our research study leads, data scientists and engineers to develop and support effective data analysis and machine learning workflows.
Key Qualifications
Experience with software engineering frameworks
Excellent coding skills in Python (e.g.,Pandas, Spark, Jupyter)
Workflow orchestrations (e.g., Airflow, Luigi)
Designing and maintaining (non-)relational databases (e.g. Postgres, Cassandra, MongoDB) and file systems (e.g. Parquet, CSV, JSON)
Great understanding of infrastructure designs
Linux, MacOS based development frameworks
iOS/ watchOS development (e.g., Swift, Objective-C)
Web Service APIs (e.g., AWS, REDCap, XNAT)
Version control frameworks (Git, virtualenv)
Familiarity with best practices for information security, including safe harbor privacy principles for sensitive data
Experience with biomedical sensors/platforms for measuring physiological signals in the health, wellness and/or fitness realms
Description
- Work closely with team members and study staff to design, build, launch and maintain systems for storing, aggregating and analyzing large amounts of data - Process, troubleshoot, and clean incoming data from human studies - Automate and monitor data ingestion and transformation pipelines, with hooks for QA, auditing, redaction and compliance checks per data management specifications - Create and maintain databases with existing and incoming clinical data - Architect data models and create tools to harmonize disparate data sources - Incorporate and comply with regulations as they pertain to electronic and clinical data and databases
Education & Experience
BS/MS in Computer Science, Engineering, Informatics, or equivalent with relevant 4+ years industry experience with biomedical, health or sensitive data.
Additional Requirements",glassdoor
170,"Apple
4.2
ML Data Collection and Data Science Engineer (TDG)
Cupertino, CA

 Summary
Posted: May 16, 2022
Role Number:200380146
Do you want to push the limits of the best Augmented Reality platform in the world? Apple's Technology Development Group (TDG) delivers algorithms that drive revolutionary Apple products, including the augmented reality (AR) platform ARKit to create ground-breaking new products. In this position, you will have the opportunity to be part of our extraordinary data team to discover and build solutions to previously-unsolved challenges and push the state of the art in AR algorithms that will change the way people experience the world! We are looking for a driven Machine Learning Data Collection Engineer that enjoys getting into the details to collect valuable data that feeds our machine learning models. As a member of the fast-paced data team, you have the rewarding opportunity to shape upcoming products that will delight and inspire millions of people every day. To succeed within this role, you should have shown experience in several of the following areas:
Key Qualifications
Ability to define/design/develop data collection efforts that focus on the end-to-end user experience, including anticipating potential failure modes, edge cases, and anomalies
Proficiency in programming languages including Python, C++, or similar
Capacity to multitask and manage several projects in parallel while meeting deadlines and providing access to clients and partners
Problem solving & critical thinking capacities, thinking outside the box in order to gain in speed, efficiency, and quality.
Excellent project management, communication, interpersonal, analytical, and organizational skills
Experience with industrial software development, a plus
Experience with CVML, a plus
Description
As a Machine Learning Data Collection Engineer, you'll be collaborating with multi-functional teams to work on CVML data collection projects, from collecting data collection requirements, designing protocols, testing software and hardwares, executing data collection, to analyzing and curating collected data. Your job responsibilities will include -Contribute to the design of CVML data collection, including hardware, software, user interface specifications, and collection protocols. -Define, implement, maintain SW and HW solutions to test data collection hardware, software and protocols. -Design, implement and maintain SW platforms to monitor date life cycle -Work with CVML engineers to design and implement data evaluation and curation process -Analyze data and build data analysis tools -Collaborate with multi-functional teams including algorithm, hardware, software, product design, project management, legal, procurement, security, logistics and vendors to define and deliver necessary study elements -Write technical documents including study instructions, operating procedures and training documents for study personnel -Drive process improvements across the organization to continuously improve the way we work
Education & Experience
B.S., M.S., or Ph.D. in Computer Science, Computer Engineering, or equivalent practical experience.
Additional Requirements",glassdoor
171,"Farmers Insurance Group
3.7
Data Engineer (Application SME I)
Remote
Employer Provided Salary:$74K - $98K

 We are Farmers!
We are… more than just your favorite commercials. We are a passionate, award winning, equal opportunity employer, committed to the strength of a diverse workforce. We are dedicated to supporting the well-being of our people through our extensive suite of benefits, as well as the well-being of the communities we serve through employee volunteer programs and nonprofit partnerships. Helping others in their time of need isn’t just our business – it’s our culture! We are Farmers!

Do you thrive in a high-volume, fast-paced environment? Do you enjoy the challenge of a position where no two days are alike? We are looking for positive, high-energy professionals who are not just looking for a job, but a meaningful career!

Job Summary
Use MS SQL SSIS to build ETL process to create new business functionalities as well to solve business problems: Respond to new requests for reports/data understanding business objectives and processes; review and refine technical requirements/User Stories; and communicate estimated hours and timeline to complete; Extract data directly from relational databases (e.g. DB2, SQL Server), data warehouses, or other data stores using SQL; Ability to create manual as well as automated data exports/reports; and Support application unit testing for enhancements or system upgrades; identify and communicate data quality issues or data differences. Work productively on assigned tasks; Collaborate effectively with other team members; Demonstrate accountability to management and business for hours spent on assigned tasks; and diligently strive to deliver value.
Essential Job Functions
Work within structure of SAFe Agile team on the successful delivery of Business Intelligence projects, enhancements, and defects. Independently lead and deliver new projects and enhancements. Collaborate with Agile team members to understand functional and technical requirements. Prepare estimates based on high-level requirements and assumptions. Translate functional requirements into technical specifications for ETL development; develop source-to-target mappings and actively manage Development, Unit Testing and Implementation efforts. Troubleshoot production defects, perform root cause analysis and provide guidance to team on the fixes.
Education Requirements
High school diploma or equivalent required.
Bachelor’s degree preferred, in Information Systems or related field.
Experience Requirements
Experience in developing ETL and reporting applications using Microsoft SQL Server (strongly preferred), or Informatica or similar ETL technologies.
Experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process on MS SQL Server or DB2 or similar DB platform.
Experience with Python and unstructured data manipulation is a plus.
Experience with cloud technologies such as AWS Glue, Azure Data Factory, Snowflake is a plus.
Experience working in an Agile Environment is a plus.
Good knowledge of business intelligence best practices, processes, and methodologies.
Good programming experience in writing Stored Procedures, Queries, Views, User Defined Functions, and Common Table Expressions using SQL or T-SQL.
Highly committed, motivated, enthusiastic and a natural team player.
Good interpersonal and communication skills (both verbal and written) and ability to interact with and effectively address concerns.
Good prioritization, time management, analytical, and organization skills.
Experienced in facilitating in-person and remote meetings with business & IT.
Experienced in effective management of multiple competing and frequently changing assignments and priorities.

Benefits
Farmers offers a competitive salary commensurate with experience, qualifications and location
Colorado Only: The pay range for this job being performed in Colorado would be 73,600 - 98,100
Bonus Opportunity (based on Company and Individual Performance)
401(k)
Medical
Dental
Vision
Health Savings and Flexible Spending Accounts
Life Insurance
Paid Time Off
Paid Parental Leave
Tuition Assistance

Job Location(s): R_US - RW - Remote Work",glassdoor
172,"Faire
4.8
Data Engineer
San Francisco, CA
$117K - $170K (Glassdoor est.)

 About Faire
Faire is an online wholesale marketplace built on the belief that the future is local — there are over 2 million independent retailers in North America and Europe doing more than $2 trillion in revenue. At Faire, we're using the power of tech, data, and machine learning to connect this thriving community of entrepreneurs across the globe. Picture your favorite boutique in town — we help them discover the best products from around the world to sell in their stores. With the right tools and insights, we believe that we can level the playing field so that small businesses everywhere can compete with these big box and e-commerce giants.
By supporting the growth of independent businesses, Faire is driving positive economic impact in local communities, globally. We're looking for smart, resourceful and passionate people to join us as we power the shop local movement. If you believe in community, come join ours.
Job Description
The Data Engineering team is the backbone of all data-related processes and enables the Data Science teams to develop and deploy a wide variety of algorithms and models that power the marketplace. Our infrastructure is used by the whole company for analytics, reporting, forecasting and research. We care about having a reliable & scalable infrastructure with quality data and building machine learning models that help our customers thrive.
As a Data Engineer you'll be responsible for developing and automating large scale, high-performance data storage and processing systems.
What you will be doing:
Develop our data infrastructure to help us scale for where we're going over the next several years
orchestrating pipelines using modern Big Data tools/architectures as well as design and engineering of existing transactional processing systems
Manage our data infrastructure and ETL platform
What it takes:
2+ years experience in a Data Engineering role with an emphasis on managing data warehouses
Strong skills in Python, Git, Docker, SQL, Airflow, real time ETL pipelines
Managing data infrastructure (AWS services, Data orchestrator) and providing framework to rationalize and simplify both real time and batch data pipelines
Familiarity with Snowflake or BigQuery
A passion for programming and solving problems with code
A bachelor's degree in Computer Science/Software Engineering or equivalent industry experience
A love for technology, and an insatiable curiosity for new tools to tackle real problems
Faire's flexible work model aims to meet the needs of our diverse employee community by making work more flexible, connected, and inclusive. Depending on the role and needs of the team, Faire employees have the flexibility to choose how they work–whether that's mainly in the office, remotely, or a mix of both.
Roles that list only a country in the location are eligible for fully remote work in that country or in- office work at a Faire office in that country, provided employees are located in the registered country/province/state. Roles with only a city location are eligible for in-office or hybrid office work in that city. Our talent team will work with candidates to determine what locations and roles are eligible for each option.
Why you'll love working at Faire
We are entrepreneurs: Faire is being built for entrepreneurs, by entrepreneurs. We believe entrepreneurship is a calling and our mission is to empower entrepreneurs to chase their dreams. Every member of our team is an owner of the business and taking part in the founding process.
We are using technology and data to level the playing field: We are leveraging the power of product innovation and machine learning to connect brands and boutiques from all over the world, building a growing community of more than 350,000 small business owners.
We build products our customers love: Everything we do is ultimately in the service of helping our customers grow their business because our goal is to grow the pie - not steal a piece from it. Running a small business is hard work, but using Faire makes it easy.
We are curious and resourceful: Inquisitive by default, we explore every possibility, test every assumption, and develop creative solutions to the challenges at hand. We lead with curiosity and data in our decision making, and reason from a first principles mentality.
Faire was founded in 2017 by a team of early product and engineering leads from Square. We're backed by some of the top investors in retail and tech including: Y Combinator, Lightspeed Venture Partners, Forerunner Ventures, Khosla Ventures, Sequoia Capital, Founders Fund, and DST Global. We have headquarters in San Francisco and Kitchener-Waterloo, and a global employee presence across offices in Salt Lake City, Atlanta, Toronto, London, New York, LA, and Sao Paulo. To learn more about Faire and our customers, you can read more on our blog.
Faire provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity or gender expression.
Faire is committed to providing access, equal opportunity and reasonable accommodation for individuals with disabilities in employment, its services, programs, and activities. To request reasonable accommodation, please fill out our Accommodation Request Form.",glassdoor
173,"Apple
4.2
Keystone Big Data Software Engineer, Global Business Intelligence
Cupertino, CA

 Summary
Posted: Jul 18, 2022
Role Number:200399924
Imagine what you could do here! At Apple, great minds come together to build products, services, and solutions that amaze the world. Imagine how your contributions could transform the world and there is no limit to what you could accomplish here. Apple's Global Business Intelligence (GBI) team is seeking an experienced Software Engineer to build high quality, scalable and resilient distributed systems that power Apple's analytics platforms and data pipelines. Apple's Enterprise Data Warehouse landscape caters to a wide variety of real-time, near real-time and batch analytical solutions. These solutions are an integral part of business functions like Sales, Operations, Finance, AppleCare, Marketing, and Internet Services, enabling business drivers to make critical decisions. If you enjoy learning new technologies, and are comfortable proposing and implementing solutions, demonstrating Software Engineering standard methodologies, you will find it rewarding to work in GBI! The ideal candidate for this position will be able to think outside of the box and should have passion for building engineering solutions to enable business in making time sensitive and critical decisions.
Key Qualifications
Strong fundamentals in data structures, algorithms, and software system design
Strong hands-on programming skills (Scala / Java / Python preferred)
Proven track record of building jobs processing high-volume data using Spark
Experience with real time data processing with Spark Streaming, Flink is a huge plus
Committed to test driven development paradigm
Strong analytical and interpersonal skills and demonstrated ability to code & collaborate
Self-starter, highly motivated and ability to research, learn, prototype quickly
Sound experience in Cloud technologies such as AWS or GCP
Experience on Cloud with databases like SnowFlake and Singlestore is a plus
Prior experience in the areas of AI/ML/Data Sciences will be a strong plus
Curiosity to explore and understand data is a plus
Description
The Frameworks team in GBI build and support critical infrastructural systems which provide services for numerous organizations within Apple and we are looking for a strong, enthusiastic developer to join as a member of this group. You are someone with ideas and real passion for software delivered as a service to improve reuse, efficiency, and simplicity. This engineer’s work will affect multiple data teams within Apple and enable our partners to derive insights and help execute their goals.
Education & Experience
BS/MS in Computer Science, Computer Engineering or similar field
Additional Requirements
Apple is an Equal Opportunity Employer that is committed to inclusion and diversity. We also take affirmative action to offer employment and advancement opportunities to all applicants, including minorities, women, protected veterans, and individuals with disabilities. Apple will not discriminate or retaliate against applicants who inquire about, disclose, or discuss their compensation or that of other applicants.
We at Apple we are committed to working with and providing reasonable accommodation to applicants with physical and mental disabilities. Learn more.",glassdoor
174,"Expression Networks
4.4
Data Engineer
Remote

 Founded in 1997 and headquartered in Washington DC, Expression Networks provides data fusion, data analytics, software engineering, information technology, and electromagnetic spectrum management solutions to the U.S. Department of Defense, Department of State, and national security community. Expression's “Perpetual Innovation” culture focuses on creating immediate and sustainable value for our clients via agile delivery of tailored solutions built through constant engagement with our clients. Expression Networks was ranked #1 on the Washington Technology 2018's Fast 50 list of fastest-growing small business Government contractors and a Top 20 Big Data Solutions Provider by CIO Review.

We make sure to provide everyone the tools and opportunities to grow while working on some of the newest technologies in the industry. With Covid-19 being a major theme the last two years having a growing collaborative culture has been one of the key focus of our C-suite and upper management. We get excited about celebrating our professionals' milestones, accomplishments, promotions, overcoming challenges, and many other aspects that make an engaging collaborative environment.

We are looking to bring on a mid-level Data Engineer to add to the continued growth of our Data Science division. This position will work in a team led by a principal data engineer on tasks related to designing and delivering high-impact data architecture and engineering solutions to our customers across a breadth of domains and use cases.
Location:
Remote, with the ability to travel per project requirements.
Security Clearance:
Ability to obtain Secret Clearance or Higher
Responsibilities:
Developing, testing, and documenting software code for data extraction, ingestion, transformation, cleaning, correlation, and analytics
Participating in end-to-end architectural design and development lifecycle for new data services/products, and making them operate at scale
Participating in cross-functional team collaboration to understand customer requirements, design prototypes, and optimize existing data services/products
Demonstrating Data Science excellence in the teams you work with across the organization, and mentoring junior members in the Data Science division
Participating in research, case studies, and prototypes on cutting-edge technologies and how they can be leveraged
Required Qualifications:
3+ years of experience bringing databases, data integration, and data analytics/ML technologies to production with a Bachelor's degree in Computer Science/Data Science/Computer Engineering or relevant field
Mastery in developing software code in one or more programming languages (Python, JavaScript, Java, Matlab, etc.)
Expert knowledge in databases (SQL, NoSQL, Graph, etc.) and data architecture (Data Lake, Delta Lake)
Knowledgeable in machine learning/AI methodologies
Experience with one or more SQL-on-Hadoop technology (Hive, Impala, Spark SQL, Presto, etc.)
Preferred Qualifications:
Experience in short release cycles and the full software lifecycle
Experience with Agile development methodology (e.g., Scrum)
Strong writing and oral communication skills to deliver design documents, technical reports, and presentations to a variety of audiences
Benefits:
Expression Networks offers competitive salaries and benefits, such as:
401k matching
PPO and HDHP medical/dental/vision insurance
Education reimbursement up to $10,000/yr.
Complimentary life insurance
Generous roll over PTO and 11 days of holiday leave
Onsite gym facility and trainer
Commuter Benefits Plan
In office Cold Brew Coffee
Equal Opportunity Employer/Veterans/Disabled",glassdoor
175,"Dataquestcorp
Data Science Engineer
Branchburg, NJ
Employer Provided Salary:$75K - $80K

 Job Role: Data Science
Note: Please don't apply C2C profiles. its only w2 positions
Benefits:
Free Training and placement.
Training provided by highly qualified, industry-experienced & certified instructors.
We do provide free accommodations & Relocation charges.
H1B Sponsorship
We do support for STEM OPT and GC processing.
Health Insurance
Relocation Assistance any where in USA.
Free accommodation.
Location: Branchburg, NJ
Job Types: Full-time, Contract
Job Types: Full-time, Contract
Salary: $75,000.00 - $80,000.00 per year
Benefits:
Health insurance
Schedule:
8 hour shift
Ability to commute/relocate:
Branchburg, NJ: Reliably commute or planning to relocate before starting work (Required)
Experience:
Python: 1 year (Preferred)
SQL: 1 year (Preferred)
Work Location: One location
Speak with the employer
+91 9089927715",glassdoor
176,"Mint Mobile
3.6
Digital Data Engineer I - Remote
Costa Mesa, CA
Employer Provided Salary:$90K - $103K

 MINT MOBILE is seeking a talented Digital Data Engineer I to join the Data Management Team! Individual reports to Customer Data Manager. Role is remote; must reside in the United States.
ABOUT THE ROLE
Provide direct data engineering development to data pipelines for ETL establishment and enhancements to and from data warehouses to customer management platform (Braze). Work collaboratively with cross-functional teams to determine digital data needs, establish data collection requirements, and deploy & maintain accurate data to ensure metrics & dimensions are addressed for analytics/reporting requirements.
Your usual day of awesomeness includes:
Transform required data conditions into performance code logic.
Develop high-performance code in SQL and Python.
Develop, automate, and enhance ELT processes for continuous data flow.
Create, modify, and deploy code to production via AWS resources including Lambda, S3, Glue, Redshift, etc.
Partner with stakeholders to support the implementation and development of data requirements.
Troubleshoot data anomalies and provide applicable solutions.
Build, test and maintain database pipeline architectures.
WHAT YOU BRING
Advanced level in SQL and Python for data engineering and backend development.
Understanding of popular code development approaches:
Test-driven development
Continuous Integration/Continuous Deployment (CI/CD)
Experienced working with AWS services (Lambda, S3, Glue, Redshift etc.) and Cloud Data Warehouse.
Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
Define digital data collection methods and implementations to DWH and customer management platforms.
Experienced with QA testing process to verify data is collected & rendered as expected.
Ability to excel in a fast-paced, cross-functional environment.
Ability to work autonomously.
Excellent written and verbal communication skills.
Proactive problem-solving and critical thinking skills.
Ability to manage time effectively and consistently meet deadlines.
NICE TO HAVE
Prior working knowledge of Braze or other Customer Management Platforms
Snowflake Cloud Data Warehouse
Terraform/Bitbucket/Airflow/Jenkins
Looker, Tableau, Power BI
WE ARE MINT MOBILE
We connect people to what's most important in their lives: Easily, affordably and reliably. We strive to be California's Preeminent Destination Employer. Oh yeah, we get it too! We understand what matters to you most. You're an individual with unique needs, and we're prepared to exceed any expectations you have for an ideal employer.
We're smart, strategic, and get things done without a lot of red tape or unnecessary politics. Everyone matters here and everyone has a voice. Expect to spend your time contributing to projects that really matter. We obsess over the employee experience. To start, we provide some of the most competitive salary, benefits, family leave, vacation, retirement and equity options in Southern California. We believe in you and invest in you. Not just your career aspirations, but your life.
In addition, we've got a laundry list of perks you'll brag about on insta - Lunch every day prepared by our very own chef, healthy snacks, onsite gym, free massages, car wash services, and most importantly, a team atmosphere. We even raise the bar on well bars, including Espresso/Cappuccino/Nitro/Cold Brew/Kombucha Bar, Froyo Bar, Breakfast Bar, Snack Bar and a, well, you know, bar (after 5 pm).
And if you feel intrigued right now reading, imagine the co-workers we have already attracted. This is the kind of team you'll want to take home to mom or invite to your kid's next birthday party. This is the kind of close-knit community happening here. Come check out how you can be part of Mint!
OUR VALUES – LET'S MAKE LIFE ULTRA TOGETHER!
Ownership: We are all owners; be the outcome and get the job done.
Action Biased: Be brilliant, proactive, and act with urgency.
Embrace the Adventure: Be agile, adaptive, and thrive on change.
Invent and Simplify: Never accept good enough.
$1,000 REFERRAL BONUS
Take a look at this job description, if you are the right person, please apply. If Mint Mobile doesn't appear to be a fit for you, refer a friend or colleague and get $1,000. Let your friend or colleague know to provide your full name and email when applying to the job. If we hire them and they stay for 90 days, you get $1000. For more details of restrictions and rules, please email recruiting@ultra.me.

Covid-19 Vaccination Requirement
UVNV, Inc. has adopted a mandated vaccination policy to support the health and safety of our team members and our community. The Company requires all employees to be fully vaccinated. The Company will provide accommodations based on medical condition or sincerely held religious beliefs or practices. Please let us know if you'd like to discuss the policy or available accommodations before proceeding with our recruitment process.
We are committed to equal employment opportunities regardless of race, color, genetic information, creed, religion, sex, sexual orientation, gender identity, lawful alien status, national origin, age, marital status, or protected veteran status. We support an inclusive workplace where associates excel based on personal merit, qualification, experience, ability, and job performance.
In support of the Equal Pay for Equal Work Act, the range of starting pay for this role is $90,000 - $103,000. This is not a guarantee of compensation or salary, actual compensation is influenced by a wide range of factors including but not limited to skill set, level of experience, education, certifications, responsibility, and geographic location. We also offer a variety of benefits including health, disability insurance, 401 (k), flexible spending accounts, EAP, education reimbursement, parental leave, unlimited vacation, bonuses, incentive stock options and company paid holidays. The specific programs and options available will vary depending on state, start date, and employment type. Our recruitment team will be happy to answer any questions you may have.
#LI-Remote",glassdoor
177,"Milo's Tea Company
4.1
Data Engineer
Remote

 Overview: Milo’s Tea Company is one of the fastest growing beverage companies in the US. Our culture and operations are built on the belief that we can make a difference in the world. That’s why we put People First and strive to continually reduce our environmental impact on the planet. We leverage our world class operations and decades-long distribution partnerships to grow the footprint of our core products and create new, innovative beverage products.
We are the #1 and fastest growing brand in the Refrigerated Tea Category in the nation.
Our core mission is that we put people and the planet first and by doing this, it will be good for our business.
We are committed to unlocking the personal genius of every associate and have a strong focus on growth and learning.
Our Company is women-led (our Executive Team is 57% female) and strongly committed to Diversity, Inclusion and Belonging.
We are committed to annual charitable giving by delivering upon our 1% profit pledge.
We are Platinum Certified in Zero Waste Manufacturing; recycling, reducing, and reusing 95% of waste at all facilities.
Being a part of the Milo’s TEAm, you’ll get to collaborate with a group of passionate and high-performing people, where everyone feels empowered to do their best work and feels good about the work they’re doing.
And as a ""People First"" company, Milo’s is committed to the success and well-being of our associates, customers, and fans, no matter their gender, race or creed. Some of the benefits offered that reflect our commitment include:
Competitive salary with bonus opportunities
100% paid medical insurance for our associates and their families
401K with a company match
Partial tuition reimbursement assistance
A robust parental leave program
Paid time off to volunteer at the charity of your choice
Employee assistance program
Responsibilities: The Data Engineer is responsible for assisting with data management, modeling, development, transformation, and reporting activities.
*
Responsibilities: *
Identify business needs, determine possible solutions, and develop solutions that include systems components, and process improvements with data driven decision making.
Work with business groups to design and develop reporting and analytics solutions that will improve efficiency and effectiveness.
Designs, implements, tests, troubleshoots, documents, and supports data models, programs, scripts, and ETL (Extract, Transform, and Load) processes.
Develop, maintain, and curate large datasets from multiple platforms. Develop reporting capabilities to support business needs by creating and supporting SQL queries, data extraction packages, and interfaces. Explores ways to enhance data quality and reliability.
Perform data validation between analytical and source systems to support ongoing data management capabilities and data governance. Perform data testing to ensure the accuracy of data transformation.
Develop data analytics, reports, and dashboards using Power BI and other business intelligence tools.
Uphold and participate in all Corporate Responsibility programming including recycling, social advocacy and MMAD volunteering opportunities.
Invest in and is an example of Milo’s Responsibility commitment which includes environmental, social, and corporate governance components.
Other duties as assigned
Supervisory: This role does not have supervisory responsibilities.
Qualifications:
BA in computer science, information systems, statistics, applied math, or any other related field.
Up to 3 years of experience in information systems or related field.
Strong experience with SQL server solutions (queries, functions, stored procedures, views, etc.).
Cloud based computing and data solutions.
Proficient with Excel and Business Intelligence tools (Power BI, Power Query, Tableau, etc.).
Understanding of relational databases and data warehouses. Hands-on experience with SQL database design.
Experience with Microsoft SQL stack (SSIS, SSRS, SSAS, etc); Experience with cloud-based data technologies, Azure preferred.
Experience working in a SharePoint environment; Experience with Python, R or other programming languages.
Experience in non-traditional SQL (noSQL, etc.) solutions.
Experience with machine learning and predictive analytics.
Experience with other ETL tools such as Alteryx.
Job Type: Full-time",glassdoor
178,"Cigna
3.8
BI Data Engineer-Work from home-eviCore
Hartford, CT
Employer Provided Salary:$96K - $160K

 Duties
Build ETL processes to allow data to flow seamlessly from source to target using tools like Databricks, Azure Data Factory, SSIS, SQL Stored Procedures and Powershell scripting
Load and enhance dimensional data models
Leverage code to apply business rules to ensure data is clean and is interpreted correctly by all business stakeholders, using tools like Databricks, SQL, Scala and Python
Perform code reviews and QA
Participate in sprint ceremonies
Provide on-call support to offshore operations team
Train operations teams on the ETL processes being developed
Troubleshoot and address issues with the data and/or the ETL process
Fine tune existing code to make processes more efficient
Maintain and create documentation to describe our data management processes
Analyze reports using various tools like Micro Strategy, Tableau and SSRS
Support user questions on data management processes and results

Minimum Required Skills
5+ Years building Big Data and Data Warehousing solutions
Knowledge of data modeling (including dimensional modeling), data architecture & data governance concepts
Experience in working with implementations of Azure cloud data solutions (ADLS, Data Bricks, Synapse, ADF)
Proficient in database concepts and technologies including MS SQ Server, DB2 and Oracle
Excellent written and oral communications skills
Must be able to effectively communicate complex technical topics to a variety of audiences
Experience with Healthcare data is a plus

Minimum Education, Licensure and Professional Certification requirement:
Bachelor’s degree with relevant experience required.
Master’s Degree is a plus.

If you will be working at home occasionally or permanently, the internet connection must be obtained through a cable broadband or fiber optic internet service provider with speeds of at least 10Mbps download/5Mbps upload.

For this position, we anticipate offering an annual salary of 95,900 - 159,800 USD / yearly, depending on relevant factors, including experience and geographic location.

This role is also anticipated to be eligible to participate in an annual bonus plan.

We want you to be healthy, balanced, and feel secure. That’s why you’ll enjoy a comprehensive range of benefits, with a focus on supporting your whole health. Starting on day one of your employment, you’ll be offered several health-related benefits including medical, vision, dental, and well-being and behavioral health programs. We also offer 401(k) with company match, company paid life insurance, tuition reimbursement, a minimum of 18 days of paid time off per year and paid holidays. For more details on our employee benefits programs, visit Life at Cigna .

About Cigna
Cigna Corporation exists to improve lives. We are a global health service company dedicated to improving the health, well-being and peace of mind of those we serve. Together, with colleagues around the world, we aspire to transform health services, making them more affordable and accessible to millions. Through our unmatched expertise, bold action, fresh ideas and an unwavering commitment to patient-centered care, we are a force of health services innovation. When you work with us, or one of our subsidiaries, you’ll enjoy meaningful career experiences that enrich people’s lives. What difference will you make?

Qualified applicants will be considered without regard to race, color, age, disability, sex, childbirth (including pregnancy) or related medical conditions including but not limited to lactation, sexual orientation, gender identity or expression, veteran or military status, religion, national origin, ancestry, marital or familial status, genetic information, status with regard to public assistance, citizenship status or any other characteristic protected by applicable equal employment opportunity laws.

If you require reasonable accommodation in completing the online application process, please email: SeeYourself@cigna.com for support. Do not email SeeYourself@cigna.com for an update on your application or to provide your resume as you will not receive a response.

Cigna has a tobacco-free policy and reserves the right not to hire tobacco/nicotine users in states where that is legally permissible. Candidates in such states who use tobacco/nicotine will not be considered for employment unless they enter a qualifying smoking cessation program prior to the start of their employment. These states include: Alabama, Alaska, Arizona, Arkansas, Delaware, Florida, Georgia, Hawaii, Idaho, Iowa, Kansas, Maryland, Massachusetts, Michigan, Nebraska, Ohio, Pennsylvania, Texas, Utah, Vermont, and Washington State.",glassdoor
179,"Netflix
4.3
Data Engineer (L5) - Games
Los Gatos, CA
$108K - $193K (Glassdoor est.)

 Los Gatos, California
Data Science and Engineering
Now is an amazing time to join Netflix as we seek to entertain the world. We have over 200 million paid members in over 190 countries, and we won’t stop there. Games are our next big frontier and an incredible opportunity for us to deliver new experiences to delight and entertain our quickly growing membership. You will be jumping in at the very beginning of this adventure and be in a position to help us redefine what a Netflix subscription means for our members around the world.
Data Science and Engineering (‘DSE’) at Netflix is aimed at using data, analytics, and sciences to improve various aspects of our business. We are looking for a Data Engineer to join our Games DSE team, supporting end-to-end analytics & data needs for our games portfolio. This role will be partnering closely with our Game stakeholders to develop software and data solutions that enable analysis across the entire library of games.
As part of this team, you will work on diverse data technologies such as Spark, Presto, Flink, Kafka, and others to build insightful, scalable, and robust data pipelines that feed directly into our key gaming dashboards; write ETL jobs to collect and aggregate data; and build high-quality data models that represent how games are performing on Netflix.
The ideal candidate will also have a background in games, with a solid knowledge of how standard industry metrics are computed.
Who You Are:
7+ years of software/data engineering experience working with video game analytics (i.e you are familiar with how key metrics such as DAU, MAU and retention rates are computed in an ETL).
Passionate about building intuitive data models and an expert in distributed data processing patterns.
Highly proficient in at least one of these programming languages: Java, Python, or Scala.
Comfortable with complex SQL.
Expert in engineering data pipelines using big data technologies (Hive, Presto, Spark, Flink) on large-scale data sets demonstrated through years of experience.
Conceptually familiar with AWS cloud resources (S3, EC2, RDS etc).
Excel at taking vague requirements and crystallizing them into scalable data solutions.
Excited about operating independently, demonstrating excellence, and learning new technologies and frameworks.
What will you do?
Engineer efficient, adaptable, and scalable data pipelines in Spark and Python/Scala to process structured data into aggregate datasets that feed all games portfolio dashboards.
Become an expert in games metrics at Netflix - act as a thought partner to the games analytics team, understand their challenges, and help them to put the right data in front of our stakeholders.
Maintain and rethink existing datasets and pipelines to service a wider variety of use cases.
Join a stunning team of data engineers with diverse skill sets, partnering closely with analytics engineering and data science counterparts.
Netflix Culture
Our culture is unique, and we live by our values. For more information on what it's like to work at Netflix, please take a look at our culture memo.",glassdoor
180,"Teknic
Data Engineer
Remote

 Role: Data Engineer
Location: Remote
JOb Description:
Skills and Experience :
Good experience on designing and developing data pipelines for data ingestion and transformation using Spark.
Distributed computing experience using Pyspark.
Good understanding of spark framework and spark architecture.
Experience working in Cloud based big data infrastructure.
Excellent in trouble shooting the performance and data skew issues.
Must have a good understanding of spark run time metrics and tune applications based on metrics.
Deep knowledge in partitioning, bucketing concepts of data ingestion.
Good understanding of AWS services like Glue, Athena, S3, Lambda, Cloud formation.
Preferred working knowledge on the implementation of datalake ETL using AWS glue, Databricks etc.
Experience with data modelling techniques for cloud data stores and on prem databases like Teradata, Teradata Vantage (TDV) etc.
Preferred working experience in ETL development in Teradata vantage and data migration from on prem to Teradata vantage.
Proficiency in SQL, relational and non-relational databases, query optimization and data modelling.
Experience with source code control systems like Gitlab.
Experience with large scale distributed relational and NoSQL database systems.
Job Type: Contract
Schedule:
8 hour shift
Experience:
Data engineer: 10 years (Preferred)
Spark.: 3 years (Preferred)
Cloud based big data infrastructure.: 1 year (Preferred)
datalake ETL: 1 year (Preferred)
AWS Glue: 1 year (Preferred)
Work Location: Remote",glassdoor
181,"Pinterest
4.1
Data Engineer
Remote

 About Pinterest:
Millions of people across the world come to Pinterest to find new ideas every day. It's where they get inspiration, dream about new possibilities and plan for what matters most. Our mission is to help those people find their inspiration and create a life they love. In your role, you'll be challenged to take on work that upholds this mission and pushes Pinterest forward. You'll grow as a person and leader in your field, all the while helping Pinners make their lives better in the positive corner of the internet.
Our new progressive work model is called PinFlex, a term that's uniquely Pinterest to describe our flexible approach to living and working. Visit our PinFlex landing page to learn more.
The Enterprise Data Platform team is looking for a Data Engineer who has experience with Building Data Pipelines and Managing/Developing on any Cloud Data Warehouse. In this role you will also advise other Data Analysts and Data Engineers from the Business teams at Pinterest on the best practices for handling data and deriving insights using Snowflake. You will gradually become the Subject Matter Expert on Snowflake and also help build out the Modern Data Stack at Pinterest.
What you'll do:
Build Data Pipelines using Python on either Airflow or AWS Lambda to ingest data into Snowflake
Build Scripts in Python to manage Data Access on Snowflake
Define and advocate the best practices for storing and analyzing data inside Snowflake
Review the Data Modeling practices of other teams
What we're looking for:
Strong skills in Python and SQL
Experience with Building Data Pipelines in Python
Experience with any Cloud Data Warehouse either as an Administrator or a Developer
Strong Data Modeling skills
#LI-BB1
#LI-Remote
Our Commitment to Diversity:
At Pinterest, our mission is to bring everyone the inspiration to create a life they love—and that includes our employees. We’re taking on the most exciting challenges of our working lives, and we succeed with a team that represents an inclusive and diverse set of identities and backgrounds.

Not Specified
0",glassdoor
182,"Luxoft
4.3
Data Engineer
Remote

 Project Description
Luxoft has contract with a major Telecommunications provider to engage with DIRECTV organization to establish integrated cloud technology platforms to ingest information from various Network Engineering support applications in order to better optimize management and planning for the future network.

To do this DIRECTV is managing data ingestion into a Snowflake Azure based deployment which allows for one cohesive platform to serve all types of users and workloads in a consistent way. Centralizing data in a unified, governed, managed data platform allows all authorized users to access accurate and timely data for analysis that is useful for highly transnational datasets. It is also useful that it can store structured and unstructured data. Additionally DIRECTV is leveraging a Palantir Deep™ instance platform for the creation and management of cost forecasting scenarios.
Responsibilities
- Analysis on Data Libraries - evaluation of data sets and current data architecture for source data pipelines. This will allow us to scope the depth/breadth of data

- Data Quality Metrics - Audits analysis and setup to determine the appropriate data quality measures. This will be used to validate with clients/users in a later phase.

- DQF research - Analyze the current Data Quality Framework to leverage as possible/needed. Assess the need for extension and/or replacement of the current DQF.

- Architecture patterns research - Analysis of data translation and business rules associated.

- Current ingestion patterns - Study and enhancement research to evaluate data pipeline for current state and opportunity to optimize for increased data quality and rigor.
Skills
Must have
Cloud, Data Engineering, SnowFlake, Big Data
Nice to have
Microsoft Azure Cloud Platform
Languages
English: C2 Proficient
Seniority
Senior
Relocation package
If needed, we can help you with relocation process.
Vacancy Specialization
BigData Development
Ref Number
VR-81593",glassdoor
183,"Pepsico
3.9
Junior Data Engineer
Remote
Employer Provided Salary:$90K - $100K

 Compensation: $80k - $90k
Benefits: Medical, Dental, Vision, 401k match and Arc
This role can be performed remote in any of our headquarter locations including Plano, Texas; Purchase, New York; Chicago, Illinois.
What PepsiCo Data Management and Operations does:
Maintain a predictable, transparent, global operating rhythm that ensures always-on access to high-quality data for stakeholders across the company
Responsible for day-to-day data collection, transportation, maintenance/curation and access to the PepsiCo corporate data asset
Work cross-functionally across the enterprise to centralize data and standardize it for use by business, data science or other stakeholders
Increase awareness about available data and democratize access to it across the company.
As a member of the data engineering team, you will be the key technical expert developing and overseeing PepsiCo's data product build & operations and drive a strong vision for how data engineering can proactively create a positive impact on the business. You'll be an empowered member of a team of data engineers who build data pipelines into various source systems, rest data on the PepsiCo Data Lake, and enable exploration and access for analytics, visualization, machine learning, and product development efforts across the company. As a member of the data engineering team, you will help lead the development of very large and complex data applications into public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. You will work closely with process owners, product owners and business users. You'll be working in a hybrid environment with in-house, on-premise data sources as well as cloud and remote systems.
Key Accountabilities:
Active contributor to code development in projects and services
Manage and scale data pipelines from internal and external data sources to support new product launches and drive data quality across data products
Build and own the automation and monitoring frameworks that capture metrics and operational KPIs for data pipeline quality and performance
Responsible for implementing best practices around systems integration, security, performance and data management
Empower the business by creating value through the increased adoption of data, data science and business intelligence landscape
Collaborate with internal clients (data science and product teams) to drive solutioning and POC discussions.
Develop and optimize procedures to “productionalize” data science models
Define and manage SLA’s for data products and processes running in production
Support large-scale experimentation done by data scientists
Prototype new approaches and build solutions at scale
Research in state-of-the-art methodologies
Create documentation for learnings and knowledge transfer
Create and audit reusable packages or libraries
COVID-19 vaccination is a condition of employment for this role. Please note that all such company vaccine requirements provide the opportunity to request an approved accommodation or exemption under applicable law
Qualifications / Requirements :
BA/BS in Computer Science, Math, Physics is mandatory.
2+ years of overall technology experience that includes hands-on building data engineering pipelines
2+ years of experience in SQL optimization and performance tuning, and development experience in programming languages like Python, PySpark, Scala etc.)
1+ years in cloud data engineering experience in Azure or AWS
1+ Years in building data engineering pipelines in Azure (ADF and databricks)
Job Type: Full-time
Pay: $90,000.00 - $100,000.00 per year
Benefits:
401(k) matching
Dental insurance
Health insurance
Retirement plan
Vision insurance
Schedule:
8 hour shift
Education:
Bachelor's (Required)
Experience:
SQL: 2 years (Required)
Cloud: 2 years (Required)
Work Location: Remote",glassdoor
184,"Apple
4.2
Data Engineer
Cupertino, CA

 Summary
Posted: Aug 10, 2022
Weekly Hours: 40
Role Number:200406892
Are you a big-picture thinker who loves setting ambitious goals? Do you have a passion for understanding how each line of code affects all the others? In the Core Operating Systems group, you’ll ensure the OS is inseparable from each device’s identity as a whole. That’s because this group is committed to building fully integrated operating systems that combine hardware, software, and apps into a single Apple experience. Your dedication to cross-disciplinary collaboration will help develop groundbreaking technologies, such as iOS, macOS, watchOS, and tvOS. By crafting these distinct, holistic user experiences, you’ll continue to uphold and advance the excellence people expect from Apple devices. The Platform Services & Operations team in Core OS is looking for a Data Engineer to inform and develop essential workflow tooling at scale. The Workflow Engineering team enable teams to deliver high quality software through best in class engineering experiences, efficient workflow, data driven insights, and a culture of continuous improvement. Your focus is building the backend data pipelines that enables visualization of data across the organization in user intuitive and configurable formats.
Key Qualifications
3 +proven experience in a Data focused posistion
Proficient in Python; data access and retrieval. Quantitative data preparation. Regular expressions and text analysis
Highly Proficient in Database Language and Design; querying large stores of data (APIs, SQL, etc.).
Access, retrieval, and storage of information. Data Structures, modeling for speed and efficiency
Software Development; understanding of build pipelines, branching and merging, Agile methods, and the delivery of code. Fluency in Git (or comparable source control tool)
Description
- Replicate data from source system into data warehouse; retrieve data through various protocols and land it in a central store - Automate data pipelines; write programs to periodically update warehouse data from source systems - Design for scale; flexible infrastructure for common enhancements including: expanding the volume of captured data, adding fields to the user-facing views, and recompiling archived data - Work with a team of data scientists and full stack engineers, to derive and develop targeted insights through centrally managed interactive dashboards
Education & Experience
B.S. in Data Science, Computer Science, or equivalent experience.
Additional Requirements
Experience as an Analyst; worked in the delivery of visual information (dashboards, reports, web-apps)
An understanding of how data can be used and applied in context (what is useful to capture and how it can be communicated)
Full Stack Development; ability to maintain back-end systems and visualize front-end data for users (with a web-kit framework like Angular, React)
Experience with Snowflake and/or other data store technologies",glassdoor
185,"Twitch
4.0
Data Engineer
San Francisco, CA
Employer Provided Salary:$140K - $171K

 About Us
Twitch is the world's biggest live streaming service, with global communities built around gaming, entertainment, music, sports, cooking, and more. It's where millions of people come together to chat, interact, and make their own entertainment.
We're about community, inside and out. You'll find coworkers who are eager to team up, collaborate, and smash (or elegantly solve) problems together. We're on a quest to empower live communities, so if this sounds good to you, see what we're up to on LinkedIn and Twitter, get interviewing tips on Instagram, and discover projects we're solving on our Blog.
About the Role
Reporting to the Head of Global Talent Acquisition, the Data Engineer will expand the reach and role of data among leaders and managers at Twitch. You will empower the business to integrate data into their daily workflow by creating/maintaining data pipelines, producing reporting, and automating our processes.
You can work in San Francisco, CA or remotely across the US.
This role is for you if:
You love automating processes and developing efficient scalable solutions
You're excited about contributing to the success, efficiency, and happiness of Twitch staff
You're excited to jump into a diverse array of data work to support the team
You enjoy working with autonomy and shaping a new function

You Will:
Delight consumers of people-related data by ensuring they have the data they need to inform decisions, where and when they need it
Build and own data pipelines, SQL queries/views, and apps
Automate processes through the use of JavaScript and other languages
Improve business, engineering, and data processes through data architecture, engineering, testing, and operational excellence best practices
Ensure the integrity of People and Places data in analyses and tools through regular audits
Partner to develop analytics products and recommend opportunities
Develop ongoing metrics, analyses, and dashboards to guide important decisions
You Have:
Experience writing SQL and a procedural language (Python, R, etc.) for data handling
Experience owning systems that collect, transform, and visualize data
Experience implementing data analytics, visualization tools and programs for HR working with Workday, Greenhouse, Tableau, Google Workspace, Google Data Studio, and Google Sheets
Experience implementing software solutions to automate data source, visualization and analytics products
Bachelors in related field, or equivalent experience
Bonus Points
Experience handling People-related data including compensation, performance, hiring, and engagement data.
Experience automating Google services (Sheets, Docs, Data Studio) with Javascript
Experience with Workday, Greenhouse, and Tableau
Demonstrated net positive contributor to company community and culture above and beyond the core job
Perks
Medical, Dental, Vision & Disability Insurance
401(k), Maternity & Parental Leave
Flexible PTO
Commuter Benefits
Amazon Employee Discount
Monthly Contribution & Discounts for Wellness Related Activities & Programs (e.g., gym memberships, off-site massages, etc.),
Breakfast, Lunch & Dinner Served Daily
Free Snacks & Beverages
We are an equal opportunity employer and value diversity at Twitch. We do not discriminate on the basis of race, religion, color, national origin, gender, gender identity, sexual orientation, age, marital status, veteran status, or disability status, or other legally protected status.
Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
Pursuant to the Los Angeles Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
The base pay range for this position in Colorado, Connecticut and Washington is $139,860 - $170,940 yr and in New York City is $153,900 - $188,100 yr. Pay is based on market location and may vary depending on job-related knowledge, skills, and experience. A sign-on payment and restricted stock units may be provided as part of the compensation package, in addition to a full range of medical, financial, and/or other benefits, dependent on the position offered. Applicants should apply via Twitch's internal or external careers site.
Workers in New York City who perform in-person work or interact with the public in the course of business must show proof they have been fully vaccinated against COVID or request and receive approval for a reasonable accommodation, including medical or religious accommodation.
Twitch values your privacy. Please consult our Candidate Privacy Notice, for information about how we collect, use, and disclose personal information of our candidates.
Job ID: TW7236
#LI-Remote #RemoteFriendly",glassdoor
186,"Realign LLC
4.5
Data Engineer
California

 Job Type: Contract
Job Category: IT
Job Description
Write and optimize queries, provide input on peer code reviews and data modeling, deploy data
updates via continuous integration / deployment (CI/CD) practices.

Collaborate with software developers, other data engineers, and database architects on projects to
ensure optimal data delivery following appropriate change management guidelines.

Collaborate with software and reliability engineers to automate repeatable data tasks.

Work with development and production support teams to troubleshoot data, application, and service
deployment issues.

Develop detailed, shared technical procedure documentation, including processes for contingency
operations.

Research, provide technical input, document, and implement new technology solutions.

Implement necessary patches, hotfixes, service packs, cumulative updates, upgrades, and
configuration change to maintain security compliance and application integrity.

Required Skills
Big Data Engineer",glassdoor
187,"Blue Cross and Blue Shield of North Carolina
4.1
Data Engineer
Remote

 Additional Locations:
Full Time Remote - Alabama, Full Time Remote - Alabama, Full Time Remote - Arizona, Full Time Remote - Arkansas, Full Time Remote - Florida, Full Time Remote - Georgia, Full Time Remote - Idaho, Full Time Remote - Indiana, Full Time Remote - Iowa, Full Time Remote - Kansas, Full Time Remote - Kentucky, Full Time Remote - Louisiana, Full Time Remote - Maryland, Full Time Remote - Michigan, Full Time Remote - Mississippi, Full Time Remote - Missouri, Full Time Remote - Ohio, Full Time Remote - Oklahoma, Full Time Remote - Pennsylvania, Full Time Remote - South Carolina, Full Time Remote - South Dakota, Full Time Remote - Tennessee, Full Time Remote - Texas, Full Time Remote - Utah, Full Time Remote - Virginia {+ 1 more}
Job Description
IT is different here. Our work as technology specialists pushes the boundaries of what’s possible in health care. You will build solutions that make a real difference in people’s lives. Driven by the importance of their work, our team members innovate to elevate. We’re encouraged to be curious, collaborate, and turn ideas into solutions that transform this space.

In this role you will work closely with senior engineers, data scientists and other stakeholders to design and maintain moderate to advanced data models. The Data Engineer is responsible for developing and supporting advanced reports that provide accurate and timely data for internal and external clients. The Data Engineer will design and grow a data infrastructure that powers our ability to make timely and data-driven decisions. You will support Membership Operations, Customer Service Operations, Digital & Consumer Experience teams.

If you are ready to make a career out of making a difference, then you are the person for this team.
What You’ll Do
Define and extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes
Document, and test moderate data systems that bring together data from disparate sources, making it available to data scientists, and other users using scripting and/or programming languages
Write and refine code to ensure performance and reliability of data extraction and processing
Participate in requirements gathering sessions with business and technical staff to distill technical requirement from business requests
Develop SQL queries to extract data for analysis and model construction
Own delivery of moderately sized data engineering projects
Design and develop scalable, efficient data pipeline processes to handle data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets to analysts and data scientists
Ensure performance and reliability of data processes
Document and test data processes including performance of through data validation and verification
Collaborate with cross functional team to resolve data quality and operational issues and ensure timely delivery of products
Develop and implement scripts for database and data process maintenance, monitoring, and performance tuning
Analyze and evaluate databases in order to identify and recommend improvements and optimization
Design eye-catching visualizations to convey information to users
What You Will Bring
Bachelor’s degree and 3 years of experience with Oracle, Data Warehouses and Data Lakes, Big Data platforms and programming in Python, R or other related language.
In lieu of degree, 5 years of the experience as stated above.
SQL and Python scripting
Experience in a cloud environment
Experience with Ab Initio or other ETL tools",glassdoor
188,"Qualtrics
4.2
Data Engineer
Provo, UT
$83K - $125K (Glassdoor est.)

 The Qualtrics XM Platform™ is a system of action that helps businesses to attract customers who stay longer and buy more, to engage and empower employees to do the best work of their lives, to develop breakthrough products people love, and to build a brand people can’t imagine living without.

Joining Qualtrics means becoming part of a team bold enough to chase breakthrough experiences - like building a technology that will be a force for good. A team committed to diversity, equity, and inclusion because of a conviction that every voice holds value, with a vision for representation that matches the world around us and inclusion that far exceeds it. You could belong to a team whose values center on transparency, being all in, having customer obsession, acting as one team, and operating with scrappiness. All so you can do the best work of your career.

We believe every interaction is an opportunity. Are we yours?
The Team
Our team is a collection of deeply passionate engineers who are riding the groundbreaking of cloud computing and web scalability. We built data analytics applications that help company leaders gain insights about technology spends, make sound decision on technology investments, and drive innovation in resource utilization and efficiency optimizations. Our environment is primarily TypeScript, Node.js, React, MySQL NoSQL, AWS, Python, PHP, and Docker. In our collaborative culture, you find plenty of opportunities to impact our full-stack products; from Web & mobile UI to data visualization & analysis to data ingestion, storage and processing.
Job Responsibilities
Developing scalable, fast, robust, and simple web-based solutions to solve complex business problems
Close collaboration with your team to collect and incorporate feedback into your feature design
Drive operational excellence by investigating production issues, driving root cause analysis and follow-up actions for mitigation
Improve performance, availability, reliability, scale, throughput and latency
Work with your team in order to meet customer work you're doing, understand the decisions that are being made and make your voice heard.
Qualifications
Bachelor's degree in Computer Science or related field
Coding experience with any programming language (Prefer experience in TypeScript/JavaScript/React/Python)
Experience with web infrastructure and distributed systems
Experience with software engineering best practices (e.g. unit testing, code reviews, design, continuous delivery, git, test automation and build\deploy systems)
Ability to work in a fast-paced and agile development environment and to learn new frameworks/stacks
Passionate about building products that help customers easily and effectively get their job done
Enthusiastic person, who communicates effectively and is easy to work with
Curious and constantly learning on your own and from others
You get satisfaction from helping others succeed, and you constantly seek ways to improve
You can identify gaps, propose solutions to important problems, then take it to resolution
Preferred Qualifications
Shown ability to troubleshoot and identify the root cause of issues
Demonstrated skill and passion for operational excellence
Experience in a 24/7 production environment is a plus
Ability to retain composure under stressful conditions, communicate effectively with wide array of individuals at Qualtrics, and get the right things done
Confirmed ability to understand large systems, drilling down to code level",glassdoor
189,"Adobe
4.4
Software Development Engineer - Data Science & Analytics
Lehi, UT
$108K - $155K (Glassdoor est.)

 Our Company

Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.

We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!

Our Company
Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands— everything they need to design and deliver exceptional digital experiences. We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.

We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours.
The Opportunity
Adobe is seeking hardworking and passionate Cloud Software Engineer to plan, design, and develop internal analytical tools, dashboards and reporting to help Engineers to Executives make data driven decisions.

We’re on a mission to hire the very best and are committed to building exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!
What You’ll Do
Develop high-performance, reliable, testable and maintainable code.
Participating in all aspects of software development activities, including design, coding, code review, testing, bug fixing, and code/API documentation.
Collaborate with engineers and participate in daily or weekly stand ups and meetings.
Develop reporting dashboards and analytical tools to help Adobe teams manage their AWS & Azure Cloud resources.
Build and automate data sets to answer key business questions using data and data visualizations.
Grow with the support of your team and help others on the team grow by providing thoughtful feedback and uplifting those around you.
Work both independently and collaboratively within a fast-paced development team, with clear, positive, and constructive communication.
What You Need to Succeed
Bachelor's or Master’s in Computer Science, Information Systems, Data Science or equivalent experience required.
Proficient in programming languages such as JavaScript, Python & SQL.
Strong technical background with analytical and problem-solving skills.
Strong proficiency with Business Analytics tools like Power BI & Tableau.
Extensive experience with cloud hosting technology, including Azure and AWS infrastructure.
Experience developing web applications using ReactJS is helpful.
Excellent problem solving and debugging skills, and direct experience with DevOps in a public cloud environment.
Passion for quality and engineering excellence at scale, attention to details, and ability to multitask and meet deadlines.
Excellent communication and collaboration skills.

If you’re looking to make an impact, Adobe’s the place for you. Discover what our employees are saying about their career experiences on the Adobe Life blog and explore the meaningful benefits we offer.
Adobe is an equal opportunity employer. We welcome and encourage diversity in the workplace regardless of race, gender, sexual orientation, gender identity, disability or veteran status.",glassdoor
190,"Antra, Inc
4.5
Jr. Data Engineer
Sterling, VA
Employer Provided Salary:$60K - $68K

 Antra started its services in the year 2008, since then we have been diligently serving every need of our clients professional and software solutions. With our unique amalgam of innovation and inspiration, backed by Agile processes, we deliver world-class services with our core values to our clients. We identify unique strategies to transforming organizations through picking their sweet spot for innovative thinking and helping them in implementing in-depth cultural shift; ultimately augmenting the innovation process to the next level – fostering the innovation race that never ends.
This role requires the design, development and implementation of data solutions to business problems. An Azure Data Engineer will be expected to perform duties such as: evaluating the performance of current data solutions, designing and implementing cloud and hybrid data solutions. Ability to adapt and learn new technologies per business requirements is also needed.
Responsibilities:
Design and implement data solutions using industry best practices.
Performs ETL, ELT operations and administration of data and systems securely and in accordance with enterprise data governance standards.
Monitor and maintain data pipelines proactively to ensure high service availability.
Works with Data Scientists and ML Engineers to understand mathematical models and optimize data solutions accordingly.
Continuous development through training and mentorship programs.
Create scripts and programs to automate data operations.
You meet our “must haves” for this role if you have:
Minimum Bachelor’s degree in Data Science, Business Intelligence, Computer Science or related fields, or the equivalent combination of education, professional training, and work experience.
0-3 years of experience working with one or more languages commonly used for data operations including SQL, Python, Scala and R.
Experience working with relational databases such as SQL Server, Oracle and MySQL.
Experience working with NoSQL databases such as Redis, Mongo DB, Cosmos DB.
Excellent problem-solving skills and ability to learn through scattered resources.
Thorough understanding of the responsibilities and duties of a data engineer, as well as established industry standards/best practices and documentation guidelines.
Outstanding communication skills, and the ability to stay self-motivated and work with little or no supervision.
Willing to relocate to any US location on Antra projects location.
Authorization(s) to work lawfully in the United States (OPT/CPT is acceptable).
Plus, if you meet any the of requirements:
Experience with cloud-based data technologies.
Experience with distributed systems utilizing tools such as Apache Hadoop, Spark or Kafka.
Working experience in Agile Scrum environments.
Experience with source control tools such as Git, SVN and TFS.
The intent of this position description is to provide a representative summary of the major duties and responsibilities performed by incumbent(s) in this position. Incumbent(s) may not be required to perform all duties in this description and incumbent(s) may be required to perform position-related tasks other than those specifically listed in this description.
Antra Inc. is an equal opportunity employer, providing equal employment opportunities (EEO). All employees and applicants for employment will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity or expression, pregnancy, protected veteran status or other status protected by law. This policy applies to all terms and conditions of employment.
Job Types: Full-time, Contract
Pay: $60,000.00 - $68,000.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Health savings account
Life insurance
Paid time off
Professional development assistance
Referral program
Relocation assistance
Vision insurance
Schedule:
Monday to Friday
Application Question(s):
Are you open for relocation within the US?
Education:
Bachelor's (Preferred)
Work Location: Hybrid remote in Sterling, VA 20166",glassdoor
191,"Vimeo
4.1
Data Engineer II, Analytics
New York, NY
$107K - $150K (Glassdoor est.)

 Vimeo is looking for an experienced Data Engineer II, Analytics to join our Data Architecture and Analytics Engineering team and work closely with Data Analysts and Data Scientists to create and maintain robust, scalable, and sustainable data models that provide decision-making insights for senior leadership including executives. The ideal candidate is a self-starter with a bias for action and results, with experience in a fast-paced, data-driven environment.
What you'll do:
Build data models that can support dynamic and efficient data analysis, and collaborate with other teams to maintain and evolve those models over time
Ensure alignment to coding standard methodologies and development of reusable code
Partner with Data Analysts to understand business processes and identify opportunities to build scalable and efficient data models that can be used for scalable, refreshable analysis and reporting
Create and enable the generation of ad-hoc / on-demand data sets for use by analysts and data scientists
Work with Engineering teams to set up monitoring and alerting systems for business and product KPIs
Skills and knowledge you should possess:
BS/MS in Computer Science or a related technical field.
2+ years working with Analytics and Data Engineering teams with a mixed data engineering and analytics background
2+ years of experience in scalable data architecture, fault-tolerant ETL, and monitoring of data quality in the cloud
Experience working on or leading initiatives around data governance, master data management, data catalogs, and enterprise data warehouse architecture
Strong analytical skills, data sensibility, and an able communicator
Open to working on multiple projects simultaneously
Proficiency in:
SQL
Python
Dimensional Modeling
Data pipeline development, workflow management, and orchestration tools
ETL optimization and best practices
Snowflake or other column-oriented and cloud-based databases
Looker or any similar Business Intelligence tool
Relational Databases
Bonus Points (Nice Skills to Have, but Not Needed):
DBT
Git / Github
Looker/Tableau is a big plus
large data sets (terabyte scale)
Apache Airflow
#LI-JS1
Vimeo (NASDAQ: VMEO) is the world's leading all-in-one video software solution. Our platform enables any professional, team, and organization to unlock the power of video to create, collaborate and communicate. We proudly serve our growing community of over 260 million users — from creatives to entrepreneurs to the world's largest companies.
Vimeo is headquartered in New York City with offices around the world. At Vimeo, we believe our impact is greatest when our workforce of passionate, dedicated people, represents our diverse and global community. We're proud to be an equal opportunity employer where diversity, equity, and inclusion is championed in how we build our products, develop our leaders, and strengthen our culture.
Learn more at www.vimeo.com
Learn more at www.vimeo.com/jobs",glassdoor
192,"Accenture
4.1
Data Engineer
San Francisco, CA

 Accenture Flex offers you the flexibility of local fixed-duration project-based work powered by Accenture, a leading global professional services company. Accenture is consistently recognized on FORTUNE's 100 Best Companies to Work For and Diversity Inc's Top 50 Companies For Diversity lists.
As an Accenture Flex employee, you will apply your skills and experience to help drive business transformation for leading organizations and communities. In addition to delivering innovative solutions for Accenture's clients, you will work with a highly skilled, diverse network of people across Accenture businesses who are using the latest emerging technologies to address today's biggest business challenges.
You will receive competitive rewards and access to benefits programs and world-class learning resources. Accenture Flex employees work in their local metro area onsite at the project, significantly reducing and/or eliminating the demands to travel.
Job Description:
As a Data Engineer, you will:
Utilize strong SQL & Python expertise to engineer sound data pipelines and conduct routine and ad hoc analysis to assess the performance of legacy products and the saliency of new features
Build reporting dashboards and visualizations to design, create, and track campaign/program KPIs
Perform analyses on large data sets to understand drivers of marketing engagement and provide recommendations on campaign and product optimization

Basic Qualifications:
Minimum 2 years of experience in Data Engineering
Minimum 2 years of experience with SQL
Minimum 2 years of experience with Python
High School Diploma or GED
Preferred Qualifications:
Experience with Data Analytics
As required by Colorado Law under the Equal Pay for Equal Work Act, Accenture provides a reasonable range of compensation for roles that may be hired in Colorado. Actual compensation is influenced by a wide array of factors including but not limited to skill set, level of experience, and specific office location. For the state of Colorado only, the starting range of pay for this role is $86.82 - $96.82 per hour, and information on benefits is here.

COVID-19 update:

The safety and well-being of our candidates, our people and their families continues to be a top priority. Until travel restrictions change, interviews will continue to be conducted virtually.

Subject to applicable law, please be aware that Accenture requires all employees to be fully vaccinated as a condition of employment. Accenture will consider requests for accommodation to this vaccination requirement during the recruiting process.

What We Believe

We have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture has the responsibility to create and sustain an inclusive environment.

Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more here

Equal Employment Opportunity Statement

Accenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation.

All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.

Accenture is committed to providing veteran employment opportunities to our service men and women.

For details, view a copy of the Accenture Equal Opportunity and Affirmative Action Policy Statement.

Requesting An Accommodation

Accenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.

If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.

Other Employment Statements

Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States.

Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.

Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.

The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.",glassdoor
193,"Mastercard
4.3
Data Engineer - Launch 2023
Arlington, VA

 Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a
culture of inclusion
for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Job Title
Data Engineer - Launch 2023
The Mastercard Launch program is aimed at early career talent, to help you develop skills and gain cross-functional work experience. Over a period of 18 months, Launch participants will be assigned to a business unit, learn and develop skills, and gain valuable on the job experience.

Be part of the Data & Services Technology Team at Mastercard, Data and Services

Data Engineers are fundamental to the success of our client engagements by acting as the bridge between raw client data and Mastercard's software. Data Engineers work closely with both Consultants while working on consulting engagements and Software Development Engineers while working to develop internal capabilities. Data Engineers are responsible for:
Designing processes to extract, transform, and load (ETL) terabytes of data into Mastercard's analytics platform
Sourcing data from clients, government and other third party data sources, and Mastercard's transaction data warehouse
Working across multiple teams, both internal and external, in order to determine the data requirements and business logic applicable to each data set
Tackling big data problems across various industries

Make an Impact as a Data Engineer
Here are just a few of the benefits that you will get to experience during your first year as a Data Engineer:
Strategic problem solving with exceptional peers who are also passionate about data
Creative freedom to innovate with new technologies and to explore a variety of solutions
Staffing on external-facing consulting projects where you will have the opportunity to work directly with clients
Flexibility to work on many new and challenging projects across diverse industries
A dynamic environment where you will have an impact and make an immediate difference
An immediate opportunity for increased responsibility, leadership, and professional growth
Committed mentoring and training by an experienced and driven leadership team
Cross-functional collaboration with others throughout Mastercard
Bring your passion and expertise

We recruit for and value the following core competencies:
Currently enrolled student pursuing a Bachelor's or Master's degree studying Computer Science, Data Engineering, or a related field
Desire to work with data and help businesses make better data-driven decisions
Understanding of relational databases, SQL, and database management
Excellent written and verbal communication skills
Strong troubleshooting and problem-solving capabilities
Demonstrated analytical and quantitative skills
The role also involves these skills. We don't require them, but it's helpful if you already have them:
Hands-on experience with the ETL process and SSIS
Knowledge of at least one programming language
COVID-19 Considerations
In many locations, we’ve implemented a virtual hiring process and continue to interview candidates by video or phone. In addition, in our NYC offices, as required by law, only individuals who have been fully vaccinated against COVID-19 will be permitted inside Mastercard offices unless a reasonable accommodation has been approved in advance.
In the US, Mastercard is an inclusive Equal Employment Opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. If you require accommodations or assistance to complete the online application process, please contact reasonable_accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.
Corporate Security Responsibility
All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.",glassdoor
194,"NucleusTeq
4.9
Data Engineer
Remote

 Data Engineer
Role Info:
Hands on BI Data Engineer role with strong
Creating KPI Dashboards - Interactive Dashboards using tableau / Quicksight
Top Skills:
BI Tableau / AWS Quicksight exp is a must
AWS (IAM, RDS, S3, Lambda) exp is a must
SQL exp is a must
Python knowledge is required
Nice to have:
AWS Certified Solutions Architect
About the Company:
NucleusTeq is a software services, solutions & products company empowering & transforming customer's business through the use of digital technologies such as Big-Data, Analytics, Cloud, Enterprise Automation, Block-chain, Mobility, etc.
We are enabling several fortune 1000 clients in the USA, Canada, UK & India to navigate their digital transformation.",glassdoor
195,"Ceribell, Inc
4.1
Clinical Data Engineer
Sunnyvale, CA
$91K - $142K (Glassdoor est.)

 About Ceribell
Ceribell Inc. is a rapidly growing venture capital backed medical technology startup based in Sunnyvale, CA. Ceribell deploys a cloud-linked, portable electroencephalogram (EEG) device to assess brain waves in minutes to identify the occurrence of seizures in emergency rooms and intensive care units. The Ceribell system is comprised of a brain stethoscope that converts brain waves into sound, enabling nurses and doctors to quickly diagnose seizures in order to more quickly administer live saving therapies. Ceribell received the first ever FDA 510(k) clearance for a digital seizure detection algorithm, and is growing its customer base and revenue rapidly. You can find more information at www.ceribell.com.
Position Overview
We are looking for a talented Clinical Data Engineer who is passionate about biomedical applications and has a strong background in clinical data management plus data annotation. The successful candidate will join the data science team and will contribute to the design and development of new state-of-the-art classification algorithms that will take the field of EEG neurodiagnostics to the next level.
This is a hybrid position. You will need to come into the office at least 4x per week
What you'll do:
Work with the team to build a research data infrastructure, including dataset management and collaboration with physicians to obtain data annotations, and developing innovative strategies to leverage research data to serve the R&D goals of the broader institution.
Understand what data and processes are needed for data science projects and participate in data collection and analysis.
Contribute to design, development and assessment of innovative machine learning classification algorithms.
What you need to be successful:
BS in Biomedical Engineering, Neuroscience, Computer Science, or equivalent Disciplines
Experience and interest in biomedical applications, biological signal processing, and algorithm development
Proficient in Matlab and/or Python and/or SQL or similar programming languages
Strong communication and analytical skills, detail-oriented and collaborative
A sense of urgency for anticipating/solving problems, the ability to manage multiple priorities at the same time.
Has an eye for detecting discrepancies – mistakes are inevitable in data handling and algorithm development. Should have an eye to detect them as early as possible before they propagate to next steps
Familiarity with signal processing and machine learning.
What we offer:
90-100K Base +Bonus + Ceribell Equity
100% Employer paid Health Benefits for the Employee
Life & Long-term disability insurance paid 100% by Ceribell
Flexible paid time off
11 Paid Holidays
Maternity and Paternity Leave
Fantastic culture with tremendous career advancement opportunities
Job Type: Full-time",glassdoor
196,"National Research Group
3.7
Data Engineer
San Francisco, CA
$88K - $128K (Glassdoor est.)

 Who We Are
National Research Group (NRG) is a leader in data driven insights and strategic consultation to the global entertainment and technology industries. Working at the confluence of technology, content, and culture, NRG offers bold insights for storytellers everywhere. Our consultants have experience working across all facets of media and technology.
Why You'll Love It Here
We are inspired by working with storytellers that challenge us to think differently and see the world in new ways. As a result, our business is driven by creative, curious, and inventive people who have a passion for pop culture. We work as a collective across disciplines and geographies to bring together the best thinking for every assignment, delivering insights to bold storytellers everywhere.
The Opportunity
We are looking for a data engineer with a background in building and maintaining data pipelines to integrate and process diverse data sources and data formats. This candidate should have a minimum of 1-year experience for a full-time position within our fast paced and growing company.
If you feel that you can make an impact through innovation and collaboration and come to work with a passion to facilitate in delivering high quality data to our teams and clients, this is a great role for you.
The Role
Build, test, orchestrate, and maintain data pipelines that support the data sciences team and customer-facing client teams.
Assist in ad-hoc data deliveries by querying data from various SQL relational databases stored in multiple data models.
Track and manage pipeline efficiency and stability.
Evaluate, parse, clean, and integrate raw data sets including third party APIs. Help build sophisticated ETL processes around first party data such as survey data, second and third-party data sources such as IP addresses, clickstream data, movie meta data.
Provide recommendations for data storage, configurations, data access tools and new technologies/architectures.
Develop code-based data transformation/aggregation in data lakes, relational databases (primary use cases) and possibly non-relational databases, as well as for the purpose of BI tools such as Power BI and Tableau.
Participate in developing data APIs for data ingestion of NRG data into client-side applications or client-side data systems.
Assist application developers in the effective use of database query and programming languages.
Contribute to managing data integrity, data storage efficiency and data ecosystem efficiency.
Who You Are
Team asset who can describe data structures, relationships, and flows behind organization database servers and applications.
Up to date on the latest data-related best practices and technologies and always looking to learn more.
Internally motivated self-starter who continuously strives to get things done, regardless of challenges encountered.
Critical thinker, able to understand and respond to complex questions or issues that may arise, and able to demonstrate willingness to experiment with new technologies.
Successfully manages time and multiple competing priorities in order to ensure deadlines are always met.
Team player who is able to work collaboratively and initiate and drive projects to completion with minimal oversight.
Ideal Candidate
BS/BA in Computer Science or related field.
1+ year experience in building data pipelines or ETL.
1+ year experience with SQL (we use Snowflake but other experience with relational databases is welcome).
1+ year experience with AWS technologies/infrastructure.
Working knowledge with Python.
A solid foundation with end-to-end development and the desire to further their technical knowledge.
Knowledge of PII (personally identifiable information) data security standards is a plus.
dbt experience is a plus.
Terraform experience is a plus.
Dagster experience is a plus.
Experience in databases structured against survey data is a big plus.
Position Type
This is a full-time, exempt position.
Work Environment
This position is expected to be fully remote. However, NRG offers flexible work options if an employee happens to live near a dedicated office (Playa Vista or New York) and wants a hybrid work model. This role routinely uses standard office equipment.
Required Application Materials:
CV/Resume
Cover Letter which should include:
Why do you want to work at NRG?
Why are you interested in working in the entertainment industry?",glassdoor
197,"Mercury
3.7
Data Engineer
San Francisco, CA
$104K - $152K (Glassdoor est.)

 SF, NY, Toronto, Portland, or remote
Full-time
Mercury
In the 1880s, Herman Hollerith noticed the US Census was taking over 8 years to calculate. To solve this, he invented a tabulating machine using punch cards that dramatically sped up the process and served as the foundation for innovation in high quality data gathering.
We’re looking for our first Data Engineer who can help us build our high quality data engine that informs how we invest in and build Mercury’s future. You’ll be early to building a data-informed culture across Mercury so that we can all determine what’s happening, react quickly, and invest intelligently.
Here are some things you’ll do on the job:
Partner with leadership, engineers, and data scientists to understand data needs and build systems that deliver high quality and reliable data.
Own and maintain the data systems that extract, transform, and load data into internal and external tooling.
Apply proven expertise and build high-performance scalable data warehouses.
Design, build, and launch efficient & reliable data pipelines to move and transform data (both large and small amounts).
Design and develop new systems in partnership with software engineers to enable quick and easy consumption of data.
You should:
Have 2+ years of experience working with analytics teams on building high quality and reliable data infrastructure.
Be able to navigate from architecture and implementation decisions related to data infrastructure to guide teams towards building reliable and accurate pipelines and company-critical data sets.
Have familiarity with postgres backend data, Snowflake, and data transformation tools like dbt.
Value quality in data tools, testing, and innovation.",glassdoor
198,"Apple
4.2
Machine Learning Data Collection Engineer, Technology Development Group (TDG)
Cupertino, CA

 Summary
Posted: Mar 15, 2022
Role Number:200356922
Do you want to push the limits of the best Augmented Reality platform in the world? Apple's Technology Development Group (TDG) delivers algorithms that drive revolutionary Apple products, including the augmented reality (AR) platform ARKit to create ground-breaking new products. In this position, you will have the opportunity to be part of our extraordinary data team to discover and build solutions to previously-unsolved challenges and push the state of the art in AR algorithms that will change the way people experience the world! We are looking for a driven Machine Learning Data Collection Engineer that enjoys getting into the details to collect valuable data that feeds our machine learning models. As a member of the fast-paced data team, you have the rewarding opportunity to shape upcoming products that will delight and inspire millions of people every day. To succeed within this role, you should have shown experience in several of the following areas:
Key Qualifications
Ability to define/design/develop data collection efforts that focus on the end-to-end user experience, including anticipating potential failure modes, edge cases, and anomalies
Capacity to multitask and manage several projects in parallel while meeting deadlines and providing access to clients and partners
Problem solving & critical thinking capacities, thinking outside the box in order to gain in speed, efficiency, and quality.
Ability to re-construct ill-defined data needs into concrete project deliverables
Ability to maintain and develop relationships with multi-functional teams
Excellent project management, communication, interpersonal, analytical, and organizational skills
Description
As a Machine Learning Data Collection Engineer, you'll be working with our customers to understand their data collection requirements, assisting them in defining their protocols, and executing on the data collection. Your job responsibilities will include: -Collaborate with algorithm teams and understand data collection requirements in order to define collection protocols -Define and design the collection requirements and lead the collection effort from start to finish -Coordinate the efforts between internal teams (Legal, privacy, security, etc) guaranteeing compliance with applicable rules, laws, and best practices -Create documents and procedures needed to run data collections -Managing and track progress of externally run data collections
Education & Experience
Bachelors degree or related practical experience
Additional Requirements",glassdoor
199,"Apple
4.2
Biomedical Data Engineer - Health Technologies
Cupertino, CA

 Summary
Posted: Aug 8, 2022
Weekly Hours: 40
Role Number:200402289
The Health Technologies Team conceives and proves out innovative technology for Apple’s future products and features in health. We are seeking a highly capable Biomedical Data Engineer to join a multi-disciplinary team. Successful candidates will be able to integrate with our research study leads, data scientists and engineers to develop and support effective data analysis and machine learning workflows.
Key Qualifications
Experience with software engineering frameworks
Excellent coding skills in Python (e.g.,Pandas, Spark, Jupyter)
Workflow orchestrations (e.g., Airflow, Luigi)
Designing and maintaining (non-)relational databases (e.g. Postgres, Cassandra, MongoDB) and file systems (e.g. Parquet, CSV, JSON)
Great understanding of infrastructure designs
Linux, MacOS based development frameworks
iOS/ watchOS development (e.g., Swift, Objective-C)
Web Service APIs (e.g., AWS, REDCap, XNAT)
Version control frameworks (Git, virtualenv)
Familiarity with best practices for information security, including safe harbor privacy principles for sensitive data
Experience with biomedical sensors/platforms for measuring physiological signals in the health, wellness and/or fitness realms
Description
- Work closely with team members and study staff to design, build, launch and maintain systems for storing, aggregating and analyzing large amounts of data - Process, troubleshoot, and clean incoming data from human studies - Automate and monitor data ingestion and transformation pipelines, with hooks for QA, auditing, redaction and compliance checks per data management specifications - Create and maintain databases with existing and incoming clinical data - Architect data models and create tools to harmonize disparate data sources - Incorporate and comply with regulations as they pertain to electronic and clinical data and databases
Education & Experience
BS/MS in Computer Science, Engineering, Informatics, or equivalent with relevant 4+ years industry experience with biomedical, health or sensitive data.
Additional Requirements",glassdoor
200,"Apple
4.2
ML Data Collection and Data Science Engineer (TDG)
Cupertino, CA

 Summary
Posted: May 16, 2022
Role Number:200380146
Do you want to push the limits of the best Augmented Reality platform in the world? Apple's Technology Development Group (TDG) delivers algorithms that drive revolutionary Apple products, including the augmented reality (AR) platform ARKit to create ground-breaking new products. In this position, you will have the opportunity to be part of our extraordinary data team to discover and build solutions to previously-unsolved challenges and push the state of the art in AR algorithms that will change the way people experience the world! We are looking for a driven Machine Learning Data Collection Engineer that enjoys getting into the details to collect valuable data that feeds our machine learning models. As a member of the fast-paced data team, you have the rewarding opportunity to shape upcoming products that will delight and inspire millions of people every day. To succeed within this role, you should have shown experience in several of the following areas:
Key Qualifications
Ability to define/design/develop data collection efforts that focus on the end-to-end user experience, including anticipating potential failure modes, edge cases, and anomalies
Proficiency in programming languages including Python, C++, or similar
Capacity to multitask and manage several projects in parallel while meeting deadlines and providing access to clients and partners
Problem solving & critical thinking capacities, thinking outside the box in order to gain in speed, efficiency, and quality.
Excellent project management, communication, interpersonal, analytical, and organizational skills
Experience with industrial software development, a plus
Experience with CVML, a plus
Description
As a Machine Learning Data Collection Engineer, you'll be collaborating with multi-functional teams to work on CVML data collection projects, from collecting data collection requirements, designing protocols, testing software and hardwares, executing data collection, to analyzing and curating collected data. Your job responsibilities will include -Contribute to the design of CVML data collection, including hardware, software, user interface specifications, and collection protocols. -Define, implement, maintain SW and HW solutions to test data collection hardware, software and protocols. -Design, implement and maintain SW platforms to monitor date life cycle -Work with CVML engineers to design and implement data evaluation and curation process -Analyze data and build data analysis tools -Collaborate with multi-functional teams including algorithm, hardware, software, product design, project management, legal, procurement, security, logistics and vendors to define and deliver necessary study elements -Write technical documents including study instructions, operating procedures and training documents for study personnel -Drive process improvements across the organization to continuously improve the way we work
Education & Experience
B.S., M.S., or Ph.D. in Computer Science, Computer Engineering, or equivalent practical experience.
Additional Requirements",glassdoor
201,"Faire
4.8
Data Engineer
San Francisco, CA
$117K - $170K (Glassdoor est.)

 About Faire
Faire is an online wholesale marketplace built on the belief that the future is local — there are over 2 million independent retailers in North America and Europe doing more than $2 trillion in revenue. At Faire, we're using the power of tech, data, and machine learning to connect this thriving community of entrepreneurs across the globe. Picture your favorite boutique in town — we help them discover the best products from around the world to sell in their stores. With the right tools and insights, we believe that we can level the playing field so that small businesses everywhere can compete with these big box and e-commerce giants.
By supporting the growth of independent businesses, Faire is driving positive economic impact in local communities, globally. We're looking for smart, resourceful and passionate people to join us as we power the shop local movement. If you believe in community, come join ours.
Job Description
The Data Engineering team is the backbone of all data-related processes and enables the Data Science teams to develop and deploy a wide variety of algorithms and models that power the marketplace. Our infrastructure is used by the whole company for analytics, reporting, forecasting and research. We care about having a reliable & scalable infrastructure with quality data and building machine learning models that help our customers thrive.
As a Data Engineer you'll be responsible for developing and automating large scale, high-performance data storage and processing systems.
What you will be doing:
Develop our data infrastructure to help us scale for where we're going over the next several years
orchestrating pipelines using modern Big Data tools/architectures as well as design and engineering of existing transactional processing systems
Manage our data infrastructure and ETL platform
What it takes:
2+ years experience in a Data Engineering role with an emphasis on managing data warehouses
Strong skills in Python, Git, Docker, SQL, Airflow, real time ETL pipelines
Managing data infrastructure (AWS services, Data orchestrator) and providing framework to rationalize and simplify both real time and batch data pipelines
Familiarity with Snowflake or BigQuery
A passion for programming and solving problems with code
A bachelor's degree in Computer Science/Software Engineering or equivalent industry experience
A love for technology, and an insatiable curiosity for new tools to tackle real problems
Faire's flexible work model aims to meet the needs of our diverse employee community by making work more flexible, connected, and inclusive. Depending on the role and needs of the team, Faire employees have the flexibility to choose how they work–whether that's mainly in the office, remotely, or a mix of both.
Roles that list only a country in the location are eligible for fully remote work in that country or in- office work at a Faire office in that country, provided employees are located in the registered country/province/state. Roles with only a city location are eligible for in-office or hybrid office work in that city. Our talent team will work with candidates to determine what locations and roles are eligible for each option.
Why you'll love working at Faire
We are entrepreneurs: Faire is being built for entrepreneurs, by entrepreneurs. We believe entrepreneurship is a calling and our mission is to empower entrepreneurs to chase their dreams. Every member of our team is an owner of the business and taking part in the founding process.
We are using technology and data to level the playing field: We are leveraging the power of product innovation and machine learning to connect brands and boutiques from all over the world, building a growing community of more than 350,000 small business owners.
We build products our customers love: Everything we do is ultimately in the service of helping our customers grow their business because our goal is to grow the pie - not steal a piece from it. Running a small business is hard work, but using Faire makes it easy.
We are curious and resourceful: Inquisitive by default, we explore every possibility, test every assumption, and develop creative solutions to the challenges at hand. We lead with curiosity and data in our decision making, and reason from a first principles mentality.
Faire was founded in 2017 by a team of early product and engineering leads from Square. We're backed by some of the top investors in retail and tech including: Y Combinator, Lightspeed Venture Partners, Forerunner Ventures, Khosla Ventures, Sequoia Capital, Founders Fund, and DST Global. We have headquarters in San Francisco and Kitchener-Waterloo, and a global employee presence across offices in Salt Lake City, Atlanta, Toronto, London, New York, LA, and Sao Paulo. To learn more about Faire and our customers, you can read more on our blog.
Faire provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity or gender expression.
Faire is committed to providing access, equal opportunity and reasonable accommodation for individuals with disabilities in employment, its services, programs, and activities. To request reasonable accommodation, please fill out our Accommodation Request Form.",glassdoor
202,"Farmers Insurance Group
3.7
Data Engineer (Application SME I)
Remote
Employer Provided Salary:$74K - $98K

 We are Farmers!
We are… more than just your favorite commercials. We are a passionate, award winning, equal opportunity employer, committed to the strength of a diverse workforce. We are dedicated to supporting the well-being of our people through our extensive suite of benefits, as well as the well-being of the communities we serve through employee volunteer programs and nonprofit partnerships. Helping others in their time of need isn’t just our business – it’s our culture! We are Farmers!

Do you thrive in a high-volume, fast-paced environment? Do you enjoy the challenge of a position where no two days are alike? We are looking for positive, high-energy professionals who are not just looking for a job, but a meaningful career!

Job Summary
Use MS SQL SSIS to build ETL process to create new business functionalities as well to solve business problems: Respond to new requests for reports/data understanding business objectives and processes; review and refine technical requirements/User Stories; and communicate estimated hours and timeline to complete; Extract data directly from relational databases (e.g. DB2, SQL Server), data warehouses, or other data stores using SQL; Ability to create manual as well as automated data exports/reports; and Support application unit testing for enhancements or system upgrades; identify and communicate data quality issues or data differences. Work productively on assigned tasks; Collaborate effectively with other team members; Demonstrate accountability to management and business for hours spent on assigned tasks; and diligently strive to deliver value.
Essential Job Functions
Education Requirements
High school diploma or equivalent required.
Bachelor’s degree preferred, in Information Systems or related field.
Experience Requirements
Experience in developing ETL and reporting applications using Microsoft SQL Server (strongly preferred), or Informatica or similar ETL technologies.
Experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process on MS SQL Server or DB2 or similar DB platform.
Experience with Python and unstructured data manipulation is a plus.
Experience with cloud technologies such as AWS Glue, Azure Data Factory, Snowflake is a plus.
Experience working in an Agile Environment is a plus.
Good knowledge of business intelligence best practices, processes, and methodologies.
Good programming experience in writing Stored Procedures, Queries, Views, User Defined Functions, and Common Table Expressions using SQL or T-SQL.
Highly committed, motivated, enthusiastic and a natural team player.
Good interpersonal and communication skills (both verbal and written) and ability to interact with and effectively address concerns.
Good prioritization, time management, analytical, and organization skills.
Experienced in facilitating in-person and remote meetings with business & IT.
Experienced in effective management of multiple competing and frequently changing assignments and priorities.

Benefits
Farmers offers a competitive salary commensurate with experience, qualifications and location
Colorado Only: The pay range for this job being performed in Colorado would be 73,600 - 98,100
Bonus Opportunity (based on Company and Individual Performance)
401(k)
Medical
Dental
Vision
Health Savings and Flexible Spending Accounts
Life Insurance
Paid Time Off
Paid Parental Leave
Tuition Assistance

Job Location(s): R_US - RW - Remote Work",glassdoor
203,"Apple
4.2
Keystone Big Data Software Engineer, Global Business Intelligence
Cupertino, CA

 Summary
Posted: Jul 18, 2022
Role Number:200399924
Imagine what you could do here! At Apple, great minds come together to build products, services, and solutions that amaze the world. Imagine how your contributions could transform the world and there is no limit to what you could accomplish here. Apple's Global Business Intelligence (GBI) team is seeking an experienced Software Engineer to build high quality, scalable and resilient distributed systems that power Apple's analytics platforms and data pipelines. Apple's Enterprise Data Warehouse landscape caters to a wide variety of real-time, near real-time and batch analytical solutions. These solutions are an integral part of business functions like Sales, Operations, Finance, AppleCare, Marketing, and Internet Services, enabling business drivers to make critical decisions. If you enjoy learning new technologies, and are comfortable proposing and implementing solutions, demonstrating Software Engineering standard methodologies, you will find it rewarding to work in GBI! The ideal candidate for this position will be able to think outside of the box and should have passion for building engineering solutions to enable business in making time sensitive and critical decisions.
Key Qualifications
Strong fundamentals in data structures, algorithms, and software system design
Strong hands-on programming skills (Scala / Java / Python preferred)
Proven track record of building jobs processing high-volume data using Spark
Experience with real time data processing with Spark Streaming, Flink is a huge plus
Committed to test driven development paradigm
Strong analytical and interpersonal skills and demonstrated ability to code & collaborate
Self-starter, highly motivated and ability to research, learn, prototype quickly
Sound experience in Cloud technologies such as AWS or GCP
Experience on Cloud with databases like SnowFlake and Singlestore is a plus
Prior experience in the areas of AI/ML/Data Sciences will be a strong plus
Curiosity to explore and understand data is a plus
Description
The Frameworks team in GBI build and support critical infrastructural systems which provide services for numerous organizations within Apple and we are looking for a strong, enthusiastic developer to join as a member of this group. You are someone with ideas and real passion for software delivered as a service to improve reuse, efficiency, and simplicity. This engineer’s work will affect multiple data teams within Apple and enable our partners to derive insights and help execute their goals.
Education & Experience
BS/MS in Computer Science, Computer Engineering or similar field
Additional Requirements
Apple is an Equal Opportunity Employer that is committed to inclusion and diversity. We also take affirmative action to offer employment and advancement opportunities to all applicants, including minorities, women, protected veterans, and individuals with disabilities. Apple will not discriminate or retaliate against applicants who inquire about, disclose, or discuss their compensation or that of other applicants.
We at Apple we are committed to working with and providing reasonable accommodation to applicants with physical and mental disabilities. Learn more.",glassdoor
204,"Expression Networks
4.4
Data Engineer
Remote

 Founded in 1997 and headquartered in Washington DC, Expression Networks provides data fusion, data analytics, software engineering, information technology, and electromagnetic spectrum management solutions to the U.S. Department of Defense, Department of State, and national security community. Expression's “Perpetual Innovation” culture focuses on creating immediate and sustainable value for our clients via agile delivery of tailored solutions built through constant engagement with our clients. Expression Networks was ranked #1 on the Washington Technology 2018's Fast 50 list of fastest-growing small business Government contractors and a Top 20 Big Data Solutions Provider by CIO Review.

We make sure to provide everyone the tools and opportunities to grow while working on some of the newest technologies in the industry. With Covid-19 being a major theme the last two years having a growing collaborative culture has been one of the key focus of our C-suite and upper management. We get excited about celebrating our professionals' milestones, accomplishments, promotions, overcoming challenges, and many other aspects that make an engaging collaborative environment.

We are looking to bring on a mid-level Data Engineer to add to the continued growth of our Data Science division. This position will work in a team led by a principal data engineer on tasks related to designing and delivering high-impact data architecture and engineering solutions to our customers across a breadth of domains and use cases.
Location:
Remote, with the ability to travel per project requirements.
Security Clearance:
Ability to obtain Secret Clearance or Higher
Responsibilities:
Developing, testing, and documenting software code for data extraction, ingestion, transformation, cleaning, correlation, and analytics
Participating in end-to-end architectural design and development lifecycle for new data services/products, and making them operate at scale
Participating in cross-functional team collaboration to understand customer requirements, design prototypes, and optimize existing data services/products
Demonstrating Data Science excellence in the teams you work with across the organization, and mentoring junior members in the Data Science division
Participating in research, case studies, and prototypes on cutting-edge technologies and how they can be leveraged
Required Qualifications:
3+ years of experience bringing databases, data integration, and data analytics/ML technologies to production with a Bachelor's degree in Computer Science/Data Science/Computer Engineering or relevant field
Mastery in developing software code in one or more programming languages (Python, JavaScript, Java, Matlab, etc.)
Expert knowledge in databases (SQL, NoSQL, Graph, etc.) and data architecture (Data Lake, Delta Lake)
Knowledgeable in machine learning/AI methodologies
Experience with one or more SQL-on-Hadoop technology (Hive, Impala, Spark SQL, Presto, etc.)
Preferred Qualifications:
Experience in short release cycles and the full software lifecycle
Experience with Agile development methodology (e.g., Scrum)
Strong writing and oral communication skills to deliver design documents, technical reports, and presentations to a variety of audiences
Benefits:
Expression Networks offers competitive salaries and benefits, such as:
401k matching
PPO and HDHP medical/dental/vision insurance
Education reimbursement up to $10,000/yr.
Complimentary life insurance
Generous roll over PTO and 11 days of holiday leave
Onsite gym facility and trainer
Commuter Benefits Plan
In office Cold Brew Coffee
Equal Opportunity Employer/Veterans/Disabled",glassdoor
205,"Cigna
3.8
BI Data Engineer-Work from home-eviCore
Hartford, CT
Employer Provided Salary:$96K - $160K

 Duties
Build ETL processes to allow data to flow seamlessly from source to target using tools like Databricks, Azure Data Factory, SSIS, SQL Stored Procedures and Powershell scripting
Load and enhance dimensional data models
Leverage code to apply business rules to ensure data is clean and is interpreted correctly by all business stakeholders, using tools like Databricks, SQL, Scala and Python
Perform code reviews and QA
Participate in sprint ceremonies
Provide on-call support to offshore operations team
Train operations teams on the ETL processes being developed
Troubleshoot and address issues with the data and/or the ETL process
Fine tune existing code to make processes more efficient
Maintain and create documentation to describe our data management processes
Analyze reports using various tools like Micro Strategy, Tableau and SSRS
Support user questions on data management processes and results

Minimum Required Skills
5+ Years building Big Data and Data Warehousing solutions
Knowledge of data modeling (including dimensional modeling), data architecture & data governance concepts
Experience in working with implementations of Azure cloud data solutions (ADLS, Data Bricks, Synapse, ADF)
Proficient in database concepts and technologies including MS SQ Server, DB2 and Oracle
Excellent written and oral communications skills
Must be able to effectively communicate complex technical topics to a variety of audiences
Experience with Healthcare data is a plus

Minimum Education, Licensure and Professional Certification requirement:
Bachelor’s degree with relevant experience required.
Master’s Degree is a plus.

If you will be working at home occasionally or permanently, the internet connection must be obtained through a cable broadband or fiber optic internet service provider with speeds of at least 10Mbps download/5Mbps upload.

For this position, we anticipate offering an annual salary of 95,900 - 159,800 USD / yearly, depending on relevant factors, including experience and geographic location.

This role is also anticipated to be eligible to participate in an annual bonus plan.

We want you to be healthy, balanced, and feel secure. That’s why you’ll enjoy a comprehensive range of benefits, with a focus on supporting your whole health. Starting on day one of your employment, you’ll be offered several health-related benefits including medical, vision, dental, and well-being and behavioral health programs. We also offer 401(k) with company match, company paid life insurance, tuition reimbursement, a minimum of 18 days of paid time off per year and paid holidays. For more details on our employee benefits programs, visit Life at Cigna .

About Cigna
Cigna Corporation exists to improve lives. We are a global health service company dedicated to improving the health, well-being and peace of mind of those we serve. Together, with colleagues around the world, we aspire to transform health services, making them more affordable and accessible to millions. Through our unmatched expertise, bold action, fresh ideas and an unwavering commitment to patient-centered care, we are a force of health services innovation. When you work with us, or one of our subsidiaries, you’ll enjoy meaningful career experiences that enrich people’s lives. What difference will you make?

Qualified applicants will be considered without regard to race, color, age, disability, sex, childbirth (including pregnancy) or related medical conditions including but not limited to lactation, sexual orientation, gender identity or expression, veteran or military status, religion, national origin, ancestry, marital or familial status, genetic information, status with regard to public assistance, citizenship status or any other characteristic protected by applicable equal employment opportunity laws.

If you require reasonable accommodation in completing the online application process, please email: SeeYourself@cigna.com for support. Do not email SeeYourself@cigna.com for an update on your application or to provide your resume as you will not receive a response.

Cigna has a tobacco-free policy and reserves the right not to hire tobacco/nicotine users in states where that is legally permissible. Candidates in such states who use tobacco/nicotine will not be considered for employment unless they enter a qualifying smoking cessation program prior to the start of their employment. These states include: Alabama, Alaska, Arizona, Arkansas, Delaware, Florida, Georgia, Hawaii, Idaho, Iowa, Kansas, Maryland, Massachusetts, Michigan, Nebraska, Ohio, Pennsylvania, Texas, Utah, Vermont, and Washington State.",glassdoor
206,"Mint Mobile
3.6
Digital Data Engineer I - Remote
Costa Mesa, CA
Employer Provided Salary:$90K - $103K

 MINT MOBILE is seeking a talented Digital Data Engineer I to join the Data Management Team! Individual reports to Customer Data Manager. Role is remote; must reside in the United States.
ABOUT THE ROLE
Provide direct data engineering development to data pipelines for ETL establishment and enhancements to and from data warehouses to customer management platform (Braze). Work collaboratively with cross-functional teams to determine digital data needs, establish data collection requirements, and deploy & maintain accurate data to ensure metrics & dimensions are addressed for analytics/reporting requirements.
Your usual day of awesomeness includes:
Transform required data conditions into performance code logic.
Develop high-performance code in SQL and Python.
Develop, automate, and enhance ELT processes for continuous data flow.
Create, modify, and deploy code to production via AWS resources including Lambda, S3, Glue, Redshift, etc.
Partner with stakeholders to support the implementation and development of data requirements.
Troubleshoot data anomalies and provide applicable solutions.
Build, test and maintain database pipeline architectures.
WHAT YOU BRING
Advanced level in SQL and Python for data engineering and backend development.
Understanding of popular code development approaches:
Test-driven development
Continuous Integration/Continuous Deployment (CI/CD)
Experienced working with AWS services (Lambda, S3, Glue, Redshift etc.) and Cloud Data Warehouse.
Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
Define digital data collection methods and implementations to DWH and customer management platforms.
Experienced with QA testing process to verify data is collected & rendered as expected.
Ability to excel in a fast-paced, cross-functional environment.
Ability to work autonomously.
Excellent written and verbal communication skills.
Proactive problem-solving and critical thinking skills.
Ability to manage time effectively and consistently meet deadlines.
NICE TO HAVE
Prior working knowledge of Braze or other Customer Management Platforms
Snowflake Cloud Data Warehouse
Terraform/Bitbucket/Airflow/Jenkins
Looker, Tableau, Power BI
WE ARE MINT MOBILE
We connect people to what's most important in their lives: Easily, affordably and reliably. We strive to be California's Preeminent Destination Employer. Oh yeah, we get it too! We understand what matters to you most. You're an individual with unique needs, and we're prepared to exceed any expectations you have for an ideal employer.
We're smart, strategic, and get things done without a lot of red tape or unnecessary politics. Everyone matters here and everyone has a voice. Expect to spend your time contributing to projects that really matter. We obsess over the employee experience. To start, we provide some of the most competitive salary, benefits, family leave, vacation, retirement and equity options in Southern California. We believe in you and invest in you. Not just your career aspirations, but your life.
In addition, we've got a laundry list of perks you'll brag about on insta - Lunch every day prepared by our very own chef, healthy snacks, onsite gym, free massages, car wash services, and most importantly, a team atmosphere. We even raise the bar on well bars, including Espresso/Cappuccino/Nitro/Cold Brew/Kombucha Bar, Froyo Bar, Breakfast Bar, Snack Bar and a, well, you know, bar (after 5 pm).
And if you feel intrigued right now reading, imagine the co-workers we have already attracted. This is the kind of team you'll want to take home to mom or invite to your kid's next birthday party. This is the kind of close-knit community happening here. Come check out how you can be part of Mint!
OUR VALUES – LET'S MAKE LIFE ULTRA TOGETHER!
Ownership: We are all owners; be the outcome and get the job done.
Action Biased: Be brilliant, proactive, and act with urgency.
Embrace the Adventure: Be agile, adaptive, and thrive on change.
Invent and Simplify: Never accept good enough.
$1,000 REFERRAL BONUS
Take a look at this job description, if you are the right person, please apply. If Mint Mobile doesn't appear to be a fit for you, refer a friend or colleague and get $1,000. Let your friend or colleague know to provide your full name and email when applying to the job. If we hire them and they stay for 90 days, you get $1000. For more details of restrictions and rules, please email recruiting@ultra.me.

Covid-19 Vaccination Requirement
UVNV, Inc. has adopted a mandated vaccination policy to support the health and safety of our team members and our community. The Company requires all employees to be fully vaccinated. The Company will provide accommodations based on medical condition or sincerely held religious beliefs or practices. Please let us know if you'd like to discuss the policy or available accommodations before proceeding with our recruitment process.
We are committed to equal employment opportunities regardless of race, color, genetic information, creed, religion, sex, sexual orientation, gender identity, lawful alien status, national origin, age, marital status, or protected veteran status. We support an inclusive workplace where associates excel based on personal merit, qualification, experience, ability, and job performance.
In support of the Equal Pay for Equal Work Act, the range of starting pay for this role is $90,000 - $103,000. This is not a guarantee of compensation or salary, actual compensation is influenced by a wide range of factors including but not limited to skill set, level of experience, education, certifications, responsibility, and geographic location. We also offer a variety of benefits including health, disability insurance, 401 (k), flexible spending accounts, EAP, education reimbursement, parental leave, unlimited vacation, bonuses, incentive stock options and company paid holidays. The specific programs and options available will vary depending on state, start date, and employment type. Our recruitment team will be happy to answer any questions you may have.
#LI-Remote",glassdoor
207,"Milo's Tea Company
4.1
Data Engineer
Remote

 Overview: Milo’s Tea Company is one of the fastest growing beverage companies in the US. Our culture and operations are built on the belief that we can make a difference in the world. That’s why we put People First and strive to continually reduce our environmental impact on the planet. We leverage our world class operations and decades-long distribution partnerships to grow the footprint of our core products and create new, innovative beverage products.
We are the #1 and fastest growing brand in the Refrigerated Tea Category in the nation.
Our core mission is that we put people and the planet first and by doing this, it will be good for our business.
We are committed to unlocking the personal genius of every associate and have a strong focus on growth and learning.
Our Company is women-led (our Executive Team is 57% female) and strongly committed to Diversity, Inclusion and Belonging.
We are committed to annual charitable giving by delivering upon our 1% profit pledge.
We are Platinum Certified in Zero Waste Manufacturing; recycling, reducing, and reusing 95% of waste at all facilities.
Being a part of the Milo’s TEAm, you’ll get to collaborate with a group of passionate and high-performing people, where everyone feels empowered to do their best work and feels good about the work they’re doing.
And as a ""People First"" company, Milo’s is committed to the success and well-being of our associates, customers, and fans, no matter their gender, race or creed. Some of the benefits offered that reflect our commitment include:
Competitive salary with bonus opportunities
100% paid medical insurance for our associates and their families
401K with a company match
Partial tuition reimbursement assistance
A robust parental leave program
Paid time off to volunteer at the charity of your choice
Employee assistance program
Responsibilities: The Data Engineer is responsible for assisting with data management, modeling, development, transformation, and reporting activities.
*
Responsibilities: *
Identify business needs, determine possible solutions, and develop solutions that include systems components, and process improvements with data driven decision making.
Work with business groups to design and develop reporting and analytics solutions that will improve efficiency and effectiveness.
Designs, implements, tests, troubleshoots, documents, and supports data models, programs, scripts, and ETL (Extract, Transform, and Load) processes.
Develop, maintain, and curate large datasets from multiple platforms. Develop reporting capabilities to support business needs by creating and supporting SQL queries, data extraction packages, and interfaces. Explores ways to enhance data quality and reliability.
Perform data validation between analytical and source systems to support ongoing data management capabilities and data governance. Perform data testing to ensure the accuracy of data transformation.
Develop data analytics, reports, and dashboards using Power BI and other business intelligence tools.
Uphold and participate in all Corporate Responsibility programming including recycling, social advocacy and MMAD volunteering opportunities.
Invest in and is an example of Milo’s Responsibility commitment which includes environmental, social, and corporate governance components.
Other duties as assigned
Supervisory: This role does not have supervisory responsibilities.
Qualifications:
BA in computer science, information systems, statistics, applied math, or any other related field.
Up to 3 years of experience in information systems or related field.
Strong experience with SQL server solutions (queries, functions, stored procedures, views, etc.).
Cloud based computing and data solutions.
Proficient with Excel and Business Intelligence tools (Power BI, Power Query, Tableau, etc.).
Understanding of relational databases and data warehouses. Hands-on experience with SQL database design.
Experience with Microsoft SQL stack (SSIS, SSRS, SSAS, etc); Experience with cloud-based data technologies, Azure preferred.
Experience working in a SharePoint environment; Experience with Python, R or other programming languages.
Experience in non-traditional SQL (noSQL, etc.) solutions.
Experience with machine learning and predictive analytics.
Experience with other ETL tools such as Alteryx.
Job Type: Full-time",glassdoor
208,"Netflix
4.3
Data Engineer (L5) - Games
Los Gatos, CA
$108K - $193K (Glassdoor est.)

 Los Gatos, California
Data Science and Engineering
Now is an amazing time to join Netflix as we seek to entertain the world. We have over 200 million paid members in over 190 countries, and we won’t stop there. Games are our next big frontier and an incredible opportunity for us to deliver new experiences to delight and entertain our quickly growing membership. You will be jumping in at the very beginning of this adventure and be in a position to help us redefine what a Netflix subscription means for our members around the world.
Data Science and Engineering (‘DSE’) at Netflix is aimed at using data, analytics, and sciences to improve various aspects of our business. We are looking for a Data Engineer to join our Games DSE team, supporting end-to-end analytics & data needs for our games portfolio. This role will be partnering closely with our Game stakeholders to develop software and data solutions that enable analysis across the entire library of games.
As part of this team, you will work on diverse data technologies such as Spark, Presto, Flink, Kafka, and others to build insightful, scalable, and robust data pipelines that feed directly into our key gaming dashboards; write ETL jobs to collect and aggregate data; and build high-quality data models that represent how games are performing on Netflix.
The ideal candidate will also have a background in games, with a solid knowledge of how standard industry metrics are computed.
Who You Are:
7+ years of software/data engineering experience working with video game analytics (i.e you are familiar with how key metrics such as DAU, MAU and retention rates are computed in an ETL).
Passionate about building intuitive data models and an expert in distributed data processing patterns.
Highly proficient in at least one of these programming languages: Java, Python, or Scala.
Comfortable with complex SQL.
Expert in engineering data pipelines using big data technologies (Hive, Presto, Spark, Flink) on large-scale data sets demonstrated through years of experience.
Conceptually familiar with AWS cloud resources (S3, EC2, RDS etc).
Excel at taking vague requirements and crystallizing them into scalable data solutions.
Excited about operating independently, demonstrating excellence, and learning new technologies and frameworks.
What will you do?
Engineer efficient, adaptable, and scalable data pipelines in Spark and Python/Scala to process structured data into aggregate datasets that feed all games portfolio dashboards.
Become an expert in games metrics at Netflix - act as a thought partner to the games analytics team, understand their challenges, and help them to put the right data in front of our stakeholders.
Maintain and rethink existing datasets and pipelines to service a wider variety of use cases.
Join a stunning team of data engineers with diverse skill sets, partnering closely with analytics engineering and data science counterparts.
Netflix Culture
Our culture is unique, and we live by our values. For more information on what it's like to work at Netflix, please take a look at our culture memo.",glassdoor
209,"Pinterest
4.1
Data Engineer
Remote

 About Pinterest:
Millions of people across the world come to Pinterest to find new ideas every day. It's where they get inspiration, dream about new possibilities and plan for what matters most. Our mission is to help those people find their inspiration and create a life they love. In your role, you'll be challenged to take on work that upholds this mission and pushes Pinterest forward. You'll grow as a person and leader in your field, all the while helping Pinners make their lives better in the positive corner of the internet.
Our new progressive work model is called PinFlex, a term that's uniquely Pinterest to describe our flexible approach to living and working. Visit our PinFlex landing page to learn more.
The Enterprise Data Platform team is looking for a Data Engineer who has experience with Building Data Pipelines and Managing/Developing on any Cloud Data Warehouse. In this role you will also advise other Data Analysts and Data Engineers from the Business teams at Pinterest on the best practices for handling data and deriving insights using Snowflake. You will gradually become the Subject Matter Expert on Snowflake and also help build out the Modern Data Stack at Pinterest.
What you'll do:
Build Data Pipelines using Python on either Airflow or AWS Lambda to ingest data into Snowflake
Build Scripts in Python to manage Data Access on Snowflake
Define and advocate the best practices for storing and analyzing data inside Snowflake
Review the Data Modeling practices of other teams
What we're looking for:
Strong skills in Python and SQL
Experience with Building Data Pipelines in Python
Experience with any Cloud Data Warehouse either as an Administrator or a Developer
Strong Data Modeling skills
#LI-BB1
#LI-Remote
Our Commitment to Diversity:
At Pinterest, our mission is to bring everyone the inspiration to create a life they love—and that includes our employees. We’re taking on the most exciting challenges of our working lives, and we succeed with a team that represents an inclusive and diverse set of identities and backgrounds.

Not Specified
0",glassdoor
210,"Realign LLC
4.5
Data Engineer
California

 Job Type: Contract
Job Category: IT
Job Description
Write and optimize queries, provide input on peer code reviews and data modeling, deploy data
updates via continuous integration / deployment (CI/CD) practices.

Collaborate with software developers, other data engineers, and database architects on projects to
ensure optimal data delivery following appropriate change management guidelines.

Collaborate with software and reliability engineers to automate repeatable data tasks.

Work with development and production support teams to troubleshoot data, application, and service
deployment issues.

Develop detailed, shared technical procedure documentation, including processes for contingency
operations.

Research, provide technical input, document, and implement new technology solutions.

Implement necessary patches, hotfixes, service packs, cumulative updates, upgrades, and
configuration change to maintain security compliance and application integrity.

Required Skills
Big Data Engineer",glassdoor
211,"Luxoft
4.3
Data Engineer
Remote

 Project Description
Luxoft has contract with a major Telecommunications provider to engage with DIRECTV organization to establish integrated cloud technology platforms to ingest information from various Network Engineering support applications in order to better optimize management and planning for the future network.

To do this DIRECTV is managing data ingestion into a Snowflake Azure based deployment which allows for one cohesive platform to serve all types of users and workloads in a consistent way. Centralizing data in a unified, governed, managed data platform allows all authorized users to access accurate and timely data for analysis that is useful for highly transnational datasets. It is also useful that it can store structured and unstructured data. Additionally DIRECTV is leveraging a Palantir Deep™ instance platform for the creation and management of cost forecasting scenarios.
Responsibilities
- Analysis on Data Libraries - evaluation of data sets and current data architecture for source data pipelines. This will allow us to scope the depth/breadth of data

- Data Quality Metrics - Audits analysis and setup to determine the appropriate data quality measures. This will be used to validate with clients/users in a later phase.

- DQF research - Analyze the current Data Quality Framework to leverage as possible/needed. Assess the need for extension and/or replacement of the current DQF.

- Architecture patterns research - Analysis of data translation and business rules associated.

- Current ingestion patterns - Study and enhancement research to evaluate data pipeline for current state and opportunity to optimize for increased data quality and rigor.
Skills
Must have
Cloud, Data Engineering, SnowFlake, Big Data
Nice to have
Microsoft Azure Cloud Platform
Languages
English: C2 Proficient
Seniority
Senior
Relocation package
If needed, we can help you with relocation process.
Vacancy Specialization
BigData Development
Ref Number
VR-81593",glassdoor
212,"Dataquestcorp
Data Science Engineer
Branchburg, NJ
Employer Provided Salary:$75K - $80K

 Job Role: Data Science
Note: Please don't apply C2C profiles. its only w2 positions
Benefits:
Free Training and placement.
Training provided by highly qualified, industry-experienced & certified instructors.
We do provide free accommodations & Relocation charges.
H1B Sponsorship
We do support for STEM OPT and GC processing.
Health Insurance
Relocation Assistance any where in USA.
Free accommodation.
Location: Branchburg, NJ
Job Types: Full-time, Contract
Job Types: Full-time, Contract
Salary: $75,000.00 - $80,000.00 per year
Benefits:
Health insurance
Schedule:
8 hour shift
Ability to commute/relocate:
Branchburg, NJ: Reliably commute or planning to relocate before starting work (Required)
Experience:
Python: 1 year (Preferred)
SQL: 1 year (Preferred)
Work Location: One location
Speak with the employer
+91 9089927715",glassdoor
213,"Teknic
Data Engineer
Remote

 Role: Data Engineer
Location: Remote
JOb Description:
Skills and Experience :
Good experience on designing and developing data pipelines for data ingestion and transformation using Spark.
Distributed computing experience using Pyspark.
Good understanding of spark framework and spark architecture.
Experience working in Cloud based big data infrastructure.
Excellent in trouble shooting the performance and data skew issues.
Must have a good understanding of spark run time metrics and tune applications based on metrics.
Deep knowledge in partitioning, bucketing concepts of data ingestion.
Good understanding of AWS services like Glue, Athena, S3, Lambda, Cloud formation.
Preferred working knowledge on the implementation of datalake ETL using AWS glue, Databricks etc.
Experience with data modelling techniques for cloud data stores and on prem databases like Teradata, Teradata Vantage (TDV) etc.
Preferred working experience in ETL development in Teradata vantage and data migration from on prem to Teradata vantage.
Proficiency in SQL, relational and non-relational databases, query optimization and data modelling.
Experience with source code control systems like Gitlab.
Experience with large scale distributed relational and NoSQL database systems.
Job Type: Contract
Schedule:
8 hour shift
Experience:
Data engineer: 10 years (Preferred)
Spark.: 3 years (Preferred)
Cloud based big data infrastructure.: 1 year (Preferred)
datalake ETL: 1 year (Preferred)
AWS Glue: 1 year (Preferred)
Work Location: Remote",glassdoor
214,"Blue Cross and Blue Shield of North Carolina
4.1
Data Engineer
Remote

 Additional Locations:
Full Time Remote - Alabama, Full Time Remote - Alabama, Full Time Remote - Arizona, Full Time Remote - Arkansas, Full Time Remote - Florida, Full Time Remote - Georgia, Full Time Remote - Idaho, Full Time Remote - Indiana, Full Time Remote - Iowa, Full Time Remote - Kansas, Full Time Remote - Kentucky, Full Time Remote - Louisiana, Full Time Remote - Maryland, Full Time Remote - Michigan, Full Time Remote - Mississippi, Full Time Remote - Missouri, Full Time Remote - Ohio, Full Time Remote - Oklahoma, Full Time Remote - Pennsylvania, Full Time Remote - South Carolina, Full Time Remote - South Dakota, Full Time Remote - Tennessee, Full Time Remote - Texas, Full Time Remote - Utah, Full Time Remote - Virginia {+ 1 more}
Job Description
IT is different here. Our work as technology specialists pushes the boundaries of what’s possible in health care. You will build solutions that make a real difference in people’s lives. Driven by the importance of their work, our team members innovate to elevate. We’re encouraged to be curious, collaborate, and turn ideas into solutions that transform this space.

In this role you will work closely with senior engineers, data scientists and other stakeholders to design and maintain moderate to advanced data models. The Data Engineer is responsible for developing and supporting advanced reports that provide accurate and timely data for internal and external clients. The Data Engineer will design and grow a data infrastructure that powers our ability to make timely and data-driven decisions. You will support Membership Operations, Customer Service Operations, Digital & Consumer Experience teams.

If you are ready to make a career out of making a difference, then you are the person for this team.
What You’ll Do
Define and extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes
Document, and test moderate data systems that bring together data from disparate sources, making it available to data scientists, and other users using scripting and/or programming languages
Write and refine code to ensure performance and reliability of data extraction and processing
Participate in requirements gathering sessions with business and technical staff to distill technical requirement from business requests
Develop SQL queries to extract data for analysis and model construction
Own delivery of moderately sized data engineering projects
Design and develop scalable, efficient data pipeline processes to handle data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets to analysts and data scientists
Ensure performance and reliability of data processes
Document and test data processes including performance of through data validation and verification
Collaborate with cross functional team to resolve data quality and operational issues and ensure timely delivery of products
Develop and implement scripts for database and data process maintenance, monitoring, and performance tuning
Analyze and evaluate databases in order to identify and recommend improvements and optimization
Design eye-catching visualizations to convey information to users
What You Will Bring
Bachelor’s degree and 3 years of experience with Oracle, Data Warehouses and Data Lakes, Big Data platforms and programming in Python, R or other related language.
In lieu of degree, 5 years of the experience as stated above.
SQL and Python scripting
Experience in a cloud environment
Experience with Ab Initio or other ETL tools",glassdoor
215,"Pepsico
3.9
Junior Data Engineer
Remote
Employer Provided Salary:$90K - $100K

 Compensation: $80k - $90k
Benefits: Medical, Dental, Vision, 401k match and Arc
This role can be performed remote in any of our headquarter locations including Plano, Texas; Purchase, New York; Chicago, Illinois.
What PepsiCo Data Management and Operations does:
Maintain a predictable, transparent, global operating rhythm that ensures always-on access to high-quality data for stakeholders across the company
Responsible for day-to-day data collection, transportation, maintenance/curation and access to the PepsiCo corporate data asset
Work cross-functionally across the enterprise to centralize data and standardize it for use by business, data science or other stakeholders
Increase awareness about available data and democratize access to it across the company.
As a member of the data engineering team, you will be the key technical expert developing and overseeing PepsiCo's data product build & operations and drive a strong vision for how data engineering can proactively create a positive impact on the business. You'll be an empowered member of a team of data engineers who build data pipelines into various source systems, rest data on the PepsiCo Data Lake, and enable exploration and access for analytics, visualization, machine learning, and product development efforts across the company. As a member of the data engineering team, you will help lead the development of very large and complex data applications into public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. You will work closely with process owners, product owners and business users. You'll be working in a hybrid environment with in-house, on-premise data sources as well as cloud and remote systems.
Key Accountabilities:
Active contributor to code development in projects and services
Manage and scale data pipelines from internal and external data sources to support new product launches and drive data quality across data products
Build and own the automation and monitoring frameworks that capture metrics and operational KPIs for data pipeline quality and performance
Responsible for implementing best practices around systems integration, security, performance and data management
Empower the business by creating value through the increased adoption of data, data science and business intelligence landscape
Collaborate with internal clients (data science and product teams) to drive solutioning and POC discussions.
Develop and optimize procedures to “productionalize” data science models
Define and manage SLA’s for data products and processes running in production
Support large-scale experimentation done by data scientists
Prototype new approaches and build solutions at scale
Research in state-of-the-art methodologies
Create documentation for learnings and knowledge transfer
Create and audit reusable packages or libraries
COVID-19 vaccination is a condition of employment for this role. Please note that all such company vaccine requirements provide the opportunity to request an approved accommodation or exemption under applicable law
Qualifications / Requirements :
BA/BS in Computer Science, Math, Physics is mandatory.
2+ years of overall technology experience that includes hands-on building data engineering pipelines
2+ years of experience in SQL optimization and performance tuning, and development experience in programming languages like Python, PySpark, Scala etc.)
1+ years in cloud data engineering experience in Azure or AWS
1+ Years in building data engineering pipelines in Azure (ADF and databricks)
Job Type: Full-time
Pay: $90,000.00 - $100,000.00 per year
Benefits:
401(k) matching
Dental insurance
Health insurance
Retirement plan
Vision insurance
Schedule:
8 hour shift
Education:
Bachelor's (Required)
Experience:
SQL: 2 years (Required)
Cloud: 2 years (Required)
Work Location: Remote",glassdoor
216,"Apple
4.2
Data Engineer
Cupertino, CA

 Summary
Posted: Aug 10, 2022
Weekly Hours: 40
Role Number:200406892
Are you a big-picture thinker who loves setting ambitious goals? Do you have a passion for understanding how each line of code affects all the others? In the Core Operating Systems group, you’ll ensure the OS is inseparable from each device’s identity as a whole. That’s because this group is committed to building fully integrated operating systems that combine hardware, software, and apps into a single Apple experience. Your dedication to cross-disciplinary collaboration will help develop groundbreaking technologies, such as iOS, macOS, watchOS, and tvOS. By crafting these distinct, holistic user experiences, you’ll continue to uphold and advance the excellence people expect from Apple devices. The Platform Services & Operations team in Core OS is looking for a Data Engineer to inform and develop essential workflow tooling at scale. The Workflow Engineering team enable teams to deliver high quality software through best in class engineering experiences, efficient workflow, data driven insights, and a culture of continuous improvement. Your focus is building the backend data pipelines that enables visualization of data across the organization in user intuitive and configurable formats.
Key Qualifications
3 +proven experience in a Data focused posistion
Proficient in Python; data access and retrieval. Quantitative data preparation. Regular expressions and text analysis
Highly Proficient in Database Language and Design; querying large stores of data (APIs, SQL, etc.).
Access, retrieval, and storage of information. Data Structures, modeling for speed and efficiency
Software Development; understanding of build pipelines, branching and merging, Agile methods, and the delivery of code. Fluency in Git (or comparable source control tool)
Description
- Replicate data from source system into data warehouse; retrieve data through various protocols and land it in a central store - Automate data pipelines; write programs to periodically update warehouse data from source systems - Design for scale; flexible infrastructure for common enhancements including: expanding the volume of captured data, adding fields to the user-facing views, and recompiling archived data - Work with a team of data scientists and full stack engineers, to derive and develop targeted insights through centrally managed interactive dashboards
Education & Experience
B.S. in Data Science, Computer Science, or equivalent experience.
Additional Requirements
Experience as an Analyst; worked in the delivery of visual information (dashboards, reports, web-apps)
An understanding of how data can be used and applied in context (what is useful to capture and how it can be communicated)
Full Stack Development; ability to maintain back-end systems and visualize front-end data for users (with a web-kit framework like Angular, React)
Experience with Snowflake and/or other data store technologies",glassdoor
217,"Twitch
4.0
Data Engineer
San Francisco, CA
Employer Provided Salary:$140K - $171K

 About Us
Twitch is the world's biggest live streaming service, with global communities built around gaming, entertainment, music, sports, cooking, and more. It's where millions of people come together to chat, interact, and make their own entertainment.
We're about community, inside and out. You'll find coworkers who are eager to team up, collaborate, and smash (or elegantly solve) problems together. We're on a quest to empower live communities, so if this sounds good to you, see what we're up to on LinkedIn and Twitter, get interviewing tips on Instagram, and discover projects we're solving on our Blog.
About the Role
Reporting to the Head of Global Talent Acquisition, the Data Engineer will expand the reach and role of data among leaders and managers at Twitch. You will empower the business to integrate data into their daily workflow by creating/maintaining data pipelines, producing reporting, and automating our processes.
You can work in San Francisco, CA or remotely across the US.
This role is for you if:
You love automating processes and developing efficient scalable solutions
You're excited about contributing to the success, efficiency, and happiness of Twitch staff
You're excited to jump into a diverse array of data work to support the team
You enjoy working with autonomy and shaping a new function

You Will:
Delight consumers of people-related data by ensuring they have the data they need to inform decisions, where and when they need it
Build and own data pipelines, SQL queries/views, and apps
Automate processes through the use of JavaScript and other languages
Improve business, engineering, and data processes through data architecture, engineering, testing, and operational excellence best practices
Ensure the integrity of People and Places data in analyses and tools through regular audits
Partner to develop analytics products and recommend opportunities
Develop ongoing metrics, analyses, and dashboards to guide important decisions
You Have:
Experience writing SQL and a procedural language (Python, R, etc.) for data handling
Experience owning systems that collect, transform, and visualize data
Experience implementing data analytics, visualization tools and programs for HR working with Workday, Greenhouse, Tableau, Google Workspace, Google Data Studio, and Google Sheets
Experience implementing software solutions to automate data source, visualization and analytics products
Bachelors in related field, or equivalent experience
Bonus Points
Experience handling People-related data including compensation, performance, hiring, and engagement data.
Experience automating Google services (Sheets, Docs, Data Studio) with Javascript
Experience with Workday, Greenhouse, and Tableau
Demonstrated net positive contributor to company community and culture above and beyond the core job
Perks
Medical, Dental, Vision & Disability Insurance
401(k), Maternity & Parental Leave
Flexible PTO
Commuter Benefits
Amazon Employee Discount
Monthly Contribution & Discounts for Wellness Related Activities & Programs (e.g., gym memberships, off-site massages, etc.),
Breakfast, Lunch & Dinner Served Daily
Free Snacks & Beverages
We are an equal opportunity employer and value diversity at Twitch. We do not discriminate on the basis of race, religion, color, national origin, gender, gender identity, sexual orientation, age, marital status, veteran status, or disability status, or other legally protected status.
Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
Pursuant to the Los Angeles Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
The base pay range for this position in Colorado, Connecticut and Washington is $139,860 - $170,940 yr and in New York City is $153,900 - $188,100 yr. Pay is based on market location and may vary depending on job-related knowledge, skills, and experience. A sign-on payment and restricted stock units may be provided as part of the compensation package, in addition to a full range of medical, financial, and/or other benefits, dependent on the position offered. Applicants should apply via Twitch's internal or external careers site.
Workers in New York City who perform in-person work or interact with the public in the course of business must show proof they have been fully vaccinated against COVID or request and receive approval for a reasonable accommodation, including medical or religious accommodation.
Twitch values your privacy. Please consult our Candidate Privacy Notice, for information about how we collect, use, and disclose personal information of our candidates.
Job ID: TW7236
#LI-Remote #RemoteFriendly",glassdoor
218,"Tesla
3.6
Data Engineer
Fremont, CA

 What to Expect
The Data Engineer is responsible for processing structured and unstructured data, validating data quality, and developing and supporting data products. We are looking for someone with strong hands on experience in all layers of data Integration and analytics! We especially need experience in using Python as an ETL tool. The Data Engineer plays a significant role in Agile planning, providing advice and guidance, and monitoring emerging technologies. Some of the technology we use: * Python * Informatica * SQL Server and MySQL * Vertica * Kafka

What You’ll Do
* Design, code, test, correct and document programs and scripts using agreed standards and tools to achieve a well-engineered result * Derive an overall strategy of data management, within an established information architecture that supports the development and secure operation of existing and new information and digital services * Plan effective data storage, security, sharing and publishing within the organization * Gathers and processes raw, structured, semi-structured, and unstructured data using batch and real-time data processing frameworks * Ensures data quality and implements tools and frameworks for automating the identification of data quality issues * Collaborate with internal and external data providers on data validation providing feedback and making customized changes to data feeds and data mappings * Mentor and lead data engineers providing technical guidance and oversight * Provides ongoing support, monitoring, and maintenance of deployed products

What You’ll Bring

* Strong experience with relational databases like SQL Server, MySQL and Vertica. NoSQL databases experience is a plus! * Strong background in data modeling, data access, and data storage techniques * Experience with design, development, and implementation of highly scalable, high-volume software systems and components, source of truth systems for different business areas, developing and maintaining web services in an agile environment * Working experience with Kafka Streaming layer * Experience in Spark Framework on both batch and real-time data processing is a plus * Experience in Big Data Integration & Analytics is a plus * Experience in Supply Chain and Logistics data is a plus",glassdoor
219,"Vimeo
4.1
Data Engineer II, Analytics
New York, NY
$107K - $150K (Glassdoor est.)

 Vimeo is looking for an experienced Data Engineer II, Analytics to join our Data Architecture and Analytics Engineering team and work closely with Data Analysts and Data Scientists to create and maintain robust, scalable, and sustainable data models that provide decision-making insights for senior leadership including executives. The ideal candidate is a self-starter with a bias for action and results, with experience in a fast-paced, data-driven environment.
What you'll do:
Build data models that can support dynamic and efficient data analysis, and collaborate with other teams to maintain and evolve those models over time
Ensure alignment to coding standard methodologies and development of reusable code
Partner with Data Analysts to understand business processes and identify opportunities to build scalable and efficient data models that can be used for scalable, refreshable analysis and reporting
Create and enable the generation of ad-hoc / on-demand data sets for use by analysts and data scientists
Work with Engineering teams to set up monitoring and alerting systems for business and product KPIs
Skills and knowledge you should possess:
BS/MS in Computer Science or a related technical field.
2+ years working with Analytics and Data Engineering teams with a mixed data engineering and analytics background
2+ years of experience in scalable data architecture, fault-tolerant ETL, and monitoring of data quality in the cloud
Experience working on or leading initiatives around data governance, master data management, data catalogs, and enterprise data warehouse architecture
Strong analytical skills, data sensibility, and an able communicator
Open to working on multiple projects simultaneously
Proficiency in:
SQL
Python
Dimensional Modeling
Data pipeline development, workflow management, and orchestration tools
ETL optimization and best practices
Snowflake or other column-oriented and cloud-based databases
Looker or any similar Business Intelligence tool
Relational Databases
Bonus Points (Nice Skills to Have, but Not Needed):
DBT
Git / Github
Looker/Tableau is a big plus
large data sets (terabyte scale)
Apache Airflow
#LI-JS1
Vimeo (NASDAQ: VMEO) is the world's leading all-in-one video software solution. Our platform enables any professional, team, and organization to unlock the power of video to create, collaborate and communicate. We proudly serve our growing community of over 260 million users — from creatives to entrepreneurs to the world's largest companies.
Vimeo is headquartered in New York City with offices around the world. At Vimeo, we believe our impact is greatest when our workforce of passionate, dedicated people, represents our diverse and global community. We're proud to be an equal opportunity employer where diversity, equity, and inclusion is championed in how we build our products, develop our leaders, and strengthen our culture.
Learn more at www.vimeo.com
Learn more at www.vimeo.com/jobs",glassdoor
220,"Antra, Inc
4.5
Jr. Data Engineer
Sterling, VA
Employer Provided Salary:$60K - $68K

 Antra started its services in the year 2008, since then we have been diligently serving every need of our clients professional and software solutions. With our unique amalgam of innovation and inspiration, backed by Agile processes, we deliver world-class services with our core values to our clients. We identify unique strategies to transforming organizations through picking their sweet spot for innovative thinking and helping them in implementing in-depth cultural shift; ultimately augmenting the innovation process to the next level – fostering the innovation race that never ends.
This role requires the design, development and implementation of data solutions to business problems. An Azure Data Engineer will be expected to perform duties such as: evaluating the performance of current data solutions, designing and implementing cloud and hybrid data solutions. Ability to adapt and learn new technologies per business requirements is also needed.
Responsibilities:
Design and implement data solutions using industry best practices.
Performs ETL, ELT operations and administration of data and systems securely and in accordance with enterprise data governance standards.
Monitor and maintain data pipelines proactively to ensure high service availability.
Works with Data Scientists and ML Engineers to understand mathematical models and optimize data solutions accordingly.
Continuous development through training and mentorship programs.
Create scripts and programs to automate data operations.
You meet our “must haves” for this role if you have:
Minimum Bachelor’s degree in Data Science, Business Intelligence, Computer Science or related fields, or the equivalent combination of education, professional training, and work experience.
0-3 years of experience working with one or more languages commonly used for data operations including SQL, Python, Scala and R.
Experience working with relational databases such as SQL Server, Oracle and MySQL.
Experience working with NoSQL databases such as Redis, Mongo DB, Cosmos DB.
Excellent problem-solving skills and ability to learn through scattered resources.
Thorough understanding of the responsibilities and duties of a data engineer, as well as established industry standards/best practices and documentation guidelines.
Outstanding communication skills, and the ability to stay self-motivated and work with little or no supervision.
Willing to relocate to any US location on Antra projects location.
Authorization(s) to work lawfully in the United States (OPT/CPT is acceptable).
Plus, if you meet any the of requirements:
Experience with cloud-based data technologies.
Experience with distributed systems utilizing tools such as Apache Hadoop, Spark or Kafka.
Working experience in Agile Scrum environments.
Experience with source control tools such as Git, SVN and TFS.
The intent of this position description is to provide a representative summary of the major duties and responsibilities performed by incumbent(s) in this position. Incumbent(s) may not be required to perform all duties in this description and incumbent(s) may be required to perform position-related tasks other than those specifically listed in this description.
Antra Inc. is an equal opportunity employer, providing equal employment opportunities (EEO). All employees and applicants for employment will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity or expression, pregnancy, protected veteran status or other status protected by law. This policy applies to all terms and conditions of employment.
Job Types: Full-time, Contract
Pay: $60,000.00 - $68,000.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Health savings account
Life insurance
Paid time off
Professional development assistance
Referral program
Relocation assistance
Vision insurance
Schedule:
Monday to Friday
Application Question(s):
Are you open for relocation within the US?
Education:
Bachelor's (Preferred)
Work Location: Hybrid remote in Sterling, VA 20166",glassdoor
221,"Qualtrics
4.2
Data Engineer
Provo, UT
$83K - $125K (Glassdoor est.)

 The Qualtrics XM Platform™ is a system of action that helps businesses to attract customers who stay longer and buy more, to engage and empower employees to do the best work of their lives, to develop breakthrough products people love, and to build a brand people can’t imagine living without.

Joining Qualtrics means becoming part of a team bold enough to chase breakthrough experiences - like building a technology that will be a force for good. A team committed to diversity, equity, and inclusion because of a conviction that every voice holds value, with a vision for representation that matches the world around us and inclusion that far exceeds it. You could belong to a team whose values center on transparency, being all in, having customer obsession, acting as one team, and operating with scrappiness. All so you can do the best work of your career.

We believe every interaction is an opportunity. Are we yours?
The Team
Our team is a collection of deeply passionate engineers who are riding the groundbreaking of cloud computing and web scalability. We built data analytics applications that help company leaders gain insights about technology spends, make sound decision on technology investments, and drive innovation in resource utilization and efficiency optimizations. Our environment is primarily TypeScript, Node.js, React, MySQL NoSQL, AWS, Python, PHP, and Docker. In our collaborative culture, you find plenty of opportunities to impact our full-stack products; from Web & mobile UI to data visualization & analysis to data ingestion, storage and processing.
Job Responsibilities
Developing scalable, fast, robust, and simple web-based solutions to solve complex business problems
Close collaboration with your team to collect and incorporate feedback into your feature design
Drive operational excellence by investigating production issues, driving root cause analysis and follow-up actions for mitigation
Improve performance, availability, reliability, scale, throughput and latency
Work with your team in order to meet customer work you're doing, understand the decisions that are being made and make your voice heard.
Qualifications
Bachelor's degree in Computer Science or related field
Coding experience with any programming language (Prefer experience in TypeScript/JavaScript/React/Python)
Experience with web infrastructure and distributed systems
Experience with software engineering best practices (e.g. unit testing, code reviews, design, continuous delivery, git, test automation and build\deploy systems)
Ability to work in a fast-paced and agile development environment and to learn new frameworks/stacks
Passionate about building products that help customers easily and effectively get their job done
Enthusiastic person, who communicates effectively and is easy to work with
Curious and constantly learning on your own and from others
You get satisfaction from helping others succeed, and you constantly seek ways to improve
You can identify gaps, propose solutions to important problems, then take it to resolution
Preferred Qualifications
Shown ability to troubleshoot and identify the root cause of issues
Demonstrated skill and passion for operational excellence
Experience in a 24/7 production environment is a plus
Ability to retain composure under stressful conditions, communicate effectively with wide array of individuals at Qualtrics, and get the right things done
Confirmed ability to understand large systems, drilling down to code level",glassdoor
222,"Ultra Mobile
4.4
Digital Data Engineer I - Remote
Costa Mesa, CA
Employer Provided Salary:$90K - $103K

 ULTRA MOBILE is seeking a talented Digital Data Engineer I to join the Data Management Team! Individual reports to Customer Data Manager. Role is remote; must reside in the United States.
ABOUT THE ROLE
Provide direct data engineering development to data pipelines for ETL establishment and enhancements to and from data warehouses to customer management platform (Braze). Work collaboratively with cross-functional teams to determine digital data needs, establish data collection requirements, and deploy & maintain accurate data to ensure metrics & dimensions are addressed for analytics/reporting requirements.
Your usual day of awesomeness includes:
Transform required data conditions into performance code logic.
Develop high-performance code in SQL and Python.
Develop, automate, and enhance ELT processes for continuous data flow.
Create, modify, and deploy code to production via AWS resources including Lambda, S3, Glue, Redshift, etc.
Partner with stakeholders to support the implementation and development of data requirements.
Troubleshoot data anomalies and provide applicable solutions.
Build, test and maintain database pipeline architectures.
WHAT YOU BRING
Advanced level in SQL and Python for data engineering and backend development.
Understanding of popular code development approaches:
Test-driven development
Continuous Integration/Continuous Deployment (CI/CD)
Experienced working with AWS services (Lambda, S3, Glue, Redshift etc.) and Cloud Data Warehouse.
Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
Define digital data collection methods and implementations to DWH and customer management platforms.
Experienced with QA testing process to verify data is collected & rendered as expected.
Ability to excel in a fast-paced, cross-functional environment.
Ability to work autonomously.
Excellent written and verbal communication skills.
Proactive problem-solving and critical thinking skills.
Ability to manage time effectively and consistently meet deadlines.
NICE TO HAVE
Prior working knowledge of Braze or other Customer Management Platforms
Snowflake Cloud Data Warehouse
Terraform/Bitbucket/Airflow/Jenkins
Looker, Tableau, Power BI
WE ARE ULTRA & MINT MOBILE
We connect people to what's most important in their lives: Easily, affordably and reliably. We strive to be California's Preeminent Destination Employer. Oh yeah, we get it too! We understand what matters to you most. You're an individual with unique needs, and we're prepared to exceed any expectations you have for an ideal employer.
We're smart, strategic, and get things done without a lot of red tape or unnecessary politics. Everyone matters here and everyone has a voice. Expect to spend your time contributing to projects that really matter. We obsess over the employee experience. To start, we provide some of the most competitive salary, benefits, family leave, vacation, retirement and equity options in Southern California. We believe in you and invest in you. Not just your career aspirations, but your life.
In addition, we've got a laundry list of perks you'll brag about on insta - Lunch every day prepared by our very own chef, healthy snacks, onsite gym, free massages, car wash services, and most importantly, a team atmosphere. We even raise the bar on well bars, including Espresso/Cappuccino/Nitro/Cold Brew/Kombucha Bar, Froyo Bar, Breakfast Bar, Snack Bar and a, well, you know, bar (after 5 pm).
And if you feel intrigued right now reading, imagine the co-workers we have already attracted. This is the kind of team you'll want to take home to mom or invite to your kid's next birthday party. This is the kind of close-knit community happening here. Come check out how you can be part of Ultra & Mint!
OUR VALUES – LET'S MAKE LIFE ULTRA TOGETHER!
Ownership: We are all owners; be the outcome and get the job done.
Action Biased: Be brilliant, proactive, and act with urgency.
Embrace the Adventure: Be agile, adaptive, and thrive on change.
Invent and Simplify: Never accept good enough.
$1,000 REFERRAL BONUS
Take a look at this job description, if you are the right person, please apply. If Ultra Mobile doesn't appear to be a fit for you, refer a friend or colleague and get $1,000. Let your friend or colleague know to provide your full name and email when applying to the job. If we hire them and they stay for 90 days, you get $1000. For more details of restrictions and rules, please email recruiting@ultra.me.

Covid-19 Vaccination Requirement
UVNV, Inc. has adopted a mandated vaccination policy to support the health and safety of our team members and our community. The Company requires all employees to be fully vaccinated. The Company will provide accommodations based on medical condition or sincerely held religious beliefs or practices. Please let us know if you'd like to discuss the policy or available accommodations before proceeding with our recruitment process.
We are committed to equal employment opportunities regardless of race, color, genetic information, creed, religion, sex, sexual orientation, gender identity, lawful alien status, national origin, age, marital status, or protected veteran status. We support an inclusive workplace where associates excel based on personal merit, qualification, experience, ability, and job performance.
In support of the Equal Pay for Equal Work Act, the range of starting pay for this role is $90,000 - $103,000. This is not a guarantee of compensation or salary, actual compensation is influenced by a wide range of factors including but not limited to skill set, level of experience, education, certifications, responsibility, and geographic location. We also offer a variety of benefits including health, disability insurance, 401 (k), flexible spending accounts, EAP, education reimbursement, parental leave, unlimited vacation, bonuses, incentive stock options and company paid holidays. The specific programs and options available will vary depending on state, start date, and employment type. Our recruitment team will be happy to answer any questions you may have.
#LI-Remote",glassdoor
223,"NucleusTeq
4.9
Data Engineer
Remote

 Data Engineer
Role Info:
Hands on BI Data Engineer role with strong
Creating KPI Dashboards - Interactive Dashboards using tableau / Quicksight
Top Skills:
BI Tableau / AWS Quicksight exp is a must
AWS (IAM, RDS, S3, Lambda) exp is a must
SQL exp is a must
Python knowledge is required
Nice to have:
AWS Certified Solutions Architect
About the Company:
NucleusTeq is a software services, solutions & products company empowering & transforming customer's business through the use of digital technologies such as Big-Data, Analytics, Cloud, Enterprise Automation, Block-chain, Mobility, etc.
We are enabling several fortune 1000 clients in the USA, Canada, UK & India to navigate their digital transformation.",glassdoor
224,"Accenture
4.1
Data Engineer
San Francisco, CA

 Accenture Flex offers you the flexibility of local fixed-duration project-based work powered by Accenture, a leading global professional services company. Accenture is consistently recognized on FORTUNE's 100 Best Companies to Work For and Diversity Inc's Top 50 Companies For Diversity lists.
As an Accenture Flex employee, you will apply your skills and experience to help drive business transformation for leading organizations and communities. In addition to delivering innovative solutions for Accenture's clients, you will work with a highly skilled, diverse network of people across Accenture businesses who are using the latest emerging technologies to address today's biggest business challenges.
You will receive competitive rewards and access to benefits programs and world-class learning resources. Accenture Flex employees work in their local metro area onsite at the project, significantly reducing and/or eliminating the demands to travel.
Job Description:
As a Data Engineer, you will:
Utilize strong SQL & Python expertise to engineer sound data pipelines and conduct routine and ad hoc analysis to assess the performance of legacy products and the saliency of new features
Build reporting dashboards and visualizations to design, create, and track campaign/program KPIs
Perform analyses on large data sets to understand drivers of marketing engagement and provide recommendations on campaign and product optimization

Basic Qualifications:
Minimum 2 years of experience in Data Engineering
Minimum 2 years of experience with SQL
Minimum 2 years of experience with Python
High School Diploma or GED
Preferred Qualifications:
Experience with Data Analytics
As required by Colorado Law under the Equal Pay for Equal Work Act, Accenture provides a reasonable range of compensation for roles that may be hired in Colorado. Actual compensation is influenced by a wide array of factors including but not limited to skill set, level of experience, and specific office location. For the state of Colorado only, the starting range of pay for this role is $86.82 - $96.82 per hour, and information on benefits is here.

COVID-19 update:

The safety and well-being of our candidates, our people and their families continues to be a top priority. Until travel restrictions change, interviews will continue to be conducted virtually.

Subject to applicable law, please be aware that Accenture requires all employees to be fully vaccinated as a condition of employment. Accenture will consider requests for accommodation to this vaccination requirement during the recruiting process.

What We Believe

We have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture has the responsibility to create and sustain an inclusive environment.

Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more here

Equal Employment Opportunity Statement

Accenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation.

All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.

Accenture is committed to providing veteran employment opportunities to our service men and women.

For details, view a copy of the Accenture Equal Opportunity and Affirmative Action Policy Statement.

Requesting An Accommodation

Accenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.

If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.

Other Employment Statements

Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States.

Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.

Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.

The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.",glassdoor
225,"Mercury
3.7
Data Engineer
San Francisco, CA
$104K - $152K (Glassdoor est.)

 SF, NY, Toronto, Portland, or remote
Full-time
Mercury
In the 1880s, Herman Hollerith noticed the US Census was taking over 8 years to calculate. To solve this, he invented a tabulating machine using punch cards that dramatically sped up the process and served as the foundation for innovation in high quality data gathering.
We’re looking for our first Data Engineer who can help us build our high quality data engine that informs how we invest in and build Mercury’s future. You’ll be early to building a data-informed culture across Mercury so that we can all determine what’s happening, react quickly, and invest intelligently.
Here are some things you’ll do on the job:
Partner with leadership, engineers, and data scientists to understand data needs and build systems that deliver high quality and reliable data.
Own and maintain the data systems that extract, transform, and load data into internal and external tooling.
Apply proven expertise and build high-performance scalable data warehouses.
Design, build, and launch efficient & reliable data pipelines to move and transform data (both large and small amounts).
Design and develop new systems in partnership with software engineers to enable quick and easy consumption of data.
You should:
Have 2+ years of experience working with analytics teams on building high quality and reliable data infrastructure.
Be able to navigate from architecture and implementation decisions related to data infrastructure to guide teams towards building reliable and accurate pipelines and company-critical data sets.
Have familiarity with postgres backend data, Snowflake, and data transformation tools like dbt.
Value quality in data tools, testing, and innovation.",glassdoor
226,"Lincoln Financial
3.6
Data Engineer (REMOTE)
Radnor, PA
Employer Provided Salary:$63K - $138K

 Date: Oct 9, 2022
Primary Location: Radnor, PA, US
Company: Lincoln Financial
Alternate Locations: Work from Home

Work Arrangement: Work from Home

Relocation assistance:: is not available for this opportunity.

Pay Range: $63,100 - $137,900

Bonus Potential: 5%

Requisition #: 69444

The Role at a Glance

This is an exciting opportunity within Lincoln’s Work Place Solutions IT Data Team for a Data Engineer/ETL Developer to help build solutions for Lincoln’s Work Place Solutions business. This position will assist Analytic Teams with the design and implementation of Data solutions and systems, including integration with databases and data warehouses, both on-Premise and in AWS Cloud. This candidate must be able to develop, enhance, and support Informatica workflows and processes using Informatica Power Center and Dataiku for the extraction and transformation of data in a UNIX and Oracle database environment. They must also have experience working within BI tools such as Tableau and Microstrategy. Experience working in the cloud using AWS native services such as Glue, Athena, Aurora, Redshift, and/or Snowflake is needed. The candidate must have experience participating in and beginning to lead teams within a Data Organization by suggesting new and innovative ways of gaining data processing efficiencies and participating in architectural and modeling discussions.

What you'll be doing

Participates in defining architecture and modeling best practices within the team
Develop tools and work on integrating disparate systems using ETL
Work on transformation of data into Facts and Dims in a Kimball and/or relational model
Works with Sr. Technical Professionals to implement data development best practices
Develop, enhance and support Informatica workflows and processes using Informatica Power Center for the extraction and translation of data in a UNIX and Oracle database environment
Develop, enhance and support Dataiku workflows and processes for transforming data into Kimball model Facts/Dims
Creates partnerships with stakeholders, POs, BSAs and Analytic teams in requirement, design and coding walkthroughs to ensure the development of quality solutions and understand complex business/technical problems and opportunities and identify potential application solutions.
Demonstrates expertise in a variety of the data warehouse concepts, practices, and procedures. Relies on extensive experience and judgment to plan and accomplish goals
Analyzes operational and analytical data requirements by working with cross functional business and application development teams
Maintains knowledge on current and emerging developments/trends for assigned area(s) of responsibility, assess the impact, and collaborates with senior management to incorporate new trends and developments in current and future solutions.
Participate with collaboration efforts with development teams to review, update and approve the data portion of project designs, participate in cost/benefit analysis and preparation of project plans.
Participate in the design, development and delivery data centric IT solutions, including large scale data staging and orchestration, integration and provisioning mechanisms
Works with business partners to prioritize business and information needs
Provides input and validates increasingly complex project plans, test plans and implementation plans
Creates increasingly complex technical specifications from business requirements/business specifications
Proactively identifies problems and presents/develops solutions
Communicates effectively with internal stakeholders and management
Defines detailed development tasks, task dependencies and estimates to complete work
What we're looking for

4 Year/Bachelor's degree or equivalent work experience (4 years of experience in lieu of Bachelor's) in Computer Science, Computer Information Systems, Information Systems, Information Technology or Computer Engineering or equivalent work experience (Minimum Required
3 - 5+ Years’ experience in application development that directly aligns with the specific responsibilities for this position (Required)
Experience with ETL development
Must have experience with Informatica; Dataiku is a plus
Must have experience with BI tools such as Tableau and Microstrategy
Experience with AWS cloud native services, such as: Glue, Athena, Aurora, Redshift
Must have a proven track record working closely with business stakeholders, BSAs, and POs, Solution Architects to understand requirements and expectations to achieve quality technical solutions
What’s it like to work here?
At Lincoln Financial Group, we love what we do. We make meaningful contributions each and every day to empower our customers to take charge of their lives. Working alongside dedicated and talented colleagues, we build fulfilling careers and stronger communities through a company that values our unique perspectives, insights and contributions and invests in programs that empower each of us to take charge of our own future.

What’s in it for YOU:
A clearly defined career framework to help you successfully manage your career
Leadership development and virtual training opportunities
PTO/parental leave
Competitive 401K and employee benefits
Free financial counseling, health coaching and employee assistance program
Tuition assistance program
A leadership team that prioritizes your health and well-being; offering a remote work environment and flexible work hybrid situations
Effective productivity/technology tools and training

Work Arrangement
Work from Home : Employees will work from home and are not required to work in a Lincoln office on a regular basis.

Lincoln will evaluate the following when setting the successful candidate's wage rate:
Prior work or industry experience.
Education level to the extent education is relevant to the position.
Unique skills

About The Company
Lincoln Financial Group, a Fortune 200 company with over 10,000 employees, provides advice and solutions that help empower Americans to take charge of their financial lives with confidence. Our core business areas — Life Insurance, Annuities, Retirement Plan Services and Group Protection — focus on supporting, preserving and enhancing over 17 million customer’s lifestyles and retirement outcomes.

Headquartered in Radnor, Pennsylvania, Lincoln Financial Group is the marketing name for Lincoln National Corporation (NYSE: LNC) and its affiliates. The company had $324 billion in end-of-period account values as of June 30, 2021.

Ranked one of the Best Large Employers in America and Best Employers for Women by Forbes magazine as well as one of Newsweek’s Most Responsible Companies, Lincoln Financial Group makes a serious investment in our employees’ futures through a broad range of wealth accumulation and protection plans, health and wellness programs, and career development resources designed to help each individual reach their personal and professional goals.

Lincoln is committed to creating a diverse and inclusive environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.

Lincoln Financial Group is a committed corporate citizen included on major sustainability indices including the Dow Jones Sustainability Index North America and FTSE4Good. Dedicated to diversity and inclusion, we earned perfect 100 percent scores on the Corporate Equality Index and the Disability Equality Index. Follow us on Facebook, Twitter, LinkedIn, and Instagram.

Be Aware of Fraudulent Recruiting Activities
If you are interested in a career at Lincoln, we encourage you to review our current openings and apply on our website. Lincoln values the privacy and security of every applicant and urges all applicants to diligently protect their sensitive personal information from scams targeting job seekers. These scams can take many forms including fake employment applications, bogus interviews and falsified offer letters.
Lincoln will not ask applicants to provide their social security numbers, date of birth, bank account information or other sensitive information in job applications. Additionally, our recruiters do not communicate with applicants through free e-mail accounts (Gmail, Yahoo, Hotmail) or conduct interviews utilizing video chat rooms. We will never ask applicants to provide payment during the hiring process or extend an offer without conducting a phone, live video or in-person interview. Please contact Lincoln's fraud team at fraudhotline@lfg.com if you encounter a recruiter or see a job opportunity that seems suspicious.

Additional Information
This position may be subject to Lincoln’s Political Contribution Policy. An offer of employment may be contingent upon disclosing to Lincoln the details of certain political contributions. Lincoln may decline to extend an offer or terminate employment for this role if it determines political contributions made could have an adverse impact on Lincoln’s current or future business interests, misrepresentations were made, or for failure to fully disclose applicable political contributions and or fundraising activities.

Any unsolicited resumes/candidate profiles submitted through our web site or to personal e-mail accounts of employees of Lincoln Financial Group are considered property of Lincoln Financial Group and are not subject to payment of agency fees.

Lincoln Financial Group (“LFG”) is an Equal Opportunity employer and, as such, is committed in policy and practice to recruit, hire, compensate, train and promote, in all job classifications, without regard to race, color, religion, sex (including pregnancy), age, national origin, disability, sexual orientation, gender identity and expression, Veteran status, or genetic information. Applicants are evaluated on the basis of job qualifications. If you are a person with a disability that impedes your ability to express your interest for a position through our online application process, or require TTY/TDD assistance, contact us by calling 260-455-2558.",glassdoor
227,"National Research Group
3.7
Data Engineer
San Francisco, CA
$88K - $128K (Glassdoor est.)

 Who We Are
National Research Group (NRG) is a leader in data driven insights and strategic consultation to the global entertainment and technology industries. Working at the confluence of technology, content, and culture, NRG offers bold insights for storytellers everywhere. Our consultants have experience working across all facets of media and technology.
Why You'll Love It Here
We are inspired by working with storytellers that challenge us to think differently and see the world in new ways. As a result, our business is driven by creative, curious, and inventive people who have a passion for pop culture. We work as a collective across disciplines and geographies to bring together the best thinking for every assignment, delivering insights to bold storytellers everywhere.
The Opportunity
We are looking for a data engineer with a background in building and maintaining data pipelines to integrate and process diverse data sources and data formats. This candidate should have a minimum of 1-year experience for a full-time position within our fast paced and growing company.
If you feel that you can make an impact through innovation and collaboration and come to work with a passion to facilitate in delivering high quality data to our teams and clients, this is a great role for you.
The Role
Build, test, orchestrate, and maintain data pipelines that support the data sciences team and customer-facing client teams.
Assist in ad-hoc data deliveries by querying data from various SQL relational databases stored in multiple data models.
Track and manage pipeline efficiency and stability.
Evaluate, parse, clean, and integrate raw data sets including third party APIs. Help build sophisticated ETL processes around first party data such as survey data, second and third-party data sources such as IP addresses, clickstream data, movie meta data.
Provide recommendations for data storage, configurations, data access tools and new technologies/architectures.
Develop code-based data transformation/aggregation in data lakes, relational databases (primary use cases) and possibly non-relational databases, as well as for the purpose of BI tools such as Power BI and Tableau.
Participate in developing data APIs for data ingestion of NRG data into client-side applications or client-side data systems.
Assist application developers in the effective use of database query and programming languages.
Contribute to managing data integrity, data storage efficiency and data ecosystem efficiency.
Who You Are
Team asset who can describe data structures, relationships, and flows behind organization database servers and applications.
Up to date on the latest data-related best practices and technologies and always looking to learn more.
Internally motivated self-starter who continuously strives to get things done, regardless of challenges encountered.
Critical thinker, able to understand and respond to complex questions or issues that may arise, and able to demonstrate willingness to experiment with new technologies.
Successfully manages time and multiple competing priorities in order to ensure deadlines are always met.
Team player who is able to work collaboratively and initiate and drive projects to completion with minimal oversight.
Ideal Candidate
BS/BA in Computer Science or related field.
1+ year experience in building data pipelines or ETL.
1+ year experience with SQL (we use Snowflake but other experience with relational databases is welcome).
1+ year experience with AWS technologies/infrastructure.
Working knowledge with Python.
A solid foundation with end-to-end development and the desire to further their technical knowledge.
Knowledge of PII (personally identifiable information) data security standards is a plus.
dbt experience is a plus.
Terraform experience is a plus.
Dagster experience is a plus.
Experience in databases structured against survey data is a big plus.
Position Type
This is a full-time, exempt position.
Work Environment
This position is expected to be fully remote. However, NRG offers flexible work options if an employee happens to live near a dedicated office (Playa Vista or New York) and wants a hybrid work model. This role routinely uses standard office equipment.
Required Application Materials:
CV/Resume
Cover Letter which should include:
Why do you want to work at NRG?
Why are you interested in working in the entertainment industry?",glassdoor
228,"Apple
4.2
Machine Learning Data Collection Engineer, Technology Development Group (TDG)
Cupertino, CA

 Summary
Posted: Mar 15, 2022
Role Number:200356922
Do you want to push the limits of the best Augmented Reality platform in the world? Apple's Technology Development Group (TDG) delivers algorithms that drive revolutionary Apple products, including the augmented reality (AR) platform ARKit to create ground-breaking new products. In this position, you will have the opportunity to be part of our extraordinary data team to discover and build solutions to previously-unsolved challenges and push the state of the art in AR algorithms that will change the way people experience the world! We are looking for a driven Machine Learning Data Collection Engineer that enjoys getting into the details to collect valuable data that feeds our machine learning models. As a member of the fast-paced data team, you have the rewarding opportunity to shape upcoming products that will delight and inspire millions of people every day. To succeed within this role, you should have shown experience in several of the following areas:
Key Qualifications
Ability to define/design/develop data collection efforts that focus on the end-to-end user experience, including anticipating potential failure modes, edge cases, and anomalies
Capacity to multitask and manage several projects in parallel while meeting deadlines and providing access to clients and partners
Problem solving & critical thinking capacities, thinking outside the box in order to gain in speed, efficiency, and quality.
Ability to re-construct ill-defined data needs into concrete project deliverables
Ability to maintain and develop relationships with multi-functional teams
Excellent project management, communication, interpersonal, analytical, and organizational skills
Description
As a Machine Learning Data Collection Engineer, you'll be working with our customers to understand their data collection requirements, assisting them in defining their protocols, and executing on the data collection. Your job responsibilities will include: -Collaborate with algorithm teams and understand data collection requirements in order to define collection protocols -Define and design the collection requirements and lead the collection effort from start to finish -Coordinate the efforts between internal teams (Legal, privacy, security, etc) guaranteeing compliance with applicable rules, laws, and best practices -Create documents and procedures needed to run data collections -Managing and track progress of externally run data collections
Education & Experience
Bachelors degree or related practical experience
Additional Requirements",glassdoor
229,"Apple
4.2
Biomedical Data Engineer - Health Technologies
Cupertino, CA

 Summary
Posted: Aug 8, 2022
Weekly Hours: 40
Role Number:200402289
The Health Technologies Team conceives and proves out innovative technology for Apple’s future products and features in health. We are seeking a highly capable Biomedical Data Engineer to join a multi-disciplinary team. Successful candidates will be able to integrate with our research study leads, data scientists and engineers to develop and support effective data analysis and machine learning workflows.
Key Qualifications
Experience with software engineering frameworks
Excellent coding skills in Python (e.g.,Pandas, Spark, Jupyter)
Workflow orchestrations (e.g., Airflow, Luigi)
Designing and maintaining (non-)relational databases (e.g. Postgres, Cassandra, MongoDB) and file systems (e.g. Parquet, CSV, JSON)
Great understanding of infrastructure designs
Linux, MacOS based development frameworks
iOS/ watchOS development (e.g., Swift, Objective-C)
Web Service APIs (e.g., AWS, REDCap, XNAT)
Version control frameworks (Git, virtualenv)
Familiarity with best practices for information security, including safe harbor privacy principles for sensitive data
Experience with biomedical sensors/platforms for measuring physiological signals in the health, wellness and/or fitness realms
Description
- Work closely with team members and study staff to design, build, launch and maintain systems for storing, aggregating and analyzing large amounts of data - Process, troubleshoot, and clean incoming data from human studies - Automate and monitor data ingestion and transformation pipelines, with hooks for QA, auditing, redaction and compliance checks per data management specifications - Create and maintain databases with existing and incoming clinical data - Architect data models and create tools to harmonize disparate data sources - Incorporate and comply with regulations as they pertain to electronic and clinical data and databases
Education & Experience
BS/MS in Computer Science, Engineering, Informatics, or equivalent with relevant 4+ years industry experience with biomedical, health or sensitive data.
Additional Requirements",glassdoor
230,"Farmers Insurance Group
3.7
Data Engineer (Application SME I)
Remote
Employer Provided Salary:$74K - $98K

 We are Farmers!
We are… more than just your favorite commercials. We are a passionate, award winning, equal opportunity employer, committed to the strength of a diverse workforce. We are dedicated to supporting the well-being of our people through our extensive suite of benefits, as well as the well-being of the communities we serve through employee volunteer programs and nonprofit partnerships. Helping others in their time of need isn’t just our business – it’s our culture! We are Farmers!

Do you thrive in a high-volume, fast-paced environment? Do you enjoy the challenge of a position where no two days are alike? We are looking for positive, high-energy professionals who are not just looking for a job, but a meaningful career!

Job Summary
Use MS SQL SSIS to build ETL process to create new business functionalities as well to solve business problems: Respond to new requests for reports/data understanding business objectives and processes; review and refine technical requirements/User Stories; and communicate estimated hours and timeline to complete; Extract data directly from relational databases (e.g. DB2, SQL Server), data warehouses, or other data stores using SQL; Ability to create manual as well as automated data exports/reports; and Support application unit testing for enhancements or system upgrades; identify and communicate data quality issues or data differences. Work productively on assigned tasks; Collaborate effectively with other team members; Demonstrate accountability to management and business for hours spent on assigned tasks; and diligently strive to deliver value.
Essential Job Functions
Education Requirements
High school diploma or equivalent required.
Bachelor’s degree preferred, in Information Systems or related field.
Experience Requirements
Experience in developing ETL and reporting applications using Microsoft SQL Server (strongly preferred), or Informatica or similar ETL technologies.
Experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process on MS SQL Server or DB2 or similar DB platform.
Experience with Python and unstructured data manipulation is a plus.
Experience with cloud technologies such as AWS Glue, Azure Data Factory, Snowflake is a plus.
Experience working in an Agile Environment is a plus.
Good knowledge of business intelligence best practices, processes, and methodologies.
Good programming experience in writing Stored Procedures, Queries, Views, User Defined Functions, and Common Table Expressions using SQL or T-SQL.
Highly committed, motivated, enthusiastic and a natural team player.
Good interpersonal and communication skills (both verbal and written) and ability to interact with and effectively address concerns.
Good prioritization, time management, analytical, and organization skills.
Experienced in facilitating in-person and remote meetings with business & IT.
Experienced in effective management of multiple competing and frequently changing assignments and priorities.

Benefits
Farmers offers a competitive salary commensurate with experience, qualifications and location
Colorado Only: The pay range for this job being performed in Colorado would be 73,600 - 98,100
Bonus Opportunity (based on Company and Individual Performance)
401(k)
Medical
Dental
Vision
Health Savings and Flexible Spending Accounts
Life Insurance
Paid Time Off
Paid Parental Leave
Tuition Assistance

Job Location(s): R_US - RW - Remote Work",glassdoor
231,"Apple
4.2
ML Data Collection and Data Science Engineer (TDG)
Cupertino, CA

 Summary
Posted: May 16, 2022
Role Number:200380146
Do you want to push the limits of the best Augmented Reality platform in the world? Apple's Technology Development Group (TDG) delivers algorithms that drive revolutionary Apple products, including the augmented reality (AR) platform ARKit to create ground-breaking new products. In this position, you will have the opportunity to be part of our extraordinary data team to discover and build solutions to previously-unsolved challenges and push the state of the art in AR algorithms that will change the way people experience the world! We are looking for a driven Machine Learning Data Collection Engineer that enjoys getting into the details to collect valuable data that feeds our machine learning models. As a member of the fast-paced data team, you have the rewarding opportunity to shape upcoming products that will delight and inspire millions of people every day. To succeed within this role, you should have shown experience in several of the following areas:
Key Qualifications
Ability to define/design/develop data collection efforts that focus on the end-to-end user experience, including anticipating potential failure modes, edge cases, and anomalies
Proficiency in programming languages including Python, C++, or similar
Capacity to multitask and manage several projects in parallel while meeting deadlines and providing access to clients and partners
Problem solving & critical thinking capacities, thinking outside the box in order to gain in speed, efficiency, and quality.
Excellent project management, communication, interpersonal, analytical, and organizational skills
Experience with industrial software development, a plus
Experience with CVML, a plus
Description
As a Machine Learning Data Collection Engineer, you'll be collaborating with multi-functional teams to work on CVML data collection projects, from collecting data collection requirements, designing protocols, testing software and hardwares, executing data collection, to analyzing and curating collected data. Your job responsibilities will include -Contribute to the design of CVML data collection, including hardware, software, user interface specifications, and collection protocols. -Define, implement, maintain SW and HW solutions to test data collection hardware, software and protocols. -Design, implement and maintain SW platforms to monitor date life cycle -Work with CVML engineers to design and implement data evaluation and curation process -Analyze data and build data analysis tools -Collaborate with multi-functional teams including algorithm, hardware, software, product design, project management, legal, procurement, security, logistics and vendors to define and deliver necessary study elements -Write technical documents including study instructions, operating procedures and training documents for study personnel -Drive process improvements across the organization to continuously improve the way we work
Education & Experience
B.S., M.S., or Ph.D. in Computer Science, Computer Engineering, or equivalent practical experience.
Additional Requirements",glassdoor
232,"Faire
4.8
Data Engineer
San Francisco, CA
$117K - $170K (Glassdoor est.)

 About Faire
Faire is an online wholesale marketplace built on the belief that the future is local — there are over 2 million independent retailers in North America and Europe doing more than $2 trillion in revenue. At Faire, we're using the power of tech, data, and machine learning to connect this thriving community of entrepreneurs across the globe. Picture your favorite boutique in town — we help them discover the best products from around the world to sell in their stores. With the right tools and insights, we believe that we can level the playing field so that small businesses everywhere can compete with these big box and e-commerce giants.
By supporting the growth of independent businesses, Faire is driving positive economic impact in local communities, globally. We're looking for smart, resourceful and passionate people to join us as we power the shop local movement. If you believe in community, come join ours.
Job Description
The Data Engineering team is the backbone of all data-related processes and enables the Data Science teams to develop and deploy a wide variety of algorithms and models that power the marketplace. Our infrastructure is used by the whole company for analytics, reporting, forecasting and research. We care about having a reliable & scalable infrastructure with quality data and building machine learning models that help our customers thrive.
As a Data Engineer you'll be responsible for developing and automating large scale, high-performance data storage and processing systems.
What you will be doing:
Develop our data infrastructure to help us scale for where we're going over the next several years
orchestrating pipelines using modern Big Data tools/architectures as well as design and engineering of existing transactional processing systems
Manage our data infrastructure and ETL platform
What it takes:
2+ years experience in a Data Engineering role with an emphasis on managing data warehouses
Strong skills in Python, Git, Docker, SQL, Airflow, real time ETL pipelines
Managing data infrastructure (AWS services, Data orchestrator) and providing framework to rationalize and simplify both real time and batch data pipelines
Familiarity with Snowflake or BigQuery
A passion for programming and solving problems with code
A bachelor's degree in Computer Science/Software Engineering or equivalent industry experience
A love for technology, and an insatiable curiosity for new tools to tackle real problems
Faire's flexible work model aims to meet the needs of our diverse employee community by making work more flexible, connected, and inclusive. Depending on the role and needs of the team, Faire employees have the flexibility to choose how they work–whether that's mainly in the office, remotely, or a mix of both.
Roles that list only a country in the location are eligible for fully remote work in that country or in- office work at a Faire office in that country, provided employees are located in the registered country/province/state. Roles with only a city location are eligible for in-office or hybrid office work in that city. Our talent team will work with candidates to determine what locations and roles are eligible for each option.
Why you'll love working at Faire
We are entrepreneurs: Faire is being built for entrepreneurs, by entrepreneurs. We believe entrepreneurship is a calling and our mission is to empower entrepreneurs to chase their dreams. Every member of our team is an owner of the business and taking part in the founding process.
We are using technology and data to level the playing field: We are leveraging the power of product innovation and machine learning to connect brands and boutiques from all over the world, building a growing community of more than 350,000 small business owners.
We build products our customers love: Everything we do is ultimately in the service of helping our customers grow their business because our goal is to grow the pie - not steal a piece from it. Running a small business is hard work, but using Faire makes it easy.
We are curious and resourceful: Inquisitive by default, we explore every possibility, test every assumption, and develop creative solutions to the challenges at hand. We lead with curiosity and data in our decision making, and reason from a first principles mentality.
Faire was founded in 2017 by a team of early product and engineering leads from Square. We're backed by some of the top investors in retail and tech including: Y Combinator, Lightspeed Venture Partners, Forerunner Ventures, Khosla Ventures, Sequoia Capital, Founders Fund, and DST Global. We have headquarters in San Francisco and Kitchener-Waterloo, and a global employee presence across offices in Salt Lake City, Atlanta, Toronto, London, New York, LA, and Sao Paulo. To learn more about Faire and our customers, you can read more on our blog.
Faire provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity or gender expression.
Faire is committed to providing access, equal opportunity and reasonable accommodation for individuals with disabilities in employment, its services, programs, and activities. To request reasonable accommodation, please fill out our Accommodation Request Form.",glassdoor
233,"Cigna
3.8
BI Data Engineer-Work from home-eviCore
Hartford, CT
Employer Provided Salary:$96K - $160K

 Duties
Build ETL processes to allow data to flow seamlessly from source to target using tools like Databricks, Azure Data Factory, SSIS, SQL Stored Procedures and Powershell scripting
Load and enhance dimensional data models
Leverage code to apply business rules to ensure data is clean and is interpreted correctly by all business stakeholders, using tools like Databricks, SQL, Scala and Python
Perform code reviews and QA
Participate in sprint ceremonies
Provide on-call support to offshore operations team
Train operations teams on the ETL processes being developed
Troubleshoot and address issues with the data and/or the ETL process
Fine tune existing code to make processes more efficient
Maintain and create documentation to describe our data management processes
Analyze reports using various tools like Micro Strategy, Tableau and SSRS
Support user questions on data management processes and results

Minimum Required Skills
5+ Years building Big Data and Data Warehousing solutions
Knowledge of data modeling (including dimensional modeling), data architecture & data governance concepts
Experience in working with implementations of Azure cloud data solutions (ADLS, Data Bricks, Synapse, ADF)
Proficient in database concepts and technologies including MS SQ Server, DB2 and Oracle
Excellent written and oral communications skills
Must be able to effectively communicate complex technical topics to a variety of audiences
Experience with Healthcare data is a plus

Minimum Education, Licensure and Professional Certification requirement:
Bachelor’s degree with relevant experience required.
Master’s Degree is a plus.

If you will be working at home occasionally or permanently, the internet connection must be obtained through a cable broadband or fiber optic internet service provider with speeds of at least 10Mbps download/5Mbps upload.

For this position, we anticipate offering an annual salary of 95,900 - 159,800 USD / yearly, depending on relevant factors, including experience and geographic location.

This role is also anticipated to be eligible to participate in an annual bonus plan.

We want you to be healthy, balanced, and feel secure. That’s why you’ll enjoy a comprehensive range of benefits, with a focus on supporting your whole health. Starting on day one of your employment, you’ll be offered several health-related benefits including medical, vision, dental, and well-being and behavioral health programs. We also offer 401(k) with company match, company paid life insurance, tuition reimbursement, a minimum of 18 days of paid time off per year and paid holidays. For more details on our employee benefits programs, visit Life at Cigna .

About Cigna
Cigna Corporation exists to improve lives. We are a global health service company dedicated to improving the health, well-being and peace of mind of those we serve. Together, with colleagues around the world, we aspire to transform health services, making them more affordable and accessible to millions. Through our unmatched expertise, bold action, fresh ideas and an unwavering commitment to patient-centered care, we are a force of health services innovation. When you work with us, or one of our subsidiaries, you’ll enjoy meaningful career experiences that enrich people’s lives. What difference will you make?

Qualified applicants will be considered without regard to race, color, age, disability, sex, childbirth (including pregnancy) or related medical conditions including but not limited to lactation, sexual orientation, gender identity or expression, veteran or military status, religion, national origin, ancestry, marital or familial status, genetic information, status with regard to public assistance, citizenship status or any other characteristic protected by applicable equal employment opportunity laws.

If you require reasonable accommodation in completing the online application process, please email: SeeYourself@cigna.com for support. Do not email SeeYourself@cigna.com for an update on your application or to provide your resume as you will not receive a response.

Cigna has a tobacco-free policy and reserves the right not to hire tobacco/nicotine users in states where that is legally permissible. Candidates in such states who use tobacco/nicotine will not be considered for employment unless they enter a qualifying smoking cessation program prior to the start of their employment. These states include: Alabama, Alaska, Arizona, Arkansas, Delaware, Florida, Georgia, Hawaii, Idaho, Iowa, Kansas, Maryland, Massachusetts, Michigan, Nebraska, Ohio, Pennsylvania, Texas, Utah, Vermont, and Washington State.",glassdoor
234,"Apple
4.2
Keystone Big Data Software Engineer, Global Business Intelligence
Cupertino, CA

 Summary
Posted: Jul 18, 2022
Role Number:200399924
Imagine what you could do here! At Apple, great minds come together to build products, services, and solutions that amaze the world. Imagine how your contributions could transform the world and there is no limit to what you could accomplish here. Apple's Global Business Intelligence (GBI) team is seeking an experienced Software Engineer to build high quality, scalable and resilient distributed systems that power Apple's analytics platforms and data pipelines. Apple's Enterprise Data Warehouse landscape caters to a wide variety of real-time, near real-time and batch analytical solutions. These solutions are an integral part of business functions like Sales, Operations, Finance, AppleCare, Marketing, and Internet Services, enabling business drivers to make critical decisions. If you enjoy learning new technologies, and are comfortable proposing and implementing solutions, demonstrating Software Engineering standard methodologies, you will find it rewarding to work in GBI! The ideal candidate for this position will be able to think outside of the box and should have passion for building engineering solutions to enable business in making time sensitive and critical decisions.
Key Qualifications
Strong fundamentals in data structures, algorithms, and software system design
Strong hands-on programming skills (Scala / Java / Python preferred)
Proficiency in developing applications in Spark & deep understanding of Spark is essential for this role
Proven track record of building jobs processing high-volume data using Spark
Experience with real time data processing with Spark Streaming, Flink is a huge plus
Committed to test driven development paradigm
Strong analytical and interpersonal skills and demonstrated ability to code & collaborate
Self-starter, highly motivated and ability to research, learn, prototype quickly
Sound experience in Cloud technologies such as AWS or GCP
Experience on Cloud with databases like SnowFlake and Singlestore is a plus
Prior experience in the areas of AI/ML/Data Sciences will be a strong plus
Curiosity to explore and understand data is a plus
Description
The Frameworks team in GBI build and support critical infrastructural systems which provide services for numerous organizations within Apple and we are looking for a strong, enthusiastic developer to join as a member of this group. You are someone with ideas and real passion for software delivered as a service to improve reuse, efficiency, and simplicity. This engineer’s work will affect multiple data teams within Apple and enable our partners to derive insights and help execute their goals.
Education & Experience
BS/MS in Computer Science, Computer Engineering or similar field
Additional Requirements
Apple is an Equal Opportunity Employer that is committed to inclusion and diversity. We also take affirmative action to offer employment and advancement opportunities to all applicants, including minorities, women, protected veterans, and individuals with disabilities. Apple will not discriminate or retaliate against applicants who inquire about, disclose, or discuss their compensation or that of other applicants.
We at Apple we are committed to working with and providing reasonable accommodation to applicants with physical and mental disabilities. Learn more.",glassdoor
235,"Mint Mobile
3.6
Digital Data Engineer I - Remote
Costa Mesa, CA
Employer Provided Salary:$90K - $103K

 MINT MOBILE is seeking a talented Digital Data Engineer I to join the Data Management Team! Individual reports to Customer Data Manager. Role is remote; must reside in the United States.
ABOUT THE ROLE
Provide direct data engineering development to data pipelines for ETL establishment and enhancements to and from data warehouses to customer management platform (Braze). Work collaboratively with cross-functional teams to determine digital data needs, establish data collection requirements, and deploy & maintain accurate data to ensure metrics & dimensions are addressed for analytics/reporting requirements.
Your usual day of awesomeness includes:
Transform required data conditions into performance code logic.
Develop high-performance code in SQL and Python.
Develop, automate, and enhance ELT processes for continuous data flow.
Create, modify, and deploy code to production via AWS resources including Lambda, S3, Glue, Redshift, etc.
Partner with stakeholders to support the implementation and development of data requirements.
Troubleshoot data anomalies and provide applicable solutions.
Build, test and maintain database pipeline architectures.
WHAT YOU BRING
Advanced level in SQL and Python for data engineering and backend development.
Understanding of popular code development approaches:
Test-driven development
Continuous Integration/Continuous Deployment (CI/CD)
Experienced working with AWS services (Lambda, S3, Glue, Redshift etc.) and Cloud Data Warehouse.
Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
Define digital data collection methods and implementations to DWH and customer management platforms.
Experienced with QA testing process to verify data is collected & rendered as expected.
Ability to excel in a fast-paced, cross-functional environment.
Ability to work autonomously.
Excellent written and verbal communication skills.
Proactive problem-solving and critical thinking skills.
Ability to manage time effectively and consistently meet deadlines.
NICE TO HAVE
Prior working knowledge of Braze or other Customer Management Platforms
Snowflake Cloud Data Warehouse
Terraform/Bitbucket/Airflow/Jenkins
Looker, Tableau, Power BI
WE ARE MINT MOBILE
We connect people to what's most important in their lives: Easily, affordably and reliably. We strive to be California's Preeminent Destination Employer. Oh yeah, we get it too! We understand what matters to you most. You're an individual with unique needs, and we're prepared to exceed any expectations you have for an ideal employer.
We're smart, strategic, and get things done without a lot of red tape or unnecessary politics. Everyone matters here and everyone has a voice. Expect to spend your time contributing to projects that really matter. We obsess over the employee experience. To start, we provide some of the most competitive salary, benefits, family leave, vacation, retirement and equity options in Southern California. We believe in you and invest in you. Not just your career aspirations, but your life.
In addition, we've got a laundry list of perks you'll brag about on insta - Lunch every day prepared by our very own chef, healthy snacks, onsite gym, free massages, car wash services, and most importantly, a team atmosphere. We even raise the bar on well bars, including Espresso/Cappuccino/Nitro/Cold Brew/Kombucha Bar, Froyo Bar, Breakfast Bar, Snack Bar and a, well, you know, bar (after 5 pm).
And if you feel intrigued right now reading, imagine the co-workers we have already attracted. This is the kind of team you'll want to take home to mom or invite to your kid's next birthday party. This is the kind of close-knit community happening here. Come check out how you can be part of Mint!
OUR VALUES – LET'S MAKE LIFE ULTRA TOGETHER!
Ownership: We are all owners; be the outcome and get the job done.
Action Biased: Be brilliant, proactive, and act with urgency.
Embrace the Adventure: Be agile, adaptive, and thrive on change.
Invent and Simplify: Never accept good enough.
$1,000 REFERRAL BONUS
Take a look at this job description, if you are the right person, please apply. If Mint Mobile doesn't appear to be a fit for you, refer a friend or colleague and get $1,000. Let your friend or colleague know to provide your full name and email when applying to the job. If we hire them and they stay for 90 days, you get $1000. For more details of restrictions and rules, please email recruiting@ultra.me.

Covid-19 Vaccination Requirement
UVNV, Inc. has adopted a mandated vaccination policy to support the health and safety of our team members and our community. The Company requires all employees to be fully vaccinated. The Company will provide accommodations based on medical condition or sincerely held religious beliefs or practices. Please let us know if you'd like to discuss the policy or available accommodations before proceeding with our recruitment process.
We are committed to equal employment opportunities regardless of race, color, genetic information, creed, religion, sex, sexual orientation, gender identity, lawful alien status, national origin, age, marital status, or protected veteran status. We support an inclusive workplace where associates excel based on personal merit, qualification, experience, ability, and job performance.
In support of the Equal Pay for Equal Work Act, the range of starting pay for this role is $90,000 - $103,000. This is not a guarantee of compensation or salary, actual compensation is influenced by a wide range of factors including but not limited to skill set, level of experience, education, certifications, responsibility, and geographic location. We also offer a variety of benefits including health, disability insurance, 401 (k), flexible spending accounts, EAP, education reimbursement, parental leave, unlimited vacation, bonuses, incentive stock options and company paid holidays. The specific programs and options available will vary depending on state, start date, and employment type. Our recruitment team will be happy to answer any questions you may have.
#LI-Remote",glassdoor
236,"Expression Networks
4.4
Data Engineer
Remote

 Founded in 1997 and headquartered in Washington DC, Expression Networks provides data fusion, data analytics, software engineering, information technology, and electromagnetic spectrum management solutions to the U.S. Department of Defense, Department of State, and national security community. Expression's “Perpetual Innovation” culture focuses on creating immediate and sustainable value for our clients via agile delivery of tailored solutions built through constant engagement with our clients. Expression Networks was ranked #1 on the Washington Technology 2018's Fast 50 list of fastest-growing small business Government contractors and a Top 20 Big Data Solutions Provider by CIO Review.

We make sure to provide everyone the tools and opportunities to grow while working on some of the newest technologies in the industry. With Covid-19 being a major theme the last two years having a growing collaborative culture has been one of the key focus of our C-suite and upper management. We get excited about celebrating our professionals' milestones, accomplishments, promotions, overcoming challenges, and many other aspects that make an engaging collaborative environment.

We are looking to bring on a mid-level Data Engineer to add to the continued growth of our Data Science division. This position will work in a team led by a principal data engineer on tasks related to designing and delivering high-impact data architecture and engineering solutions to our customers across a breadth of domains and use cases.
Location:
Remote, with the ability to travel per project requirements.
Security Clearance:
Ability to obtain Secret Clearance or Higher
Responsibilities:
Developing, testing, and documenting software code for data extraction, ingestion, transformation, cleaning, correlation, and analytics
Participating in end-to-end architectural design and development lifecycle for new data services/products, and making them operate at scale
Participating in cross-functional team collaboration to understand customer requirements, design prototypes, and optimize existing data services/products
Demonstrating Data Science excellence in the teams you work with across the organization, and mentoring junior members in the Data Science division
Participating in research, case studies, and prototypes on cutting-edge technologies and how they can be leveraged
Required Qualifications:
3+ years of experience bringing databases, data integration, and data analytics/ML technologies to production with a Bachelor's degree in Computer Science/Data Science/Computer Engineering or relevant field
Mastery in developing software code in one or more programming languages (Python, JavaScript, Java, Matlab, etc.)
Expert knowledge in databases (SQL, NoSQL, Graph, etc.) and data architecture (Data Lake, Delta Lake)
Knowledgeable in machine learning/AI methodologies
Experience with one or more SQL-on-Hadoop technology (Hive, Impala, Spark SQL, Presto, etc.)
Preferred Qualifications:
Experience in short release cycles and the full software lifecycle
Experience with Agile development methodology (e.g., Scrum)
Strong writing and oral communication skills to deliver design documents, technical reports, and presentations to a variety of audiences
Benefits:
Expression Networks offers competitive salaries and benefits, such as:
401k matching
PPO and HDHP medical/dental/vision insurance
Education reimbursement up to $10,000/yr.
Complimentary life insurance
Generous roll over PTO and 11 days of holiday leave
Onsite gym facility and trainer
Commuter Benefits Plan
In office Cold Brew Coffee
Equal Opportunity Employer/Veterans/Disabled",glassdoor
237,"Netflix
4.3
Data Engineer (L5) - Games
Los Gatos, CA
$108K - $193K (Glassdoor est.)

 Los Gatos, California
Data Science and Engineering
Now is an amazing time to join Netflix as we seek to entertain the world. We have over 200 million paid members in over 190 countries, and we won’t stop there. Games are our next big frontier and an incredible opportunity for us to deliver new experiences to delight and entertain our quickly growing membership. You will be jumping in at the very beginning of this adventure and be in a position to help us redefine what a Netflix subscription means for our members around the world.
Data Science and Engineering (‘DSE’) at Netflix is aimed at using data, analytics, and sciences to improve various aspects of our business. We are looking for a Data Engineer to join our Games DSE team, supporting end-to-end analytics & data needs for our games portfolio. This role will be partnering closely with our Game stakeholders to develop software and data solutions that enable analysis across the entire library of games.
As part of this team, you will work on diverse data technologies such as Spark, Presto, Flink, Kafka, and others to build insightful, scalable, and robust data pipelines that feed directly into our key gaming dashboards; write ETL jobs to collect and aggregate data; and build high-quality data models that represent how games are performing on Netflix.
The ideal candidate will also have a background in games, with a solid knowledge of how standard industry metrics are computed.
Who You Are:
7+ years of software/data engineering experience working with video game analytics (i.e you are familiar with how key metrics such as DAU, MAU and retention rates are computed in an ETL).
Passionate about building intuitive data models and an expert in distributed data processing patterns.
Highly proficient in at least one of these programming languages: Java, Python, or Scala.
Comfortable with complex SQL.
Expert in engineering data pipelines using big data technologies (Hive, Presto, Spark, Flink) on large-scale data sets demonstrated through years of experience.
Conceptually familiar with AWS cloud resources (S3, EC2, RDS etc).
Excel at taking vague requirements and crystallizing them into scalable data solutions.
Excited about operating independently, demonstrating excellence, and learning new technologies and frameworks.
What will you do?
Engineer efficient, adaptable, and scalable data pipelines in Spark and Python/Scala to process structured data into aggregate datasets that feed all games portfolio dashboards.
Become an expert in games metrics at Netflix - act as a thought partner to the games analytics team, understand their challenges, and help them to put the right data in front of our stakeholders.
Maintain and rethink existing datasets and pipelines to service a wider variety of use cases.
Join a stunning team of data engineers with diverse skill sets, partnering closely with analytics engineering and data science counterparts.
Netflix Culture
Our culture is unique, and we live by our values. For more information on what it's like to work at Netflix, please take a look at our culture memo.",glassdoor
238,"Milo's Tea Company
4.1
Data Engineer
Remote

 Overview: Milo’s Tea Company is one of the fastest growing beverage companies in the US. Our culture and operations are built on the belief that we can make a difference in the world. That’s why we put People First and strive to continually reduce our environmental impact on the planet. We leverage our world class operations and decades-long distribution partnerships to grow the footprint of our core products and create new, innovative beverage products.
We are the #1 and fastest growing brand in the Refrigerated Tea Category in the nation.
Our core mission is that we put people and the planet first and by doing this, it will be good for our business.
We are committed to unlocking the personal genius of every associate and have a strong focus on growth and learning.
Our Company is women-led (our Executive Team is 57% female) and strongly committed to Diversity, Inclusion and Belonging.
We are committed to annual charitable giving by delivering upon our 1% profit pledge.
We are Platinum Certified in Zero Waste Manufacturing; recycling, reducing, and reusing 95% of waste at all facilities.
Being a part of the Milo’s TEAm, you’ll get to collaborate with a group of passionate and high-performing people, where everyone feels empowered to do their best work and feels good about the work they’re doing.
And as a ""People First"" company, Milo’s is committed to the success and well-being of our associates, customers, and fans, no matter their gender, race or creed. Some of the benefits offered that reflect our commitment include:
Competitive salary with bonus opportunities
100% paid medical insurance for our associates and their families
401K with a company match
Partial tuition reimbursement assistance
A robust parental leave program
Paid time off to volunteer at the charity of your choice
Employee assistance program
Responsibilities: The Data Engineer is responsible for assisting with data management, modeling, development, transformation, and reporting activities.
*
Responsibilities: *
Identify business needs, determine possible solutions, and develop solutions that include systems components, and process improvements with data driven decision making.
Work with business groups to design and develop reporting and analytics solutions that will improve efficiency and effectiveness.
Designs, implements, tests, troubleshoots, documents, and supports data models, programs, scripts, and ETL (Extract, Transform, and Load) processes.
Develop, maintain, and curate large datasets from multiple platforms. Develop reporting capabilities to support business needs by creating and supporting SQL queries, data extraction packages, and interfaces. Explores ways to enhance data quality and reliability.
Perform data validation between analytical and source systems to support ongoing data management capabilities and data governance. Perform data testing to ensure the accuracy of data transformation.
Develop data analytics, reports, and dashboards using Power BI and other business intelligence tools.
Uphold and participate in all Corporate Responsibility programming including recycling, social advocacy and MMAD volunteering opportunities.
Invest in and is an example of Milo’s Responsibility commitment which includes environmental, social, and corporate governance components.
Other duties as assigned
Supervisory: This role does not have supervisory responsibilities.
Qualifications:
BA in computer science, information systems, statistics, applied math, or any other related field.
Up to 3 years of experience in information systems or related field.
Strong experience with SQL server solutions (queries, functions, stored procedures, views, etc.).
Cloud based computing and data solutions.
Proficient with Excel and Business Intelligence tools (Power BI, Power Query, Tableau, etc.).
Understanding of relational databases and data warehouses. Hands-on experience with SQL database design.
Experience with Microsoft SQL stack (SSIS, SSRS, SSAS, etc); Experience with cloud-based data technologies, Azure preferred.
Experience working in a SharePoint environment; Experience with Python, R or other programming languages.
Experience in non-traditional SQL (noSQL, etc.) solutions.
Experience with machine learning and predictive analytics.
Experience with other ETL tools such as Alteryx.
Job Type: Full-time",glassdoor
239,"Pinterest
4.1
Data Engineer
Remote

 About Pinterest:
Millions of people across the world come to Pinterest to find new ideas every day. It's where they get inspiration, dream about new possibilities and plan for what matters most. Our mission is to help those people find their inspiration and create a life they love. In your role, you'll be challenged to take on work that upholds this mission and pushes Pinterest forward. You'll grow as a person and leader in your field, all the while helping Pinners make their lives better in the positive corner of the internet.
Our new progressive work model is called PinFlex, a term that's uniquely Pinterest to describe our flexible approach to living and working. Visit our PinFlex landing page to learn more.
The Enterprise Data Platform team is looking for a Data Engineer who has experience with Building Data Pipelines and Managing/Developing on any Cloud Data Warehouse. In this role you will also advise other Data Analysts and Data Engineers from the Business teams at Pinterest on the best practices for handling data and deriving insights using Snowflake. You will gradually become the Subject Matter Expert on Snowflake and also help build out the Modern Data Stack at Pinterest.
What you'll do:
Build Data Pipelines using Python on either Airflow or AWS Lambda to ingest data into Snowflake
Build Scripts in Python to manage Data Access on Snowflake
Define and advocate the best practices for storing and analyzing data inside Snowflake
Review the Data Modeling practices of other teams
What we're looking for:
Strong skills in Python and SQL
Experience with Building Data Pipelines in Python
Experience with any Cloud Data Warehouse either as an Administrator or a Developer
Strong Data Modeling skills
#LI-BB1
#LI-Remote
Our Commitment to Diversity:
At Pinterest, our mission is to bring everyone the inspiration to create a life they love—and that includes our employees. We’re taking on the most exciting challenges of our working lives, and we succeed with a team that represents an inclusive and diverse set of identities and backgrounds.

Not Specified
0",glassdoor
240,"Dataquestcorp
Data Science Engineer
Branchburg, NJ
Employer Provided Salary:$75K - $80K

 Job Role: Data Science
Note: Please don't apply C2C profiles. its only w2 positions
Benefits:
Free Training and placement.
Training provided by highly qualified, industry-experienced & certified instructors.
We do provide free accommodations & Relocation charges.
H1B Sponsorship
We do support for STEM OPT and GC processing.
Health Insurance
Relocation Assistance any where in USA.
Free accommodation.
Location: Branchburg, NJ
Job Types: Full-time, Contract
Job Types: Full-time, Contract
Salary: $75,000.00 - $80,000.00 per year
Benefits:
Health insurance
Schedule:
8 hour shift
Ability to commute/relocate:
Branchburg, NJ: Reliably commute or planning to relocate before starting work (Required)
Experience:
Python: 1 year (Preferred)
SQL: 1 year (Preferred)
Work Location: One location
Speak with the employer
+91 9089927715",glassdoor
241,"Apple
4.2
Data Engineer
Cupertino, CA

 Summary
Posted: Aug 10, 2022
Weekly Hours: 40
Role Number:200406892
Are you a big-picture thinker who loves setting ambitious goals? Do you have a passion for understanding how each line of code affects all the others? In the Core Operating Systems group, you’ll ensure the OS is inseparable from each device’s identity as a whole. That’s because this group is committed to building fully integrated operating systems that combine hardware, software, and apps into a single Apple experience. Your dedication to cross-disciplinary collaboration will help develop groundbreaking technologies, such as iOS, macOS, watchOS, and tvOS. By crafting these distinct, holistic user experiences, you’ll continue to uphold and advance the excellence people expect from Apple devices. The Platform Services & Operations team in Core OS is looking for a Data Engineer to inform and develop essential workflow tooling at scale. The Workflow Engineering team enable teams to deliver high quality software through best in class engineering experiences, efficient workflow, data driven insights, and a culture of continuous improvement. Your focus is building the backend data pipelines that enables visualization of data across the organization in user intuitive and configurable formats.
Key Qualifications
3 +proven experience in a Data focused posistion
Proficient in Python; data access and retrieval. Quantitative data preparation. Regular expressions and text analysis
Highly Proficient in Database Language and Design; querying large stores of data (APIs, SQL, etc.).
Access, retrieval, and storage of information. Data Structures, modeling for speed and efficiency
Software Development; understanding of build pipelines, branching and merging, Agile methods, and the delivery of code. Fluency in Git (or comparable source control tool)
Description
- Replicate data from source system into data warehouse; retrieve data through various protocols and land it in a central store - Automate data pipelines; write programs to periodically update warehouse data from source systems - Design for scale; flexible infrastructure for common enhancements including: expanding the volume of captured data, adding fields to the user-facing views, and recompiling archived data - Work with a team of data scientists and full stack engineers, to derive and develop targeted insights through centrally managed interactive dashboards
Education & Experience
B.S. in Data Science, Computer Science, or equivalent experience.
Additional Requirements
Experience as an Analyst; worked in the delivery of visual information (dashboards, reports, web-apps)
An understanding of how data can be used and applied in context (what is useful to capture and how it can be communicated)
Full Stack Development; ability to maintain back-end systems and visualize front-end data for users (with a web-kit framework like Angular, React)
Experience with Snowflake and/or other data store technologies",glassdoor
242,"Realign LLC
4.5
Data Engineer
California

 Job Type: Contract
Job Category: IT
Job Description
Write and optimize queries, provide input on peer code reviews and data modeling, deploy data
updates via continuous integration / deployment (CI/CD) practices.

Collaborate with software developers, other data engineers, and database architects on projects to
ensure optimal data delivery following appropriate change management guidelines.

Collaborate with software and reliability engineers to automate repeatable data tasks.

Work with development and production support teams to troubleshoot data, application, and service
deployment issues.

Develop detailed, shared technical procedure documentation, including processes for contingency
operations.

Research, provide technical input, document, and implement new technology solutions.

Implement necessary patches, hotfixes, service packs, cumulative updates, upgrades, and
configuration change to maintain security compliance and application integrity.

Required Skills
Big Data Engineer",glassdoor
243,"Blue Cross and Blue Shield of North Carolina
4.1
Data Engineer
Remote

 Additional Locations:
Full Time Remote - Alabama, Full Time Remote - Alabama, Full Time Remote - Arizona, Full Time Remote - Arkansas, Full Time Remote - Florida, Full Time Remote - Georgia, Full Time Remote - Idaho, Full Time Remote - Indiana, Full Time Remote - Iowa, Full Time Remote - Kansas, Full Time Remote - Kentucky, Full Time Remote - Louisiana, Full Time Remote - Maryland, Full Time Remote - Michigan, Full Time Remote - Mississippi, Full Time Remote - Missouri, Full Time Remote - Ohio, Full Time Remote - Oklahoma, Full Time Remote - Pennsylvania, Full Time Remote - South Carolina, Full Time Remote - South Dakota, Full Time Remote - Tennessee, Full Time Remote - Texas, Full Time Remote - Utah, Full Time Remote - Virginia {+ 1 more}
Job Description
IT is different here. Our work as technology specialists pushes the boundaries of what’s possible in health care. You will build solutions that make a real difference in people’s lives. Driven by the importance of their work, our team members innovate to elevate. We’re encouraged to be curious, collaborate, and turn ideas into solutions that transform this space.

In this role you will work closely with senior engineers, data scientists and other stakeholders to design and maintain moderate to advanced data models. The Data Engineer is responsible for developing and supporting advanced reports that provide accurate and timely data for internal and external clients. The Data Engineer will design and grow a data infrastructure that powers our ability to make timely and data-driven decisions. You will support Membership Operations, Customer Service Operations, Digital & Consumer Experience teams.

If you are ready to make a career out of making a difference, then you are the person for this team.
What You’ll Do
Define and extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes
Document, and test moderate data systems that bring together data from disparate sources, making it available to data scientists, and other users using scripting and/or programming languages
Write and refine code to ensure performance and reliability of data extraction and processing
Participate in requirements gathering sessions with business and technical staff to distill technical requirement from business requests
Develop SQL queries to extract data for analysis and model construction
Own delivery of moderately sized data engineering projects
Design and develop scalable, efficient data pipeline processes to handle data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets to analysts and data scientists
Ensure performance and reliability of data processes
Document and test data processes including performance of through data validation and verification
Collaborate with cross functional team to resolve data quality and operational issues and ensure timely delivery of products
Develop and implement scripts for database and data process maintenance, monitoring, and performance tuning
Analyze and evaluate databases in order to identify and recommend improvements and optimization
Design eye-catching visualizations to convey information to users
What You Will Bring
Bachelor’s degree and 3 years of experience with Oracle, Data Warehouses and Data Lakes, Big Data platforms and programming in Python, R or other related language.
In lieu of degree, 5 years of the experience as stated above.
SQL and Python scripting
Experience in a cloud environment
Experience with Ab Initio or other ETL tools",glassdoor
244,"Twitch
4.0
Data Engineer
San Francisco, CA
Employer Provided Salary:$140K - $171K

 About Us
Twitch is the world's biggest live streaming service, with global communities built around gaming, entertainment, music, sports, cooking, and more. It's where millions of people come together to chat, interact, and make their own entertainment.
We're about community, inside and out. You'll find coworkers who are eager to team up, collaborate, and smash (or elegantly solve) problems together. We're on a quest to empower live communities, so if this sounds good to you, see what we're up to on LinkedIn and Twitter, get interviewing tips on Instagram, and discover projects we're solving on our Blog.
About the Role
Reporting to the Head of Global Talent Acquisition, the Data Engineer will expand the reach and role of data among leaders and managers at Twitch. You will empower the business to integrate data into their daily workflow by creating/maintaining data pipelines, producing reporting, and automating our processes.
You can work in San Francisco, CA or remotely across the US.
This role is for you if:
You love automating processes and developing efficient scalable solutions
You're excited about contributing to the success, efficiency, and happiness of Twitch staff
You're excited to jump into a diverse array of data work to support the team
You enjoy working with autonomy and shaping a new function

You Will:
Delight consumers of people-related data by ensuring they have the data they need to inform decisions, where and when they need it
Build and own data pipelines, SQL queries/views, and apps
Automate processes through the use of JavaScript and other languages
Improve business, engineering, and data processes through data architecture, engineering, testing, and operational excellence best practices
Ensure the integrity of People and Places data in analyses and tools through regular audits
Partner to develop analytics products and recommend opportunities
Develop ongoing metrics, analyses, and dashboards to guide important decisions
You Have:
Experience writing SQL and a procedural language (Python, R, etc.) for data handling
Experience owning systems that collect, transform, and visualize data
Experience implementing data analytics, visualization tools and programs for HR working with Workday, Greenhouse, Tableau, Google Workspace, Google Data Studio, and Google Sheets
Experience implementing software solutions to automate data source, visualization and analytics products
Bachelors in related field, or equivalent experience
Bonus Points
Experience handling People-related data including compensation, performance, hiring, and engagement data.
Experience automating Google services (Sheets, Docs, Data Studio) with Javascript
Experience with Workday, Greenhouse, and Tableau
Demonstrated net positive contributor to company community and culture above and beyond the core job
Perks
Medical, Dental, Vision & Disability Insurance
401(k), Maternity & Parental Leave
Flexible PTO
Commuter Benefits
Amazon Employee Discount
Monthly Contribution & Discounts for Wellness Related Activities & Programs (e.g., gym memberships, off-site massages, etc.),
Breakfast, Lunch & Dinner Served Daily
Free Snacks & Beverages
We are an equal opportunity employer and value diversity at Twitch. We do not discriminate on the basis of race, religion, color, national origin, gender, gender identity, sexual orientation, age, marital status, veteran status, or disability status, or other legally protected status.
Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
Pursuant to the Los Angeles Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
The base pay range for this position in Colorado, Connecticut and Washington is $139,860 - $170,940 yr and in New York City is $153,900 - $188,100 yr. Pay is based on market location and may vary depending on job-related knowledge, skills, and experience. A sign-on payment and restricted stock units may be provided as part of the compensation package, in addition to a full range of medical, financial, and/or other benefits, dependent on the position offered. Applicants should apply via Twitch's internal or external careers site.
Workers in New York City who perform in-person work or interact with the public in the course of business must show proof they have been fully vaccinated against COVID or request and receive approval for a reasonable accommodation, including medical or religious accommodation.
Twitch values your privacy. Please consult our Candidate Privacy Notice, for information about how we collect, use, and disclose personal information of our candidates.
Job ID: TW7236
#LI-Remote #RemoteFriendly",glassdoor
245,"Luxoft
4.3
Data Engineer
Remote

 Project Description
Luxoft has contract with a major Telecommunications provider to engage with DIRECTV organization to establish integrated cloud technology platforms to ingest information from various Network Engineering support applications in order to better optimize management and planning for the future network.

To do this DIRECTV is managing data ingestion into a Snowflake Azure based deployment which allows for one cohesive platform to serve all types of users and workloads in a consistent way. Centralizing data in a unified, governed, managed data platform allows all authorized users to access accurate and timely data for analysis that is useful for highly transnational datasets. It is also useful that it can store structured and unstructured data. Additionally DIRECTV is leveraging a Palantir Deep™ instance platform for the creation and management of cost forecasting scenarios.
Responsibilities
- Analysis on Data Libraries - evaluation of data sets and current data architecture for source data pipelines. This will allow us to scope the depth/breadth of data

- Data Quality Metrics - Audits analysis and setup to determine the appropriate data quality measures. This will be used to validate with clients/users in a later phase.

- DQF research - Analyze the current Data Quality Framework to leverage as possible/needed. Assess the need for extension and/or replacement of the current DQF.

- Architecture patterns research - Analysis of data translation and business rules associated.

- Current ingestion patterns - Study and enhancement research to evaluate data pipeline for current state and opportunity to optimize for increased data quality and rigor.
Skills
Must have
Cloud, Data Engineering, SnowFlake, Big Data
Nice to have
Microsoft Azure Cloud Platform
Languages
English: C2 Proficient
Seniority
Senior
Relocation package
If needed, we can help you with relocation process.
Vacancy Specialization
BigData Development
Ref Number
VR-81593",glassdoor
246,"Teknic
Data Engineer
Remote

 Role: Data Engineer
Location: Remote
JOb Description:
Skills and Experience :
Good experience on designing and developing data pipelines for data ingestion and transformation using Spark.
Distributed computing experience using Pyspark.
Good understanding of spark framework and spark architecture.
Experience working in Cloud based big data infrastructure.
Excellent in trouble shooting the performance and data skew issues.
Must have a good understanding of spark run time metrics and tune applications based on metrics.
Deep knowledge in partitioning, bucketing concepts of data ingestion.
Good understanding of AWS services like Glue, Athena, S3, Lambda, Cloud formation.
Preferred working knowledge on the implementation of datalake ETL using AWS glue, Databricks etc.
Experience with data modelling techniques for cloud data stores and on prem databases like Teradata, Teradata Vantage (TDV) etc.
Preferred working experience in ETL development in Teradata vantage and data migration from on prem to Teradata vantage.
Proficiency in SQL, relational and non-relational databases, query optimization and data modelling.
Experience with source code control systems like Gitlab.
Experience with large scale distributed relational and NoSQL database systems.
Job Type: Contract
Schedule:
8 hour shift
Experience:
Data engineer: 10 years (Preferred)
Spark.: 3 years (Preferred)
Cloud based big data infrastructure.: 1 year (Preferred)
datalake ETL: 1 year (Preferred)
AWS Glue: 1 year (Preferred)
Work Location: Remote",glassdoor
247,"Pepsico
3.9
Junior Data Engineer
Remote
Employer Provided Salary:$90K - $100K

 Compensation: $80k - $90k
Benefits: Medical, Dental, Vision, 401k match and Arc
This role can be performed remote in any of our headquarter locations including Plano, Texas; Purchase, New York; Chicago, Illinois.
What PepsiCo Data Management and Operations does:
Maintain a predictable, transparent, global operating rhythm that ensures always-on access to high-quality data for stakeholders across the company
Responsible for day-to-day data collection, transportation, maintenance/curation and access to the PepsiCo corporate data asset
Work cross-functionally across the enterprise to centralize data and standardize it for use by business, data science or other stakeholders
Increase awareness about available data and democratize access to it across the company.
As a member of the data engineering team, you will be the key technical expert developing and overseeing PepsiCo's data product build & operations and drive a strong vision for how data engineering can proactively create a positive impact on the business. You'll be an empowered member of a team of data engineers who build data pipelines into various source systems, rest data on the PepsiCo Data Lake, and enable exploration and access for analytics, visualization, machine learning, and product development efforts across the company. As a member of the data engineering team, you will help lead the development of very large and complex data applications into public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. You will work closely with process owners, product owners and business users. You'll be working in a hybrid environment with in-house, on-premise data sources as well as cloud and remote systems.
Key Accountabilities:
Active contributor to code development in projects and services
Manage and scale data pipelines from internal and external data sources to support new product launches and drive data quality across data products
Build and own the automation and monitoring frameworks that capture metrics and operational KPIs for data pipeline quality and performance
Responsible for implementing best practices around systems integration, security, performance and data management
Empower the business by creating value through the increased adoption of data, data science and business intelligence landscape
Collaborate with internal clients (data science and product teams) to drive solutioning and POC discussions.
Develop and optimize procedures to “productionalize” data science models
Define and manage SLA’s for data products and processes running in production
Support large-scale experimentation done by data scientists
Prototype new approaches and build solutions at scale
Research in state-of-the-art methodologies
Create documentation for learnings and knowledge transfer
Create and audit reusable packages or libraries
COVID-19 vaccination is a condition of employment for this role. Please note that all such company vaccine requirements provide the opportunity to request an approved accommodation or exemption under applicable law
Qualifications / Requirements :
BA/BS in Computer Science, Math, Physics is mandatory.
2+ years of overall technology experience that includes hands-on building data engineering pipelines
2+ years of experience in SQL optimization and performance tuning, and development experience in programming languages like Python, PySpark, Scala etc.)
1+ years in cloud data engineering experience in Azure or AWS
1+ Years in building data engineering pipelines in Azure (ADF and databricks)
Job Type: Full-time
Pay: $90,000.00 - $100,000.00 per year
Benefits:
401(k) matching
Dental insurance
Health insurance
Retirement plan
Vision insurance
Schedule:
8 hour shift
Education:
Bachelor's (Required)
Experience:
SQL: 2 years (Required)
Cloud: 2 years (Required)
Work Location: Remote",glassdoor
248,"Tesla
3.6
Data Engineer
Fremont, CA

 What to Expect
The Data Engineer is responsible for processing structured and unstructured data, validating data quality, and developing and supporting data products. We are looking for someone with strong hands on experience in all layers of data Integration and analytics! We especially need experience in using Python as an ETL tool. The Data Engineer plays a significant role in Agile planning, providing advice and guidance, and monitoring emerging technologies. Some of the technology we use: * Python * Informatica * SQL Server and MySQL * Vertica * Kafka

What You’ll Do
* Design, code, test, correct and document programs and scripts using agreed standards and tools to achieve a well-engineered result * Derive an overall strategy of data management, within an established information architecture that supports the development and secure operation of existing and new information and digital services * Plan effective data storage, security, sharing and publishing within the organization * Gathers and processes raw, structured, semi-structured, and unstructured data using batch and real-time data processing frameworks * Ensures data quality and implements tools and frameworks for automating the identification of data quality issues * Collaborate with internal and external data providers on data validation providing feedback and making customized changes to data feeds and data mappings * Mentor and lead data engineers providing technical guidance and oversight * Provides ongoing support, monitoring, and maintenance of deployed products

What You’ll Bring

* Strong experience with relational databases like SQL Server, MySQL and Vertica. NoSQL databases experience is a plus! * Strong background in data modeling, data access, and data storage techniques * Experience with design, development, and implementation of highly scalable, high-volume software systems and components, source of truth systems for different business areas, developing and maintaining web services in an agile environment * Working experience with Kafka Streaming layer * Experience in Spark Framework on both batch and real-time data processing is a plus * Experience in Big Data Integration & Analytics is a plus * Experience in Supply Chain and Logistics data is a plus",glassdoor
249,"Qualtrics
4.2
Data Engineer
Provo, UT
$83K - $125K (Glassdoor est.)

 The Qualtrics XM Platform™ is a system of action that helps businesses to attract customers who stay longer and buy more, to engage and empower employees to do the best work of their lives, to develop breakthrough products people love, and to build a brand people can’t imagine living without.

Joining Qualtrics means becoming part of a team bold enough to chase breakthrough experiences - like building a technology that will be a force for good. A team committed to diversity, equity, and inclusion because of a conviction that every voice holds value, with a vision for representation that matches the world around us and inclusion that far exceeds it. You could belong to a team whose values center on transparency, being all in, having customer obsession, acting as one team, and operating with scrappiness. All so you can do the best work of your career.

We believe every interaction is an opportunity. Are we yours?
The Team
Our team is a collection of deeply passionate engineers who are riding the groundbreaking of cloud computing and web scalability. We built data analytics applications that help company leaders gain insights about technology spends, make sound decision on technology investments, and drive innovation in resource utilization and efficiency optimizations. Our environment is primarily TypeScript, Node.js, React, MySQL NoSQL, AWS, Python, PHP, and Docker. In our collaborative culture, you find plenty of opportunities to impact our full-stack products; from Web & mobile UI to data visualization & analysis to data ingestion, storage and processing.
Job Responsibilities
Developing scalable, fast, robust, and simple web-based solutions to solve complex business problems
Close collaboration with your team to collect and incorporate feedback into your feature design
Drive operational excellence by investigating production issues, driving root cause analysis and follow-up actions for mitigation
Improve performance, availability, reliability, scale, throughput and latency
Work with your team in order to meet customer work you're doing, understand the decisions that are being made and make your voice heard.
Qualifications
Bachelor's degree in Computer Science or related field
Coding experience with any programming language (Prefer experience in TypeScript/JavaScript/React/Python)
Experience with web infrastructure and distributed systems
Experience with software engineering best practices (e.g. unit testing, code reviews, design, continuous delivery, git, test automation and build\deploy systems)
Ability to work in a fast-paced and agile development environment and to learn new frameworks/stacks
Passionate about building products that help customers easily and effectively get their job done
Enthusiastic person, who communicates effectively and is easy to work with
Curious and constantly learning on your own and from others
You get satisfaction from helping others succeed, and you constantly seek ways to improve
You can identify gaps, propose solutions to important problems, then take it to resolution
Preferred Qualifications
Shown ability to troubleshoot and identify the root cause of issues
Demonstrated skill and passion for operational excellence
Experience in a 24/7 production environment is a plus
Ability to retain composure under stressful conditions, communicate effectively with wide array of individuals at Qualtrics, and get the right things done
Confirmed ability to understand large systems, drilling down to code level",glassdoor
250,"Ultra Mobile
4.4
Digital Data Engineer I - Remote
Costa Mesa, CA
Employer Provided Salary:$90K - $103K

 ULTRA MOBILE is seeking a talented Digital Data Engineer I to join the Data Management Team! Individual reports to Customer Data Manager. Role is remote; must reside in the United States.
ABOUT THE ROLE
Provide direct data engineering development to data pipelines for ETL establishment and enhancements to and from data warehouses to customer management platform (Braze). Work collaboratively with cross-functional teams to determine digital data needs, establish data collection requirements, and deploy & maintain accurate data to ensure metrics & dimensions are addressed for analytics/reporting requirements.
Your usual day of awesomeness includes:
Transform required data conditions into performance code logic.
Develop high-performance code in SQL and Python.
Develop, automate, and enhance ELT processes for continuous data flow.
Create, modify, and deploy code to production via AWS resources including Lambda, S3, Glue, Redshift, etc.
Partner with stakeholders to support the implementation and development of data requirements.
Troubleshoot data anomalies and provide applicable solutions.
Build, test and maintain database pipeline architectures.
WHAT YOU BRING
Advanced level in SQL and Python for data engineering and backend development.
Understanding of popular code development approaches:
Test-driven development
Continuous Integration/Continuous Deployment (CI/CD)
Experienced working with AWS services (Lambda, S3, Glue, Redshift etc.) and Cloud Data Warehouse.
Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
Define digital data collection methods and implementations to DWH and customer management platforms.
Experienced with QA testing process to verify data is collected & rendered as expected.
Ability to excel in a fast-paced, cross-functional environment.
Ability to work autonomously.
Excellent written and verbal communication skills.
Proactive problem-solving and critical thinking skills.
Ability to manage time effectively and consistently meet deadlines.
NICE TO HAVE
Prior working knowledge of Braze or other Customer Management Platforms
Snowflake Cloud Data Warehouse
Terraform/Bitbucket/Airflow/Jenkins
Looker, Tableau, Power BI
WE ARE ULTRA & MINT MOBILE
We connect people to what's most important in their lives: Easily, affordably and reliably. We strive to be California's Preeminent Destination Employer. Oh yeah, we get it too! We understand what matters to you most. You're an individual with unique needs, and we're prepared to exceed any expectations you have for an ideal employer.
We're smart, strategic, and get things done without a lot of red tape or unnecessary politics. Everyone matters here and everyone has a voice. Expect to spend your time contributing to projects that really matter. We obsess over the employee experience. To start, we provide some of the most competitive salary, benefits, family leave, vacation, retirement and equity options in Southern California. We believe in you and invest in you. Not just your career aspirations, but your life.
In addition, we've got a laundry list of perks you'll brag about on insta - Lunch every day prepared by our very own chef, healthy snacks, onsite gym, free massages, car wash services, and most importantly, a team atmosphere. We even raise the bar on well bars, including Espresso/Cappuccino/Nitro/Cold Brew/Kombucha Bar, Froyo Bar, Breakfast Bar, Snack Bar and a, well, you know, bar (after 5 pm).
And if you feel intrigued right now reading, imagine the co-workers we have already attracted. This is the kind of team you'll want to take home to mom or invite to your kid's next birthday party. This is the kind of close-knit community happening here. Come check out how you can be part of Ultra & Mint!
OUR VALUES – LET'S MAKE LIFE ULTRA TOGETHER!
Ownership: We are all owners; be the outcome and get the job done.
Action Biased: Be brilliant, proactive, and act with urgency.
Embrace the Adventure: Be agile, adaptive, and thrive on change.
Invent and Simplify: Never accept good enough.
$1,000 REFERRAL BONUS
Take a look at this job description, if you are the right person, please apply. If Ultra Mobile doesn't appear to be a fit for you, refer a friend or colleague and get $1,000. Let your friend or colleague know to provide your full name and email when applying to the job. If we hire them and they stay for 90 days, you get $1000. For more details of restrictions and rules, please email recruiting@ultra.me.

Covid-19 Vaccination Requirement
UVNV, Inc. has adopted a mandated vaccination policy to support the health and safety of our team members and our community. The Company requires all employees to be fully vaccinated. The Company will provide accommodations based on medical condition or sincerely held religious beliefs or practices. Please let us know if you'd like to discuss the policy or available accommodations before proceeding with our recruitment process.
We are committed to equal employment opportunities regardless of race, color, genetic information, creed, religion, sex, sexual orientation, gender identity, lawful alien status, national origin, age, marital status, or protected veteran status. We support an inclusive workplace where associates excel based on personal merit, qualification, experience, ability, and job performance.
In support of the Equal Pay for Equal Work Act, the range of starting pay for this role is $90,000 - $103,000. This is not a guarantee of compensation or salary, actual compensation is influenced by a wide range of factors including but not limited to skill set, level of experience, education, certifications, responsibility, and geographic location. We also offer a variety of benefits including health, disability insurance, 401 (k), flexible spending accounts, EAP, education reimbursement, parental leave, unlimited vacation, bonuses, incentive stock options and company paid holidays. The specific programs and options available will vary depending on state, start date, and employment type. Our recruitment team will be happy to answer any questions you may have.
#LI-Remote",glassdoor
251,"Accenture
4.1
Data Engineer
San Francisco, CA

 Accenture Flex offers you the flexibility of local fixed-duration project-based work powered by Accenture, a leading global professional services company. Accenture is consistently recognized on FORTUNE's 100 Best Companies to Work For and Diversity Inc's Top 50 Companies For Diversity lists.
As an Accenture Flex employee, you will apply your skills and experience to help drive business transformation for leading organizations and communities. In addition to delivering innovative solutions for Accenture's clients, you will work with a highly skilled, diverse network of people across Accenture businesses who are using the latest emerging technologies to address today's biggest business challenges.
You will receive competitive rewards and access to benefits programs and world-class learning resources. Accenture Flex employees work in their local metro area onsite at the project, significantly reducing and/or eliminating the demands to travel.
Job Description:
As a Data Engineer, you will:
Utilize strong SQL & Python expertise to engineer sound data pipelines and conduct routine and ad hoc analysis to assess the performance of legacy products and the saliency of new features
Build reporting dashboards and visualizations to design, create, and track campaign/program KPIs
Perform analyses on large data sets to understand drivers of marketing engagement and provide recommendations on campaign and product optimization

Basic Qualifications:
Minimum 2 years of experience in Data Engineering
Minimum 2 years of experience with SQL
Minimum 2 years of experience with Python
High School Diploma or GED
Preferred Qualifications:
Experience with Data Analytics
As required by Colorado Law under the Equal Pay for Equal Work Act, Accenture provides a reasonable range of compensation for roles that may be hired in Colorado. Actual compensation is influenced by a wide array of factors including but not limited to skill set, level of experience, and specific office location. For the state of Colorado only, the starting range of pay for this role is $86.82 - $96.82 per hour, and information on benefits is here.

COVID-19 update:

The safety and well-being of our candidates, our people and their families continues to be a top priority. Until travel restrictions change, interviews will continue to be conducted virtually.

Subject to applicable law, please be aware that Accenture requires all employees to be fully vaccinated as a condition of employment. Accenture will consider requests for accommodation to this vaccination requirement during the recruiting process.

What We Believe

We have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture has the responsibility to create and sustain an inclusive environment.

Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more here

Equal Employment Opportunity Statement

Accenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation.

All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.

Accenture is committed to providing veteran employment opportunities to our service men and women.

For details, view a copy of the Accenture Equal Opportunity and Affirmative Action Policy Statement.

Requesting An Accommodation

Accenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.

If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.

Other Employment Statements

Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States.

Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.

Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.

The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.",glassdoor
252,"Lincoln Financial
3.6
Data Engineer (REMOTE)
Radnor, PA
Employer Provided Salary:$63K - $138K

 Date: Oct 9, 2022
Primary Location: Radnor, PA, US
Company: Lincoln Financial
Alternate Locations: Work from Home

Work Arrangement: Work from Home

Relocation assistance:: is not available for this opportunity.

Pay Range: $63,100 - $137,900

Bonus Potential: 5%

Requisition #: 69444

The Role at a Glance

This is an exciting opportunity within Lincoln’s Work Place Solutions IT Data Team for a Data Engineer/ETL Developer to help build solutions for Lincoln’s Work Place Solutions business. This position will assist Analytic Teams with the design and implementation of Data solutions and systems, including integration with databases and data warehouses, both on-Premise and in AWS Cloud. This candidate must be able to develop, enhance, and support Informatica workflows and processes using Informatica Power Center and Dataiku for the extraction and transformation of data in a UNIX and Oracle database environment. They must also have experience working within BI tools such as Tableau and Microstrategy. Experience working in the cloud using AWS native services such as Glue, Athena, Aurora, Redshift, and/or Snowflake is needed. The candidate must have experience participating in and beginning to lead teams within a Data Organization by suggesting new and innovative ways of gaining data processing efficiencies and participating in architectural and modeling discussions.

What you'll be doing

Participates in defining architecture and modeling best practices within the team
Develop tools and work on integrating disparate systems using ETL
Work on transformation of data into Facts and Dims in a Kimball and/or relational model
Works with Sr. Technical Professionals to implement data development best practices
Develop, enhance and support Informatica workflows and processes using Informatica Power Center for the extraction and translation of data in a UNIX and Oracle database environment
Develop, enhance and support Dataiku workflows and processes for transforming data into Kimball model Facts/Dims
Creates partnerships with stakeholders, POs, BSAs and Analytic teams in requirement, design and coding walkthroughs to ensure the development of quality solutions and understand complex business/technical problems and opportunities and identify potential application solutions.
Demonstrates expertise in a variety of the data warehouse concepts, practices, and procedures. Relies on extensive experience and judgment to plan and accomplish goals
Analyzes operational and analytical data requirements by working with cross functional business and application development teams
Maintains knowledge on current and emerging developments/trends for assigned area(s) of responsibility, assess the impact, and collaborates with senior management to incorporate new trends and developments in current and future solutions.
Participate with collaboration efforts with development teams to review, update and approve the data portion of project designs, participate in cost/benefit analysis and preparation of project plans.
Participate in the design, development and delivery data centric IT solutions, including large scale data staging and orchestration, integration and provisioning mechanisms
Works with business partners to prioritize business and information needs
Provides input and validates increasingly complex project plans, test plans and implementation plans
Creates increasingly complex technical specifications from business requirements/business specifications
Proactively identifies problems and presents/develops solutions
Communicates effectively with internal stakeholders and management
Defines detailed development tasks, task dependencies and estimates to complete work
What we're looking for

4 Year/Bachelor's degree or equivalent work experience (4 years of experience in lieu of Bachelor's) in Computer Science, Computer Information Systems, Information Systems, Information Technology or Computer Engineering or equivalent work experience (Minimum Required
3 - 5+ Years’ experience in application development that directly aligns with the specific responsibilities for this position (Required)
Experience with ETL development
Must have experience with Informatica; Dataiku is a plus
Must have experience with BI tools such as Tableau and Microstrategy
Experience with AWS cloud native services, such as: Glue, Athena, Aurora, Redshift
Must have a proven track record working closely with business stakeholders, BSAs, and POs, Solution Architects to understand requirements and expectations to achieve quality technical solutions
What’s it like to work here?
At Lincoln Financial Group, we love what we do. We make meaningful contributions each and every day to empower our customers to take charge of their lives. Working alongside dedicated and talented colleagues, we build fulfilling careers and stronger communities through a company that values our unique perspectives, insights and contributions and invests in programs that empower each of us to take charge of our own future.

What’s in it for YOU:
A clearly defined career framework to help you successfully manage your career
Leadership development and virtual training opportunities
PTO/parental leave
Competitive 401K and employee benefits
Free financial counseling, health coaching and employee assistance program
Tuition assistance program
A leadership team that prioritizes your health and well-being; offering a remote work environment and flexible work hybrid situations
Effective productivity/technology tools and training

Work Arrangement
Work from Home : Employees will work from home and are not required to work in a Lincoln office on a regular basis.

Lincoln will evaluate the following when setting the successful candidate's wage rate:
Prior work or industry experience.
Education level to the extent education is relevant to the position.
Unique skills

About The Company
Lincoln Financial Group, a Fortune 200 company with over 10,000 employees, provides advice and solutions that help empower Americans to take charge of their financial lives with confidence. Our core business areas — Life Insurance, Annuities, Retirement Plan Services and Group Protection — focus on supporting, preserving and enhancing over 17 million customer’s lifestyles and retirement outcomes.

Headquartered in Radnor, Pennsylvania, Lincoln Financial Group is the marketing name for Lincoln National Corporation (NYSE: LNC) and its affiliates. The company had $324 billion in end-of-period account values as of June 30, 2021.

Ranked one of the Best Large Employers in America and Best Employers for Women by Forbes magazine as well as one of Newsweek’s Most Responsible Companies, Lincoln Financial Group makes a serious investment in our employees’ futures through a broad range of wealth accumulation and protection plans, health and wellness programs, and career development resources designed to help each individual reach their personal and professional goals.

Lincoln is committed to creating a diverse and inclusive environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.

Lincoln Financial Group is a committed corporate citizen included on major sustainability indices including the Dow Jones Sustainability Index North America and FTSE4Good. Dedicated to diversity and inclusion, we earned perfect 100 percent scores on the Corporate Equality Index and the Disability Equality Index. Follow us on Facebook, Twitter, LinkedIn, and Instagram.

Be Aware of Fraudulent Recruiting Activities
If you are interested in a career at Lincoln, we encourage you to review our current openings and apply on our website. Lincoln values the privacy and security of every applicant and urges all applicants to diligently protect their sensitive personal information from scams targeting job seekers. These scams can take many forms including fake employment applications, bogus interviews and falsified offer letters.
Lincoln will not ask applicants to provide their social security numbers, date of birth, bank account information or other sensitive information in job applications. Additionally, our recruiters do not communicate with applicants through free e-mail accounts (Gmail, Yahoo, Hotmail) or conduct interviews utilizing video chat rooms. We will never ask applicants to provide payment during the hiring process or extend an offer without conducting a phone, live video or in-person interview. Please contact Lincoln's fraud team at fraudhotline@lfg.com if you encounter a recruiter or see a job opportunity that seems suspicious.

Additional Information
This position may be subject to Lincoln’s Political Contribution Policy. An offer of employment may be contingent upon disclosing to Lincoln the details of certain political contributions. Lincoln may decline to extend an offer or terminate employment for this role if it determines political contributions made could have an adverse impact on Lincoln’s current or future business interests, misrepresentations were made, or for failure to fully disclose applicable political contributions and or fundraising activities.

Any unsolicited resumes/candidate profiles submitted through our web site or to personal e-mail accounts of employees of Lincoln Financial Group are considered property of Lincoln Financial Group and are not subject to payment of agency fees.

Lincoln Financial Group (“LFG”) is an Equal Opportunity employer and, as such, is committed in policy and practice to recruit, hire, compensate, train and promote, in all job classifications, without regard to race, color, religion, sex (including pregnancy), age, national origin, disability, sexual orientation, gender identity and expression, Veteran status, or genetic information. Applicants are evaluated on the basis of job qualifications. If you are a person with a disability that impedes your ability to express your interest for a position through our online application process, or require TTY/TDD assistance, contact us by calling 260-455-2558.",glassdoor
253,"Antra, Inc
4.5
Jr. Data Engineer
Sterling, VA
Employer Provided Salary:$60K - $68K

 Antra started its services in the year 2008, since then we have been diligently serving every need of our clients professional and software solutions. With our unique amalgam of innovation and inspiration, backed by Agile processes, we deliver world-class services with our core values to our clients. We identify unique strategies to transforming organizations through picking their sweet spot for innovative thinking and helping them in implementing in-depth cultural shift; ultimately augmenting the innovation process to the next level – fostering the innovation race that never ends.
This role requires the design, development and implementation of data solutions to business problems. An Azure Data Engineer will be expected to perform duties such as: evaluating the performance of current data solutions, designing and implementing cloud and hybrid data solutions. Ability to adapt and learn new technologies per business requirements is also needed.
Responsibilities:
Design and implement data solutions using industry best practices.
Performs ETL, ELT operations and administration of data and systems securely and in accordance with enterprise data governance standards.
Monitor and maintain data pipelines proactively to ensure high service availability.
Works with Data Scientists and ML Engineers to understand mathematical models and optimize data solutions accordingly.
Continuous development through training and mentorship programs.
Create scripts and programs to automate data operations.
You meet our “must haves” for this role if you have:
Minimum Bachelor’s degree in Data Science, Business Intelligence, Computer Science or related fields, or the equivalent combination of education, professional training, and work experience.
0-3 years of experience working with one or more languages commonly used for data operations including SQL, Python, Scala and R.
Experience working with relational databases such as SQL Server, Oracle and MySQL.
Experience working with NoSQL databases such as Redis, Mongo DB, Cosmos DB.
Excellent problem-solving skills and ability to learn through scattered resources.
Thorough understanding of the responsibilities and duties of a data engineer, as well as established industry standards/best practices and documentation guidelines.
Outstanding communication skills, and the ability to stay self-motivated and work with little or no supervision.
Willing to relocate to any US location on Antra projects location.
Authorization(s) to work lawfully in the United States (OPT/CPT is acceptable).
Plus, if you meet any the of requirements:
Experience with cloud-based data technologies.
Experience with distributed systems utilizing tools such as Apache Hadoop, Spark or Kafka.
Working experience in Agile Scrum environments.
Experience with source control tools such as Git, SVN and TFS.
The intent of this position description is to provide a representative summary of the major duties and responsibilities performed by incumbent(s) in this position. Incumbent(s) may not be required to perform all duties in this description and incumbent(s) may be required to perform position-related tasks other than those specifically listed in this description.
Antra Inc. is an equal opportunity employer, providing equal employment opportunities (EEO). All employees and applicants for employment will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity or expression, pregnancy, protected veteran status or other status protected by law. This policy applies to all terms and conditions of employment.
Job Types: Full-time, Contract
Pay: $60,000.00 - $68,000.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Health savings account
Life insurance
Paid time off
Professional development assistance
Referral program
Relocation assistance
Vision insurance
Schedule:
Monday to Friday
Application Question(s):
Are you open for relocation within the US?
Education:
Bachelor's (Preferred)
Work Location: Hybrid remote in Sterling, VA 20166",glassdoor
254,"Adobe
4.4
Software Development Engineer - Data Science & Analytics
Lehi, UT
$108K - $155K (Glassdoor est.)

 Our Company

Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.

We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!

Our Company
Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands— everything they need to design and deliver exceptional digital experiences. We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.

We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours.
The Opportunity
Adobe is seeking hardworking and passionate Cloud Software Engineer to plan, design, and develop internal analytical tools, dashboards and reporting to help Engineers to Executives make data driven decisions.

We’re on a mission to hire the very best and are committed to building exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!
What You’ll Do
Develop high-performance, reliable, testable and maintainable code.
Participating in all aspects of software development activities, including design, coding, code review, testing, bug fixing, and code/API documentation.
Collaborate with engineers and participate in daily or weekly stand ups and meetings.
Develop reporting dashboards and analytical tools to help Adobe teams manage their AWS & Azure Cloud resources.
Build and automate data sets to answer key business questions using data and data visualizations.
Grow with the support of your team and help others on the team grow by providing thoughtful feedback and uplifting those around you.
Work both independently and collaboratively within a fast-paced development team, with clear, positive, and constructive communication.
What You Need to Succeed
Bachelor's or Master’s in Computer Science, Information Systems, Data Science or equivalent experience required.
Proficient in programming languages such as JavaScript, Python & SQL.
Strong technical background with analytical and problem-solving skills.
Strong proficiency with Business Analytics tools like Power BI & Tableau.
Extensive experience with cloud hosting technology, including Azure and AWS infrastructure.
Experience developing web applications using ReactJS is helpful.
Excellent problem solving and debugging skills, and direct experience with DevOps in a public cloud environment.
Passion for quality and engineering excellence at scale, attention to details, and ability to multitask and meet deadlines.
Excellent communication and collaboration skills.

If you’re looking to make an impact, Adobe’s the place for you. Discover what our employees are saying about their career experiences on the Adobe Life blog and explore the meaningful benefits we offer.
Adobe is an equal opportunity employer. We welcome and encourage diversity in the workplace regardless of race, gender, sexual orientation, gender identity, disability or veteran status.",glassdoor
255,"Vimeo
4.1
Data Engineer II, Analytics
New York, NY
$107K - $150K (Glassdoor est.)

 Vimeo is looking for an experienced Data Engineer II, Analytics to join our Data Architecture and Analytics Engineering team and work closely with Data Analysts and Data Scientists to create and maintain robust, scalable, and sustainable data models that provide decision-making insights for senior leadership including executives. The ideal candidate is a self-starter with a bias for action and results, with experience in a fast-paced, data-driven environment.
What you'll do:
Build data models that can support dynamic and efficient data analysis, and collaborate with other teams to maintain and evolve those models over time
Ensure alignment to coding standard methodologies and development of reusable code
Partner with Data Analysts to understand business processes and identify opportunities to build scalable and efficient data models that can be used for scalable, refreshable analysis and reporting
Create and enable the generation of ad-hoc / on-demand data sets for use by analysts and data scientists
Work with Engineering teams to set up monitoring and alerting systems for business and product KPIs
Skills and knowledge you should possess:
BS/MS in Computer Science or a related technical field.
2+ years working with Analytics and Data Engineering teams with a mixed data engineering and analytics background
2+ years of experience in scalable data architecture, fault-tolerant ETL, and monitoring of data quality in the cloud
Experience working on or leading initiatives around data governance, master data management, data catalogs, and enterprise data warehouse architecture
Strong analytical skills, data sensibility, and an able communicator
Open to working on multiple projects simultaneously
Proficiency in:
SQL
Python
Dimensional Modeling
Data pipeline development, workflow management, and orchestration tools
ETL optimization and best practices
Snowflake or other column-oriented and cloud-based databases
Looker or any similar Business Intelligence tool
Relational Databases
Bonus Points (Nice Skills to Have, but Not Needed):
DBT
Git / Github
Looker/Tableau is a big plus
large data sets (terabyte scale)
Apache Airflow
#LI-JS1
Vimeo (NASDAQ: VMEO) is the world's leading all-in-one video software solution. Our platform enables any professional, team, and organization to unlock the power of video to create, collaborate and communicate. We proudly serve our growing community of over 260 million users — from creatives to entrepreneurs to the world's largest companies.
Vimeo is headquartered in New York City with offices around the world. At Vimeo, we believe our impact is greatest when our workforce of passionate, dedicated people, represents our diverse and global community. We're proud to be an equal opportunity employer where diversity, equity, and inclusion is championed in how we build our products, develop our leaders, and strengthen our culture.
Learn more at www.vimeo.com
Learn more at www.vimeo.com/jobs",glassdoor
256,"NucleusTeq
4.9
Data Engineer
Remote

 Data Engineer
Role Info:
Hands on BI Data Engineer role with strong
Creating KPI Dashboards - Interactive Dashboards using tableau / Quicksight
Top Skills:
BI Tableau / AWS Quicksight exp is a must
AWS (IAM, RDS, S3, Lambda) exp is a must
SQL exp is a must
Python knowledge is required
Nice to have:
AWS Certified Solutions Architect
About the Company:
NucleusTeq is a software services, solutions & products company empowering & transforming customer's business through the use of digital technologies such as Big-Data, Analytics, Cloud, Enterprise Automation, Block-chain, Mobility, etc.
We are enabling several fortune 1000 clients in the USA, Canada, UK & India to navigate their digital transformation.",glassdoor
257,"Mastercard
4.3
Data Engineer - Launch 2023
Arlington, VA

 Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a
culture of inclusion
for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Job Title
Data Engineer - Launch 2023
The Mastercard Launch program is aimed at early career talent, to help you develop skills and gain cross-functional work experience. Over a period of 18 months, Launch participants will be assigned to a business unit, learn and develop skills, and gain valuable on the job experience.

Be part of the Data & Services Technology Team at Mastercard, Data and Services

Data Engineers are fundamental to the success of our client engagements by acting as the bridge between raw client data and Mastercard's software. Data Engineers work closely with both Consultants while working on consulting engagements and Software Development Engineers while working to develop internal capabilities. Data Engineers are responsible for:
Designing processes to extract, transform, and load (ETL) terabytes of data into Mastercard's analytics platform
Sourcing data from clients, government and other third party data sources, and Mastercard's transaction data warehouse
Working across multiple teams, both internal and external, in order to determine the data requirements and business logic applicable to each data set
Tackling big data problems across various industries

Make an Impact as a Data Engineer
Here are just a few of the benefits that you will get to experience during your first year as a Data Engineer:
Strategic problem solving with exceptional peers who are also passionate about data
Creative freedom to innovate with new technologies and to explore a variety of solutions
Staffing on external-facing consulting projects where you will have the opportunity to work directly with clients
Flexibility to work on many new and challenging projects across diverse industries
A dynamic environment where you will have an impact and make an immediate difference
An immediate opportunity for increased responsibility, leadership, and professional growth
Committed mentoring and training by an experienced and driven leadership team
Cross-functional collaboration with others throughout Mastercard
Bring your passion and expertise

We recruit for and value the following core competencies:
Currently enrolled student pursuing a Bachelor's or Master's degree studying Computer Science, Data Engineering, or a related field
Desire to work with data and help businesses make better data-driven decisions
Understanding of relational databases, SQL, and database management
Excellent written and verbal communication skills
Strong troubleshooting and problem-solving capabilities
Demonstrated analytical and quantitative skills
The role also involves these skills. We don't require them, but it's helpful if you already have them:
Hands-on experience with the ETL process and SSIS
Knowledge of at least one programming language
COVID-19 Considerations
In many locations, we’ve implemented a virtual hiring process and continue to interview candidates by video or phone. In addition, in our NYC offices, as required by law, only individuals who have been fully vaccinated against COVID-19 will be permitted inside Mastercard offices unless a reasonable accommodation has been approved in advance.
In the US, Mastercard is an inclusive Equal Employment Opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. If you require accommodations or assistance to complete the online application process, please contact reasonable_accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.
Corporate Security Responsibility
All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.",glassdoor
258,"Apple
4.2
Machine Learning Data Collection Engineer, Technology Development Group (TDG)
Cupertino, CA

 Summary
Posted: Mar 15, 2022
Role Number:200356922
Do you want to push the limits of the best Augmented Reality platform in the world? Apple's Technology Development Group (TDG) delivers algorithms that drive revolutionary Apple products, including the augmented reality (AR) platform ARKit to create ground-breaking new products. In this position, you will have the opportunity to be part of our extraordinary data team to discover and build solutions to previously-unsolved challenges and push the state of the art in AR algorithms that will change the way people experience the world! We are looking for a driven Machine Learning Data Collection Engineer that enjoys getting into the details to collect valuable data that feeds our machine learning models. As a member of the fast-paced data team, you have the rewarding opportunity to shape upcoming products that will delight and inspire millions of people every day. To succeed within this role, you should have shown experience in several of the following areas:
Key Qualifications
Ability to define/design/develop data collection efforts that focus on the end-to-end user experience, including anticipating potential failure modes, edge cases, and anomalies
Capacity to multitask and manage several projects in parallel while meeting deadlines and providing access to clients and partners
Problem solving & critical thinking capacities, thinking outside the box in order to gain in speed, efficiency, and quality.
Ability to re-construct ill-defined data needs into concrete project deliverables
Ability to maintain and develop relationships with multi-functional teams
Excellent project management, communication, interpersonal, analytical, and organizational skills
Description
As a Machine Learning Data Collection Engineer, you'll be working with our customers to understand their data collection requirements, assisting them in defining their protocols, and executing on the data collection. Your job responsibilities will include: -Collaborate with algorithm teams and understand data collection requirements in order to define collection protocols -Define and design the collection requirements and lead the collection effort from start to finish -Coordinate the efforts between internal teams (Legal, privacy, security, etc) guaranteeing compliance with applicable rules, laws, and best practices -Create documents and procedures needed to run data collections -Managing and track progress of externally run data collections
Education & Experience
Bachelors degree or related practical experience
Additional Requirements",glassdoor
259,"Apple
4.2
Biomedical Data Engineer - Health Technologies
Cupertino, CA

 Summary
Posted: Aug 8, 2022
Weekly Hours: 40
Role Number:200402289
The Health Technologies Team conceives and proves out innovative technology for Apple’s future products and features in health. We are seeking a highly capable Biomedical Data Engineer to join a multi-disciplinary team. Successful candidates will be able to integrate with our research study leads, data scientists and engineers to develop and support effective data analysis and machine learning workflows.
Key Qualifications
Experience with software engineering frameworks
Excellent coding skills in Python (e.g.,Pandas, Spark, Jupyter)
Workflow orchestrations (e.g., Airflow, Luigi)
Designing and maintaining (non-)relational databases (e.g. Postgres, Cassandra, MongoDB) and file systems (e.g. Parquet, CSV, JSON)
Great understanding of infrastructure designs
Linux, MacOS based development frameworks
iOS/ watchOS development (e.g., Swift, Objective-C)
Web Service APIs (e.g., AWS, REDCap, XNAT)
Version control frameworks (Git, virtualenv)
Familiarity with best practices for information security, including safe harbor privacy principles for sensitive data
Experience with biomedical sensors/platforms for measuring physiological signals in the health, wellness and/or fitness realms
Description
- Work closely with team members and study staff to design, build, launch and maintain systems for storing, aggregating and analyzing large amounts of data - Process, troubleshoot, and clean incoming data from human studies - Automate and monitor data ingestion and transformation pipelines, with hooks for QA, auditing, redaction and compliance checks per data management specifications - Create and maintain databases with existing and incoming clinical data - Architect data models and create tools to harmonize disparate data sources - Incorporate and comply with regulations as they pertain to electronic and clinical data and databases
Education & Experience
BS/MS in Computer Science, Engineering, Informatics, or equivalent with relevant 4+ years industry experience with biomedical, health or sensitive data.
Additional Requirements",glassdoor
260,"Farmers Insurance Group
3.7
Data Engineer (Application SME I)
Remote
Employer Provided Salary:$74K - $98K

 We are Farmers!
We are… more than just your favorite commercials. We are a passionate, award winning, equal opportunity employer, committed to the strength of a diverse workforce. We are dedicated to supporting the well-being of our people through our extensive suite of benefits, as well as the well-being of the communities we serve through employee volunteer programs and nonprofit partnerships. Helping others in their time of need isn’t just our business – it’s our culture! We are Farmers!

Do you thrive in a high-volume, fast-paced environment? Do you enjoy the challenge of a position where no two days are alike? We are looking for positive, high-energy professionals who are not just looking for a job, but a meaningful career!

Job Summary
Use MS SQL SSIS to build ETL process to create new business functionalities as well to solve business problems: Respond to new requests for reports/data understanding business objectives and processes; review and refine technical requirements/User Stories; and communicate estimated hours and timeline to complete; Extract data directly from relational databases (e.g. DB2, SQL Server), data warehouses, or other data stores using SQL; Ability to create manual as well as automated data exports/reports; and Support application unit testing for enhancements or system upgrades; identify and communicate data quality issues or data differences. Work productively on assigned tasks; Collaborate effectively with other team members; Demonstrate accountability to management and business for hours spent on assigned tasks; and diligently strive to deliver value.
Essential Job Functions
Education Requirements
High school diploma or equivalent required.
Bachelor’s degree preferred, in Information Systems or related field.
Experience Requirements
Experience in developing ETL and reporting applications using Microsoft SQL Server (strongly preferred), or Informatica or similar ETL technologies.
Experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process on MS SQL Server or DB2 or similar DB platform.
Experience with Python and unstructured data manipulation is a plus.
Experience with cloud technologies such as AWS Glue, Azure Data Factory, Snowflake is a plus.
Experience working in an Agile Environment is a plus.
Good knowledge of business intelligence best practices, processes, and methodologies.
Good programming experience in writing Stored Procedures, Queries, Views, User Defined Functions, and Common Table Expressions using SQL or T-SQL.
Highly committed, motivated, enthusiastic and a natural team player.
Good interpersonal and communication skills (both verbal and written) and ability to interact with and effectively address concerns.
Good prioritization, time management, analytical, and organization skills.
Experienced in facilitating in-person and remote meetings with business & IT.
Experienced in effective management of multiple competing and frequently changing assignments and priorities.

Benefits
Farmers offers a competitive salary commensurate with experience, qualifications and location
Colorado Only: The pay range for this job being performed in Colorado would be 73,600 - 98,100
Bonus Opportunity (based on Company and Individual Performance)
401(k)
Medical
Dental
Vision
Health Savings and Flexible Spending Accounts
Life Insurance
Paid Time Off
Paid Parental Leave
Tuition Assistance

Job Location(s): R_US - RW - Remote Work",glassdoor
261,"Apple
4.2
ML Data Collection and Data Science Engineer (TDG)
Cupertino, CA

 Summary
Posted: May 16, 2022
Role Number:200380146
Do you want to push the limits of the best Augmented Reality platform in the world? Apple's Technology Development Group (TDG) delivers algorithms that drive revolutionary Apple products, including the augmented reality (AR) platform ARKit to create ground-breaking new products. In this position, you will have the opportunity to be part of our extraordinary data team to discover and build solutions to previously-unsolved challenges and push the state of the art in AR algorithms that will change the way people experience the world! We are looking for a driven Machine Learning Data Collection Engineer that enjoys getting into the details to collect valuable data that feeds our machine learning models. As a member of the fast-paced data team, you have the rewarding opportunity to shape upcoming products that will delight and inspire millions of people every day. To succeed within this role, you should have shown experience in several of the following areas:
Key Qualifications
Ability to define/design/develop data collection efforts that focus on the end-to-end user experience, including anticipating potential failure modes, edge cases, and anomalies
Proficiency in programming languages including Python, C++, or similar
Capacity to multitask and manage several projects in parallel while meeting deadlines and providing access to clients and partners
Problem solving & critical thinking capacities, thinking outside the box in order to gain in speed, efficiency, and quality.
Excellent project management, communication, interpersonal, analytical, and organizational skills
Experience with industrial software development, a plus
Experience with CVML, a plus
Description
As a Machine Learning Data Collection Engineer, you'll be collaborating with multi-functional teams to work on CVML data collection projects, from collecting data collection requirements, designing protocols, testing software and hardwares, executing data collection, to analyzing and curating collected data. Your job responsibilities will include -Contribute to the design of CVML data collection, including hardware, software, user interface specifications, and collection protocols. -Define, implement, maintain SW and HW solutions to test data collection hardware, software and protocols. -Design, implement and maintain SW platforms to monitor date life cycle -Work with CVML engineers to design and implement data evaluation and curation process -Analyze data and build data analysis tools -Collaborate with multi-functional teams including algorithm, hardware, software, product design, project management, legal, procurement, security, logistics and vendors to define and deliver necessary study elements -Write technical documents including study instructions, operating procedures and training documents for study personnel -Drive process improvements across the organization to continuously improve the way we work
Education & Experience
B.S., M.S., or Ph.D. in Computer Science, Computer Engineering, or equivalent practical experience.
Additional Requirements",glassdoor
262,"Faire
4.8
Data Engineer
San Francisco, CA
$117K - $170K (Glassdoor est.)

 About Faire
Faire is an online wholesale marketplace built on the belief that the future is local — there are over 2 million independent retailers in North America and Europe doing more than $2 trillion in revenue. At Faire, we're using the power of tech, data, and machine learning to connect this thriving community of entrepreneurs across the globe. Picture your favorite boutique in town — we help them discover the best products from around the world to sell in their stores. With the right tools and insights, we believe that we can level the playing field so that small businesses everywhere can compete with these big box and e-commerce giants.
By supporting the growth of independent businesses, Faire is driving positive economic impact in local communities, globally. We're looking for smart, resourceful and passionate people to join us as we power the shop local movement. If you believe in community, come join ours.
Job Description
The Data Engineering team is the backbone of all data-related processes and enables the Data Science teams to develop and deploy a wide variety of algorithms and models that power the marketplace. Our infrastructure is used by the whole company for analytics, reporting, forecasting and research. We care about having a reliable & scalable infrastructure with quality data and building machine learning models that help our customers thrive.
As a Data Engineer you'll be responsible for developing and automating large scale, high-performance data storage and processing systems.
What you will be doing:
Develop our data infrastructure to help us scale for where we're going over the next several years
orchestrating pipelines using modern Big Data tools/architectures as well as design and engineering of existing transactional processing systems
Manage our data infrastructure and ETL platform
What it takes:
2+ years experience in a Data Engineering role with an emphasis on managing data warehouses
Strong skills in Python, Git, Docker, SQL, Airflow, real time ETL pipelines
Managing data infrastructure (AWS services, Data orchestrator) and providing framework to rationalize and simplify both real time and batch data pipelines
Familiarity with Snowflake or BigQuery
A passion for programming and solving problems with code
A bachelor's degree in Computer Science/Software Engineering or equivalent industry experience
A love for technology, and an insatiable curiosity for new tools to tackle real problems
Faire's flexible work model aims to meet the needs of our diverse employee community by making work more flexible, connected, and inclusive. Depending on the role and needs of the team, Faire employees have the flexibility to choose how they work–whether that's mainly in the office, remotely, or a mix of both.
Roles that list only a country in the location are eligible for fully remote work in that country or in- office work at a Faire office in that country, provided employees are located in the registered country/province/state. Roles with only a city location are eligible for in-office or hybrid office work in that city. Our talent team will work with candidates to determine what locations and roles are eligible for each option.
Why you'll love working at Faire
We are entrepreneurs: Faire is being built for entrepreneurs, by entrepreneurs. We believe entrepreneurship is a calling and our mission is to empower entrepreneurs to chase their dreams. Every member of our team is an owner of the business and taking part in the founding process.
We are using technology and data to level the playing field: We are leveraging the power of product innovation and machine learning to connect brands and boutiques from all over the world, building a growing community of more than 350,000 small business owners.
We build products our customers love: Everything we do is ultimately in the service of helping our customers grow their business because our goal is to grow the pie - not steal a piece from it. Running a small business is hard work, but using Faire makes it easy.
We are curious and resourceful: Inquisitive by default, we explore every possibility, test every assumption, and develop creative solutions to the challenges at hand. We lead with curiosity and data in our decision making, and reason from a first principles mentality.
Faire was founded in 2017 by a team of early product and engineering leads from Square. We're backed by some of the top investors in retail and tech including: Y Combinator, Lightspeed Venture Partners, Forerunner Ventures, Khosla Ventures, Sequoia Capital, Founders Fund, and DST Global. We have headquarters in San Francisco and Kitchener-Waterloo, and a global employee presence across offices in Salt Lake City, Atlanta, Toronto, London, New York, LA, and Sao Paulo. To learn more about Faire and our customers, you can read more on our blog.
Faire provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity or gender expression.
Faire is committed to providing access, equal opportunity and reasonable accommodation for individuals with disabilities in employment, its services, programs, and activities. To request reasonable accommodation, please fill out our Accommodation Request Form.",glassdoor
263,"Apple
4.2
Keystone Big Data Software Engineer, Global Business Intelligence
Cupertino, CA

 Summary
Posted: Jul 18, 2022
Role Number:200399924
Imagine what you could do here! At Apple, great minds come together to build products, services, and solutions that amaze the world. Imagine how your contributions could transform the world and there is no limit to what you could accomplish here. Apple's Global Business Intelligence (GBI) team is seeking an experienced Software Engineer to build high quality, scalable and resilient distributed systems that power Apple's analytics platforms and data pipelines. Apple's Enterprise Data Warehouse landscape caters to a wide variety of real-time, near real-time and batch analytical solutions. These solutions are an integral part of business functions like Sales, Operations, Finance, AppleCare, Marketing, and Internet Services, enabling business drivers to make critical decisions. If you enjoy learning new technologies, and are comfortable proposing and implementing solutions, demonstrating Software Engineering standard methodologies, you will find it rewarding to work in GBI! The ideal candidate for this position will be able to think outside of the box and should have passion for building engineering solutions to enable business in making time sensitive and critical decisions.
Key Qualifications
Strong fundamentals in data structures, algorithms, and software system design
Strong hands-on programming skills (Scala / Java / Python preferred)
Proven track record of building jobs processing high-volume data using Spark
Experience with real time data processing with Spark Streaming, Flink is a huge plus
Committed to test driven development paradigm
Strong analytical and interpersonal skills and demonstrated ability to code & collaborate
Self-starter, highly motivated and ability to research, learn, prototype quickly
Sound experience in Cloud technologies such as AWS or GCP
Experience on Cloud with databases like SnowFlake and Singlestore is a plus
Prior experience in the areas of AI/ML/Data Sciences will be a strong plus
Curiosity to explore and understand data is a plus
Description
The Frameworks team in GBI build and support critical infrastructural systems which provide services for numerous organizations within Apple and we are looking for a strong, enthusiastic developer to join as a member of this group. You are someone with ideas and real passion for software delivered as a service to improve reuse, efficiency, and simplicity. This engineer’s work will affect multiple data teams within Apple and enable our partners to derive insights and help execute their goals.
Education & Experience
BS/MS in Computer Science, Computer Engineering or similar field
Additional Requirements
Apple is an Equal Opportunity Employer that is committed to inclusion and diversity. We also take affirmative action to offer employment and advancement opportunities to all applicants, including minorities, women, protected veterans, and individuals with disabilities. Apple will not discriminate or retaliate against applicants who inquire about, disclose, or discuss their compensation or that of other applicants.
We at Apple we are committed to working with and providing reasonable accommodation to applicants with physical and mental disabilities. Learn more.",glassdoor
264,"Cigna
3.8
BI Data Engineer-Work from home-eviCore
Hartford, CT
Employer Provided Salary:$96K - $160K

 Duties
Build ETL processes to allow data to flow seamlessly from source to target using tools like Databricks, Azure Data Factory, SSIS, SQL Stored Procedures and Powershell scripting
Load and enhance dimensional data models
Leverage code to apply business rules to ensure data is clean and is interpreted correctly by all business stakeholders, using tools like Databricks, SQL, Scala and Python
Perform code reviews and QA
Participate in sprint ceremonies
Provide on-call support to offshore operations team
Train operations teams on the ETL processes being developed
Troubleshoot and address issues with the data and/or the ETL process
Fine tune existing code to make processes more efficient
Maintain and create documentation to describe our data management processes
Analyze reports using various tools like Micro Strategy, Tableau and SSRS
Support user questions on data management processes and results

Minimum Required Skills
5+ Years building Big Data and Data Warehousing solutions
Knowledge of data modeling (including dimensional modeling), data architecture & data governance concepts
Experience in working with implementations of Azure cloud data solutions (ADLS, Data Bricks, Synapse, ADF)
Proficient in database concepts and technologies including MS SQ Server, DB2 and Oracle
Excellent written and oral communications skills
Must be able to effectively communicate complex technical topics to a variety of audiences
Experience with Healthcare data is a plus

Minimum Education, Licensure and Professional Certification requirement:
Bachelor’s degree with relevant experience required.
Master’s Degree is a plus.

If you will be working at home occasionally or permanently, the internet connection must be obtained through a cable broadband or fiber optic internet service provider with speeds of at least 10Mbps download/5Mbps upload.

For this position, we anticipate offering an annual salary of 95,900 - 159,800 USD / yearly, depending on relevant factors, including experience and geographic location.

This role is also anticipated to be eligible to participate in an annual bonus plan.

We want you to be healthy, balanced, and feel secure. That’s why you’ll enjoy a comprehensive range of benefits, with a focus on supporting your whole health. Starting on day one of your employment, you’ll be offered several health-related benefits including medical, vision, dental, and well-being and behavioral health programs. We also offer 401(k) with company match, company paid life insurance, tuition reimbursement, a minimum of 18 days of paid time off per year and paid holidays. For more details on our employee benefits programs, visit Life at Cigna .

About Cigna
Cigna Corporation exists to improve lives. We are a global health service company dedicated to improving the health, well-being and peace of mind of those we serve. Together, with colleagues around the world, we aspire to transform health services, making them more affordable and accessible to millions. Through our unmatched expertise, bold action, fresh ideas and an unwavering commitment to patient-centered care, we are a force of health services innovation. When you work with us, or one of our subsidiaries, you’ll enjoy meaningful career experiences that enrich people’s lives. What difference will you make?

Qualified applicants will be considered without regard to race, color, age, disability, sex, childbirth (including pregnancy) or related medical conditions including but not limited to lactation, sexual orientation, gender identity or expression, veteran or military status, religion, national origin, ancestry, marital or familial status, genetic information, status with regard to public assistance, citizenship status or any other characteristic protected by applicable equal employment opportunity laws.

If you require reasonable accommodation in completing the online application process, please email: SeeYourself@cigna.com for support. Do not email SeeYourself@cigna.com for an update on your application or to provide your resume as you will not receive a response.

Cigna has a tobacco-free policy and reserves the right not to hire tobacco/nicotine users in states where that is legally permissible. Candidates in such states who use tobacco/nicotine will not be considered for employment unless they enter a qualifying smoking cessation program prior to the start of their employment. These states include: Alabama, Alaska, Arizona, Arkansas, Delaware, Florida, Georgia, Hawaii, Idaho, Iowa, Kansas, Maryland, Massachusetts, Michigan, Nebraska, Ohio, Pennsylvania, Texas, Utah, Vermont, and Washington State.",glassdoor
265,"Expression Networks
4.4
Data Engineer
Remote

 Founded in 1997 and headquartered in Washington DC, Expression Networks provides data fusion, data analytics, software engineering, information technology, and electromagnetic spectrum management solutions to the U.S. Department of Defense, Department of State, and national security community. Expression's “Perpetual Innovation” culture focuses on creating immediate and sustainable value for our clients via agile delivery of tailored solutions built through constant engagement with our clients. Expression Networks was ranked #1 on the Washington Technology 2018's Fast 50 list of fastest-growing small business Government contractors and a Top 20 Big Data Solutions Provider by CIO Review.

We make sure to provide everyone the tools and opportunities to grow while working on some of the newest technologies in the industry. With Covid-19 being a major theme the last two years having a growing collaborative culture has been one of the key focus of our C-suite and upper management. We get excited about celebrating our professionals' milestones, accomplishments, promotions, overcoming challenges, and many other aspects that make an engaging collaborative environment.

We are looking to bring on a mid-level Data Engineer to add to the continued growth of our Data Science division. This position will work in a team led by a principal data engineer on tasks related to designing and delivering high-impact data architecture and engineering solutions to our customers across a breadth of domains and use cases.
Location:
Remote, with the ability to travel per project requirements.
Security Clearance:
Ability to obtain Secret Clearance or Higher
Responsibilities:
Developing, testing, and documenting software code for data extraction, ingestion, transformation, cleaning, correlation, and analytics
Participating in end-to-end architectural design and development lifecycle for new data services/products, and making them operate at scale
Participating in cross-functional team collaboration to understand customer requirements, design prototypes, and optimize existing data services/products
Demonstrating Data Science excellence in the teams you work with across the organization, and mentoring junior members in the Data Science division
Participating in research, case studies, and prototypes on cutting-edge technologies and how they can be leveraged
Required Qualifications:
3+ years of experience bringing databases, data integration, and data analytics/ML technologies to production with a Bachelor's degree in Computer Science/Data Science/Computer Engineering or relevant field
Mastery in developing software code in one or more programming languages (Python, JavaScript, Java, Matlab, etc.)
Expert knowledge in databases (SQL, NoSQL, Graph, etc.) and data architecture (Data Lake, Delta Lake)
Knowledgeable in machine learning/AI methodologies
Experience with one or more SQL-on-Hadoop technology (Hive, Impala, Spark SQL, Presto, etc.)
Preferred Qualifications:
Experience in short release cycles and the full software lifecycle
Experience with Agile development methodology (e.g., Scrum)
Strong writing and oral communication skills to deliver design documents, technical reports, and presentations to a variety of audiences
Benefits:
Expression Networks offers competitive salaries and benefits, such as:
401k matching
PPO and HDHP medical/dental/vision insurance
Education reimbursement up to $10,000/yr.
Complimentary life insurance
Generous roll over PTO and 11 days of holiday leave
Onsite gym facility and trainer
Commuter Benefits Plan
In office Cold Brew Coffee
Equal Opportunity Employer/Veterans/Disabled",glassdoor
266,"Mint Mobile
3.6
Digital Data Engineer I - Remote
Costa Mesa, CA
Employer Provided Salary:$90K - $103K

 MINT MOBILE is seeking a talented Digital Data Engineer I to join the Data Management Team! Individual reports to Customer Data Manager. Role is remote; must reside in the United States.
ABOUT THE ROLE
Provide direct data engineering development to data pipelines for ETL establishment and enhancements to and from data warehouses to customer management platform (Braze). Work collaboratively with cross-functional teams to determine digital data needs, establish data collection requirements, and deploy & maintain accurate data to ensure metrics & dimensions are addressed for analytics/reporting requirements.
Your usual day of awesomeness includes:
Transform required data conditions into performance code logic.
Develop high-performance code in SQL and Python.
Develop, automate, and enhance ELT processes for continuous data flow.
Create, modify, and deploy code to production via AWS resources including Lambda, S3, Glue, Redshift, etc.
Partner with stakeholders to support the implementation and development of data requirements.
Troubleshoot data anomalies and provide applicable solutions.
Build, test and maintain database pipeline architectures.
WHAT YOU BRING
Advanced level in SQL and Python for data engineering and backend development.
Understanding of popular code development approaches:
Test-driven development
Continuous Integration/Continuous Deployment (CI/CD)
Experienced working with AWS services (Lambda, S3, Glue, Redshift etc.) and Cloud Data Warehouse.
Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
Define digital data collection methods and implementations to DWH and customer management platforms.
Experienced with QA testing process to verify data is collected & rendered as expected.
Ability to excel in a fast-paced, cross-functional environment.
Ability to work autonomously.
Excellent written and verbal communication skills.
Proactive problem-solving and critical thinking skills.
Ability to manage time effectively and consistently meet deadlines.
NICE TO HAVE
Prior working knowledge of Braze or other Customer Management Platforms
Snowflake Cloud Data Warehouse
Terraform/Bitbucket/Airflow/Jenkins
Looker, Tableau, Power BI
WE ARE MINT MOBILE
We connect people to what's most important in their lives: Easily, affordably and reliably. We strive to be California's Preeminent Destination Employer. Oh yeah, we get it too! We understand what matters to you most. You're an individual with unique needs, and we're prepared to exceed any expectations you have for an ideal employer.
We're smart, strategic, and get things done without a lot of red tape or unnecessary politics. Everyone matters here and everyone has a voice. Expect to spend your time contributing to projects that really matter. We obsess over the employee experience. To start, we provide some of the most competitive salary, benefits, family leave, vacation, retirement and equity options in Southern California. We believe in you and invest in you. Not just your career aspirations, but your life.
In addition, we've got a laundry list of perks you'll brag about on insta - Lunch every day prepared by our very own chef, healthy snacks, onsite gym, free massages, car wash services, and most importantly, a team atmosphere. We even raise the bar on well bars, including Espresso/Cappuccino/Nitro/Cold Brew/Kombucha Bar, Froyo Bar, Breakfast Bar, Snack Bar and a, well, you know, bar (after 5 pm).
And if you feel intrigued right now reading, imagine the co-workers we have already attracted. This is the kind of team you'll want to take home to mom or invite to your kid's next birthday party. This is the kind of close-knit community happening here. Come check out how you can be part of Mint!
OUR VALUES – LET'S MAKE LIFE ULTRA TOGETHER!
Ownership: We are all owners; be the outcome and get the job done.
Action Biased: Be brilliant, proactive, and act with urgency.
Embrace the Adventure: Be agile, adaptive, and thrive on change.
Invent and Simplify: Never accept good enough.
$1,000 REFERRAL BONUS
Take a look at this job description, if you are the right person, please apply. If Mint Mobile doesn't appear to be a fit for you, refer a friend or colleague and get $1,000. Let your friend or colleague know to provide your full name and email when applying to the job. If we hire them and they stay for 90 days, you get $1000. For more details of restrictions and rules, please email recruiting@ultra.me.

Covid-19 Vaccination Requirement
UVNV, Inc. has adopted a mandated vaccination policy to support the health and safety of our team members and our community. The Company requires all employees to be fully vaccinated. The Company will provide accommodations based on medical condition or sincerely held religious beliefs or practices. Please let us know if you'd like to discuss the policy or available accommodations before proceeding with our recruitment process.
We are committed to equal employment opportunities regardless of race, color, genetic information, creed, religion, sex, sexual orientation, gender identity, lawful alien status, national origin, age, marital status, or protected veteran status. We support an inclusive workplace where associates excel based on personal merit, qualification, experience, ability, and job performance.
In support of the Equal Pay for Equal Work Act, the range of starting pay for this role is $90,000 - $103,000. This is not a guarantee of compensation or salary, actual compensation is influenced by a wide range of factors including but not limited to skill set, level of experience, education, certifications, responsibility, and geographic location. We also offer a variety of benefits including health, disability insurance, 401 (k), flexible spending accounts, EAP, education reimbursement, parental leave, unlimited vacation, bonuses, incentive stock options and company paid holidays. The specific programs and options available will vary depending on state, start date, and employment type. Our recruitment team will be happy to answer any questions you may have.
#LI-Remote",glassdoor
267,"Milo's Tea Company
4.1
Data Engineer
Remote

 Overview: Milo’s Tea Company is one of the fastest growing beverage companies in the US. Our culture and operations are built on the belief that we can make a difference in the world. That’s why we put People First and strive to continually reduce our environmental impact on the planet. We leverage our world class operations and decades-long distribution partnerships to grow the footprint of our core products and create new, innovative beverage products.
We are the #1 and fastest growing brand in the Refrigerated Tea Category in the nation.
Our core mission is that we put people and the planet first and by doing this, it will be good for our business.
We are committed to unlocking the personal genius of every associate and have a strong focus on growth and learning.
Our Company is women-led (our Executive Team is 57% female) and strongly committed to Diversity, Inclusion and Belonging.
We are committed to annual charitable giving by delivering upon our 1% profit pledge.
We are Platinum Certified in Zero Waste Manufacturing; recycling, reducing, and reusing 95% of waste at all facilities.
Being a part of the Milo’s TEAm, you’ll get to collaborate with a group of passionate and high-performing people, where everyone feels empowered to do their best work and feels good about the work they’re doing.
And as a ""People First"" company, Milo’s is committed to the success and well-being of our associates, customers, and fans, no matter their gender, race or creed. Some of the benefits offered that reflect our commitment include:
Competitive salary with bonus opportunities
100% paid medical insurance for our associates and their families
401K with a company match
Partial tuition reimbursement assistance
A robust parental leave program
Paid time off to volunteer at the charity of your choice
Employee assistance program
Responsibilities: The Data Engineer is responsible for assisting with data management, modeling, development, transformation, and reporting activities.
*
Responsibilities: *
Identify business needs, determine possible solutions, and develop solutions that include systems components, and process improvements with data driven decision making.
Work with business groups to design and develop reporting and analytics solutions that will improve efficiency and effectiveness.
Designs, implements, tests, troubleshoots, documents, and supports data models, programs, scripts, and ETL (Extract, Transform, and Load) processes.
Develop, maintain, and curate large datasets from multiple platforms. Develop reporting capabilities to support business needs by creating and supporting SQL queries, data extraction packages, and interfaces. Explores ways to enhance data quality and reliability.
Perform data validation between analytical and source systems to support ongoing data management capabilities and data governance. Perform data testing to ensure the accuracy of data transformation.
Develop data analytics, reports, and dashboards using Power BI and other business intelligence tools.
Uphold and participate in all Corporate Responsibility programming including recycling, social advocacy and MMAD volunteering opportunities.
Invest in and is an example of Milo’s Responsibility commitment which includes environmental, social, and corporate governance components.
Other duties as assigned
Supervisory: This role does not have supervisory responsibilities.
Qualifications:
BA in computer science, information systems, statistics, applied math, or any other related field.
Up to 3 years of experience in information systems or related field.
Strong experience with SQL server solutions (queries, functions, stored procedures, views, etc.).
Cloud based computing and data solutions.
Proficient with Excel and Business Intelligence tools (Power BI, Power Query, Tableau, etc.).
Understanding of relational databases and data warehouses. Hands-on experience with SQL database design.
Experience with Microsoft SQL stack (SSIS, SSRS, SSAS, etc); Experience with cloud-based data technologies, Azure preferred.
Experience working in a SharePoint environment; Experience with Python, R or other programming languages.
Experience in non-traditional SQL (noSQL, etc.) solutions.
Experience with machine learning and predictive analytics.
Experience with other ETL tools such as Alteryx.
Job Type: Full-time",glassdoor
268,"Pinterest
4.1
Data Engineer
Remote

 About Pinterest:
Millions of people across the world come to Pinterest to find new ideas every day. It's where they get inspiration, dream about new possibilities and plan for what matters most. Our mission is to help those people find their inspiration and create a life they love. In your role, you'll be challenged to take on work that upholds this mission and pushes Pinterest forward. You'll grow as a person and leader in your field, all the while helping Pinners make their lives better in the positive corner of the internet.
Our new progressive work model is called PinFlex, a term that's uniquely Pinterest to describe our flexible approach to living and working. Visit our PinFlex landing page to learn more.
The Enterprise Data Platform team is looking for a Data Engineer who has experience with Building Data Pipelines and Managing/Developing on any Cloud Data Warehouse. In this role you will also advise other Data Analysts and Data Engineers from the Business teams at Pinterest on the best practices for handling data and deriving insights using Snowflake. You will gradually become the Subject Matter Expert on Snowflake and also help build out the Modern Data Stack at Pinterest.
What you'll do:
Build Data Pipelines using Python on either Airflow or AWS Lambda to ingest data into Snowflake
Build Scripts in Python to manage Data Access on Snowflake
Define and advocate the best practices for storing and analyzing data inside Snowflake
Review the Data Modeling practices of other teams
What we're looking for:
Strong skills in Python and SQL
Experience with Building Data Pipelines in Python
Experience with any Cloud Data Warehouse either as an Administrator or a Developer
Strong Data Modeling skills
#LI-BB1
#LI-Remote
Our Commitment to Diversity:
At Pinterest, our mission is to bring everyone the inspiration to create a life they love—and that includes our employees. We’re taking on the most exciting challenges of our working lives, and we succeed with a team that represents an inclusive and diverse set of identities and backgrounds.

Not Specified
0",glassdoor
269,"Netflix
4.3
Data Engineer (L5) - Games
Los Gatos, CA
$108K - $193K (Glassdoor est.)

 Los Gatos, California
Data Science and Engineering
Now is an amazing time to join Netflix as we seek to entertain the world. We have over 200 million paid members in over 190 countries, and we won’t stop there. Games are our next big frontier and an incredible opportunity for us to deliver new experiences to delight and entertain our quickly growing membership. You will be jumping in at the very beginning of this adventure and be in a position to help us redefine what a Netflix subscription means for our members around the world.
Data Science and Engineering (‘DSE’) at Netflix is aimed at using data, analytics, and sciences to improve various aspects of our business. We are looking for a Data Engineer to join our Games DSE team, supporting end-to-end analytics & data needs for our games portfolio. This role will be partnering closely with our Game stakeholders to develop software and data solutions that enable analysis across the entire library of games.
As part of this team, you will work on diverse data technologies such as Spark, Presto, Flink, Kafka, and others to build insightful, scalable, and robust data pipelines that feed directly into our key gaming dashboards; write ETL jobs to collect and aggregate data; and build high-quality data models that represent how games are performing on Netflix.
The ideal candidate will also have a background in games, with a solid knowledge of how standard industry metrics are computed.
Who You Are:
7+ years of software/data engineering experience working with video game analytics (i.e you are familiar with how key metrics such as DAU, MAU and retention rates are computed in an ETL).
Passionate about building intuitive data models and an expert in distributed data processing patterns.
Highly proficient in at least one of these programming languages: Java, Python, or Scala.
Comfortable with complex SQL.
Expert in engineering data pipelines using big data technologies (Hive, Presto, Spark, Flink) on large-scale data sets demonstrated through years of experience.
Conceptually familiar with AWS cloud resources (S3, EC2, RDS etc).
Excel at taking vague requirements and crystallizing them into scalable data solutions.
Excited about operating independently, demonstrating excellence, and learning new technologies and frameworks.
What will you do?
Engineer efficient, adaptable, and scalable data pipelines in Spark and Python/Scala to process structured data into aggregate datasets that feed all games portfolio dashboards.
Become an expert in games metrics at Netflix - act as a thought partner to the games analytics team, understand their challenges, and help them to put the right data in front of our stakeholders.
Maintain and rethink existing datasets and pipelines to service a wider variety of use cases.
Join a stunning team of data engineers with diverse skill sets, partnering closely with analytics engineering and data science counterparts.
Netflix Culture
Our culture is unique, and we live by our values. For more information on what it's like to work at Netflix, please take a look at our culture memo.",glassdoor
270,"Dataquestcorp
Data Science Engineer
Branchburg, NJ
Employer Provided Salary:$75K - $80K

 Job Role: Data Science
Note: Please don't apply C2C profiles. its only w2 positions
Benefits:
Free Training and placement.
Training provided by highly qualified, industry-experienced & certified instructors.
We do provide free accommodations & Relocation charges.
H1B Sponsorship
We do support for STEM OPT and GC processing.
Health Insurance
Relocation Assistance any where in USA.
Free accommodation.
Location: Branchburg, NJ
Job Types: Full-time, Contract
Job Types: Full-time, Contract
Salary: $75,000.00 - $80,000.00 per year
Benefits:
Health insurance
Schedule:
8 hour shift
Ability to commute/relocate:
Branchburg, NJ: Reliably commute or planning to relocate before starting work (Required)
Experience:
Python: 1 year (Preferred)
SQL: 1 year (Preferred)
Work Location: One location
Speak with the employer
+91 9089927715",glassdoor
271,"Luxoft
4.3
Data Engineer
Remote

 Project Description
Luxoft has contract with a major Telecommunications provider to engage with DIRECTV organization to establish integrated cloud technology platforms to ingest information from various Network Engineering support applications in order to better optimize management and planning for the future network.

To do this DIRECTV is managing data ingestion into a Snowflake Azure based deployment which allows for one cohesive platform to serve all types of users and workloads in a consistent way. Centralizing data in a unified, governed, managed data platform allows all authorized users to access accurate and timely data for analysis that is useful for highly transnational datasets. It is also useful that it can store structured and unstructured data. Additionally DIRECTV is leveraging a Palantir Deep™ instance platform for the creation and management of cost forecasting scenarios.
Responsibilities
- Analysis on Data Libraries - evaluation of data sets and current data architecture for source data pipelines. This will allow us to scope the depth/breadth of data

- Data Quality Metrics - Audits analysis and setup to determine the appropriate data quality measures. This will be used to validate with clients/users in a later phase.

- DQF research - Analyze the current Data Quality Framework to leverage as possible/needed. Assess the need for extension and/or replacement of the current DQF.

- Architecture patterns research - Analysis of data translation and business rules associated.

- Current ingestion patterns - Study and enhancement research to evaluate data pipeline for current state and opportunity to optimize for increased data quality and rigor.
Skills
Must have
Cloud, Data Engineering, SnowFlake, Big Data
Nice to have
Microsoft Azure Cloud Platform
Languages
English: C2 Proficient
Seniority
Senior
Relocation package
If needed, we can help you with relocation process.
Vacancy Specialization
BigData Development
Ref Number
VR-81593",glassdoor
272,"Teknic
Data Engineer
Remote

 Role: Data Engineer
Location: Remote
JOb Description:
Skills and Experience :
Good experience on designing and developing data pipelines for data ingestion and transformation using Spark.
Distributed computing experience using Pyspark.
Good understanding of spark framework and spark architecture.
Experience working in Cloud based big data infrastructure.
Excellent in trouble shooting the performance and data skew issues.
Must have a good understanding of spark run time metrics and tune applications based on metrics.
Deep knowledge in partitioning, bucketing concepts of data ingestion.
Good understanding of AWS services like Glue, Athena, S3, Lambda, Cloud formation.
Preferred working knowledge on the implementation of datalake ETL using AWS glue, Databricks etc.
Experience with data modelling techniques for cloud data stores and on prem databases like Teradata, Teradata Vantage (TDV) etc.
Preferred working experience in ETL development in Teradata vantage and data migration from on prem to Teradata vantage.
Proficiency in SQL, relational and non-relational databases, query optimization and data modelling.
Experience with source code control systems like Gitlab.
Experience with large scale distributed relational and NoSQL database systems.
Job Type: Contract
Schedule:
8 hour shift
Experience:
Data engineer: 10 years (Preferred)
Spark.: 3 years (Preferred)
Cloud based big data infrastructure.: 1 year (Preferred)
datalake ETL: 1 year (Preferred)
AWS Glue: 1 year (Preferred)
Work Location: Remote",glassdoor
273,"Realign LLC
4.5
Data Engineer
California

 Job Type: Contract
Job Category: IT
Job Description
Write and optimize queries, provide input on peer code reviews and data modeling, deploy data
updates via continuous integration / deployment (CI/CD) practices.

Collaborate with software developers, other data engineers, and database architects on projects to
ensure optimal data delivery following appropriate change management guidelines.

Collaborate with software and reliability engineers to automate repeatable data tasks.

Work with development and production support teams to troubleshoot data, application, and service
deployment issues.

Develop detailed, shared technical procedure documentation, including processes for contingency
operations.

Research, provide technical input, document, and implement new technology solutions.

Implement necessary patches, hotfixes, service packs, cumulative updates, upgrades, and
configuration change to maintain security compliance and application integrity.

Required Skills
Big Data Engineer",glassdoor
274,"Blue Cross and Blue Shield of North Carolina
4.1
Data Engineer
Remote

 Additional Locations:
Full Time Remote - Alabama, Full Time Remote - Alabama, Full Time Remote - Arizona, Full Time Remote - Arkansas, Full Time Remote - Florida, Full Time Remote - Georgia, Full Time Remote - Idaho, Full Time Remote - Indiana, Full Time Remote - Iowa, Full Time Remote - Kansas, Full Time Remote - Kentucky, Full Time Remote - Louisiana, Full Time Remote - Maryland, Full Time Remote - Michigan, Full Time Remote - Mississippi, Full Time Remote - Missouri, Full Time Remote - Ohio, Full Time Remote - Oklahoma, Full Time Remote - Pennsylvania, Full Time Remote - South Carolina, Full Time Remote - South Dakota, Full Time Remote - Tennessee, Full Time Remote - Texas, Full Time Remote - Utah, Full Time Remote - Virginia {+ 1 more}
Job Description
IT is different here. Our work as technology specialists pushes the boundaries of what’s possible in health care. You will build solutions that make a real difference in people’s lives. Driven by the importance of their work, our team members innovate to elevate. We’re encouraged to be curious, collaborate, and turn ideas into solutions that transform this space.

In this role you will work closely with senior engineers, data scientists and other stakeholders to design and maintain moderate to advanced data models. The Data Engineer is responsible for developing and supporting advanced reports that provide accurate and timely data for internal and external clients. The Data Engineer will design and grow a data infrastructure that powers our ability to make timely and data-driven decisions. You will support Membership Operations, Customer Service Operations, Digital & Consumer Experience teams.

If you are ready to make a career out of making a difference, then you are the person for this team.
What You’ll Do
Define and extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes
Document, and test moderate data systems that bring together data from disparate sources, making it available to data scientists, and other users using scripting and/or programming languages
Write and refine code to ensure performance and reliability of data extraction and processing
Participate in requirements gathering sessions with business and technical staff to distill technical requirement from business requests
Develop SQL queries to extract data for analysis and model construction
Own delivery of moderately sized data engineering projects
Design and develop scalable, efficient data pipeline processes to handle data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets to analysts and data scientists
Ensure performance and reliability of data processes
Document and test data processes including performance of through data validation and verification
Collaborate with cross functional team to resolve data quality and operational issues and ensure timely delivery of products
Develop and implement scripts for database and data process maintenance, monitoring, and performance tuning
Analyze and evaluate databases in order to identify and recommend improvements and optimization
Design eye-catching visualizations to convey information to users
What You Will Bring
Bachelor’s degree and 3 years of experience with Oracle, Data Warehouses and Data Lakes, Big Data platforms and programming in Python, R or other related language.
In lieu of degree, 5 years of the experience as stated above.
SQL and Python scripting
Experience in a cloud environment
Experience with Ab Initio or other ETL tools",glassdoor
275,"Pepsico
3.9
Junior Data Engineer
Remote
Employer Provided Salary:$90K - $100K

 Compensation: $80k - $90k
Benefits: Medical, Dental, Vision, 401k match and Arc
This role can be performed remote in any of our headquarter locations including Plano, Texas; Purchase, New York; Chicago, Illinois.
What PepsiCo Data Management and Operations does:
Maintain a predictable, transparent, global operating rhythm that ensures always-on access to high-quality data for stakeholders across the company
Responsible for day-to-day data collection, transportation, maintenance/curation and access to the PepsiCo corporate data asset
Work cross-functionally across the enterprise to centralize data and standardize it for use by business, data science or other stakeholders
Increase awareness about available data and democratize access to it across the company.
As a member of the data engineering team, you will be the key technical expert developing and overseeing PepsiCo's data product build & operations and drive a strong vision for how data engineering can proactively create a positive impact on the business. You'll be an empowered member of a team of data engineers who build data pipelines into various source systems, rest data on the PepsiCo Data Lake, and enable exploration and access for analytics, visualization, machine learning, and product development efforts across the company. As a member of the data engineering team, you will help lead the development of very large and complex data applications into public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. You will work closely with process owners, product owners and business users. You'll be working in a hybrid environment with in-house, on-premise data sources as well as cloud and remote systems.
Key Accountabilities:
Active contributor to code development in projects and services
Manage and scale data pipelines from internal and external data sources to support new product launches and drive data quality across data products
Build and own the automation and monitoring frameworks that capture metrics and operational KPIs for data pipeline quality and performance
Responsible for implementing best practices around systems integration, security, performance and data management
Empower the business by creating value through the increased adoption of data, data science and business intelligence landscape
Collaborate with internal clients (data science and product teams) to drive solutioning and POC discussions.
Develop and optimize procedures to “productionalize” data science models
Define and manage SLA’s for data products and processes running in production
Support large-scale experimentation done by data scientists
Prototype new approaches and build solutions at scale
Research in state-of-the-art methodologies
Create documentation for learnings and knowledge transfer
Create and audit reusable packages or libraries
COVID-19 vaccination is a condition of employment for this role. Please note that all such company vaccine requirements provide the opportunity to request an approved accommodation or exemption under applicable law
Qualifications / Requirements :
BA/BS in Computer Science, Math, Physics is mandatory.
2+ years of overall technology experience that includes hands-on building data engineering pipelines
2+ years of experience in SQL optimization and performance tuning, and development experience in programming languages like Python, PySpark, Scala etc.)
1+ years in cloud data engineering experience in Azure or AWS
1+ Years in building data engineering pipelines in Azure (ADF and databricks)
Job Type: Full-time
Pay: $90,000.00 - $100,000.00 per year
Benefits:
401(k) matching
Dental insurance
Health insurance
Retirement plan
Vision insurance
Schedule:
8 hour shift
Education:
Bachelor's (Required)
Experience:
SQL: 2 years (Required)
Cloud: 2 years (Required)
Work Location: Remote",glassdoor
276,"Twitch
4.0
Data Engineer
San Francisco, CA
Employer Provided Salary:$140K - $171K

 About Us
Twitch is the world's biggest live streaming service, with global communities built around gaming, entertainment, music, sports, cooking, and more. It's where millions of people come together to chat, interact, and make their own entertainment.
We're about community, inside and out. You'll find coworkers who are eager to team up, collaborate, and smash (or elegantly solve) problems together. We're on a quest to empower live communities, so if this sounds good to you, see what we're up to on LinkedIn and Twitter, get interviewing tips on Instagram, and discover projects we're solving on our Blog.
About the Role
Reporting to the Head of Global Talent Acquisition, the Data Engineer will expand the reach and role of data among leaders and managers at Twitch. You will empower the business to integrate data into their daily workflow by creating/maintaining data pipelines, producing reporting, and automating our processes.
You can work in San Francisco, CA or remotely across the US.
This role is for you if:
You love automating processes and developing efficient scalable solutions
You're excited about contributing to the success, efficiency, and happiness of Twitch staff
You're excited to jump into a diverse array of data work to support the team
You enjoy working with autonomy and shaping a new function

You Will:
Delight consumers of people-related data by ensuring they have the data they need to inform decisions, where and when they need it
Build and own data pipelines, SQL queries/views, and apps
Automate processes through the use of JavaScript and other languages
Improve business, engineering, and data processes through data architecture, engineering, testing, and operational excellence best practices
Ensure the integrity of People and Places data in analyses and tools through regular audits
Partner to develop analytics products and recommend opportunities
Develop ongoing metrics, analyses, and dashboards to guide important decisions
You Have:
Experience writing SQL and a procedural language (Python, R, etc.) for data handling
Experience owning systems that collect, transform, and visualize data
Experience implementing data analytics, visualization tools and programs for HR working with Workday, Greenhouse, Tableau, Google Workspace, Google Data Studio, and Google Sheets
Experience implementing software solutions to automate data source, visualization and analytics products
Bachelors in related field, or equivalent experience
Bonus Points
Experience handling People-related data including compensation, performance, hiring, and engagement data.
Experience automating Google services (Sheets, Docs, Data Studio) with Javascript
Experience with Workday, Greenhouse, and Tableau
Demonstrated net positive contributor to company community and culture above and beyond the core job
Perks
Medical, Dental, Vision & Disability Insurance
401(k), Maternity & Parental Leave
Flexible PTO
Commuter Benefits
Amazon Employee Discount
Monthly Contribution & Discounts for Wellness Related Activities & Programs (e.g., gym memberships, off-site massages, etc.),
Breakfast, Lunch & Dinner Served Daily
Free Snacks & Beverages
We are an equal opportunity employer and value diversity at Twitch. We do not discriminate on the basis of race, religion, color, national origin, gender, gender identity, sexual orientation, age, marital status, veteran status, or disability status, or other legally protected status.
Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
Pursuant to the Los Angeles Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
The base pay range for this position in Colorado, Connecticut and Washington is $139,860 - $170,940 yr and in New York City is $153,900 - $188,100 yr. Pay is based on market location and may vary depending on job-related knowledge, skills, and experience. A sign-on payment and restricted stock units may be provided as part of the compensation package, in addition to a full range of medical, financial, and/or other benefits, dependent on the position offered. Applicants should apply via Twitch's internal or external careers site.
Workers in New York City who perform in-person work or interact with the public in the course of business must show proof they have been fully vaccinated against COVID or request and receive approval for a reasonable accommodation, including medical or religious accommodation.
Twitch values your privacy. Please consult our Candidate Privacy Notice, for information about how we collect, use, and disclose personal information of our candidates.
Job ID: TW7236
#LI-Remote #RemoteFriendly",glassdoor
277,"Apple
4.2
Data Engineer
Cupertino, CA

 Summary
Posted: Aug 10, 2022
Weekly Hours: 40
Role Number:200406892
Are you a big-picture thinker who loves setting ambitious goals? Do you have a passion for understanding how each line of code affects all the others? In the Core Operating Systems group, you’ll ensure the OS is inseparable from each device’s identity as a whole. That’s because this group is committed to building fully integrated operating systems that combine hardware, software, and apps into a single Apple experience. Your dedication to cross-disciplinary collaboration will help develop groundbreaking technologies, such as iOS, macOS, watchOS, and tvOS. By crafting these distinct, holistic user experiences, you’ll continue to uphold and advance the excellence people expect from Apple devices. The Platform Services & Operations team in Core OS is looking for a Data Engineer to inform and develop essential workflow tooling at scale. The Workflow Engineering team enable teams to deliver high quality software through best in class engineering experiences, efficient workflow, data driven insights, and a culture of continuous improvement. Your focus is building the backend data pipelines that enables visualization of data across the organization in user intuitive and configurable formats.
Key Qualifications
3 +proven experience in a Data focused posistion
Proficient in Python; data access and retrieval. Quantitative data preparation. Regular expressions and text analysis
Highly Proficient in Database Language and Design; querying large stores of data (APIs, SQL, etc.).
Access, retrieval, and storage of information. Data Structures, modeling for speed and efficiency
Software Development; understanding of build pipelines, branching and merging, Agile methods, and the delivery of code. Fluency in Git (or comparable source control tool)
Description
- Replicate data from source system into data warehouse; retrieve data through various protocols and land it in a central store - Automate data pipelines; write programs to periodically update warehouse data from source systems - Design for scale; flexible infrastructure for common enhancements including: expanding the volume of captured data, adding fields to the user-facing views, and recompiling archived data - Work with a team of data scientists and full stack engineers, to derive and develop targeted insights through centrally managed interactive dashboards
Education & Experience
B.S. in Data Science, Computer Science, or equivalent experience.
Additional Requirements
Experience as an Analyst; worked in the delivery of visual information (dashboards, reports, web-apps)
An understanding of how data can be used and applied in context (what is useful to capture and how it can be communicated)
Full Stack Development; ability to maintain back-end systems and visualize front-end data for users (with a web-kit framework like Angular, React)
Experience with Snowflake and/or other data store technologies",glassdoor
278,"Tesla
3.6
Data Engineer
Fremont, CA

 What to Expect
The Data Engineer is responsible for processing structured and unstructured data, validating data quality, and developing and supporting data products. We are looking for someone with strong hands on experience in all layers of data Integration and analytics! We especially need experience in using Python as an ETL tool. The Data Engineer plays a significant role in Agile planning, providing advice and guidance, and monitoring emerging technologies. Some of the technology we use: * Python * Informatica * SQL Server and MySQL * Vertica * Kafka

What You’ll Do
* Design, code, test, correct and document programs and scripts using agreed standards and tools to achieve a well-engineered result * Derive an overall strategy of data management, within an established information architecture that supports the development and secure operation of existing and new information and digital services * Plan effective data storage, security, sharing and publishing within the organization * Gathers and processes raw, structured, semi-structured, and unstructured data using batch and real-time data processing frameworks * Ensures data quality and implements tools and frameworks for automating the identification of data quality issues * Collaborate with internal and external data providers on data validation providing feedback and making customized changes to data feeds and data mappings * Mentor and lead data engineers providing technical guidance and oversight * Provides ongoing support, monitoring, and maintenance of deployed products

What You’ll Bring

* Strong experience with relational databases like SQL Server, MySQL and Vertica. NoSQL databases experience is a plus! * Strong background in data modeling, data access, and data storage techniques * Experience with design, development, and implementation of highly scalable, high-volume software systems and components, source of truth systems for different business areas, developing and maintaining web services in an agile environment * Working experience with Kafka Streaming layer * Experience in Spark Framework on both batch and real-time data processing is a plus * Experience in Big Data Integration & Analytics is a plus * Experience in Supply Chain and Logistics data is a plus",glassdoor
279,"NucleusTeq
4.9
Data Engineer
Remote

 Data Engineer
Role Info:
Hands on BI Data Engineer role with strong
Creating KPI Dashboards - Interactive Dashboards using tableau / Quicksight
Top Skills:
BI Tableau / AWS Quicksight exp is a must
AWS (IAM, RDS, S3, Lambda) exp is a must
SQL exp is a must
Python knowledge is required
Nice to have:
AWS Certified Solutions Architect
About the Company:
NucleusTeq is a software services, solutions & products company empowering & transforming customer's business through the use of digital technologies such as Big-Data, Analytics, Cloud, Enterprise Automation, Block-chain, Mobility, etc.
We are enabling several fortune 1000 clients in the USA, Canada, UK & India to navigate their digital transformation.",glassdoor
280,"Ultra Mobile
4.4
Digital Data Engineer I - Remote
Costa Mesa, CA
Employer Provided Salary:$90K - $103K

 ULTRA MOBILE is seeking a talented Digital Data Engineer I to join the Data Management Team! Individual reports to Customer Data Manager. Role is remote; must reside in the United States.
ABOUT THE ROLE
Provide direct data engineering development to data pipelines for ETL establishment and enhancements to and from data warehouses to customer management platform (Braze). Work collaboratively with cross-functional teams to determine digital data needs, establish data collection requirements, and deploy & maintain accurate data to ensure metrics & dimensions are addressed for analytics/reporting requirements.
Your usual day of awesomeness includes:
Transform required data conditions into performance code logic.
Develop high-performance code in SQL and Python.
Develop, automate, and enhance ELT processes for continuous data flow.
Create, modify, and deploy code to production via AWS resources including Lambda, S3, Glue, Redshift, etc.
Partner with stakeholders to support the implementation and development of data requirements.
Troubleshoot data anomalies and provide applicable solutions.
Build, test and maintain database pipeline architectures.
WHAT YOU BRING
Advanced level in SQL and Python for data engineering and backend development.
Understanding of popular code development approaches:
Test-driven development
Continuous Integration/Continuous Deployment (CI/CD)
Experienced working with AWS services (Lambda, S3, Glue, Redshift etc.) and Cloud Data Warehouse.
Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
Define digital data collection methods and implementations to DWH and customer management platforms.
Experienced with QA testing process to verify data is collected & rendered as expected.
Ability to excel in a fast-paced, cross-functional environment.
Ability to work autonomously.
Excellent written and verbal communication skills.
Proactive problem-solving and critical thinking skills.
Ability to manage time effectively and consistently meet deadlines.
NICE TO HAVE
Prior working knowledge of Braze or other Customer Management Platforms
Snowflake Cloud Data Warehouse
Terraform/Bitbucket/Airflow/Jenkins
Looker, Tableau, Power BI
WE ARE ULTRA & MINT MOBILE
We connect people to what's most important in their lives: Easily, affordably and reliably. We strive to be California's Preeminent Destination Employer. Oh yeah, we get it too! We understand what matters to you most. You're an individual with unique needs, and we're prepared to exceed any expectations you have for an ideal employer.
We're smart, strategic, and get things done without a lot of red tape or unnecessary politics. Everyone matters here and everyone has a voice. Expect to spend your time contributing to projects that really matter. We obsess over the employee experience. To start, we provide some of the most competitive salary, benefits, family leave, vacation, retirement and equity options in Southern California. We believe in you and invest in you. Not just your career aspirations, but your life.
In addition, we've got a laundry list of perks you'll brag about on insta - Lunch every day prepared by our very own chef, healthy snacks, onsite gym, free massages, car wash services, and most importantly, a team atmosphere. We even raise the bar on well bars, including Espresso/Cappuccino/Nitro/Cold Brew/Kombucha Bar, Froyo Bar, Breakfast Bar, Snack Bar and a, well, you know, bar (after 5 pm).
And if you feel intrigued right now reading, imagine the co-workers we have already attracted. This is the kind of team you'll want to take home to mom or invite to your kid's next birthday party. This is the kind of close-knit community happening here. Come check out how you can be part of Ultra & Mint!
OUR VALUES – LET'S MAKE LIFE ULTRA TOGETHER!
Ownership: We are all owners; be the outcome and get the job done.
Action Biased: Be brilliant, proactive, and act with urgency.
Embrace the Adventure: Be agile, adaptive, and thrive on change.
Invent and Simplify: Never accept good enough.
$1,000 REFERRAL BONUS
Take a look at this job description, if you are the right person, please apply. If Ultra Mobile doesn't appear to be a fit for you, refer a friend or colleague and get $1,000. Let your friend or colleague know to provide your full name and email when applying to the job. If we hire them and they stay for 90 days, you get $1000. For more details of restrictions and rules, please email recruiting@ultra.me.

Covid-19 Vaccination Requirement
UVNV, Inc. has adopted a mandated vaccination policy to support the health and safety of our team members and our community. The Company requires all employees to be fully vaccinated. The Company will provide accommodations based on medical condition or sincerely held religious beliefs or practices. Please let us know if you'd like to discuss the policy or available accommodations before proceeding with our recruitment process.
We are committed to equal employment opportunities regardless of race, color, genetic information, creed, religion, sex, sexual orientation, gender identity, lawful alien status, national origin, age, marital status, or protected veteran status. We support an inclusive workplace where associates excel based on personal merit, qualification, experience, ability, and job performance.
In support of the Equal Pay for Equal Work Act, the range of starting pay for this role is $90,000 - $103,000. This is not a guarantee of compensation or salary, actual compensation is influenced by a wide range of factors including but not limited to skill set, level of experience, education, certifications, responsibility, and geographic location. We also offer a variety of benefits including health, disability insurance, 401 (k), flexible spending accounts, EAP, education reimbursement, parental leave, unlimited vacation, bonuses, incentive stock options and company paid holidays. The specific programs and options available will vary depending on state, start date, and employment type. Our recruitment team will be happy to answer any questions you may have.
#LI-Remote",glassdoor
281,"Adobe
4.4
Software Development Engineer - Data Science & Analytics
Lehi, UT
$108K - $155K (Glassdoor est.)

 Our Company

Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.

We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!

Our Company
Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands— everything they need to design and deliver exceptional digital experiences. We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.

We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours.
The Opportunity
Adobe is seeking hardworking and passionate Cloud Software Engineer to plan, design, and develop internal analytical tools, dashboards and reporting to help Engineers to Executives make data driven decisions.

We’re on a mission to hire the very best and are committed to building exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!
What You’ll Do
Develop high-performance, reliable, testable and maintainable code.
Participating in all aspects of software development activities, including design, coding, code review, testing, bug fixing, and code/API documentation.
Collaborate with engineers and participate in daily or weekly stand ups and meetings.
Develop reporting dashboards and analytical tools to help Adobe teams manage their AWS & Azure Cloud resources.
Build and automate data sets to answer key business questions using data and data visualizations.
Grow with the support of your team and help others on the team grow by providing thoughtful feedback and uplifting those around you.
Work both independently and collaboratively within a fast-paced development team, with clear, positive, and constructive communication.
What You Need to Succeed
Bachelor's or Master’s in Computer Science, Information Systems, Data Science or equivalent experience required.
Proficient in programming languages such as JavaScript, Python & SQL.
Strong technical background with analytical and problem-solving skills.
Strong proficiency with Business Analytics tools like Power BI & Tableau.
Extensive experience with cloud hosting technology, including Azure and AWS infrastructure.
Experience developing web applications using ReactJS is helpful.
Excellent problem solving and debugging skills, and direct experience with DevOps in a public cloud environment.
Passion for quality and engineering excellence at scale, attention to details, and ability to multitask and meet deadlines.
Excellent communication and collaboration skills.

If you’re looking to make an impact, Adobe’s the place for you. Discover what our employees are saying about their career experiences on the Adobe Life blog and explore the meaningful benefits we offer.
Adobe is an equal opportunity employer. We welcome and encourage diversity in the workplace regardless of race, gender, sexual orientation, gender identity, disability or veteran status.",glassdoor
282,"Vimeo
4.1
Data Engineer II, Analytics
New York, NY
$107K - $150K (Glassdoor est.)

 Vimeo is looking for an experienced Data Engineer II, Analytics to join our Data Architecture and Analytics Engineering team and work closely with Data Analysts and Data Scientists to create and maintain robust, scalable, and sustainable data models that provide decision-making insights for senior leadership including executives. The ideal candidate is a self-starter with a bias for action and results, with experience in a fast-paced, data-driven environment.
What you'll do:
Build data models that can support dynamic and efficient data analysis, and collaborate with other teams to maintain and evolve those models over time
Ensure alignment to coding standard methodologies and development of reusable code
Partner with Data Analysts to understand business processes and identify opportunities to build scalable and efficient data models that can be used for scalable, refreshable analysis and reporting
Create and enable the generation of ad-hoc / on-demand data sets for use by analysts and data scientists
Work with Engineering teams to set up monitoring and alerting systems for business and product KPIs
Skills and knowledge you should possess:
BS/MS in Computer Science or a related technical field.
2+ years working with Analytics and Data Engineering teams with a mixed data engineering and analytics background
2+ years of experience in scalable data architecture, fault-tolerant ETL, and monitoring of data quality in the cloud
Experience working on or leading initiatives around data governance, master data management, data catalogs, and enterprise data warehouse architecture
Strong analytical skills, data sensibility, and an able communicator
Open to working on multiple projects simultaneously
Proficiency in:
SQL
Python
Dimensional Modeling
Data pipeline development, workflow management, and orchestration tools
ETL optimization and best practices
Snowflake or other column-oriented and cloud-based databases
Looker or any similar Business Intelligence tool
Relational Databases
Bonus Points (Nice Skills to Have, but Not Needed):
DBT
Git / Github
Looker/Tableau is a big plus
large data sets (terabyte scale)
Apache Airflow
#LI-JS1
Vimeo (NASDAQ: VMEO) is the world's leading all-in-one video software solution. Our platform enables any professional, team, and organization to unlock the power of video to create, collaborate and communicate. We proudly serve our growing community of over 260 million users — from creatives to entrepreneurs to the world's largest companies.
Vimeo is headquartered in New York City with offices around the world. At Vimeo, we believe our impact is greatest when our workforce of passionate, dedicated people, represents our diverse and global community. We're proud to be an equal opportunity employer where diversity, equity, and inclusion is championed in how we build our products, develop our leaders, and strengthen our culture.
Learn more at www.vimeo.com
Learn more at www.vimeo.com/jobs",glassdoor
283,"Qualtrics
4.2
Data Engineer
Provo, UT
$83K - $125K (Glassdoor est.)

 The Qualtrics XM Platform™ is a system of action that helps businesses to attract customers who stay longer and buy more, to engage and empower employees to do the best work of their lives, to develop breakthrough products people love, and to build a brand people can’t imagine living without.

Joining Qualtrics means becoming part of a team bold enough to chase breakthrough experiences - like building a technology that will be a force for good. A team committed to diversity, equity, and inclusion because of a conviction that every voice holds value, with a vision for representation that matches the world around us and inclusion that far exceeds it. You could belong to a team whose values center on transparency, being all in, having customer obsession, acting as one team, and operating with scrappiness. All so you can do the best work of your career.

We believe every interaction is an opportunity. Are we yours?
The Team
Our team is a collection of deeply passionate engineers who are riding the groundbreaking of cloud computing and web scalability. We built data analytics applications that help company leaders gain insights about technology spends, make sound decision on technology investments, and drive innovation in resource utilization and efficiency optimizations. Our environment is primarily TypeScript, Node.js, React, MySQL NoSQL, AWS, Python, PHP, and Docker. In our collaborative culture, you find plenty of opportunities to impact our full-stack products; from Web & mobile UI to data visualization & analysis to data ingestion, storage and processing.
Job Responsibilities
Developing scalable, fast, robust, and simple web-based solutions to solve complex business problems
Close collaboration with your team to collect and incorporate feedback into your feature design
Drive operational excellence by investigating production issues, driving root cause analysis and follow-up actions for mitigation
Improve performance, availability, reliability, scale, throughput and latency
Work with your team in order to meet customer work you're doing, understand the decisions that are being made and make your voice heard.
Qualifications
Bachelor's degree in Computer Science or related field
Coding experience with any programming language (Prefer experience in TypeScript/JavaScript/React/Python)
Experience with web infrastructure and distributed systems
Experience with software engineering best practices (e.g. unit testing, code reviews, design, continuous delivery, git, test automation and build\deploy systems)
Ability to work in a fast-paced and agile development environment and to learn new frameworks/stacks
Passionate about building products that help customers easily and effectively get their job done
Enthusiastic person, who communicates effectively and is easy to work with
Curious and constantly learning on your own and from others
You get satisfaction from helping others succeed, and you constantly seek ways to improve
You can identify gaps, propose solutions to important problems, then take it to resolution
Preferred Qualifications
Shown ability to troubleshoot and identify the root cause of issues
Demonstrated skill and passion for operational excellence
Experience in a 24/7 production environment is a plus
Ability to retain composure under stressful conditions, communicate effectively with wide array of individuals at Qualtrics, and get the right things done
Confirmed ability to understand large systems, drilling down to code level",glassdoor
284,"Lincoln Financial
3.6
Data Engineer (REMOTE)
Radnor, PA
Employer Provided Salary:$63K - $138K

 Date: Oct 9, 2022
Primary Location: Radnor, PA, US
Company: Lincoln Financial
Alternate Locations: Work from Home

Work Arrangement: Work from Home

Relocation assistance:: is not available for this opportunity.

Pay Range: $63,100 - $137,900

Bonus Potential: 5%

Requisition #: 69444

The Role at a Glance

This is an exciting opportunity within Lincoln’s Work Place Solutions IT Data Team for a Data Engineer/ETL Developer to help build solutions for Lincoln’s Work Place Solutions business. This position will assist Analytic Teams with the design and implementation of Data solutions and systems, including integration with databases and data warehouses, both on-Premise and in AWS Cloud. This candidate must be able to develop, enhance, and support Informatica workflows and processes using Informatica Power Center and Dataiku for the extraction and transformation of data in a UNIX and Oracle database environment. They must also have experience working within BI tools such as Tableau and Microstrategy. Experience working in the cloud using AWS native services such as Glue, Athena, Aurora, Redshift, and/or Snowflake is needed. The candidate must have experience participating in and beginning to lead teams within a Data Organization by suggesting new and innovative ways of gaining data processing efficiencies and participating in architectural and modeling discussions.

What you'll be doing

Participates in defining architecture and modeling best practices within the team
Develop tools and work on integrating disparate systems using ETL
Work on transformation of data into Facts and Dims in a Kimball and/or relational model
Works with Sr. Technical Professionals to implement data development best practices
Develop, enhance and support Informatica workflows and processes using Informatica Power Center for the extraction and translation of data in a UNIX and Oracle database environment
Develop, enhance and support Dataiku workflows and processes for transforming data into Kimball model Facts/Dims
Creates partnerships with stakeholders, POs, BSAs and Analytic teams in requirement, design and coding walkthroughs to ensure the development of quality solutions and understand complex business/technical problems and opportunities and identify potential application solutions.
Demonstrates expertise in a variety of the data warehouse concepts, practices, and procedures. Relies on extensive experience and judgment to plan and accomplish goals
Analyzes operational and analytical data requirements by working with cross functional business and application development teams
Maintains knowledge on current and emerging developments/trends for assigned area(s) of responsibility, assess the impact, and collaborates with senior management to incorporate new trends and developments in current and future solutions.
Participate with collaboration efforts with development teams to review, update and approve the data portion of project designs, participate in cost/benefit analysis and preparation of project plans.
Participate in the design, development and delivery data centric IT solutions, including large scale data staging and orchestration, integration and provisioning mechanisms
Works with business partners to prioritize business and information needs
Provides input and validates increasingly complex project plans, test plans and implementation plans
Creates increasingly complex technical specifications from business requirements/business specifications
Proactively identifies problems and presents/develops solutions
Communicates effectively with internal stakeholders and management
Defines detailed development tasks, task dependencies and estimates to complete work
What we're looking for

4 Year/Bachelor's degree or equivalent work experience (4 years of experience in lieu of Bachelor's) in Computer Science, Computer Information Systems, Information Systems, Information Technology or Computer Engineering or equivalent work experience (Minimum Required
3 - 5+ Years’ experience in application development that directly aligns with the specific responsibilities for this position (Required)
Experience with ETL development
Must have experience with Informatica; Dataiku is a plus
Must have experience with BI tools such as Tableau and Microstrategy
Experience with AWS cloud native services, such as: Glue, Athena, Aurora, Redshift
Must have a proven track record working closely with business stakeholders, BSAs, and POs, Solution Architects to understand requirements and expectations to achieve quality technical solutions
What’s it like to work here?
At Lincoln Financial Group, we love what we do. We make meaningful contributions each and every day to empower our customers to take charge of their lives. Working alongside dedicated and talented colleagues, we build fulfilling careers and stronger communities through a company that values our unique perspectives, insights and contributions and invests in programs that empower each of us to take charge of our own future.

What’s in it for YOU:
A clearly defined career framework to help you successfully manage your career
Leadership development and virtual training opportunities
PTO/parental leave
Competitive 401K and employee benefits
Free financial counseling, health coaching and employee assistance program
Tuition assistance program
A leadership team that prioritizes your health and well-being; offering a remote work environment and flexible work hybrid situations
Effective productivity/technology tools and training

Work Arrangement
Work from Home : Employees will work from home and are not required to work in a Lincoln office on a regular basis.

Lincoln will evaluate the following when setting the successful candidate's wage rate:
Prior work or industry experience.
Education level to the extent education is relevant to the position.
Unique skills

About The Company
Lincoln Financial Group, a Fortune 200 company with over 10,000 employees, provides advice and solutions that help empower Americans to take charge of their financial lives with confidence. Our core business areas — Life Insurance, Annuities, Retirement Plan Services and Group Protection — focus on supporting, preserving and enhancing over 17 million customer’s lifestyles and retirement outcomes.

Headquartered in Radnor, Pennsylvania, Lincoln Financial Group is the marketing name for Lincoln National Corporation (NYSE: LNC) and its affiliates. The company had $324 billion in end-of-period account values as of June 30, 2021.

Ranked one of the Best Large Employers in America and Best Employers for Women by Forbes magazine as well as one of Newsweek’s Most Responsible Companies, Lincoln Financial Group makes a serious investment in our employees’ futures through a broad range of wealth accumulation and protection plans, health and wellness programs, and career development resources designed to help each individual reach their personal and professional goals.

Lincoln is committed to creating a diverse and inclusive environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.

Lincoln Financial Group is a committed corporate citizen included on major sustainability indices including the Dow Jones Sustainability Index North America and FTSE4Good. Dedicated to diversity and inclusion, we earned perfect 100 percent scores on the Corporate Equality Index and the Disability Equality Index. Follow us on Facebook, Twitter, LinkedIn, and Instagram.

Be Aware of Fraudulent Recruiting Activities
If you are interested in a career at Lincoln, we encourage you to review our current openings and apply on our website. Lincoln values the privacy and security of every applicant and urges all applicants to diligently protect their sensitive personal information from scams targeting job seekers. These scams can take many forms including fake employment applications, bogus interviews and falsified offer letters.
Lincoln will not ask applicants to provide their social security numbers, date of birth, bank account information or other sensitive information in job applications. Additionally, our recruiters do not communicate with applicants through free e-mail accounts (Gmail, Yahoo, Hotmail) or conduct interviews utilizing video chat rooms. We will never ask applicants to provide payment during the hiring process or extend an offer without conducting a phone, live video or in-person interview. Please contact Lincoln's fraud team at fraudhotline@lfg.com if you encounter a recruiter or see a job opportunity that seems suspicious.

Additional Information
This position may be subject to Lincoln’s Political Contribution Policy. An offer of employment may be contingent upon disclosing to Lincoln the details of certain political contributions. Lincoln may decline to extend an offer or terminate employment for this role if it determines political contributions made could have an adverse impact on Lincoln’s current or future business interests, misrepresentations were made, or for failure to fully disclose applicable political contributions and or fundraising activities.

Any unsolicited resumes/candidate profiles submitted through our web site or to personal e-mail accounts of employees of Lincoln Financial Group are considered property of Lincoln Financial Group and are not subject to payment of agency fees.

Lincoln Financial Group (“LFG”) is an Equal Opportunity employer and, as such, is committed in policy and practice to recruit, hire, compensate, train and promote, in all job classifications, without regard to race, color, religion, sex (including pregnancy), age, national origin, disability, sexual orientation, gender identity and expression, Veteran status, or genetic information. Applicants are evaluated on the basis of job qualifications. If you are a person with a disability that impedes your ability to express your interest for a position through our online application process, or require TTY/TDD assistance, contact us by calling 260-455-2558.",glassdoor
285,"Accenture
4.1
Data Engineer
San Francisco, CA

 Accenture Flex offers you the flexibility of local fixed-duration project-based work powered by Accenture, a leading global professional services company. Accenture is consistently recognized on FORTUNE's 100 Best Companies to Work For and Diversity Inc's Top 50 Companies For Diversity lists.
As an Accenture Flex employee, you will apply your skills and experience to help drive business transformation for leading organizations and communities. In addition to delivering innovative solutions for Accenture's clients, you will work with a highly skilled, diverse network of people across Accenture businesses who are using the latest emerging technologies to address today's biggest business challenges.
You will receive competitive rewards and access to benefits programs and world-class learning resources. Accenture Flex employees work in their local metro area onsite at the project, significantly reducing and/or eliminating the demands to travel.
Job Description:
As a Data Engineer, you will:
Utilize strong SQL & Python expertise to engineer sound data pipelines and conduct routine and ad hoc analysis to assess the performance of legacy products and the saliency of new features
Build reporting dashboards and visualizations to design, create, and track campaign/program KPIs
Perform analyses on large data sets to understand drivers of marketing engagement and provide recommendations on campaign and product optimization

Basic Qualifications:
Minimum 2 years of experience in Data Engineering
Minimum 2 years of experience with SQL
Minimum 2 years of experience with Python
High School Diploma or GED
Preferred Qualifications:
Experience with Data Analytics
As required by Colorado Law under the Equal Pay for Equal Work Act, Accenture provides a reasonable range of compensation for roles that may be hired in Colorado. Actual compensation is influenced by a wide array of factors including but not limited to skill set, level of experience, and specific office location. For the state of Colorado only, the starting range of pay for this role is $86.82 - $96.82 per hour, and information on benefits is here.

COVID-19 update:

The safety and well-being of our candidates, our people and their families continues to be a top priority. Until travel restrictions change, interviews will continue to be conducted virtually.

Subject to applicable law, please be aware that Accenture requires all employees to be fully vaccinated as a condition of employment. Accenture will consider requests for accommodation to this vaccination requirement during the recruiting process.

What We Believe

We have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture has the responsibility to create and sustain an inclusive environment.

Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more here

Equal Employment Opportunity Statement

Accenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation.

All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.

Accenture is committed to providing veteran employment opportunities to our service men and women.

For details, view a copy of the Accenture Equal Opportunity and Affirmative Action Policy Statement.

Requesting An Accommodation

Accenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.

If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.

Other Employment Statements

Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States.

Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.

Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.

The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.",glassdoor
286,"National Research Group
3.7
Data Engineer
San Francisco, CA
$88K - $128K (Glassdoor est.)

 Who We Are
National Research Group (NRG) is a leader in data driven insights and strategic consultation to the global entertainment and technology industries. Working at the confluence of technology, content, and culture, NRG offers bold insights for storytellers everywhere. Our consultants have experience working across all facets of media and technology.
Why You'll Love It Here
We are inspired by working with storytellers that challenge us to think differently and see the world in new ways. As a result, our business is driven by creative, curious, and inventive people who have a passion for pop culture. We work as a collective across disciplines and geographies to bring together the best thinking for every assignment, delivering insights to bold storytellers everywhere.
The Opportunity
We are looking for a data engineer with a background in building and maintaining data pipelines to integrate and process diverse data sources and data formats. This candidate should have a minimum of 1-year experience for a full-time position within our fast paced and growing company.
If you feel that you can make an impact through innovation and collaboration and come to work with a passion to facilitate in delivering high quality data to our teams and clients, this is a great role for you.
The Role
Build, test, orchestrate, and maintain data pipelines that support the data sciences team and customer-facing client teams.
Assist in ad-hoc data deliveries by querying data from various SQL relational databases stored in multiple data models.
Track and manage pipeline efficiency and stability.
Evaluate, parse, clean, and integrate raw data sets including third party APIs. Help build sophisticated ETL processes around first party data such as survey data, second and third-party data sources such as IP addresses, clickstream data, movie meta data.
Provide recommendations for data storage, configurations, data access tools and new technologies/architectures.
Develop code-based data transformation/aggregation in data lakes, relational databases (primary use cases) and possibly non-relational databases, as well as for the purpose of BI tools such as Power BI and Tableau.
Participate in developing data APIs for data ingestion of NRG data into client-side applications or client-side data systems.
Assist application developers in the effective use of database query and programming languages.
Contribute to managing data integrity, data storage efficiency and data ecosystem efficiency.
Who You Are
Team asset who can describe data structures, relationships, and flows behind organization database servers and applications.
Up to date on the latest data-related best practices and technologies and always looking to learn more.
Internally motivated self-starter who continuously strives to get things done, regardless of challenges encountered.
Critical thinker, able to understand and respond to complex questions or issues that may arise, and able to demonstrate willingness to experiment with new technologies.
Successfully manages time and multiple competing priorities in order to ensure deadlines are always met.
Team player who is able to work collaboratively and initiate and drive projects to completion with minimal oversight.
Ideal Candidate
BS/BA in Computer Science or related field.
1+ year experience in building data pipelines or ETL.
1+ year experience with SQL (we use Snowflake but other experience with relational databases is welcome).
1+ year experience with AWS technologies/infrastructure.
Working knowledge with Python.
A solid foundation with end-to-end development and the desire to further their technical knowledge.
Knowledge of PII (personally identifiable information) data security standards is a plus.
dbt experience is a plus.
Terraform experience is a plus.
Dagster experience is a plus.
Experience in databases structured against survey data is a big plus.
Position Type
This is a full-time, exempt position.
Work Environment
This position is expected to be fully remote. However, NRG offers flexible work options if an employee happens to live near a dedicated office (Playa Vista or New York) and wants a hybrid work model. This role routinely uses standard office equipment.
Required Application Materials:
CV/Resume
Cover Letter which should include:
Why do you want to work at NRG?
Why are you interested in working in the entertainment industry?",glassdoor
287,"GenSpark
4.1
Data Engineer
Remote

 Position: Data Engineer
Location: Remote/ Atlanta
** Only US Citizens and GreenCard Holders eligible**
Requirements:
1. 3+ years of working experience on Python on Data side, NymPy, Pandas
2. Should have working experience on SQL
3. Data Engineer mindset
Job Type: Full-time
Salary: $75.00 - $90.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Paid time off
Vision insurance
Schedule:
8 hour shift
Monday to Friday
No weekends
Education:
Bachelor's (Preferred)
Experience:
python: 3 years (Preferred)
Work Location: Remote",glassdoor
288,"Apple
4.2
Machine Learning Data Collection Engineer, Technology Development Group (TDG)
Cupertino, CA

 Summary
Posted: Mar 15, 2022
Role Number:200356922
Do you want to push the limits of the best Augmented Reality platform in the world? Apple's Technology Development Group (TDG) delivers algorithms that drive revolutionary Apple products, including the augmented reality (AR) platform ARKit to create ground-breaking new products. In this position, you will have the opportunity to be part of our extraordinary data team to discover and build solutions to previously-unsolved challenges and push the state of the art in AR algorithms that will change the way people experience the world! We are looking for a driven Machine Learning Data Collection Engineer that enjoys getting into the details to collect valuable data that feeds our machine learning models. As a member of the fast-paced data team, you have the rewarding opportunity to shape upcoming products that will delight and inspire millions of people every day. To succeed within this role, you should have shown experience in several of the following areas:
Key Qualifications
Ability to define/design/develop data collection efforts that focus on the end-to-end user experience, including anticipating potential failure modes, edge cases, and anomalies
Capacity to multitask and manage several projects in parallel while meeting deadlines and providing access to clients and partners
Problem solving & critical thinking capacities, thinking outside the box in order to gain in speed, efficiency, and quality.
Ability to re-construct ill-defined data needs into concrete project deliverables
Ability to maintain and develop relationships with multi-functional teams
Excellent project management, communication, interpersonal, analytical, and organizational skills
Description
As a Machine Learning Data Collection Engineer, you'll be working with our customers to understand their data collection requirements, assisting them in defining their protocols, and executing on the data collection. Your job responsibilities will include: -Collaborate with algorithm teams and understand data collection requirements in order to define collection protocols -Define and design the collection requirements and lead the collection effort from start to finish -Coordinate the efforts between internal teams (Legal, privacy, security, etc) guaranteeing compliance with applicable rules, laws, and best practices -Create documents and procedures needed to run data collections -Managing and track progress of externally run data collections
Education & Experience
Bachelors degree or related practical experience
Additional Requirements",glassdoor
289,"Apple
4.2
Biomedical Data Engineer - Health Technologies
Cupertino, CA

 Summary
Posted: Aug 8, 2022
Weekly Hours: 40
Role Number:200402289
The Health Technologies Team conceives and proves out innovative technology for Apple’s future products and features in health. We are seeking a highly capable Biomedical Data Engineer to join a multi-disciplinary team. Successful candidates will be able to integrate with our research study leads, data scientists and engineers to develop and support effective data analysis and machine learning workflows.
Key Qualifications
Experience with software engineering frameworks
Excellent coding skills in Python (e.g.,Pandas, Spark, Jupyter)
Workflow orchestrations (e.g., Airflow, Luigi)
Designing and maintaining (non-)relational databases (e.g. Postgres, Cassandra, MongoDB) and file systems (e.g. Parquet, CSV, JSON)
Great understanding of infrastructure designs
Linux, MacOS based development frameworks
iOS/ watchOS development (e.g., Swift, Objective-C)
Web Service APIs (e.g., AWS, REDCap, XNAT)
Version control frameworks (Git, virtualenv)
Familiarity with best practices for information security, including safe harbor privacy principles for sensitive data
Experience with biomedical sensors/platforms for measuring physiological signals in the health, wellness and/or fitness realms
Description
- Work closely with team members and study staff to design, build, launch and maintain systems for storing, aggregating and analyzing large amounts of data - Process, troubleshoot, and clean incoming data from human studies - Automate and monitor data ingestion and transformation pipelines, with hooks for QA, auditing, redaction and compliance checks per data management specifications - Create and maintain databases with existing and incoming clinical data - Architect data models and create tools to harmonize disparate data sources - Incorporate and comply with regulations as they pertain to electronic and clinical data and databases
Education & Experience
BS/MS in Computer Science, Engineering, Informatics, or equivalent with relevant 4+ years industry experience with biomedical, health or sensitive data.
Additional Requirements",glassdoor
290,"Apple
4.2
ML Data Collection and Data Science Engineer (TDG)
Cupertino, CA

 Summary
Posted: May 16, 2022
Role Number:200380146
Do you want to push the limits of the best Augmented Reality platform in the world? Apple's Technology Development Group (TDG) delivers algorithms that drive revolutionary Apple products, including the augmented reality (AR) platform ARKit to create ground-breaking new products. In this position, you will have the opportunity to be part of our extraordinary data team to discover and build solutions to previously-unsolved challenges and push the state of the art in AR algorithms that will change the way people experience the world! We are looking for a driven Machine Learning Data Collection Engineer that enjoys getting into the details to collect valuable data that feeds our machine learning models. As a member of the fast-paced data team, you have the rewarding opportunity to shape upcoming products that will delight and inspire millions of people every day. To succeed within this role, you should have shown experience in several of the following areas:
Key Qualifications
Ability to define/design/develop data collection efforts that focus on the end-to-end user experience, including anticipating potential failure modes, edge cases, and anomalies
Proficiency in programming languages including Python, C++, or similar
Capacity to multitask and manage several projects in parallel while meeting deadlines and providing access to clients and partners
Problem solving & critical thinking capacities, thinking outside the box in order to gain in speed, efficiency, and quality.
Excellent project management, communication, interpersonal, analytical, and organizational skills
Experience with industrial software development, a plus
Experience with CVML, a plus
Description
As a Machine Learning Data Collection Engineer, you'll be collaborating with multi-functional teams to work on CVML data collection projects, from collecting data collection requirements, designing protocols, testing software and hardwares, executing data collection, to analyzing and curating collected data. Your job responsibilities will include -Contribute to the design of CVML data collection, including hardware, software, user interface specifications, and collection protocols. -Define, implement, maintain SW and HW solutions to test data collection hardware, software and protocols. -Design, implement and maintain SW platforms to monitor date life cycle -Work with CVML engineers to design and implement data evaluation and curation process -Analyze data and build data analysis tools -Collaborate with multi-functional teams including algorithm, hardware, software, product design, project management, legal, procurement, security, logistics and vendors to define and deliver necessary study elements -Write technical documents including study instructions, operating procedures and training documents for study personnel -Drive process improvements across the organization to continuously improve the way we work
Education & Experience
B.S., M.S., or Ph.D. in Computer Science, Computer Engineering, or equivalent practical experience.
Additional Requirements",glassdoor
291,"Farmers Insurance Group
3.7
Data Engineer (Application SME I)
Remote
Employer Provided Salary:$74K - $98K

 We are Farmers!
We are… more than just your favorite commercials. We are a passionate, award winning, equal opportunity employer, committed to the strength of a diverse workforce. We are dedicated to supporting the well-being of our people through our extensive suite of benefits, as well as the well-being of the communities we serve through employee volunteer programs and nonprofit partnerships. Helping others in their time of need isn’t just our business – it’s our culture! We are Farmers!

Do you thrive in a high-volume, fast-paced environment? Do you enjoy the challenge of a position where no two days are alike? We are looking for positive, high-energy professionals who are not just looking for a job, but a meaningful career!

Job Summary
Use MS SQL SSIS to build ETL process to create new business functionalities as well to solve business problems: Respond to new requests for reports/data understanding business objectives and processes; review and refine technical requirements/User Stories; and communicate estimated hours and timeline to complete; Extract data directly from relational databases (e.g. DB2, SQL Server), data warehouses, or other data stores using SQL; Ability to create manual as well as automated data exports/reports; and Support application unit testing for enhancements or system upgrades; identify and communicate data quality issues or data differences. Work productively on assigned tasks; Collaborate effectively with other team members; Demonstrate accountability to management and business for hours spent on assigned tasks; and diligently strive to deliver value.
Essential Job Functions
Education Requirements
High school diploma or equivalent required.
Bachelor’s degree preferred, in Information Systems or related field.
Experience Requirements
Experience in developing ETL and reporting applications using Microsoft SQL Server (strongly preferred), or Informatica or similar ETL technologies.
Experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process on MS SQL Server or DB2 or similar DB platform.
Experience with Python and unstructured data manipulation is a plus.
Experience with cloud technologies such as AWS Glue, Azure Data Factory, Snowflake is a plus.
Experience working in an Agile Environment is a plus.
Good knowledge of business intelligence best practices, processes, and methodologies.
Good programming experience in writing Stored Procedures, Queries, Views, User Defined Functions, and Common Table Expressions using SQL or T-SQL.
Highly committed, motivated, enthusiastic and a natural team player.
Good interpersonal and communication skills (both verbal and written) and ability to interact with and effectively address concerns.
Good prioritization, time management, analytical, and organization skills.
Experienced in facilitating in-person and remote meetings with business & IT.
Experienced in effective management of multiple competing and frequently changing assignments and priorities.

Benefits
Farmers offers a competitive salary commensurate with experience, qualifications and location
Colorado Only: The pay range for this job being performed in Colorado would be 73,600 - 98,100
Bonus Opportunity (based on Company and Individual Performance)
401(k)
Medical
Dental
Vision
Health Savings and Flexible Spending Accounts
Life Insurance
Paid Time Off
Paid Parental Leave
Tuition Assistance

Job Location(s): R_US - RW - Remote Work",glassdoor
292,"Cigna
3.8
BI Data Engineer-Work from home-eviCore
Hartford, CT
Employer Provided Salary:$96K - $160K

 Duties
Build ETL processes to allow data to flow seamlessly from source to target using tools like Databricks, Azure Data Factory, SSIS, SQL Stored Procedures and Powershell scripting
Load and enhance dimensional data models
Leverage code to apply business rules to ensure data is clean and is interpreted correctly by all business stakeholders, using tools like Databricks, SQL, Scala and Python
Perform code reviews and QA
Participate in sprint ceremonies
Provide on-call support to offshore operations team
Train operations teams on the ETL processes being developed
Troubleshoot and address issues with the data and/or the ETL process
Fine tune existing code to make processes more efficient
Maintain and create documentation to describe our data management processes
Analyze reports using various tools like Micro Strategy, Tableau and SSRS
Support user questions on data management processes and results

Minimum Required Skills
5+ Years building Big Data and Data Warehousing solutions
Knowledge of data modeling (including dimensional modeling), data architecture & data governance concepts
Experience in working with implementations of Azure cloud data solutions (ADLS, Data Bricks, Synapse, ADF)
Proficient in database concepts and technologies including MS SQ Server, DB2 and Oracle
Excellent written and oral communications skills
Must be able to effectively communicate complex technical topics to a variety of audiences
Experience with Healthcare data is a plus

Minimum Education, Licensure and Professional Certification requirement:
Bachelor’s degree with relevant experience required.
Master’s Degree is a plus.

If you will be working at home occasionally or permanently, the internet connection must be obtained through a cable broadband or fiber optic internet service provider with speeds of at least 10Mbps download/5Mbps upload.

For this position, we anticipate offering an annual salary of 95,900 - 159,800 USD / yearly, depending on relevant factors, including experience and geographic location.

This role is also anticipated to be eligible to participate in an annual bonus plan.

We want you to be healthy, balanced, and feel secure. That’s why you’ll enjoy a comprehensive range of benefits, with a focus on supporting your whole health. Starting on day one of your employment, you’ll be offered several health-related benefits including medical, vision, dental, and well-being and behavioral health programs. We also offer 401(k) with company match, company paid life insurance, tuition reimbursement, a minimum of 18 days of paid time off per year and paid holidays. For more details on our employee benefits programs, visit Life at Cigna .

About Cigna
Cigna Corporation exists to improve lives. We are a global health service company dedicated to improving the health, well-being and peace of mind of those we serve. Together, with colleagues around the world, we aspire to transform health services, making them more affordable and accessible to millions. Through our unmatched expertise, bold action, fresh ideas and an unwavering commitment to patient-centered care, we are a force of health services innovation. When you work with us, or one of our subsidiaries, you’ll enjoy meaningful career experiences that enrich people’s lives. What difference will you make?

Qualified applicants will be considered without regard to race, color, age, disability, sex, childbirth (including pregnancy) or related medical conditions including but not limited to lactation, sexual orientation, gender identity or expression, veteran or military status, religion, national origin, ancestry, marital or familial status, genetic information, status with regard to public assistance, citizenship status or any other characteristic protected by applicable equal employment opportunity laws.

If you require reasonable accommodation in completing the online application process, please email: SeeYourself@cigna.com for support. Do not email SeeYourself@cigna.com for an update on your application or to provide your resume as you will not receive a response.

Cigna has a tobacco-free policy and reserves the right not to hire tobacco/nicotine users in states where that is legally permissible. Candidates in such states who use tobacco/nicotine will not be considered for employment unless they enter a qualifying smoking cessation program prior to the start of their employment. These states include: Alabama, Alaska, Arizona, Arkansas, Delaware, Florida, Georgia, Hawaii, Idaho, Iowa, Kansas, Maryland, Massachusetts, Michigan, Nebraska, Ohio, Pennsylvania, Texas, Utah, Vermont, and Washington State.",glassdoor
293,"Faire
4.8
Data Engineer
San Francisco, CA
$117K - $170K (Glassdoor est.)

 About Faire
Faire is an online wholesale marketplace built on the belief that the future is local — there are over 2 million independent retailers in North America and Europe doing more than $2 trillion in revenue. At Faire, we're using the power of tech, data, and machine learning to connect this thriving community of entrepreneurs across the globe. Picture your favorite boutique in town — we help them discover the best products from around the world to sell in their stores. With the right tools and insights, we believe that we can level the playing field so that small businesses everywhere can compete with these big box and e-commerce giants.
By supporting the growth of independent businesses, Faire is driving positive economic impact in local communities, globally. We're looking for smart, resourceful and passionate people to join us as we power the shop local movement. If you believe in community, come join ours.
Job Description
The Data Engineering team is the backbone of all data-related processes and enables the Data Science teams to develop and deploy a wide variety of algorithms and models that power the marketplace. Our infrastructure is used by the whole company for analytics, reporting, forecasting and research. We care about having a reliable & scalable infrastructure with quality data and building machine learning models that help our customers thrive.
As a Data Engineer you'll be responsible for developing and automating large scale, high-performance data storage and processing systems.
What you will be doing:
Develop our data infrastructure to help us scale for where we're going over the next several years
orchestrating pipelines using modern Big Data tools/architectures as well as design and engineering of existing transactional processing systems
Manage our data infrastructure and ETL platform
What it takes:
2+ years experience in a Data Engineering role with an emphasis on managing data warehouses
Strong skills in Python, Git, Docker, SQL, Airflow, real time ETL pipelines
Managing data infrastructure (AWS services, Data orchestrator) and providing framework to rationalize and simplify both real time and batch data pipelines
Familiarity with Snowflake or BigQuery
A passion for programming and solving problems with code
A bachelor's degree in Computer Science/Software Engineering or equivalent industry experience
A love for technology, and an insatiable curiosity for new tools to tackle real problems
Faire's flexible work model aims to meet the needs of our diverse employee community by making work more flexible, connected, and inclusive. Depending on the role and needs of the team, Faire employees have the flexibility to choose how they work–whether that's mainly in the office, remotely, or a mix of both.
Roles that list only a country in the location are eligible for fully remote work in that country or in- office work at a Faire office in that country, provided employees are located in the registered country/province/state. Roles with only a city location are eligible for in-office or hybrid office work in that city. Our talent team will work with candidates to determine what locations and roles are eligible for each option.
Why you'll love working at Faire
We are entrepreneurs: Faire is being built for entrepreneurs, by entrepreneurs. We believe entrepreneurship is a calling and our mission is to empower entrepreneurs to chase their dreams. Every member of our team is an owner of the business and taking part in the founding process.
We are using technology and data to level the playing field: We are leveraging the power of product innovation and machine learning to connect brands and boutiques from all over the world, building a growing community of more than 350,000 small business owners.
We build products our customers love: Everything we do is ultimately in the service of helping our customers grow their business because our goal is to grow the pie - not steal a piece from it. Running a small business is hard work, but using Faire makes it easy.
We are curious and resourceful: Inquisitive by default, we explore every possibility, test every assumption, and develop creative solutions to the challenges at hand. We lead with curiosity and data in our decision making, and reason from a first principles mentality.
Faire was founded in 2017 by a team of early product and engineering leads from Square. We're backed by some of the top investors in retail and tech including: Y Combinator, Lightspeed Venture Partners, Forerunner Ventures, Khosla Ventures, Sequoia Capital, Founders Fund, and DST Global. We have headquarters in San Francisco and Kitchener-Waterloo, and a global employee presence across offices in Salt Lake City, Atlanta, Toronto, London, New York, LA, and Sao Paulo. To learn more about Faire and our customers, you can read more on our blog.
Faire provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity or gender expression.
Faire is committed to providing access, equal opportunity and reasonable accommodation for individuals with disabilities in employment, its services, programs, and activities. To request reasonable accommodation, please fill out our Accommodation Request Form.",glassdoor
294,"Mint Mobile
3.6
Digital Data Engineer I - Remote
Costa Mesa, CA
Employer Provided Salary:$90K - $103K

 MINT MOBILE is seeking a talented Digital Data Engineer I to join the Data Management Team! Individual reports to Customer Data Manager. Role is remote; must reside in the United States.
ABOUT THE ROLE
Provide direct data engineering development to data pipelines for ETL establishment and enhancements to and from data warehouses to customer management platform (Braze). Work collaboratively with cross-functional teams to determine digital data needs, establish data collection requirements, and deploy & maintain accurate data to ensure metrics & dimensions are addressed for analytics/reporting requirements.
Your usual day of awesomeness includes:
Transform required data conditions into performance code logic.
Develop high-performance code in SQL and Python.
Develop, automate, and enhance ELT processes for continuous data flow.
Create, modify, and deploy code to production via AWS resources including Lambda, S3, Glue, Redshift, etc.
Partner with stakeholders to support the implementation and development of data requirements.
Troubleshoot data anomalies and provide applicable solutions.
Build, test and maintain database pipeline architectures.
WHAT YOU BRING
Advanced level in SQL and Python for data engineering and backend development.
Understanding of popular code development approaches:
Test-driven development
Continuous Integration/Continuous Deployment (CI/CD)
Experienced working with AWS services (Lambda, S3, Glue, Redshift etc.) and Cloud Data Warehouse.
Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
Define digital data collection methods and implementations to DWH and customer management platforms.
Experienced with QA testing process to verify data is collected & rendered as expected.
Ability to excel in a fast-paced, cross-functional environment.
Ability to work autonomously.
Excellent written and verbal communication skills.
Proactive problem-solving and critical thinking skills.
Ability to manage time effectively and consistently meet deadlines.
NICE TO HAVE
Prior working knowledge of Braze or other Customer Management Platforms
Snowflake Cloud Data Warehouse
Terraform/Bitbucket/Airflow/Jenkins
Looker, Tableau, Power BI
WE ARE MINT MOBILE
We connect people to what's most important in their lives: Easily, affordably and reliably. We strive to be California's Preeminent Destination Employer. Oh yeah, we get it too! We understand what matters to you most. You're an individual with unique needs, and we're prepared to exceed any expectations you have for an ideal employer.
We're smart, strategic, and get things done without a lot of red tape or unnecessary politics. Everyone matters here and everyone has a voice. Expect to spend your time contributing to projects that really matter. We obsess over the employee experience. To start, we provide some of the most competitive salary, benefits, family leave, vacation, retirement and equity options in Southern California. We believe in you and invest in you. Not just your career aspirations, but your life.
In addition, we've got a laundry list of perks you'll brag about on insta - Lunch every day prepared by our very own chef, healthy snacks, onsite gym, free massages, car wash services, and most importantly, a team atmosphere. We even raise the bar on well bars, including Espresso/Cappuccino/Nitro/Cold Brew/Kombucha Bar, Froyo Bar, Breakfast Bar, Snack Bar and a, well, you know, bar (after 5 pm).
And if you feel intrigued right now reading, imagine the co-workers we have already attracted. This is the kind of team you'll want to take home to mom or invite to your kid's next birthday party. This is the kind of close-knit community happening here. Come check out how you can be part of Mint!
OUR VALUES – LET'S MAKE LIFE ULTRA TOGETHER!
Ownership: We are all owners; be the outcome and get the job done.
Action Biased: Be brilliant, proactive, and act with urgency.
Embrace the Adventure: Be agile, adaptive, and thrive on change.
Invent and Simplify: Never accept good enough.
$1,000 REFERRAL BONUS
Take a look at this job description, if you are the right person, please apply. If Mint Mobile doesn't appear to be a fit for you, refer a friend or colleague and get $1,000. Let your friend or colleague know to provide your full name and email when applying to the job. If we hire them and they stay for 90 days, you get $1000. For more details of restrictions and rules, please email recruiting@ultra.me.

Covid-19 Vaccination Requirement
UVNV, Inc. has adopted a mandated vaccination policy to support the health and safety of our team members and our community. The Company requires all employees to be fully vaccinated. The Company will provide accommodations based on medical condition or sincerely held religious beliefs or practices. Please let us know if you'd like to discuss the policy or available accommodations before proceeding with our recruitment process.
We are committed to equal employment opportunities regardless of race, color, genetic information, creed, religion, sex, sexual orientation, gender identity, lawful alien status, national origin, age, marital status, or protected veteran status. We support an inclusive workplace where associates excel based on personal merit, qualification, experience, ability, and job performance.
In support of the Equal Pay for Equal Work Act, the range of starting pay for this role is $90,000 - $103,000. This is not a guarantee of compensation or salary, actual compensation is influenced by a wide range of factors including but not limited to skill set, level of experience, education, certifications, responsibility, and geographic location. We also offer a variety of benefits including health, disability insurance, 401 (k), flexible spending accounts, EAP, education reimbursement, parental leave, unlimited vacation, bonuses, incentive stock options and company paid holidays. The specific programs and options available will vary depending on state, start date, and employment type. Our recruitment team will be happy to answer any questions you may have.
#LI-Remote",glassdoor
295,"Expression Networks
4.4
Data Engineer
Remote

 Founded in 1997 and headquartered in Washington DC, Expression Networks provides data fusion, data analytics, software engineering, information technology, and electromagnetic spectrum management solutions to the U.S. Department of Defense, Department of State, and national security community. Expression's “Perpetual Innovation” culture focuses on creating immediate and sustainable value for our clients via agile delivery of tailored solutions built through constant engagement with our clients. Expression Networks was ranked #1 on the Washington Technology 2018's Fast 50 list of fastest-growing small business Government contractors and a Top 20 Big Data Solutions Provider by CIO Review.

We make sure to provide everyone the tools and opportunities to grow while working on some of the newest technologies in the industry. With Covid-19 being a major theme the last two years having a growing collaborative culture has been one of the key focus of our C-suite and upper management. We get excited about celebrating our professionals' milestones, accomplishments, promotions, overcoming challenges, and many other aspects that make an engaging collaborative environment.

We are looking to bring on a mid-level Data Engineer to add to the continued growth of our Data Science division. This position will work in a team led by a principal data engineer on tasks related to designing and delivering high-impact data architecture and engineering solutions to our customers across a breadth of domains and use cases.
Location:
Remote, with the ability to travel per project requirements.
Security Clearance:
Ability to obtain Secret Clearance or Higher
Responsibilities:
Developing, testing, and documenting software code for data extraction, ingestion, transformation, cleaning, correlation, and analytics
Participating in end-to-end architectural design and development lifecycle for new data services/products, and making them operate at scale
Participating in cross-functional team collaboration to understand customer requirements, design prototypes, and optimize existing data services/products
Demonstrating Data Science excellence in the teams you work with across the organization, and mentoring junior members in the Data Science division
Participating in research, case studies, and prototypes on cutting-edge technologies and how they can be leveraged
Required Qualifications:
3+ years of experience bringing databases, data integration, and data analytics/ML technologies to production with a Bachelor's degree in Computer Science/Data Science/Computer Engineering or relevant field
Mastery in developing software code in one or more programming languages (Python, JavaScript, Java, Matlab, etc.)
Expert knowledge in databases (SQL, NoSQL, Graph, etc.) and data architecture (Data Lake, Delta Lake)
Knowledgeable in machine learning/AI methodologies
Experience with one or more SQL-on-Hadoop technology (Hive, Impala, Spark SQL, Presto, etc.)
Preferred Qualifications:
Experience in short release cycles and the full software lifecycle
Experience with Agile development methodology (e.g., Scrum)
Strong writing and oral communication skills to deliver design documents, technical reports, and presentations to a variety of audiences
Benefits:
Expression Networks offers competitive salaries and benefits, such as:
401k matching
PPO and HDHP medical/dental/vision insurance
Education reimbursement up to $10,000/yr.
Complimentary life insurance
Generous roll over PTO and 11 days of holiday leave
Onsite gym facility and trainer
Commuter Benefits Plan
In office Cold Brew Coffee
Equal Opportunity Employer/Veterans/Disabled",glassdoor
296,"Apple
4.2
Keystone Big Data Software Engineer, Global Business Intelligence
Cupertino, CA

 Summary
Posted: Jul 18, 2022
Role Number:200399924
Imagine what you could do here! At Apple, great minds come together to build products, services, and solutions that amaze the world. Imagine how your contributions could transform the world and there is no limit to what you could accomplish here. Apple's Global Business Intelligence (GBI) team is seeking an experienced Software Engineer to build high quality, scalable and resilient distributed systems that power Apple's analytics platforms and data pipelines. Apple's Enterprise Data Warehouse landscape caters to a wide variety of real-time, near real-time and batch analytical solutions. These solutions are an integral part of business functions like Sales, Operations, Finance, AppleCare, Marketing, and Internet Services, enabling business drivers to make critical decisions. If you enjoy learning new technologies, and are comfortable proposing and implementing solutions, demonstrating Software Engineering standard methodologies, you will find it rewarding to work in GBI! The ideal candidate for this position will be able to think outside of the box and should have passion for building engineering solutions to enable business in making time sensitive and critical decisions.
Key Qualifications
Strong fundamentals in data structures, algorithms, and software system design
Strong hands-on programming skills (Scala / Java / Python preferred)
Proficiency in developing applications in Spark & deep understanding of Spark is essential for this role
Proven track record of building jobs processing high-volume data using Spark
Experience with real time data processing with Spark Streaming, Flink is a huge plus
Committed to test driven development paradigm
Strong analytical and interpersonal skills and demonstrated ability to code & collaborate
Self-starter, highly motivated and ability to research, learn, prototype quickly
Sound experience in Cloud technologies such as AWS or GCP
Experience on Cloud with databases like SnowFlake and Singlestore is a plus
Prior experience in the areas of AI/ML/Data Sciences will be a strong plus
Curiosity to explore and understand data is a plus
Description
The Frameworks team in GBI build and support critical infrastructural systems which provide services for numerous organizations within Apple and we are looking for a strong, enthusiastic developer to join as a member of this group. You are someone with ideas and real passion for software delivered as a service to improve reuse, efficiency, and simplicity. This engineer’s work will affect multiple data teams within Apple and enable our partners to derive insights and help execute their goals.
Education & Experience
BS/MS in Computer Science, Computer Engineering or similar field
Additional Requirements
Apple is an Equal Opportunity Employer that is committed to inclusion and diversity. We also take affirmative action to offer employment and advancement opportunities to all applicants, including minorities, women, protected veterans, and individuals with disabilities. Apple will not discriminate or retaliate against applicants who inquire about, disclose, or discuss their compensation or that of other applicants.
We at Apple we are committed to working with and providing reasonable accommodation to applicants with physical and mental disabilities. Learn more.",glassdoor
297,"Milo's Tea Company
4.1
Data Engineer
Remote

 Overview: Milo’s Tea Company is one of the fastest growing beverage companies in the US. Our culture and operations are built on the belief that we can make a difference in the world. That’s why we put People First and strive to continually reduce our environmental impact on the planet. We leverage our world class operations and decades-long distribution partnerships to grow the footprint of our core products and create new, innovative beverage products.
We are the #1 and fastest growing brand in the Refrigerated Tea Category in the nation.
Our core mission is that we put people and the planet first and by doing this, it will be good for our business.
We are committed to unlocking the personal genius of every associate and have a strong focus on growth and learning.
Our Company is women-led (our Executive Team is 57% female) and strongly committed to Diversity, Inclusion and Belonging.
We are committed to annual charitable giving by delivering upon our 1% profit pledge.
We are Platinum Certified in Zero Waste Manufacturing; recycling, reducing, and reusing 95% of waste at all facilities.
Being a part of the Milo’s TEAm, you’ll get to collaborate with a group of passionate and high-performing people, where everyone feels empowered to do their best work and feels good about the work they’re doing.
And as a ""People First"" company, Milo’s is committed to the success and well-being of our associates, customers, and fans, no matter their gender, race or creed. Some of the benefits offered that reflect our commitment include:
Competitive salary with bonus opportunities
100% paid medical insurance for our associates and their families
401K with a company match
Partial tuition reimbursement assistance
A robust parental leave program
Paid time off to volunteer at the charity of your choice
Employee assistance program
Responsibilities: The Data Engineer is responsible for assisting with data management, modeling, development, transformation, and reporting activities.
*
Responsibilities: *
Identify business needs, determine possible solutions, and develop solutions that include systems components, and process improvements with data driven decision making.
Work with business groups to design and develop reporting and analytics solutions that will improve efficiency and effectiveness.
Designs, implements, tests, troubleshoots, documents, and supports data models, programs, scripts, and ETL (Extract, Transform, and Load) processes.
Develop, maintain, and curate large datasets from multiple platforms. Develop reporting capabilities to support business needs by creating and supporting SQL queries, data extraction packages, and interfaces. Explores ways to enhance data quality and reliability.
Perform data validation between analytical and source systems to support ongoing data management capabilities and data governance. Perform data testing to ensure the accuracy of data transformation.
Develop data analytics, reports, and dashboards using Power BI and other business intelligence tools.
Uphold and participate in all Corporate Responsibility programming including recycling, social advocacy and MMAD volunteering opportunities.
Invest in and is an example of Milo’s Responsibility commitment which includes environmental, social, and corporate governance components.
Other duties as assigned
Supervisory: This role does not have supervisory responsibilities.
Qualifications:
BA in computer science, information systems, statistics, applied math, or any other related field.
Up to 3 years of experience in information systems or related field.
Strong experience with SQL server solutions (queries, functions, stored procedures, views, etc.).
Cloud based computing and data solutions.
Proficient with Excel and Business Intelligence tools (Power BI, Power Query, Tableau, etc.).
Understanding of relational databases and data warehouses. Hands-on experience with SQL database design.
Experience with Microsoft SQL stack (SSIS, SSRS, SSAS, etc); Experience with cloud-based data technologies, Azure preferred.
Experience working in a SharePoint environment; Experience with Python, R or other programming languages.
Experience in non-traditional SQL (noSQL, etc.) solutions.
Experience with machine learning and predictive analytics.
Experience with other ETL tools such as Alteryx.
Job Type: Full-time",glassdoor
298,"Dataquestcorp
Data Science Engineer
Branchburg, NJ
Employer Provided Salary:$75K - $80K

 Job Role: Data Science
Note: Please don't apply C2C profiles. its only w2 positions
Benefits:
Free Training and placement.
Training provided by highly qualified, industry-experienced & certified instructors.
We do provide free accommodations & Relocation charges.
H1B Sponsorship
We do support for STEM OPT and GC processing.
Health Insurance
Relocation Assistance any where in USA.
Free accommodation.
Location: Branchburg, NJ
Job Types: Full-time, Contract
Job Types: Full-time, Contract
Salary: $75,000.00 - $80,000.00 per year
Benefits:
Health insurance
Schedule:
8 hour shift
Ability to commute/relocate:
Branchburg, NJ: Reliably commute or planning to relocate before starting work (Required)
Experience:
Python: 1 year (Preferred)
SQL: 1 year (Preferred)
Work Location: One location
Speak with the employer
+91 9089927715",glassdoor
299,"Pinterest
4.1
Data Engineer
Remote

 About Pinterest:
Millions of people across the world come to Pinterest to find new ideas every day. It's where they get inspiration, dream about new possibilities and plan for what matters most. Our mission is to help those people find their inspiration and create a life they love. In your role, you'll be challenged to take on work that upholds this mission and pushes Pinterest forward. You'll grow as a person and leader in your field, all the while helping Pinners make their lives better in the positive corner of the internet.
Our new progressive work model is called PinFlex, a term that's uniquely Pinterest to describe our flexible approach to living and working. Visit our PinFlex landing page to learn more.
The Enterprise Data Platform team is looking for a Data Engineer who has experience with Building Data Pipelines and Managing/Developing on any Cloud Data Warehouse. In this role you will also advise other Data Analysts and Data Engineers from the Business teams at Pinterest on the best practices for handling data and deriving insights using Snowflake. You will gradually become the Subject Matter Expert on Snowflake and also help build out the Modern Data Stack at Pinterest.
What you'll do:
Build Data Pipelines using Python on either Airflow or AWS Lambda to ingest data into Snowflake
Build Scripts in Python to manage Data Access on Snowflake
Define and advocate the best practices for storing and analyzing data inside Snowflake
Review the Data Modeling practices of other teams
What we're looking for:
Strong skills in Python and SQL
Experience with Building Data Pipelines in Python
Experience with any Cloud Data Warehouse either as an Administrator or a Developer
Strong Data Modeling skills
#LI-BB1
#LI-Remote
Our Commitment to Diversity:
At Pinterest, our mission is to bring everyone the inspiration to create a life they love—and that includes our employees. We’re taking on the most exciting challenges of our working lives, and we succeed with a team that represents an inclusive and diverse set of identities and backgrounds.

Not Specified
0",glassdoor
300,"Netflix
4.3
Data Engineer (L5) - Games
Los Gatos, CA
$108K - $193K (Glassdoor est.)

 Los Gatos, California
Data Science and Engineering
Now is an amazing time to join Netflix as we seek to entertain the world. We have over 200 million paid members in over 190 countries, and we won’t stop there. Games are our next big frontier and an incredible opportunity for us to deliver new experiences to delight and entertain our quickly growing membership. You will be jumping in at the very beginning of this adventure and be in a position to help us redefine what a Netflix subscription means for our members around the world.
Data Science and Engineering (‘DSE’) at Netflix is aimed at using data, analytics, and sciences to improve various aspects of our business. We are looking for a Data Engineer to join our Games DSE team, supporting end-to-end analytics & data needs for our games portfolio. This role will be partnering closely with our Game stakeholders to develop software and data solutions that enable analysis across the entire library of games.
As part of this team, you will work on diverse data technologies such as Spark, Presto, Flink, Kafka, and others to build insightful, scalable, and robust data pipelines that feed directly into our key gaming dashboards; write ETL jobs to collect and aggregate data; and build high-quality data models that represent how games are performing on Netflix.
The ideal candidate will also have a background in games, with a solid knowledge of how standard industry metrics are computed.
Who You Are:
7+ years of software/data engineering experience working with video game analytics (i.e you are familiar with how key metrics such as DAU, MAU and retention rates are computed in an ETL).
Passionate about building intuitive data models and an expert in distributed data processing patterns.
Highly proficient in at least one of these programming languages: Java, Python, or Scala.
Comfortable with complex SQL.
Expert in engineering data pipelines using big data technologies (Hive, Presto, Spark, Flink) on large-scale data sets demonstrated through years of experience.
Conceptually familiar with AWS cloud resources (S3, EC2, RDS etc).
Excel at taking vague requirements and crystallizing them into scalable data solutions.
Excited about operating independently, demonstrating excellence, and learning new technologies and frameworks.
What will you do?
Engineer efficient, adaptable, and scalable data pipelines in Spark and Python/Scala to process structured data into aggregate datasets that feed all games portfolio dashboards.
Become an expert in games metrics at Netflix - act as a thought partner to the games analytics team, understand their challenges, and help them to put the right data in front of our stakeholders.
Maintain and rethink existing datasets and pipelines to service a wider variety of use cases.
Join a stunning team of data engineers with diverse skill sets, partnering closely with analytics engineering and data science counterparts.
Netflix Culture
Our culture is unique, and we live by our values. For more information on what it's like to work at Netflix, please take a look at our culture memo.",glassdoor
301,"Luxoft
4.3
Data Engineer
Remote

 Project Description
Luxoft has contract with a major Telecommunications provider to engage with DIRECTV organization to establish integrated cloud technology platforms to ingest information from various Network Engineering support applications in order to better optimize management and planning for the future network.

To do this DIRECTV is managing data ingestion into a Snowflake Azure based deployment which allows for one cohesive platform to serve all types of users and workloads in a consistent way. Centralizing data in a unified, governed, managed data platform allows all authorized users to access accurate and timely data for analysis that is useful for highly transnational datasets. It is also useful that it can store structured and unstructured data. Additionally DIRECTV is leveraging a Palantir Deep™ instance platform for the creation and management of cost forecasting scenarios.
Responsibilities
- Analysis on Data Libraries - evaluation of data sets and current data architecture for source data pipelines. This will allow us to scope the depth/breadth of data

- Data Quality Metrics - Audits analysis and setup to determine the appropriate data quality measures. This will be used to validate with clients/users in a later phase.

- DQF research - Analyze the current Data Quality Framework to leverage as possible/needed. Assess the need for extension and/or replacement of the current DQF.

- Architecture patterns research - Analysis of data translation and business rules associated.

- Current ingestion patterns - Study and enhancement research to evaluate data pipeline for current state and opportunity to optimize for increased data quality and rigor.
Skills
Must have
Cloud, Data Engineering, SnowFlake, Big Data
Nice to have
Microsoft Azure Cloud Platform
Languages
English: C2 Proficient
Seniority
Senior
Relocation package
If needed, we can help you with relocation process.
Vacancy Specialization
BigData Development
Ref Number
VR-81593",glassdoor
302,"NucleusTeq
4.9
Data Engineer
Remote

 Data Engineer
Role Info:
Hands on BI Data Engineer role with strong
Creating KPI Dashboards - Interactive Dashboards using tableau / Quicksight
Top Skills:
BI Tableau / AWS Quicksight exp is a must
AWS (IAM, RDS, S3, Lambda) exp is a must
SQL exp is a must
Python knowledge is required
Nice to have:
AWS Certified Solutions Architect
About the Company:
NucleusTeq is a software services, solutions & products company empowering & transforming customer's business through the use of digital technologies such as Big-Data, Analytics, Cloud, Enterprise Automation, Block-chain, Mobility, etc.
We are enabling several fortune 1000 clients in the USA, Canada, UK & India to navigate their digital transformation.",glassdoor
303,"Twitch
4.0
Data Engineer
San Francisco, CA
Employer Provided Salary:$140K - $171K

 About Us
Twitch is the world's biggest live streaming service, with global communities built around gaming, entertainment, music, sports, cooking, and more. It's where millions of people come together to chat, interact, and make their own entertainment.
We're about community, inside and out. You'll find coworkers who are eager to team up, collaborate, and smash (or elegantly solve) problems together. We're on a quest to empower live communities, so if this sounds good to you, see what we're up to on LinkedIn and Twitter, get interviewing tips on Instagram, and discover projects we're solving on our Blog.
About the Role
Reporting to the Head of Global Talent Acquisition, the Data Engineer will expand the reach and role of data among leaders and managers at Twitch. You will empower the business to integrate data into their daily workflow by creating/maintaining data pipelines, producing reporting, and automating our processes.
You can work in San Francisco, CA or remotely across the US.
This role is for you if:
You love automating processes and developing efficient scalable solutions
You're excited about contributing to the success, efficiency, and happiness of Twitch staff
You're excited to jump into a diverse array of data work to support the team
You enjoy working with autonomy and shaping a new function

You Will:
Delight consumers of people-related data by ensuring they have the data they need to inform decisions, where and when they need it
Build and own data pipelines, SQL queries/views, and apps
Automate processes through the use of JavaScript and other languages
Improve business, engineering, and data processes through data architecture, engineering, testing, and operational excellence best practices
Ensure the integrity of People and Places data in analyses and tools through regular audits
Partner to develop analytics products and recommend opportunities
Develop ongoing metrics, analyses, and dashboards to guide important decisions
You Have:
Experience writing SQL and a procedural language (Python, R, etc.) for data handling
Experience owning systems that collect, transform, and visualize data
Experience implementing data analytics, visualization tools and programs for HR working with Workday, Greenhouse, Tableau, Google Workspace, Google Data Studio, and Google Sheets
Experience implementing software solutions to automate data source, visualization and analytics products
Bachelors in related field, or equivalent experience
Bonus Points
Experience handling People-related data including compensation, performance, hiring, and engagement data.
Experience automating Google services (Sheets, Docs, Data Studio) with Javascript
Experience with Workday, Greenhouse, and Tableau
Demonstrated net positive contributor to company community and culture above and beyond the core job
Perks
Medical, Dental, Vision & Disability Insurance
401(k), Maternity & Parental Leave
Flexible PTO
Commuter Benefits
Amazon Employee Discount
Monthly Contribution & Discounts for Wellness Related Activities & Programs (e.g., gym memberships, off-site massages, etc.),
Breakfast, Lunch & Dinner Served Daily
Free Snacks & Beverages
We are an equal opportunity employer and value diversity at Twitch. We do not discriminate on the basis of race, religion, color, national origin, gender, gender identity, sexual orientation, age, marital status, veteran status, or disability status, or other legally protected status.
Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
Pursuant to the Los Angeles Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
The base pay range for this position in Colorado, Connecticut and Washington is $139,860 - $170,940 yr and in New York City is $153,900 - $188,100 yr. Pay is based on market location and may vary depending on job-related knowledge, skills, and experience. A sign-on payment and restricted stock units may be provided as part of the compensation package, in addition to a full range of medical, financial, and/or other benefits, dependent on the position offered. Applicants should apply via Twitch's internal or external careers site.
Workers in New York City who perform in-person work or interact with the public in the course of business must show proof they have been fully vaccinated against COVID or request and receive approval for a reasonable accommodation, including medical or religious accommodation.
Twitch values your privacy. Please consult our Candidate Privacy Notice, for information about how we collect, use, and disclose personal information of our candidates.
Job ID: TW7236
#LI-Remote #RemoteFriendly",glassdoor
304,"Teknic
Data Engineer
Remote

 Role: Data Engineer
Location: Remote
JOb Description:
Skills and Experience :
Good experience on designing and developing data pipelines for data ingestion and transformation using Spark.
Distributed computing experience using Pyspark.
Good understanding of spark framework and spark architecture.
Experience working in Cloud based big data infrastructure.
Excellent in trouble shooting the performance and data skew issues.
Must have a good understanding of spark run time metrics and tune applications based on metrics.
Deep knowledge in partitioning, bucketing concepts of data ingestion.
Good understanding of AWS services like Glue, Athena, S3, Lambda, Cloud formation.
Preferred working knowledge on the implementation of datalake ETL using AWS glue, Databricks etc.
Experience with data modelling techniques for cloud data stores and on prem databases like Teradata, Teradata Vantage (TDV) etc.
Preferred working experience in ETL development in Teradata vantage and data migration from on prem to Teradata vantage.
Proficiency in SQL, relational and non-relational databases, query optimization and data modelling.
Experience with source code control systems like Gitlab.
Experience with large scale distributed relational and NoSQL database systems.
Job Type: Contract
Schedule:
8 hour shift
Experience:
Data engineer: 10 years (Preferred)
Spark.: 3 years (Preferred)
Cloud based big data infrastructure.: 1 year (Preferred)
datalake ETL: 1 year (Preferred)
AWS Glue: 1 year (Preferred)
Work Location: Remote",glassdoor
305,"Realign LLC
4.5
Data Engineer
California

 Job Type: Contract
Job Category: IT
Job Description
Write and optimize queries, provide input on peer code reviews and data modeling, deploy data
updates via continuous integration / deployment (CI/CD) practices.

Collaborate with software developers, other data engineers, and database architects on projects to
ensure optimal data delivery following appropriate change management guidelines.

Collaborate with software and reliability engineers to automate repeatable data tasks.

Work with development and production support teams to troubleshoot data, application, and service
deployment issues.

Develop detailed, shared technical procedure documentation, including processes for contingency
operations.

Research, provide technical input, document, and implement new technology solutions.

Implement necessary patches, hotfixes, service packs, cumulative updates, upgrades, and
configuration change to maintain security compliance and application integrity.

Required Skills
Big Data Engineer",glassdoor
306,"Pepsico
3.9
Junior Data Engineer
Remote
Employer Provided Salary:$90K - $100K

 Compensation: $80k - $90k
Benefits: Medical, Dental, Vision, 401k match and Arc
This role can be performed remote in any of our headquarter locations including Plano, Texas; Purchase, New York; Chicago, Illinois.
What PepsiCo Data Management and Operations does:
Maintain a predictable, transparent, global operating rhythm that ensures always-on access to high-quality data for stakeholders across the company
Responsible for day-to-day data collection, transportation, maintenance/curation and access to the PepsiCo corporate data asset
Work cross-functionally across the enterprise to centralize data and standardize it for use by business, data science or other stakeholders
Increase awareness about available data and democratize access to it across the company.
As a member of the data engineering team, you will be the key technical expert developing and overseeing PepsiCo's data product build & operations and drive a strong vision for how data engineering can proactively create a positive impact on the business. You'll be an empowered member of a team of data engineers who build data pipelines into various source systems, rest data on the PepsiCo Data Lake, and enable exploration and access for analytics, visualization, machine learning, and product development efforts across the company. As a member of the data engineering team, you will help lead the development of very large and complex data applications into public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. You will work closely with process owners, product owners and business users. You'll be working in a hybrid environment with in-house, on-premise data sources as well as cloud and remote systems.
Key Accountabilities:
Active contributor to code development in projects and services
Manage and scale data pipelines from internal and external data sources to support new product launches and drive data quality across data products
Build and own the automation and monitoring frameworks that capture metrics and operational KPIs for data pipeline quality and performance
Responsible for implementing best practices around systems integration, security, performance and data management
Empower the business by creating value through the increased adoption of data, data science and business intelligence landscape
Collaborate with internal clients (data science and product teams) to drive solutioning and POC discussions.
Develop and optimize procedures to “productionalize” data science models
Define and manage SLA’s for data products and processes running in production
Support large-scale experimentation done by data scientists
Prototype new approaches and build solutions at scale
Research in state-of-the-art methodologies
Create documentation for learnings and knowledge transfer
Create and audit reusable packages or libraries
COVID-19 vaccination is a condition of employment for this role. Please note that all such company vaccine requirements provide the opportunity to request an approved accommodation or exemption under applicable law
Qualifications / Requirements :
BA/BS in Computer Science, Math, Physics is mandatory.
2+ years of overall technology experience that includes hands-on building data engineering pipelines
2+ years of experience in SQL optimization and performance tuning, and development experience in programming languages like Python, PySpark, Scala etc.)
1+ years in cloud data engineering experience in Azure or AWS
1+ Years in building data engineering pipelines in Azure (ADF and databricks)
Job Type: Full-time
Pay: $90,000.00 - $100,000.00 per year
Benefits:
401(k) matching
Dental insurance
Health insurance
Retirement plan
Vision insurance
Schedule:
8 hour shift
Education:
Bachelor's (Required)
Experience:
SQL: 2 years (Required)
Cloud: 2 years (Required)
Work Location: Remote",glassdoor
307,"Blue Cross and Blue Shield of North Carolina
4.1
Data Engineer
Remote

 Additional Locations:
Full Time Remote - Alabama, Full Time Remote - Alabama, Full Time Remote - Arizona, Full Time Remote - Arkansas, Full Time Remote - Florida, Full Time Remote - Georgia, Full Time Remote - Idaho, Full Time Remote - Indiana, Full Time Remote - Iowa, Full Time Remote - Kansas, Full Time Remote - Kentucky, Full Time Remote - Louisiana, Full Time Remote - Maryland, Full Time Remote - Michigan, Full Time Remote - Mississippi, Full Time Remote - Missouri, Full Time Remote - Ohio, Full Time Remote - Oklahoma, Full Time Remote - Pennsylvania, Full Time Remote - South Carolina, Full Time Remote - South Dakota, Full Time Remote - Tennessee, Full Time Remote - Texas, Full Time Remote - Utah, Full Time Remote - Virginia {+ 1 more}
Job Description
IT is different here. Our work as technology specialists pushes the boundaries of what’s possible in health care. You will build solutions that make a real difference in people’s lives. Driven by the importance of their work, our team members innovate to elevate. We’re encouraged to be curious, collaborate, and turn ideas into solutions that transform this space.

In this role you will work closely with senior engineers, data scientists and other stakeholders to design and maintain moderate to advanced data models. The Data Engineer is responsible for developing and supporting advanced reports that provide accurate and timely data for internal and external clients. The Data Engineer will design and grow a data infrastructure that powers our ability to make timely and data-driven decisions. You will support Membership Operations, Customer Service Operations, Digital & Consumer Experience teams.

If you are ready to make a career out of making a difference, then you are the person for this team.
What You’ll Do
Define and extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes
Document, and test moderate data systems that bring together data from disparate sources, making it available to data scientists, and other users using scripting and/or programming languages
Write and refine code to ensure performance and reliability of data extraction and processing
Participate in requirements gathering sessions with business and technical staff to distill technical requirement from business requests
Develop SQL queries to extract data for analysis and model construction
Own delivery of moderately sized data engineering projects
Design and develop scalable, efficient data pipeline processes to handle data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets to analysts and data scientists
Ensure performance and reliability of data processes
Document and test data processes including performance of through data validation and verification
Collaborate with cross functional team to resolve data quality and operational issues and ensure timely delivery of products
Develop and implement scripts for database and data process maintenance, monitoring, and performance tuning
Analyze and evaluate databases in order to identify and recommend improvements and optimization
Design eye-catching visualizations to convey information to users
What You Will Bring
Bachelor’s degree and 3 years of experience with Oracle, Data Warehouses and Data Lakes, Big Data platforms and programming in Python, R or other related language.
In lieu of degree, 5 years of the experience as stated above.
SQL and Python scripting
Experience in a cloud environment
Experience with Ab Initio or other ETL tools",glassdoor
308,"Apple
4.2
Data Engineer
Cupertino, CA

 Summary
Posted: Aug 10, 2022
Weekly Hours: 40
Role Number:200406892
Are you a big-picture thinker who loves setting ambitious goals? Do you have a passion for understanding how each line of code affects all the others? In the Core Operating Systems group, you’ll ensure the OS is inseparable from each device’s identity as a whole. That’s because this group is committed to building fully integrated operating systems that combine hardware, software, and apps into a single Apple experience. Your dedication to cross-disciplinary collaboration will help develop groundbreaking technologies, such as iOS, macOS, watchOS, and tvOS. By crafting these distinct, holistic user experiences, you’ll continue to uphold and advance the excellence people expect from Apple devices. The Platform Services & Operations team in Core OS is looking for a Data Engineer to inform and develop essential workflow tooling at scale. The Workflow Engineering team enable teams to deliver high quality software through best in class engineering experiences, efficient workflow, data driven insights, and a culture of continuous improvement. Your focus is building the backend data pipelines that enables visualization of data across the organization in user intuitive and configurable formats.
Key Qualifications
3 +proven experience in a Data focused posistion
Proficient in Python; data access and retrieval. Quantitative data preparation. Regular expressions and text analysis
Highly Proficient in Database Language and Design; querying large stores of data (APIs, SQL, etc.).
Access, retrieval, and storage of information. Data Structures, modeling for speed and efficiency
Software Development; understanding of build pipelines, branching and merging, Agile methods, and the delivery of code. Fluency in Git (or comparable source control tool)
Description
- Replicate data from source system into data warehouse; retrieve data through various protocols and land it in a central store - Automate data pipelines; write programs to periodically update warehouse data from source systems - Design for scale; flexible infrastructure for common enhancements including: expanding the volume of captured data, adding fields to the user-facing views, and recompiling archived data - Work with a team of data scientists and full stack engineers, to derive and develop targeted insights through centrally managed interactive dashboards
Education & Experience
B.S. in Data Science, Computer Science, or equivalent experience.
Additional Requirements
Experience as an Analyst; worked in the delivery of visual information (dashboards, reports, web-apps)
An understanding of how data can be used and applied in context (what is useful to capture and how it can be communicated)
Full Stack Development; ability to maintain back-end systems and visualize front-end data for users (with a web-kit framework like Angular, React)
Experience with Snowflake and/or other data store technologies",glassdoor
309,"Tesla
3.6
Data Engineer
Fremont, CA

 What to Expect
The Data Engineer is responsible for processing structured and unstructured data, validating data quality, and developing and supporting data products. We are looking for someone with strong hands on experience in all layers of data Integration and analytics! We especially need experience in using Python as an ETL tool. The Data Engineer plays a significant role in Agile planning, providing advice and guidance, and monitoring emerging technologies. Some of the technology we use: * Python * Informatica * SQL Server and MySQL * Vertica * Kafka

What You’ll Do
* Design, code, test, correct and document programs and scripts using agreed standards and tools to achieve a well-engineered result * Derive an overall strategy of data management, within an established information architecture that supports the development and secure operation of existing and new information and digital services * Plan effective data storage, security, sharing and publishing within the organization * Gathers and processes raw, structured, semi-structured, and unstructured data using batch and real-time data processing frameworks * Ensures data quality and implements tools and frameworks for automating the identification of data quality issues * Collaborate with internal and external data providers on data validation providing feedback and making customized changes to data feeds and data mappings * Mentor and lead data engineers providing technical guidance and oversight * Provides ongoing support, monitoring, and maintenance of deployed products

What You’ll Bring

* Strong experience with relational databases like SQL Server, MySQL and Vertica. NoSQL databases experience is a plus! * Strong background in data modeling, data access, and data storage techniques * Experience with design, development, and implementation of highly scalable, high-volume software systems and components, source of truth systems for different business areas, developing and maintaining web services in an agile environment * Working experience with Kafka Streaming layer * Experience in Spark Framework on both batch and real-time data processing is a plus * Experience in Big Data Integration & Analytics is a plus * Experience in Supply Chain and Logistics data is a plus",glassdoor
310,"Accenture
4.1
Data Engineer
San Francisco, CA

 Accenture Flex offers you the flexibility of local fixed-duration project-based work powered by Accenture, a leading global professional services company. Accenture is consistently recognized on FORTUNE's 100 Best Companies to Work For and Diversity Inc's Top 50 Companies For Diversity lists.
As an Accenture Flex employee, you will apply your skills and experience to help drive business transformation for leading organizations and communities. In addition to delivering innovative solutions for Accenture's clients, you will work with a highly skilled, diverse network of people across Accenture businesses who are using the latest emerging technologies to address today's biggest business challenges.
You will receive competitive rewards and access to benefits programs and world-class learning resources. Accenture Flex employees work in their local metro area onsite at the project, significantly reducing and/or eliminating the demands to travel.
Job Description:
As a Data Engineer, you will:
Utilize strong SQL & Python expertise to engineer sound data pipelines and conduct routine and ad hoc analysis to assess the performance of legacy products and the saliency of new features
Build reporting dashboards and visualizations to design, create, and track campaign/program KPIs
Perform analyses on large data sets to understand drivers of marketing engagement and provide recommendations on campaign and product optimization

Basic Qualifications:
Minimum 2 years of experience in Data Engineering
Minimum 2 years of experience with SQL
Minimum 2 years of experience with Python
High School Diploma or GED
Preferred Qualifications:
Experience with Data Analytics
As required by Colorado Law under the Equal Pay for Equal Work Act, Accenture provides a reasonable range of compensation for roles that may be hired in Colorado. Actual compensation is influenced by a wide array of factors including but not limited to skill set, level of experience, and specific office location. For the state of Colorado only, the starting range of pay for this role is $86.82 - $96.82 per hour, and information on benefits is here.

COVID-19 update:

The safety and well-being of our candidates, our people and their families continues to be a top priority. Until travel restrictions change, interviews will continue to be conducted virtually.

Subject to applicable law, please be aware that Accenture requires all employees to be fully vaccinated as a condition of employment. Accenture will consider requests for accommodation to this vaccination requirement during the recruiting process.

What We Believe

We have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture has the responsibility to create and sustain an inclusive environment.

Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more here

Equal Employment Opportunity Statement

Accenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation.

All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.

Accenture is committed to providing veteran employment opportunities to our service men and women.

For details, view a copy of the Accenture Equal Opportunity and Affirmative Action Policy Statement.

Requesting An Accommodation

Accenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.

If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.

Other Employment Statements

Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States.

Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.

Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.

The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.",glassdoor
311,"Qualtrics
4.2
Data Engineer
Provo, UT
$83K - $125K (Glassdoor est.)

 The Qualtrics XM Platform™ is a system of action that helps businesses to attract customers who stay longer and buy more, to engage and empower employees to do the best work of their lives, to develop breakthrough products people love, and to build a brand people can’t imagine living without.

Joining Qualtrics means becoming part of a team bold enough to chase breakthrough experiences - like building a technology that will be a force for good. A team committed to diversity, equity, and inclusion because of a conviction that every voice holds value, with a vision for representation that matches the world around us and inclusion that far exceeds it. You could belong to a team whose values center on transparency, being all in, having customer obsession, acting as one team, and operating with scrappiness. All so you can do the best work of your career.

We believe every interaction is an opportunity. Are we yours?
The Team
Our team is a collection of deeply passionate engineers who are riding the groundbreaking of cloud computing and web scalability. We built data analytics applications that help company leaders gain insights about technology spends, make sound decision on technology investments, and drive innovation in resource utilization and efficiency optimizations. Our environment is primarily TypeScript, Node.js, React, MySQL NoSQL, AWS, Python, PHP, and Docker. In our collaborative culture, you find plenty of opportunities to impact our full-stack products; from Web & mobile UI to data visualization & analysis to data ingestion, storage and processing.
Job Responsibilities
Developing scalable, fast, robust, and simple web-based solutions to solve complex business problems
Close collaboration with your team to collect and incorporate feedback into your feature design
Drive operational excellence by investigating production issues, driving root cause analysis and follow-up actions for mitigation
Improve performance, availability, reliability, scale, throughput and latency
Work with your team in order to meet customer work you're doing, understand the decisions that are being made and make your voice heard.
Qualifications
Bachelor's degree in Computer Science or related field
Coding experience with any programming language (Prefer experience in TypeScript/JavaScript/React/Python)
Experience with web infrastructure and distributed systems
Experience with software engineering best practices (e.g. unit testing, code reviews, design, continuous delivery, git, test automation and build\deploy systems)
Ability to work in a fast-paced and agile development environment and to learn new frameworks/stacks
Passionate about building products that help customers easily and effectively get their job done
Enthusiastic person, who communicates effectively and is easy to work with
Curious and constantly learning on your own and from others
You get satisfaction from helping others succeed, and you constantly seek ways to improve
You can identify gaps, propose solutions to important problems, then take it to resolution
Preferred Qualifications
Shown ability to troubleshoot and identify the root cause of issues
Demonstrated skill and passion for operational excellence
Experience in a 24/7 production environment is a plus
Ability to retain composure under stressful conditions, communicate effectively with wide array of individuals at Qualtrics, and get the right things done
Confirmed ability to understand large systems, drilling down to code level",glassdoor
312,"Lincoln Financial
3.6
Data Engineer (REMOTE)
Radnor, PA
Employer Provided Salary:$63K - $138K

 Date: Oct 9, 2022
Primary Location: Radnor, PA, US
Company: Lincoln Financial
Alternate Locations: Work from Home

Work Arrangement: Work from Home

Relocation assistance:: is not available for this opportunity.

Pay Range: $63,100 - $137,900

Bonus Potential: 5%

Requisition #: 69444

The Role at a Glance

This is an exciting opportunity within Lincoln’s Work Place Solutions IT Data Team for a Data Engineer/ETL Developer to help build solutions for Lincoln’s Work Place Solutions business. This position will assist Analytic Teams with the design and implementation of Data solutions and systems, including integration with databases and data warehouses, both on-Premise and in AWS Cloud. This candidate must be able to develop, enhance, and support Informatica workflows and processes using Informatica Power Center and Dataiku for the extraction and transformation of data in a UNIX and Oracle database environment. They must also have experience working within BI tools such as Tableau and Microstrategy. Experience working in the cloud using AWS native services such as Glue, Athena, Aurora, Redshift, and/or Snowflake is needed. The candidate must have experience participating in and beginning to lead teams within a Data Organization by suggesting new and innovative ways of gaining data processing efficiencies and participating in architectural and modeling discussions.

What you'll be doing

Participates in defining architecture and modeling best practices within the team
Develop tools and work on integrating disparate systems using ETL
Work on transformation of data into Facts and Dims in a Kimball and/or relational model
Works with Sr. Technical Professionals to implement data development best practices
Develop, enhance and support Informatica workflows and processes using Informatica Power Center for the extraction and translation of data in a UNIX and Oracle database environment
Develop, enhance and support Dataiku workflows and processes for transforming data into Kimball model Facts/Dims
Creates partnerships with stakeholders, POs, BSAs and Analytic teams in requirement, design and coding walkthroughs to ensure the development of quality solutions and understand complex business/technical problems and opportunities and identify potential application solutions.
Demonstrates expertise in a variety of the data warehouse concepts, practices, and procedures. Relies on extensive experience and judgment to plan and accomplish goals
Analyzes operational and analytical data requirements by working with cross functional business and application development teams
Maintains knowledge on current and emerging developments/trends for assigned area(s) of responsibility, assess the impact, and collaborates with senior management to incorporate new trends and developments in current and future solutions.
Participate with collaboration efforts with development teams to review, update and approve the data portion of project designs, participate in cost/benefit analysis and preparation of project plans.
Participate in the design, development and delivery data centric IT solutions, including large scale data staging and orchestration, integration and provisioning mechanisms
Works with business partners to prioritize business and information needs
Provides input and validates increasingly complex project plans, test plans and implementation plans
Creates increasingly complex technical specifications from business requirements/business specifications
Proactively identifies problems and presents/develops solutions
Communicates effectively with internal stakeholders and management
Defines detailed development tasks, task dependencies and estimates to complete work
What we're looking for

4 Year/Bachelor's degree or equivalent work experience (4 years of experience in lieu of Bachelor's) in Computer Science, Computer Information Systems, Information Systems, Information Technology or Computer Engineering or equivalent work experience (Minimum Required
3 - 5+ Years’ experience in application development that directly aligns with the specific responsibilities for this position (Required)
Experience with ETL development
Must have experience with Informatica; Dataiku is a plus
Must have experience with BI tools such as Tableau and Microstrategy
Experience with AWS cloud native services, such as: Glue, Athena, Aurora, Redshift
Must have a proven track record working closely with business stakeholders, BSAs, and POs, Solution Architects to understand requirements and expectations to achieve quality technical solutions
What’s it like to work here?
At Lincoln Financial Group, we love what we do. We make meaningful contributions each and every day to empower our customers to take charge of their lives. Working alongside dedicated and talented colleagues, we build fulfilling careers and stronger communities through a company that values our unique perspectives, insights and contributions and invests in programs that empower each of us to take charge of our own future.

What’s in it for YOU:
A clearly defined career framework to help you successfully manage your career
Leadership development and virtual training opportunities
PTO/parental leave
Competitive 401K and employee benefits
Free financial counseling, health coaching and employee assistance program
Tuition assistance program
A leadership team that prioritizes your health and well-being; offering a remote work environment and flexible work hybrid situations
Effective productivity/technology tools and training

Work Arrangement
Work from Home : Employees will work from home and are not required to work in a Lincoln office on a regular basis.

Lincoln will evaluate the following when setting the successful candidate's wage rate:
Prior work or industry experience.
Education level to the extent education is relevant to the position.
Unique skills

About The Company
Lincoln Financial Group, a Fortune 200 company with over 10,000 employees, provides advice and solutions that help empower Americans to take charge of their financial lives with confidence. Our core business areas — Life Insurance, Annuities, Retirement Plan Services and Group Protection — focus on supporting, preserving and enhancing over 17 million customer’s lifestyles and retirement outcomes.

Headquartered in Radnor, Pennsylvania, Lincoln Financial Group is the marketing name for Lincoln National Corporation (NYSE: LNC) and its affiliates. The company had $324 billion in end-of-period account values as of June 30, 2021.

Ranked one of the Best Large Employers in America and Best Employers for Women by Forbes magazine as well as one of Newsweek’s Most Responsible Companies, Lincoln Financial Group makes a serious investment in our employees’ futures through a broad range of wealth accumulation and protection plans, health and wellness programs, and career development resources designed to help each individual reach their personal and professional goals.

Lincoln is committed to creating a diverse and inclusive environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.

Lincoln Financial Group is a committed corporate citizen included on major sustainability indices including the Dow Jones Sustainability Index North America and FTSE4Good. Dedicated to diversity and inclusion, we earned perfect 100 percent scores on the Corporate Equality Index and the Disability Equality Index. Follow us on Facebook, Twitter, LinkedIn, and Instagram.

Be Aware of Fraudulent Recruiting Activities
If you are interested in a career at Lincoln, we encourage you to review our current openings and apply on our website. Lincoln values the privacy and security of every applicant and urges all applicants to diligently protect their sensitive personal information from scams targeting job seekers. These scams can take many forms including fake employment applications, bogus interviews and falsified offer letters.
Lincoln will not ask applicants to provide their social security numbers, date of birth, bank account information or other sensitive information in job applications. Additionally, our recruiters do not communicate with applicants through free e-mail accounts (Gmail, Yahoo, Hotmail) or conduct interviews utilizing video chat rooms. We will never ask applicants to provide payment during the hiring process or extend an offer without conducting a phone, live video or in-person interview. Please contact Lincoln's fraud team at fraudhotline@lfg.com if you encounter a recruiter or see a job opportunity that seems suspicious.

Additional Information
This position may be subject to Lincoln’s Political Contribution Policy. An offer of employment may be contingent upon disclosing to Lincoln the details of certain political contributions. Lincoln may decline to extend an offer or terminate employment for this role if it determines political contributions made could have an adverse impact on Lincoln’s current or future business interests, misrepresentations were made, or for failure to fully disclose applicable political contributions and or fundraising activities.

Any unsolicited resumes/candidate profiles submitted through our web site or to personal e-mail accounts of employees of Lincoln Financial Group are considered property of Lincoln Financial Group and are not subject to payment of agency fees.

Lincoln Financial Group (“LFG”) is an Equal Opportunity employer and, as such, is committed in policy and practice to recruit, hire, compensate, train and promote, in all job classifications, without regard to race, color, religion, sex (including pregnancy), age, national origin, disability, sexual orientation, gender identity and expression, Veteran status, or genetic information. Applicants are evaluated on the basis of job qualifications. If you are a person with a disability that impedes your ability to express your interest for a position through our online application process, or require TTY/TDD assistance, contact us by calling 260-455-2558.",glassdoor
313,"Ultra Mobile
4.4
Digital Data Engineer I - Remote
Costa Mesa, CA
Employer Provided Salary:$90K - $103K

 ULTRA MOBILE is seeking a talented Digital Data Engineer I to join the Data Management Team! Individual reports to Customer Data Manager. Role is remote; must reside in the United States.
ABOUT THE ROLE
Provide direct data engineering development to data pipelines for ETL establishment and enhancements to and from data warehouses to customer management platform (Braze). Work collaboratively with cross-functional teams to determine digital data needs, establish data collection requirements, and deploy & maintain accurate data to ensure metrics & dimensions are addressed for analytics/reporting requirements.
Your usual day of awesomeness includes:
Transform required data conditions into performance code logic.
Develop high-performance code in SQL and Python.
Develop, automate, and enhance ELT processes for continuous data flow.
Create, modify, and deploy code to production via AWS resources including Lambda, S3, Glue, Redshift, etc.
Partner with stakeholders to support the implementation and development of data requirements.
Troubleshoot data anomalies and provide applicable solutions.
Build, test and maintain database pipeline architectures.
WHAT YOU BRING
Advanced level in SQL and Python for data engineering and backend development.
Understanding of popular code development approaches:
Test-driven development
Continuous Integration/Continuous Deployment (CI/CD)
Experienced working with AWS services (Lambda, S3, Glue, Redshift etc.) and Cloud Data Warehouse.
Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
Define digital data collection methods and implementations to DWH and customer management platforms.
Experienced with QA testing process to verify data is collected & rendered as expected.
Ability to excel in a fast-paced, cross-functional environment.
Ability to work autonomously.
Excellent written and verbal communication skills.
Proactive problem-solving and critical thinking skills.
Ability to manage time effectively and consistently meet deadlines.
NICE TO HAVE
Prior working knowledge of Braze or other Customer Management Platforms
Snowflake Cloud Data Warehouse
Terraform/Bitbucket/Airflow/Jenkins
Looker, Tableau, Power BI
WE ARE ULTRA & MINT MOBILE
We connect people to what's most important in their lives: Easily, affordably and reliably. We strive to be California's Preeminent Destination Employer. Oh yeah, we get it too! We understand what matters to you most. You're an individual with unique needs, and we're prepared to exceed any expectations you have for an ideal employer.
We're smart, strategic, and get things done without a lot of red tape or unnecessary politics. Everyone matters here and everyone has a voice. Expect to spend your time contributing to projects that really matter. We obsess over the employee experience. To start, we provide some of the most competitive salary, benefits, family leave, vacation, retirement and equity options in Southern California. We believe in you and invest in you. Not just your career aspirations, but your life.
In addition, we've got a laundry list of perks you'll brag about on insta - Lunch every day prepared by our very own chef, healthy snacks, onsite gym, free massages, car wash services, and most importantly, a team atmosphere. We even raise the bar on well bars, including Espresso/Cappuccino/Nitro/Cold Brew/Kombucha Bar, Froyo Bar, Breakfast Bar, Snack Bar and a, well, you know, bar (after 5 pm).
And if you feel intrigued right now reading, imagine the co-workers we have already attracted. This is the kind of team you'll want to take home to mom or invite to your kid's next birthday party. This is the kind of close-knit community happening here. Come check out how you can be part of Ultra & Mint!
OUR VALUES – LET'S MAKE LIFE ULTRA TOGETHER!
Ownership: We are all owners; be the outcome and get the job done.
Action Biased: Be brilliant, proactive, and act with urgency.
Embrace the Adventure: Be agile, adaptive, and thrive on change.
Invent and Simplify: Never accept good enough.
$1,000 REFERRAL BONUS
Take a look at this job description, if you are the right person, please apply. If Ultra Mobile doesn't appear to be a fit for you, refer a friend or colleague and get $1,000. Let your friend or colleague know to provide your full name and email when applying to the job. If we hire them and they stay for 90 days, you get $1000. For more details of restrictions and rules, please email recruiting@ultra.me.

Covid-19 Vaccination Requirement
UVNV, Inc. has adopted a mandated vaccination policy to support the health and safety of our team members and our community. The Company requires all employees to be fully vaccinated. The Company will provide accommodations based on medical condition or sincerely held religious beliefs or practices. Please let us know if you'd like to discuss the policy or available accommodations before proceeding with our recruitment process.
We are committed to equal employment opportunities regardless of race, color, genetic information, creed, religion, sex, sexual orientation, gender identity, lawful alien status, national origin, age, marital status, or protected veteran status. We support an inclusive workplace where associates excel based on personal merit, qualification, experience, ability, and job performance.
In support of the Equal Pay for Equal Work Act, the range of starting pay for this role is $90,000 - $103,000. This is not a guarantee of compensation or salary, actual compensation is influenced by a wide range of factors including but not limited to skill set, level of experience, education, certifications, responsibility, and geographic location. We also offer a variety of benefits including health, disability insurance, 401 (k), flexible spending accounts, EAP, education reimbursement, parental leave, unlimited vacation, bonuses, incentive stock options and company paid holidays. The specific programs and options available will vary depending on state, start date, and employment type. Our recruitment team will be happy to answer any questions you may have.
#LI-Remote",glassdoor
314,"Antra, Inc
4.5
Jr. Data Engineer
Sterling, VA
Employer Provided Salary:$60K - $68K

 Antra started its services in the year 2008, since then we have been diligently serving every need of our clients professional and software solutions. With our unique amalgam of innovation and inspiration, backed by Agile processes, we deliver world-class services with our core values to our clients. We identify unique strategies to transforming organizations through picking their sweet spot for innovative thinking and helping them in implementing in-depth cultural shift; ultimately augmenting the innovation process to the next level – fostering the innovation race that never ends.
This role requires the design, development and implementation of data solutions to business problems. An Azure Data Engineer will be expected to perform duties such as: evaluating the performance of current data solutions, designing and implementing cloud and hybrid data solutions. Ability to adapt and learn new technologies per business requirements is also needed.
Responsibilities:
Design and implement data solutions using industry best practices.
Performs ETL, ELT operations and administration of data and systems securely and in accordance with enterprise data governance standards.
Monitor and maintain data pipelines proactively to ensure high service availability.
Works with Data Scientists and ML Engineers to understand mathematical models and optimize data solutions accordingly.
Continuous development through training and mentorship programs.
Create scripts and programs to automate data operations.
You meet our “must haves” for this role if you have:
Minimum Bachelor’s degree in Data Science, Business Intelligence, Computer Science or related fields, or the equivalent combination of education, professional training, and work experience.
0-3 years of experience working with one or more languages commonly used for data operations including SQL, Python, Scala and R.
Experience working with relational databases such as SQL Server, Oracle and MySQL.
Experience working with NoSQL databases such as Redis, Mongo DB, Cosmos DB.
Excellent problem-solving skills and ability to learn through scattered resources.
Thorough understanding of the responsibilities and duties of a data engineer, as well as established industry standards/best practices and documentation guidelines.
Outstanding communication skills, and the ability to stay self-motivated and work with little or no supervision.
Willing to relocate to any US location on Antra projects location.
Authorization(s) to work lawfully in the United States (OPT/CPT is acceptable).
Plus, if you meet any the of requirements:
Experience with cloud-based data technologies.
Experience with distributed systems utilizing tools such as Apache Hadoop, Spark or Kafka.
Working experience in Agile Scrum environments.
Experience with source control tools such as Git, SVN and TFS.
The intent of this position description is to provide a representative summary of the major duties and responsibilities performed by incumbent(s) in this position. Incumbent(s) may not be required to perform all duties in this description and incumbent(s) may be required to perform position-related tasks other than those specifically listed in this description.
Antra Inc. is an equal opportunity employer, providing equal employment opportunities (EEO). All employees and applicants for employment will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity or expression, pregnancy, protected veteran status or other status protected by law. This policy applies to all terms and conditions of employment.
Job Types: Full-time, Contract
Pay: $60,000.00 - $68,000.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Health savings account
Life insurance
Paid time off
Professional development assistance
Referral program
Relocation assistance
Vision insurance
Schedule:
Monday to Friday
Application Question(s):
Are you open for relocation within the US?
Education:
Bachelor's (Preferred)
Work Location: Hybrid remote in Sterling, VA 20166",glassdoor
315,"GenSpark
4.1
Data Engineer
Remote

 Position: Data Engineer
Location: Remote/ Atlanta
** Only US Citizens and GreenCard Holders eligible**
Requirements:
1. 3+ years of working experience on Python on Data side, NymPy, Pandas
2. Should have working experience on SQL
3. Data Engineer mindset
Job Type: Full-time
Salary: $75.00 - $90.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Paid time off
Vision insurance
Schedule:
8 hour shift
Monday to Friday
No weekends
Education:
Bachelor's (Preferred)
Experience:
python: 3 years (Preferred)
Work Location: Remote",glassdoor
316,"Adobe
4.4
Software Development Engineer - Data Science & Analytics
Lehi, UT
$108K - $155K (Glassdoor est.)

 Our Company

Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.

We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!

Our Company
Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands— everything they need to design and deliver exceptional digital experiences. We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.

We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours.
The Opportunity
Adobe is seeking hardworking and passionate Cloud Software Engineer to plan, design, and develop internal analytical tools, dashboards and reporting to help Engineers to Executives make data driven decisions.

We’re on a mission to hire the very best and are committed to building exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!
What You’ll Do
Develop high-performance, reliable, testable and maintainable code.
Participating in all aspects of software development activities, including design, coding, code review, testing, bug fixing, and code/API documentation.
Collaborate with engineers and participate in daily or weekly stand ups and meetings.
Develop reporting dashboards and analytical tools to help Adobe teams manage their AWS & Azure Cloud resources.
Build and automate data sets to answer key business questions using data and data visualizations.
Grow with the support of your team and help others on the team grow by providing thoughtful feedback and uplifting those around you.
Work both independently and collaboratively within a fast-paced development team, with clear, positive, and constructive communication.
What You Need to Succeed
Bachelor's or Master’s in Computer Science, Information Systems, Data Science or equivalent experience required.
Proficient in programming languages such as JavaScript, Python & SQL.
Strong technical background with analytical and problem-solving skills.
Strong proficiency with Business Analytics tools like Power BI & Tableau.
Extensive experience with cloud hosting technology, including Azure and AWS infrastructure.
Experience developing web applications using ReactJS is helpful.
Excellent problem solving and debugging skills, and direct experience with DevOps in a public cloud environment.
Passion for quality and engineering excellence at scale, attention to details, and ability to multitask and meet deadlines.
Excellent communication and collaboration skills.

If you’re looking to make an impact, Adobe’s the place for you. Discover what our employees are saying about their career experiences on the Adobe Life blog and explore the meaningful benefits we offer.
Adobe is an equal opportunity employer. We welcome and encourage diversity in the workplace regardless of race, gender, sexual orientation, gender identity, disability or veteran status.",glassdoor
317,"Vimeo
4.1
Data Engineer II, Analytics
New York, NY
$107K - $150K (Glassdoor est.)

 Vimeo is looking for an experienced Data Engineer II, Analytics to join our Data Architecture and Analytics Engineering team and work closely with Data Analysts and Data Scientists to create and maintain robust, scalable, and sustainable data models that provide decision-making insights for senior leadership including executives. The ideal candidate is a self-starter with a bias for action and results, with experience in a fast-paced, data-driven environment.
What you'll do:
Build data models that can support dynamic and efficient data analysis, and collaborate with other teams to maintain and evolve those models over time
Ensure alignment to coding standard methodologies and development of reusable code
Partner with Data Analysts to understand business processes and identify opportunities to build scalable and efficient data models that can be used for scalable, refreshable analysis and reporting
Create and enable the generation of ad-hoc / on-demand data sets for use by analysts and data scientists
Work with Engineering teams to set up monitoring and alerting systems for business and product KPIs
Skills and knowledge you should possess:
BS/MS in Computer Science or a related technical field.
2+ years working with Analytics and Data Engineering teams with a mixed data engineering and analytics background
2+ years of experience in scalable data architecture, fault-tolerant ETL, and monitoring of data quality in the cloud
Experience working on or leading initiatives around data governance, master data management, data catalogs, and enterprise data warehouse architecture
Strong analytical skills, data sensibility, and an able communicator
Open to working on multiple projects simultaneously
Proficiency in:
SQL
Python
Dimensional Modeling
Data pipeline development, workflow management, and orchestration tools
ETL optimization and best practices
Snowflake or other column-oriented and cloud-based databases
Looker or any similar Business Intelligence tool
Relational Databases
Bonus Points (Nice Skills to Have, but Not Needed):
DBT
Git / Github
Looker/Tableau is a big plus
large data sets (terabyte scale)
Apache Airflow
#LI-JS1
Vimeo (NASDAQ: VMEO) is the world's leading all-in-one video software solution. Our platform enables any professional, team, and organization to unlock the power of video to create, collaborate and communicate. We proudly serve our growing community of over 260 million users — from creatives to entrepreneurs to the world's largest companies.
Vimeo is headquartered in New York City with offices around the world. At Vimeo, we believe our impact is greatest when our workforce of passionate, dedicated people, represents our diverse and global community. We're proud to be an equal opportunity employer where diversity, equity, and inclusion is championed in how we build our products, develop our leaders, and strengthen our culture.
Learn more at www.vimeo.com
Learn more at www.vimeo.com/jobs",glassdoor
318,"Apple
4.2
Machine Learning Data Collection Engineer, Technology Development Group (TDG)
Cupertino, CA

 Summary
Posted: Mar 15, 2022
Role Number:200356922
Do you want to push the limits of the best Augmented Reality platform in the world? Apple's Technology Development Group (TDG) delivers algorithms that drive revolutionary Apple products, including the augmented reality (AR) platform ARKit to create ground-breaking new products. In this position, you will have the opportunity to be part of our extraordinary data team to discover and build solutions to previously-unsolved challenges and push the state of the art in AR algorithms that will change the way people experience the world! We are looking for a driven Machine Learning Data Collection Engineer that enjoys getting into the details to collect valuable data that feeds our machine learning models. As a member of the fast-paced data team, you have the rewarding opportunity to shape upcoming products that will delight and inspire millions of people every day. To succeed within this role, you should have shown experience in several of the following areas:
Key Qualifications
Ability to define/design/develop data collection efforts that focus on the end-to-end user experience, including anticipating potential failure modes, edge cases, and anomalies
Capacity to multitask and manage several projects in parallel while meeting deadlines and providing access to clients and partners
Problem solving & critical thinking capacities, thinking outside the box in order to gain in speed, efficiency, and quality.
Ability to re-construct ill-defined data needs into concrete project deliverables
Ability to maintain and develop relationships with multi-functional teams
Excellent project management, communication, interpersonal, analytical, and organizational skills
Description
As a Machine Learning Data Collection Engineer, you'll be working with our customers to understand their data collection requirements, assisting them in defining their protocols, and executing on the data collection. Your job responsibilities will include: -Collaborate with algorithm teams and understand data collection requirements in order to define collection protocols -Define and design the collection requirements and lead the collection effort from start to finish -Coordinate the efforts between internal teams (Legal, privacy, security, etc) guaranteeing compliance with applicable rules, laws, and best practices -Create documents and procedures needed to run data collections -Managing and track progress of externally run data collections
Education & Experience
Bachelors degree or related practical experience
Additional Requirements",glassdoor
319,"Apple
4.2
Biomedical Data Engineer - Health Technologies
Cupertino, CA

 Summary
Posted: Aug 8, 2022
Weekly Hours: 40
Role Number:200402289
The Health Technologies Team conceives and proves out innovative technology for Apple’s future products and features in health. We are seeking a highly capable Biomedical Data Engineer to join a multi-disciplinary team. Successful candidates will be able to integrate with our research study leads, data scientists and engineers to develop and support effective data analysis and machine learning workflows.
Key Qualifications
Experience with software engineering frameworks
Excellent coding skills in Python (e.g.,Pandas, Spark, Jupyter)
Workflow orchestrations (e.g., Airflow, Luigi)
Designing and maintaining (non-)relational databases (e.g. Postgres, Cassandra, MongoDB) and file systems (e.g. Parquet, CSV, JSON)
Great understanding of infrastructure designs
Linux, MacOS based development frameworks
iOS/ watchOS development (e.g., Swift, Objective-C)
Web Service APIs (e.g., AWS, REDCap, XNAT)
Version control frameworks (Git, virtualenv)
Familiarity with best practices for information security, including safe harbor privacy principles for sensitive data
Experience with biomedical sensors/platforms for measuring physiological signals in the health, wellness and/or fitness realms
Description
- Work closely with team members and study staff to design, build, launch and maintain systems for storing, aggregating and analyzing large amounts of data - Process, troubleshoot, and clean incoming data from human studies - Automate and monitor data ingestion and transformation pipelines, with hooks for QA, auditing, redaction and compliance checks per data management specifications - Create and maintain databases with existing and incoming clinical data - Architect data models and create tools to harmonize disparate data sources - Incorporate and comply with regulations as they pertain to electronic and clinical data and databases
Education & Experience
BS/MS in Computer Science, Engineering, Informatics, or equivalent with relevant 4+ years industry experience with biomedical, health or sensitive data.
Additional Requirements",glassdoor
320,"Apple
4.2
ML Data Collection and Data Science Engineer (TDG)
Cupertino, CA

 Summary
Posted: May 16, 2022
Role Number:200380146
Do you want to push the limits of the best Augmented Reality platform in the world? Apple's Technology Development Group (TDG) delivers algorithms that drive revolutionary Apple products, including the augmented reality (AR) platform ARKit to create ground-breaking new products. In this position, you will have the opportunity to be part of our extraordinary data team to discover and build solutions to previously-unsolved challenges and push the state of the art in AR algorithms that will change the way people experience the world! We are looking for a driven Machine Learning Data Collection Engineer that enjoys getting into the details to collect valuable data that feeds our machine learning models. As a member of the fast-paced data team, you have the rewarding opportunity to shape upcoming products that will delight and inspire millions of people every day. To succeed within this role, you should have shown experience in several of the following areas:
Key Qualifications
Ability to define/design/develop data collection efforts that focus on the end-to-end user experience, including anticipating potential failure modes, edge cases, and anomalies
Proficiency in programming languages including Python, C++, or similar
Capacity to multitask and manage several projects in parallel while meeting deadlines and providing access to clients and partners
Problem solving & critical thinking capacities, thinking outside the box in order to gain in speed, efficiency, and quality.
Excellent project management, communication, interpersonal, analytical, and organizational skills
Experience with industrial software development, a plus
Experience with CVML, a plus
Description
As a Machine Learning Data Collection Engineer, you'll be collaborating with multi-functional teams to work on CVML data collection projects, from collecting data collection requirements, designing protocols, testing software and hardwares, executing data collection, to analyzing and curating collected data. Your job responsibilities will include -Contribute to the design of CVML data collection, including hardware, software, user interface specifications, and collection protocols. -Define, implement, maintain SW and HW solutions to test data collection hardware, software and protocols. -Design, implement and maintain SW platforms to monitor date life cycle -Work with CVML engineers to design and implement data evaluation and curation process -Analyze data and build data analysis tools -Collaborate with multi-functional teams including algorithm, hardware, software, product design, project management, legal, procurement, security, logistics and vendors to define and deliver necessary study elements -Write technical documents including study instructions, operating procedures and training documents for study personnel -Drive process improvements across the organization to continuously improve the way we work
Education & Experience
B.S., M.S., or Ph.D. in Computer Science, Computer Engineering, or equivalent practical experience.
Additional Requirements",glassdoor
321,"Farmers Insurance Group
3.7
Data Engineer (Application SME I)
Remote
Employer Provided Salary:$74K - $98K

 We are Farmers!
We are… more than just your favorite commercials. We are a passionate, award winning, equal opportunity employer, committed to the strength of a diverse workforce. We are dedicated to supporting the well-being of our people through our extensive suite of benefits, as well as the well-being of the communities we serve through employee volunteer programs and nonprofit partnerships. Helping others in their time of need isn’t just our business – it’s our culture! We are Farmers!

Do you thrive in a high-volume, fast-paced environment? Do you enjoy the challenge of a position where no two days are alike? We are looking for positive, high-energy professionals who are not just looking for a job, but a meaningful career!

Job Summary
Use MS SQL SSIS to build ETL process to create new business functionalities as well to solve business problems: Respond to new requests for reports/data understanding business objectives and processes; review and refine technical requirements/User Stories; and communicate estimated hours and timeline to complete; Extract data directly from relational databases (e.g. DB2, SQL Server), data warehouses, or other data stores using SQL; Ability to create manual as well as automated data exports/reports; and Support application unit testing for enhancements or system upgrades; identify and communicate data quality issues or data differences. Work productively on assigned tasks; Collaborate effectively with other team members; Demonstrate accountability to management and business for hours spent on assigned tasks; and diligently strive to deliver value.
Essential Job Functions
Education Requirements
High school diploma or equivalent required.
Bachelor’s degree preferred, in Information Systems or related field.
Experience Requirements
Experience in developing ETL and reporting applications using Microsoft SQL Server (strongly preferred), or Informatica or similar ETL technologies.
Experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process on MS SQL Server or DB2 or similar DB platform.
Experience with Python and unstructured data manipulation is a plus.
Experience with cloud technologies such as AWS Glue, Azure Data Factory, Snowflake is a plus.
Experience working in an Agile Environment is a plus.
Good knowledge of business intelligence best practices, processes, and methodologies.
Good programming experience in writing Stored Procedures, Queries, Views, User Defined Functions, and Common Table Expressions using SQL or T-SQL.
Highly committed, motivated, enthusiastic and a natural team player.
Good interpersonal and communication skills (both verbal and written) and ability to interact with and effectively address concerns.
Good prioritization, time management, analytical, and organization skills.
Experienced in facilitating in-person and remote meetings with business & IT.
Experienced in effective management of multiple competing and frequently changing assignments and priorities.

Benefits
Farmers offers a competitive salary commensurate with experience, qualifications and location
Colorado Only: The pay range for this job being performed in Colorado would be 73,600 - 98,100
Bonus Opportunity (based on Company and Individual Performance)
401(k)
Medical
Dental
Vision
Health Savings and Flexible Spending Accounts
Life Insurance
Paid Time Off
Paid Parental Leave
Tuition Assistance

Job Location(s): R_US - RW - Remote Work",glassdoor
322,"Cigna
3.8
BI Data Engineer-Work from home-eviCore
Hartford, CT
Employer Provided Salary:$96K - $160K

 Duties
Build ETL processes to allow data to flow seamlessly from source to target using tools like Databricks, Azure Data Factory, SSIS, SQL Stored Procedures and Powershell scripting
Load and enhance dimensional data models
Leverage code to apply business rules to ensure data is clean and is interpreted correctly by all business stakeholders, using tools like Databricks, SQL, Scala and Python
Perform code reviews and QA
Participate in sprint ceremonies
Provide on-call support to offshore operations team
Train operations teams on the ETL processes being developed
Troubleshoot and address issues with the data and/or the ETL process
Fine tune existing code to make processes more efficient
Maintain and create documentation to describe our data management processes
Analyze reports using various tools like Micro Strategy, Tableau and SSRS
Support user questions on data management processes and results

Minimum Required Skills
5+ Years building Big Data and Data Warehousing solutions
Knowledge of data modeling (including dimensional modeling), data architecture & data governance concepts
Experience in working with implementations of Azure cloud data solutions (ADLS, Data Bricks, Synapse, ADF)
Proficient in database concepts and technologies including MS SQ Server, DB2 and Oracle
Excellent written and oral communications skills
Must be able to effectively communicate complex technical topics to a variety of audiences
Experience with Healthcare data is a plus

Minimum Education, Licensure and Professional Certification requirement:
Bachelor’s degree with relevant experience required.
Master’s Degree is a plus.

If you will be working at home occasionally or permanently, the internet connection must be obtained through a cable broadband or fiber optic internet service provider with speeds of at least 10Mbps download/5Mbps upload.

For this position, we anticipate offering an annual salary of 95,900 - 159,800 USD / yearly, depending on relevant factors, including experience and geographic location.

This role is also anticipated to be eligible to participate in an annual bonus plan.

We want you to be healthy, balanced, and feel secure. That’s why you’ll enjoy a comprehensive range of benefits, with a focus on supporting your whole health. Starting on day one of your employment, you’ll be offered several health-related benefits including medical, vision, dental, and well-being and behavioral health programs. We also offer 401(k) with company match, company paid life insurance, tuition reimbursement, a minimum of 18 days of paid time off per year and paid holidays. For more details on our employee benefits programs, visit Life at Cigna .

About Cigna
Cigna Corporation exists to improve lives. We are a global health service company dedicated to improving the health, well-being and peace of mind of those we serve. Together, with colleagues around the world, we aspire to transform health services, making them more affordable and accessible to millions. Through our unmatched expertise, bold action, fresh ideas and an unwavering commitment to patient-centered care, we are a force of health services innovation. When you work with us, or one of our subsidiaries, you’ll enjoy meaningful career experiences that enrich people’s lives. What difference will you make?

Qualified applicants will be considered without regard to race, color, age, disability, sex, childbirth (including pregnancy) or related medical conditions including but not limited to lactation, sexual orientation, gender identity or expression, veteran or military status, religion, national origin, ancestry, marital or familial status, genetic information, status with regard to public assistance, citizenship status or any other characteristic protected by applicable equal employment opportunity laws.

If you require reasonable accommodation in completing the online application process, please email: SeeYourself@cigna.com for support. Do not email SeeYourself@cigna.com for an update on your application or to provide your resume as you will not receive a response.

Cigna has a tobacco-free policy and reserves the right not to hire tobacco/nicotine users in states where that is legally permissible. Candidates in such states who use tobacco/nicotine will not be considered for employment unless they enter a qualifying smoking cessation program prior to the start of their employment. These states include: Alabama, Alaska, Arizona, Arkansas, Delaware, Florida, Georgia, Hawaii, Idaho, Iowa, Kansas, Maryland, Massachusetts, Michigan, Nebraska, Ohio, Pennsylvania, Texas, Utah, Vermont, and Washington State.",glassdoor
323,"Faire
4.8
Data Engineer
San Francisco, CA
$117K - $170K (Glassdoor est.)

 About Faire
Faire is an online wholesale marketplace built on the belief that the future is local — there are over 2 million independent retailers in North America and Europe doing more than $2 trillion in revenue. At Faire, we're using the power of tech, data, and machine learning to connect this thriving community of entrepreneurs across the globe. Picture your favorite boutique in town — we help them discover the best products from around the world to sell in their stores. With the right tools and insights, we believe that we can level the playing field so that small businesses everywhere can compete with these big box and e-commerce giants.
By supporting the growth of independent businesses, Faire is driving positive economic impact in local communities, globally. We're looking for smart, resourceful and passionate people to join us as we power the shop local movement. If you believe in community, come join ours.
Job Description
The Data Engineering team is the backbone of all data-related processes and enables the Data Science teams to develop and deploy a wide variety of algorithms and models that power the marketplace. Our infrastructure is used by the whole company for analytics, reporting, forecasting and research. We care about having a reliable & scalable infrastructure with quality data and building machine learning models that help our customers thrive.
As a Data Engineer you'll be responsible for developing and automating large scale, high-performance data storage and processing systems.
What you will be doing:
Develop our data infrastructure to help us scale for where we're going over the next several years
orchestrating pipelines using modern Big Data tools/architectures as well as design and engineering of existing transactional processing systems
Manage our data infrastructure and ETL platform
What it takes:
2+ years experience in a Data Engineering role with an emphasis on managing data warehouses
Strong skills in Python, Git, Docker, SQL, Airflow, real time ETL pipelines
Managing data infrastructure (AWS services, Data orchestrator) and providing framework to rationalize and simplify both real time and batch data pipelines
Familiarity with Snowflake or BigQuery
A passion for programming and solving problems with code
A bachelor's degree in Computer Science/Software Engineering or equivalent industry experience
A love for technology, and an insatiable curiosity for new tools to tackle real problems
Faire's flexible work model aims to meet the needs of our diverse employee community by making work more flexible, connected, and inclusive. Depending on the role and needs of the team, Faire employees have the flexibility to choose how they work–whether that's mainly in the office, remotely, or a mix of both.
Roles that list only a country in the location are eligible for fully remote work in that country or in- office work at a Faire office in that country, provided employees are located in the registered country/province/state. Roles with only a city location are eligible for in-office or hybrid office work in that city. Our talent team will work with candidates to determine what locations and roles are eligible for each option.
Why you'll love working at Faire
We are entrepreneurs: Faire is being built for entrepreneurs, by entrepreneurs. We believe entrepreneurship is a calling and our mission is to empower entrepreneurs to chase their dreams. Every member of our team is an owner of the business and taking part in the founding process.
We are using technology and data to level the playing field: We are leveraging the power of product innovation and machine learning to connect brands and boutiques from all over the world, building a growing community of more than 350,000 small business owners.
We build products our customers love: Everything we do is ultimately in the service of helping our customers grow their business because our goal is to grow the pie - not steal a piece from it. Running a small business is hard work, but using Faire makes it easy.
We are curious and resourceful: Inquisitive by default, we explore every possibility, test every assumption, and develop creative solutions to the challenges at hand. We lead with curiosity and data in our decision making, and reason from a first principles mentality.
Faire was founded in 2017 by a team of early product and engineering leads from Square. We're backed by some of the top investors in retail and tech including: Y Combinator, Lightspeed Venture Partners, Forerunner Ventures, Khosla Ventures, Sequoia Capital, Founders Fund, and DST Global. We have headquarters in San Francisco and Kitchener-Waterloo, and a global employee presence across offices in Salt Lake City, Atlanta, Toronto, London, New York, LA, and Sao Paulo. To learn more about Faire and our customers, you can read more on our blog.
Faire provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity or gender expression.
Faire is committed to providing access, equal opportunity and reasonable accommodation for individuals with disabilities in employment, its services, programs, and activities. To request reasonable accommodation, please fill out our Accommodation Request Form.",glassdoor
324,"Mint Mobile
3.6
Digital Data Engineer I - Remote
Costa Mesa, CA
Employer Provided Salary:$90K - $103K

 MINT MOBILE is seeking a talented Digital Data Engineer I to join the Data Management Team! Individual reports to Customer Data Manager. Role is remote; must reside in the United States.
ABOUT THE ROLE
Provide direct data engineering development to data pipelines for ETL establishment and enhancements to and from data warehouses to customer management platform (Braze). Work collaboratively with cross-functional teams to determine digital data needs, establish data collection requirements, and deploy & maintain accurate data to ensure metrics & dimensions are addressed for analytics/reporting requirements.
Your usual day of awesomeness includes:
Transform required data conditions into performance code logic.
Develop high-performance code in SQL and Python.
Develop, automate, and enhance ELT processes for continuous data flow.
Create, modify, and deploy code to production via AWS resources including Lambda, S3, Glue, Redshift, etc.
Partner with stakeholders to support the implementation and development of data requirements.
Troubleshoot data anomalies and provide applicable solutions.
Build, test and maintain database pipeline architectures.
WHAT YOU BRING
Advanced level in SQL and Python for data engineering and backend development.
Understanding of popular code development approaches:
Test-driven development
Continuous Integration/Continuous Deployment (CI/CD)
Experienced working with AWS services (Lambda, S3, Glue, Redshift etc.) and Cloud Data Warehouse.
Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
Define digital data collection methods and implementations to DWH and customer management platforms.
Experienced with QA testing process to verify data is collected & rendered as expected.
Ability to excel in a fast-paced, cross-functional environment.
Ability to work autonomously.
Excellent written and verbal communication skills.
Proactive problem-solving and critical thinking skills.
Ability to manage time effectively and consistently meet deadlines.
NICE TO HAVE
Prior working knowledge of Braze or other Customer Management Platforms
Snowflake Cloud Data Warehouse
Terraform/Bitbucket/Airflow/Jenkins
Looker, Tableau, Power BI
WE ARE MINT MOBILE
We connect people to what's most important in their lives: Easily, affordably and reliably. We strive to be California's Preeminent Destination Employer. Oh yeah, we get it too! We understand what matters to you most. You're an individual with unique needs, and we're prepared to exceed any expectations you have for an ideal employer.
We're smart, strategic, and get things done without a lot of red tape or unnecessary politics. Everyone matters here and everyone has a voice. Expect to spend your time contributing to projects that really matter. We obsess over the employee experience. To start, we provide some of the most competitive salary, benefits, family leave, vacation, retirement and equity options in Southern California. We believe in you and invest in you. Not just your career aspirations, but your life.
In addition, we've got a laundry list of perks you'll brag about on insta - Lunch every day prepared by our very own chef, healthy snacks, onsite gym, free massages, car wash services, and most importantly, a team atmosphere. We even raise the bar on well bars, including Espresso/Cappuccino/Nitro/Cold Brew/Kombucha Bar, Froyo Bar, Breakfast Bar, Snack Bar and a, well, you know, bar (after 5 pm).
And if you feel intrigued right now reading, imagine the co-workers we have already attracted. This is the kind of team you'll want to take home to mom or invite to your kid's next birthday party. This is the kind of close-knit community happening here. Come check out how you can be part of Mint!
OUR VALUES – LET'S MAKE LIFE ULTRA TOGETHER!
Ownership: We are all owners; be the outcome and get the job done.
Action Biased: Be brilliant, proactive, and act with urgency.
Embrace the Adventure: Be agile, adaptive, and thrive on change.
Invent and Simplify: Never accept good enough.
$1,000 REFERRAL BONUS
Take a look at this job description, if you are the right person, please apply. If Mint Mobile doesn't appear to be a fit for you, refer a friend or colleague and get $1,000. Let your friend or colleague know to provide your full name and email when applying to the job. If we hire them and they stay for 90 days, you get $1000. For more details of restrictions and rules, please email recruiting@ultra.me.

Covid-19 Vaccination Requirement
UVNV, Inc. has adopted a mandated vaccination policy to support the health and safety of our team members and our community. The Company requires all employees to be fully vaccinated. The Company will provide accommodations based on medical condition or sincerely held religious beliefs or practices. Please let us know if you'd like to discuss the policy or available accommodations before proceeding with our recruitment process.
We are committed to equal employment opportunities regardless of race, color, genetic information, creed, religion, sex, sexual orientation, gender identity, lawful alien status, national origin, age, marital status, or protected veteran status. We support an inclusive workplace where associates excel based on personal merit, qualification, experience, ability, and job performance.
In support of the Equal Pay for Equal Work Act, the range of starting pay for this role is $90,000 - $103,000. This is not a guarantee of compensation or salary, actual compensation is influenced by a wide range of factors including but not limited to skill set, level of experience, education, certifications, responsibility, and geographic location. We also offer a variety of benefits including health, disability insurance, 401 (k), flexible spending accounts, EAP, education reimbursement, parental leave, unlimited vacation, bonuses, incentive stock options and company paid holidays. The specific programs and options available will vary depending on state, start date, and employment type. Our recruitment team will be happy to answer any questions you may have.
#LI-Remote",glassdoor
325,"Expression Networks
4.4
Data Engineer
Remote

 Founded in 1997 and headquartered in Washington DC, Expression Networks provides data fusion, data analytics, software engineering, information technology, and electromagnetic spectrum management solutions to the U.S. Department of Defense, Department of State, and national security community. Expression's “Perpetual Innovation” culture focuses on creating immediate and sustainable value for our clients via agile delivery of tailored solutions built through constant engagement with our clients. Expression Networks was ranked #1 on the Washington Technology 2018's Fast 50 list of fastest-growing small business Government contractors and a Top 20 Big Data Solutions Provider by CIO Review.

We make sure to provide everyone the tools and opportunities to grow while working on some of the newest technologies in the industry. With Covid-19 being a major theme the last two years having a growing collaborative culture has been one of the key focus of our C-suite and upper management. We get excited about celebrating our professionals' milestones, accomplishments, promotions, overcoming challenges, and many other aspects that make an engaging collaborative environment.

We are looking to bring on a mid-level Data Engineer to add to the continued growth of our Data Science division. This position will work in a team led by a principal data engineer on tasks related to designing and delivering high-impact data architecture and engineering solutions to our customers across a breadth of domains and use cases.
Location:
Remote, with the ability to travel per project requirements.
Security Clearance:
Ability to obtain Secret Clearance or Higher
Responsibilities:
Developing, testing, and documenting software code for data extraction, ingestion, transformation, cleaning, correlation, and analytics
Participating in end-to-end architectural design and development lifecycle for new data services/products, and making them operate at scale
Participating in cross-functional team collaboration to understand customer requirements, design prototypes, and optimize existing data services/products
Demonstrating Data Science excellence in the teams you work with across the organization, and mentoring junior members in the Data Science division
Participating in research, case studies, and prototypes on cutting-edge technologies and how they can be leveraged
Required Qualifications:
3+ years of experience bringing databases, data integration, and data analytics/ML technologies to production with a Bachelor's degree in Computer Science/Data Science/Computer Engineering or relevant field
Mastery in developing software code in one or more programming languages (Python, JavaScript, Java, Matlab, etc.)
Expert knowledge in databases (SQL, NoSQL, Graph, etc.) and data architecture (Data Lake, Delta Lake)
Knowledgeable in machine learning/AI methodologies
Experience with one or more SQL-on-Hadoop technology (Hive, Impala, Spark SQL, Presto, etc.)
Preferred Qualifications:
Experience in short release cycles and the full software lifecycle
Experience with Agile development methodology (e.g., Scrum)
Strong writing and oral communication skills to deliver design documents, technical reports, and presentations to a variety of audiences
Benefits:
Expression Networks offers competitive salaries and benefits, such as:
401k matching
PPO and HDHP medical/dental/vision insurance
Education reimbursement up to $10,000/yr.
Complimentary life insurance
Generous roll over PTO and 11 days of holiday leave
Onsite gym facility and trainer
Commuter Benefits Plan
In office Cold Brew Coffee
Equal Opportunity Employer/Veterans/Disabled",glassdoor
326,"Apple
4.2
Keystone Big Data Software Engineer, Global Business Intelligence
Cupertino, CA

 Summary
Posted: Jul 18, 2022
Role Number:200399924
Imagine what you could do here! At Apple, great minds come together to build products, services, and solutions that amaze the world. Imagine how your contributions could transform the world and there is no limit to what you could accomplish here. Apple's Global Business Intelligence (GBI) team is seeking an experienced Software Engineer to build high quality, scalable and resilient distributed systems that power Apple's analytics platforms and data pipelines. Apple's Enterprise Data Warehouse landscape caters to a wide variety of real-time, near real-time and batch analytical solutions. These solutions are an integral part of business functions like Sales, Operations, Finance, AppleCare, Marketing, and Internet Services, enabling business drivers to make critical decisions. If you enjoy learning new technologies, and are comfortable proposing and implementing solutions, demonstrating Software Engineering standard methodologies, you will find it rewarding to work in GBI! The ideal candidate for this position will be able to think outside of the box and should have passion for building engineering solutions to enable business in making time sensitive and critical decisions.
Key Qualifications
Strong fundamentals in data structures, algorithms, and software system design
Strong hands-on programming skills (Scala / Java / Python preferred)
Proficiency in developing applications in Spark & deep understanding of Spark is essential for this role
Proven track record of building jobs processing high-volume data using Spark
Experience with real time data processing with Spark Streaming, Flink is a huge plus
Committed to test driven development paradigm
Strong analytical and interpersonal skills and demonstrated ability to code & collaborate
Self-starter, highly motivated and ability to research, learn, prototype quickly
Sound experience in Cloud technologies such as AWS or GCP
Experience on Cloud with databases like SnowFlake and Singlestore is a plus
Prior experience in the areas of AI/ML/Data Sciences will be a strong plus
Curiosity to explore and understand data is a plus
Description
The Frameworks team in GBI build and support critical infrastructural systems which provide services for numerous organizations within Apple and we are looking for a strong, enthusiastic developer to join as a member of this group. You are someone with ideas and real passion for software delivered as a service to improve reuse, efficiency, and simplicity. This engineer’s work will affect multiple data teams within Apple and enable our partners to derive insights and help execute their goals.
Education & Experience
BS/MS in Computer Science, Computer Engineering or similar field
Additional Requirements
Apple is an Equal Opportunity Employer that is committed to inclusion and diversity. We also take affirmative action to offer employment and advancement opportunities to all applicants, including minorities, women, protected veterans, and individuals with disabilities. Apple will not discriminate or retaliate against applicants who inquire about, disclose, or discuss their compensation or that of other applicants.
We at Apple we are committed to working with and providing reasonable accommodation to applicants with physical and mental disabilities. Learn more.",glassdoor
327,"Milo's Tea Company
4.1
Data Engineer
Remote

 Overview: Milo’s Tea Company is one of the fastest growing beverage companies in the US. Our culture and operations are built on the belief that we can make a difference in the world. That’s why we put People First and strive to continually reduce our environmental impact on the planet. We leverage our world class operations and decades-long distribution partnerships to grow the footprint of our core products and create new, innovative beverage products.
We are the #1 and fastest growing brand in the Refrigerated Tea Category in the nation.
Our core mission is that we put people and the planet first and by doing this, it will be good for our business.
We are committed to unlocking the personal genius of every associate and have a strong focus on growth and learning.
Our Company is women-led (our Executive Team is 57% female) and strongly committed to Diversity, Inclusion and Belonging.
We are committed to annual charitable giving by delivering upon our 1% profit pledge.
We are Platinum Certified in Zero Waste Manufacturing; recycling, reducing, and reusing 95% of waste at all facilities.
Being a part of the Milo’s TEAm, you’ll get to collaborate with a group of passionate and high-performing people, where everyone feels empowered to do their best work and feels good about the work they’re doing.
And as a ""People First"" company, Milo’s is committed to the success and well-being of our associates, customers, and fans, no matter their gender, race or creed. Some of the benefits offered that reflect our commitment include:
Competitive salary with bonus opportunities
100% paid medical insurance for our associates and their families
401K with a company match
Partial tuition reimbursement assistance
A robust parental leave program
Paid time off to volunteer at the charity of your choice
Employee assistance program
Responsibilities: The Data Engineer is responsible for assisting with data management, modeling, development, transformation, and reporting activities.
*
Responsibilities: *
Identify business needs, determine possible solutions, and develop solutions that include systems components, and process improvements with data driven decision making.
Work with business groups to design and develop reporting and analytics solutions that will improve efficiency and effectiveness.
Designs, implements, tests, troubleshoots, documents, and supports data models, programs, scripts, and ETL (Extract, Transform, and Load) processes.
Develop, maintain, and curate large datasets from multiple platforms. Develop reporting capabilities to support business needs by creating and supporting SQL queries, data extraction packages, and interfaces. Explores ways to enhance data quality and reliability.
Perform data validation between analytical and source systems to support ongoing data management capabilities and data governance. Perform data testing to ensure the accuracy of data transformation.
Develop data analytics, reports, and dashboards using Power BI and other business intelligence tools.
Uphold and participate in all Corporate Responsibility programming including recycling, social advocacy and MMAD volunteering opportunities.
Invest in and is an example of Milo’s Responsibility commitment which includes environmental, social, and corporate governance components.
Other duties as assigned
Supervisory: This role does not have supervisory responsibilities.
Qualifications:
BA in computer science, information systems, statistics, applied math, or any other related field.
Up to 3 years of experience in information systems or related field.
Strong experience with SQL server solutions (queries, functions, stored procedures, views, etc.).
Cloud based computing and data solutions.
Proficient with Excel and Business Intelligence tools (Power BI, Power Query, Tableau, etc.).
Understanding of relational databases and data warehouses. Hands-on experience with SQL database design.
Experience with Microsoft SQL stack (SSIS, SSRS, SSAS, etc); Experience with cloud-based data technologies, Azure preferred.
Experience working in a SharePoint environment; Experience with Python, R or other programming languages.
Experience in non-traditional SQL (noSQL, etc.) solutions.
Experience with machine learning and predictive analytics.
Experience with other ETL tools such as Alteryx.
Job Type: Full-time",glassdoor
328,"Dataquestcorp
Data Science Engineer
Branchburg, NJ
Employer Provided Salary:$75K - $80K

 Job Role: Data Science
Note: Please don't apply C2C profiles. its only w2 positions
Benefits:
Free Training and placement.
Training provided by highly qualified, industry-experienced & certified instructors.
We do provide free accommodations & Relocation charges.
H1B Sponsorship
We do support for STEM OPT and GC processing.
Health Insurance
Relocation Assistance any where in USA.
Free accommodation.
Location: Branchburg, NJ
Job Types: Full-time, Contract
Job Types: Full-time, Contract
Salary: $75,000.00 - $80,000.00 per year
Benefits:
Health insurance
Schedule:
8 hour shift
Ability to commute/relocate:
Branchburg, NJ: Reliably commute or planning to relocate before starting work (Required)
Experience:
Python: 1 year (Preferred)
SQL: 1 year (Preferred)
Work Location: One location
Speak with the employer
+91 9089927715",glassdoor
329,"Pinterest
4.1
Data Engineer
Remote

 About Pinterest:
Millions of people across the world come to Pinterest to find new ideas every day. It's where they get inspiration, dream about new possibilities and plan for what matters most. Our mission is to help those people find their inspiration and create a life they love. In your role, you'll be challenged to take on work that upholds this mission and pushes Pinterest forward. You'll grow as a person and leader in your field, all the while helping Pinners make their lives better in the positive corner of the internet.
Our new progressive work model is called PinFlex, a term that's uniquely Pinterest to describe our flexible approach to living and working. Visit our PinFlex landing page to learn more.
The Enterprise Data Platform team is looking for a Data Engineer who has experience with Building Data Pipelines and Managing/Developing on any Cloud Data Warehouse. In this role you will also advise other Data Analysts and Data Engineers from the Business teams at Pinterest on the best practices for handling data and deriving insights using Snowflake. You will gradually become the Subject Matter Expert on Snowflake and also help build out the Modern Data Stack at Pinterest.
What you'll do:
Build Data Pipelines using Python on either Airflow or AWS Lambda to ingest data into Snowflake
Build Scripts in Python to manage Data Access on Snowflake
Define and advocate the best practices for storing and analyzing data inside Snowflake
Review the Data Modeling practices of other teams
What we're looking for:
Strong skills in Python and SQL
Experience with Building Data Pipelines in Python
Experience with any Cloud Data Warehouse either as an Administrator or a Developer
Strong Data Modeling skills
#LI-BB1
#LI-Remote
Our Commitment to Diversity:
At Pinterest, our mission is to bring everyone the inspiration to create a life they love—and that includes our employees. We’re taking on the most exciting challenges of our working lives, and we succeed with a team that represents an inclusive and diverse set of identities and backgrounds.

Not Specified
0",glassdoor
330,"Netflix
4.3
Data Engineer (L5) - Games
Los Gatos, CA
$108K - $193K (Glassdoor est.)

 Los Gatos, California
Data Science and Engineering
Now is an amazing time to join Netflix as we seek to entertain the world. We have over 200 million paid members in over 190 countries, and we won’t stop there. Games are our next big frontier and an incredible opportunity for us to deliver new experiences to delight and entertain our quickly growing membership. You will be jumping in at the very beginning of this adventure and be in a position to help us redefine what a Netflix subscription means for our members around the world.
Data Science and Engineering (‘DSE’) at Netflix is aimed at using data, analytics, and sciences to improve various aspects of our business. We are looking for a Data Engineer to join our Games DSE team, supporting end-to-end analytics & data needs for our games portfolio. This role will be partnering closely with our Game stakeholders to develop software and data solutions that enable analysis across the entire library of games.
As part of this team, you will work on diverse data technologies such as Spark, Presto, Flink, Kafka, and others to build insightful, scalable, and robust data pipelines that feed directly into our key gaming dashboards; write ETL jobs to collect and aggregate data; and build high-quality data models that represent how games are performing on Netflix.
The ideal candidate will also have a background in games, with a solid knowledge of how standard industry metrics are computed.
Who You Are:
7+ years of software/data engineering experience working with video game analytics (i.e you are familiar with how key metrics such as DAU, MAU and retention rates are computed in an ETL).
Passionate about building intuitive data models and an expert in distributed data processing patterns.
Highly proficient in at least one of these programming languages: Java, Python, or Scala.
Comfortable with complex SQL.
Expert in engineering data pipelines using big data technologies (Hive, Presto, Spark, Flink) on large-scale data sets demonstrated through years of experience.
Conceptually familiar with AWS cloud resources (S3, EC2, RDS etc).
Excel at taking vague requirements and crystallizing them into scalable data solutions.
Excited about operating independently, demonstrating excellence, and learning new technologies and frameworks.
What will you do?
Engineer efficient, adaptable, and scalable data pipelines in Spark and Python/Scala to process structured data into aggregate datasets that feed all games portfolio dashboards.
Become an expert in games metrics at Netflix - act as a thought partner to the games analytics team, understand their challenges, and help them to put the right data in front of our stakeholders.
Maintain and rethink existing datasets and pipelines to service a wider variety of use cases.
Join a stunning team of data engineers with diverse skill sets, partnering closely with analytics engineering and data science counterparts.
Netflix Culture
Our culture is unique, and we live by our values. For more information on what it's like to work at Netflix, please take a look at our culture memo.",glassdoor
331,"Luxoft
4.3
Data Engineer
Remote

 Project Description
Luxoft has contract with a major Telecommunications provider to engage with DIRECTV organization to establish integrated cloud technology platforms to ingest information from various Network Engineering support applications in order to better optimize management and planning for the future network.

To do this DIRECTV is managing data ingestion into a Snowflake Azure based deployment which allows for one cohesive platform to serve all types of users and workloads in a consistent way. Centralizing data in a unified, governed, managed data platform allows all authorized users to access accurate and timely data for analysis that is useful for highly transnational datasets. It is also useful that it can store structured and unstructured data. Additionally DIRECTV is leveraging a Palantir Deep™ instance platform for the creation and management of cost forecasting scenarios.
Responsibilities
- Analysis on Data Libraries - evaluation of data sets and current data architecture for source data pipelines. This will allow us to scope the depth/breadth of data

- Data Quality Metrics - Audits analysis and setup to determine the appropriate data quality measures. This will be used to validate with clients/users in a later phase.

- DQF research - Analyze the current Data Quality Framework to leverage as possible/needed. Assess the need for extension and/or replacement of the current DQF.

- Architecture patterns research - Analysis of data translation and business rules associated.

- Current ingestion patterns - Study and enhancement research to evaluate data pipeline for current state and opportunity to optimize for increased data quality and rigor.
Skills
Must have
Cloud, Data Engineering, SnowFlake, Big Data
Nice to have
Microsoft Azure Cloud Platform
Languages
English: C2 Proficient
Seniority
Senior
Relocation package
If needed, we can help you with relocation process.
Vacancy Specialization
BigData Development
Ref Number
VR-81593",glassdoor
332,"NucleusTeq
4.9
Data Engineer
Remote

 Data Engineer
Role Info:
Hands on BI Data Engineer role with strong
Creating KPI Dashboards - Interactive Dashboards using tableau / Quicksight
Top Skills:
BI Tableau / AWS Quicksight exp is a must
AWS (IAM, RDS, S3, Lambda) exp is a must
SQL exp is a must
Python knowledge is required
Nice to have:
AWS Certified Solutions Architect
About the Company:
NucleusTeq is a software services, solutions & products company empowering & transforming customer's business through the use of digital technologies such as Big-Data, Analytics, Cloud, Enterprise Automation, Block-chain, Mobility, etc.
We are enabling several fortune 1000 clients in the USA, Canada, UK & India to navigate their digital transformation.",glassdoor
333,"Twitch
4.0
Data Engineer
San Francisco, CA
Employer Provided Salary:$140K - $171K

 About Us
Twitch is the world's biggest live streaming service, with global communities built around gaming, entertainment, music, sports, cooking, and more. It's where millions of people come together to chat, interact, and make their own entertainment.
We're about community, inside and out. You'll find coworkers who are eager to team up, collaborate, and smash (or elegantly solve) problems together. We're on a quest to empower live communities, so if this sounds good to you, see what we're up to on LinkedIn and Twitter, get interviewing tips on Instagram, and discover projects we're solving on our Blog.
About the Role
Reporting to the Head of Global Talent Acquisition, the Data Engineer will expand the reach and role of data among leaders and managers at Twitch. You will empower the business to integrate data into their daily workflow by creating/maintaining data pipelines, producing reporting, and automating our processes.
You can work in San Francisco, CA or remotely across the US.
This role is for you if:
You love automating processes and developing efficient scalable solutions
You're excited about contributing to the success, efficiency, and happiness of Twitch staff
You're excited to jump into a diverse array of data work to support the team
You enjoy working with autonomy and shaping a new function

You Will:
Delight consumers of people-related data by ensuring they have the data they need to inform decisions, where and when they need it
Build and own data pipelines, SQL queries/views, and apps
Automate processes through the use of JavaScript and other languages
Improve business, engineering, and data processes through data architecture, engineering, testing, and operational excellence best practices
Ensure the integrity of People and Places data in analyses and tools through regular audits
Partner to develop analytics products and recommend opportunities
Develop ongoing metrics, analyses, and dashboards to guide important decisions
You Have:
Experience writing SQL and a procedural language (Python, R, etc.) for data handling
Experience owning systems that collect, transform, and visualize data
Experience implementing data analytics, visualization tools and programs for HR working with Workday, Greenhouse, Tableau, Google Workspace, Google Data Studio, and Google Sheets
Experience implementing software solutions to automate data source, visualization and analytics products
Bachelors in related field, or equivalent experience
Bonus Points
Experience handling People-related data including compensation, performance, hiring, and engagement data.
Experience automating Google services (Sheets, Docs, Data Studio) with Javascript
Experience with Workday, Greenhouse, and Tableau
Demonstrated net positive contributor to company community and culture above and beyond the core job
Perks
Medical, Dental, Vision & Disability Insurance
401(k), Maternity & Parental Leave
Flexible PTO
Commuter Benefits
Amazon Employee Discount
Monthly Contribution & Discounts for Wellness Related Activities & Programs (e.g., gym memberships, off-site massages, etc.),
Breakfast, Lunch & Dinner Served Daily
Free Snacks & Beverages
We are an equal opportunity employer and value diversity at Twitch. We do not discriminate on the basis of race, religion, color, national origin, gender, gender identity, sexual orientation, age, marital status, veteran status, or disability status, or other legally protected status.
Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
Pursuant to the Los Angeles Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
The base pay range for this position in Colorado, Connecticut and Washington is $139,860 - $170,940 yr and in New York City is $153,900 - $188,100 yr. Pay is based on market location and may vary depending on job-related knowledge, skills, and experience. A sign-on payment and restricted stock units may be provided as part of the compensation package, in addition to a full range of medical, financial, and/or other benefits, dependent on the position offered. Applicants should apply via Twitch's internal or external careers site.
Workers in New York City who perform in-person work or interact with the public in the course of business must show proof they have been fully vaccinated against COVID or request and receive approval for a reasonable accommodation, including medical or religious accommodation.
Twitch values your privacy. Please consult our Candidate Privacy Notice, for information about how we collect, use, and disclose personal information of our candidates.
Job ID: TW7236
#LI-Remote #RemoteFriendly",glassdoor
334,"Teknic
Data Engineer
Remote

 Role: Data Engineer
Location: Remote
JOb Description:
Skills and Experience :
Good experience on designing and developing data pipelines for data ingestion and transformation using Spark.
Distributed computing experience using Pyspark.
Good understanding of spark framework and spark architecture.
Experience working in Cloud based big data infrastructure.
Excellent in trouble shooting the performance and data skew issues.
Must have a good understanding of spark run time metrics and tune applications based on metrics.
Deep knowledge in partitioning, bucketing concepts of data ingestion.
Good understanding of AWS services like Glue, Athena, S3, Lambda, Cloud formation.
Preferred working knowledge on the implementation of datalake ETL using AWS glue, Databricks etc.
Experience with data modelling techniques for cloud data stores and on prem databases like Teradata, Teradata Vantage (TDV) etc.
Preferred working experience in ETL development in Teradata vantage and data migration from on prem to Teradata vantage.
Proficiency in SQL, relational and non-relational databases, query optimization and data modelling.
Experience with source code control systems like Gitlab.
Experience with large scale distributed relational and NoSQL database systems.
Job Type: Contract
Schedule:
8 hour shift
Experience:
Data engineer: 10 years (Preferred)
Spark.: 3 years (Preferred)
Cloud based big data infrastructure.: 1 year (Preferred)
datalake ETL: 1 year (Preferred)
AWS Glue: 1 year (Preferred)
Work Location: Remote",glassdoor
335,"Realign LLC
4.5
Data Engineer
California

 Job Type: Contract
Job Category: IT
Job Description
Write and optimize queries, provide input on peer code reviews and data modeling, deploy data
updates via continuous integration / deployment (CI/CD) practices.

Collaborate with software developers, other data engineers, and database architects on projects to
ensure optimal data delivery following appropriate change management guidelines.

Collaborate with software and reliability engineers to automate repeatable data tasks.

Work with development and production support teams to troubleshoot data, application, and service
deployment issues.

Develop detailed, shared technical procedure documentation, including processes for contingency
operations.

Research, provide technical input, document, and implement new technology solutions.

Implement necessary patches, hotfixes, service packs, cumulative updates, upgrades, and
configuration change to maintain security compliance and application integrity.

Required Skills
Big Data Engineer",glassdoor
336,"Pepsico
3.9
Junior Data Engineer
Remote
Employer Provided Salary:$90K - $100K

 Compensation: $80k - $90k
Benefits: Medical, Dental, Vision, 401k match and Arc
This role can be performed remote in any of our headquarter locations including Plano, Texas; Purchase, New York; Chicago, Illinois.
What PepsiCo Data Management and Operations does:
Maintain a predictable, transparent, global operating rhythm that ensures always-on access to high-quality data for stakeholders across the company
Responsible for day-to-day data collection, transportation, maintenance/curation and access to the PepsiCo corporate data asset
Work cross-functionally across the enterprise to centralize data and standardize it for use by business, data science or other stakeholders
Increase awareness about available data and democratize access to it across the company.
As a member of the data engineering team, you will be the key technical expert developing and overseeing PepsiCo's data product build & operations and drive a strong vision for how data engineering can proactively create a positive impact on the business. You'll be an empowered member of a team of data engineers who build data pipelines into various source systems, rest data on the PepsiCo Data Lake, and enable exploration and access for analytics, visualization, machine learning, and product development efforts across the company. As a member of the data engineering team, you will help lead the development of very large and complex data applications into public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. You will work closely with process owners, product owners and business users. You'll be working in a hybrid environment with in-house, on-premise data sources as well as cloud and remote systems.
Key Accountabilities:
Active contributor to code development in projects and services
Manage and scale data pipelines from internal and external data sources to support new product launches and drive data quality across data products
Build and own the automation and monitoring frameworks that capture metrics and operational KPIs for data pipeline quality and performance
Responsible for implementing best practices around systems integration, security, performance and data management
Empower the business by creating value through the increased adoption of data, data science and business intelligence landscape
Collaborate with internal clients (data science and product teams) to drive solutioning and POC discussions.
Develop and optimize procedures to “productionalize” data science models
Define and manage SLA’s for data products and processes running in production
Support large-scale experimentation done by data scientists
Prototype new approaches and build solutions at scale
Research in state-of-the-art methodologies
Create documentation for learnings and knowledge transfer
Create and audit reusable packages or libraries
COVID-19 vaccination is a condition of employment for this role. Please note that all such company vaccine requirements provide the opportunity to request an approved accommodation or exemption under applicable law
Qualifications / Requirements :
BA/BS in Computer Science, Math, Physics is mandatory.
2+ years of overall technology experience that includes hands-on building data engineering pipelines
2+ years of experience in SQL optimization and performance tuning, and development experience in programming languages like Python, PySpark, Scala etc.)
1+ years in cloud data engineering experience in Azure or AWS
1+ Years in building data engineering pipelines in Azure (ADF and databricks)
Job Type: Full-time
Pay: $90,000.00 - $100,000.00 per year
Benefits:
401(k) matching
Dental insurance
Health insurance
Retirement plan
Vision insurance
Schedule:
8 hour shift
Education:
Bachelor's (Required)
Experience:
SQL: 2 years (Required)
Cloud: 2 years (Required)
Work Location: Remote",glassdoor
337,"Blue Cross and Blue Shield of North Carolina
4.1
Data Engineer
Remote

 Additional Locations:
Full Time Remote - Alabama, Full Time Remote - Alabama, Full Time Remote - Arizona, Full Time Remote - Arkansas, Full Time Remote - Florida, Full Time Remote - Georgia, Full Time Remote - Idaho, Full Time Remote - Indiana, Full Time Remote - Iowa, Full Time Remote - Kansas, Full Time Remote - Kentucky, Full Time Remote - Louisiana, Full Time Remote - Maryland, Full Time Remote - Michigan, Full Time Remote - Mississippi, Full Time Remote - Missouri, Full Time Remote - Ohio, Full Time Remote - Oklahoma, Full Time Remote - Pennsylvania, Full Time Remote - South Carolina, Full Time Remote - South Dakota, Full Time Remote - Tennessee, Full Time Remote - Texas, Full Time Remote - Utah, Full Time Remote - Virginia {+ 1 more}
Job Description
IT is different here. Our work as technology specialists pushes the boundaries of what’s possible in health care. You will build solutions that make a real difference in people’s lives. Driven by the importance of their work, our team members innovate to elevate. We’re encouraged to be curious, collaborate, and turn ideas into solutions that transform this space.

In this role you will work closely with senior engineers, data scientists and other stakeholders to design and maintain moderate to advanced data models. The Data Engineer is responsible for developing and supporting advanced reports that provide accurate and timely data for internal and external clients. The Data Engineer will design and grow a data infrastructure that powers our ability to make timely and data-driven decisions. You will support Membership Operations, Customer Service Operations, Digital & Consumer Experience teams.

If you are ready to make a career out of making a difference, then you are the person for this team.
What You’ll Do
Define and extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes
Document, and test moderate data systems that bring together data from disparate sources, making it available to data scientists, and other users using scripting and/or programming languages
Write and refine code to ensure performance and reliability of data extraction and processing
Participate in requirements gathering sessions with business and technical staff to distill technical requirement from business requests
Develop SQL queries to extract data for analysis and model construction
Own delivery of moderately sized data engineering projects
Design and develop scalable, efficient data pipeline processes to handle data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets to analysts and data scientists
Ensure performance and reliability of data processes
Document and test data processes including performance of through data validation and verification
Collaborate with cross functional team to resolve data quality and operational issues and ensure timely delivery of products
Develop and implement scripts for database and data process maintenance, monitoring, and performance tuning
Analyze and evaluate databases in order to identify and recommend improvements and optimization
Design eye-catching visualizations to convey information to users
What You Will Bring
Bachelor’s degree and 3 years of experience with Oracle, Data Warehouses and Data Lakes, Big Data platforms and programming in Python, R or other related language.
In lieu of degree, 5 years of the experience as stated above.
SQL and Python scripting
Experience in a cloud environment
Experience with Ab Initio or other ETL tools",glassdoor
338,"Qualtrics
4.2
Data Engineer
Provo, UT
$83K - $125K (Glassdoor est.)

 The Qualtrics XM Platform™ is a system of action that helps businesses to attract customers who stay longer and buy more, to engage and empower employees to do the best work of their lives, to develop breakthrough products people love, and to build a brand people can’t imagine living without.

Joining Qualtrics means becoming part of a team bold enough to chase breakthrough experiences - like building a technology that will be a force for good. A team committed to diversity, equity, and inclusion because of a conviction that every voice holds value, with a vision for representation that matches the world around us and inclusion that far exceeds it. You could belong to a team whose values center on transparency, being all in, having customer obsession, acting as one team, and operating with scrappiness. All so you can do the best work of your career.

We believe every interaction is an opportunity. Are we yours?
The Team
Our team is a collection of deeply passionate engineers who are riding the groundbreaking of cloud computing and web scalability. We built data analytics applications that help company leaders gain insights about technology spends, make sound decision on technology investments, and drive innovation in resource utilization and efficiency optimizations. Our environment is primarily TypeScript, Node.js, React, MySQL NoSQL, AWS, Python, PHP, and Docker. In our collaborative culture, you find plenty of opportunities to impact our full-stack products; from Web & mobile UI to data visualization & analysis to data ingestion, storage and processing.
Job Responsibilities
Developing scalable, fast, robust, and simple web-based solutions to solve complex business problems
Close collaboration with your team to collect and incorporate feedback into your feature design
Drive operational excellence by investigating production issues, driving root cause analysis and follow-up actions for mitigation
Improve performance, availability, reliability, scale, throughput and latency
Work with your team in order to meet customer work you're doing, understand the decisions that are being made and make your voice heard.
Qualifications
Bachelor's degree in Computer Science or related field
Coding experience with any programming language (Prefer experience in TypeScript/JavaScript/React/Python)
Experience with web infrastructure and distributed systems
Experience with software engineering best practices (e.g. unit testing, code reviews, design, continuous delivery, git, test automation and build\deploy systems)
Ability to work in a fast-paced and agile development environment and to learn new frameworks/stacks
Passionate about building products that help customers easily and effectively get their job done
Enthusiastic person, who communicates effectively and is easy to work with
Curious and constantly learning on your own and from others
You get satisfaction from helping others succeed, and you constantly seek ways to improve
You can identify gaps, propose solutions to important problems, then take it to resolution
Preferred Qualifications
Shown ability to troubleshoot and identify the root cause of issues
Demonstrated skill and passion for operational excellence
Experience in a 24/7 production environment is a plus
Ability to retain composure under stressful conditions, communicate effectively with wide array of individuals at Qualtrics, and get the right things done
Confirmed ability to understand large systems, drilling down to code level",glassdoor
339,"Apple
4.2
Data Engineer
Cupertino, CA

 Summary
Posted: Aug 10, 2022
Weekly Hours: 40
Role Number:200406892
Are you a big-picture thinker who loves setting ambitious goals? Do you have a passion for understanding how each line of code affects all the others? In the Core Operating Systems group, you’ll ensure the OS is inseparable from each device’s identity as a whole. That’s because this group is committed to building fully integrated operating systems that combine hardware, software, and apps into a single Apple experience. Your dedication to cross-disciplinary collaboration will help develop groundbreaking technologies, such as iOS, macOS, watchOS, and tvOS. By crafting these distinct, holistic user experiences, you’ll continue to uphold and advance the excellence people expect from Apple devices. The Platform Services & Operations team in Core OS is looking for a Data Engineer to inform and develop essential workflow tooling at scale. The Workflow Engineering team enable teams to deliver high quality software through best in class engineering experiences, efficient workflow, data driven insights, and a culture of continuous improvement. Your focus is building the backend data pipelines that enables visualization of data across the organization in user intuitive and configurable formats.
Key Qualifications
3 +proven experience in a Data focused posistion
Proficient in Python; data access and retrieval. Quantitative data preparation. Regular expressions and text analysis
Highly Proficient in Database Language and Design; querying large stores of data (APIs, SQL, etc.).
Access, retrieval, and storage of information. Data Structures, modeling for speed and efficiency
Software Development; understanding of build pipelines, branching and merging, Agile methods, and the delivery of code. Fluency in Git (or comparable source control tool)
Description
- Replicate data from source system into data warehouse; retrieve data through various protocols and land it in a central store - Automate data pipelines; write programs to periodically update warehouse data from source systems - Design for scale; flexible infrastructure for common enhancements including: expanding the volume of captured data, adding fields to the user-facing views, and recompiling archived data - Work with a team of data scientists and full stack engineers, to derive and develop targeted insights through centrally managed interactive dashboards
Education & Experience
B.S. in Data Science, Computer Science, or equivalent experience.
Additional Requirements
Experience as an Analyst; worked in the delivery of visual information (dashboards, reports, web-apps)
An understanding of how data can be used and applied in context (what is useful to capture and how it can be communicated)
Full Stack Development; ability to maintain back-end systems and visualize front-end data for users (with a web-kit framework like Angular, React)
Experience with Snowflake and/or other data store technologies",glassdoor
340,"Tesla
3.6
Data Engineer
Fremont, CA

 What to Expect
The Data Engineer is responsible for processing structured and unstructured data, validating data quality, and developing and supporting data products. We are looking for someone with strong hands on experience in all layers of data Integration and analytics! We especially need experience in using Python as an ETL tool. The Data Engineer plays a significant role in Agile planning, providing advice and guidance, and monitoring emerging technologies. Some of the technology we use: * Python * Informatica * SQL Server and MySQL * Vertica * Kafka

What You’ll Do
* Design, code, test, correct and document programs and scripts using agreed standards and tools to achieve a well-engineered result * Derive an overall strategy of data management, within an established information architecture that supports the development and secure operation of existing and new information and digital services * Plan effective data storage, security, sharing and publishing within the organization * Gathers and processes raw, structured, semi-structured, and unstructured data using batch and real-time data processing frameworks * Ensures data quality and implements tools and frameworks for automating the identification of data quality issues * Collaborate with internal and external data providers on data validation providing feedback and making customized changes to data feeds and data mappings * Mentor and lead data engineers providing technical guidance and oversight * Provides ongoing support, monitoring, and maintenance of deployed products

What You’ll Bring

* Strong experience with relational databases like SQL Server, MySQL and Vertica. NoSQL databases experience is a plus! * Strong background in data modeling, data access, and data storage techniques * Experience with design, development, and implementation of highly scalable, high-volume software systems and components, source of truth systems for different business areas, developing and maintaining web services in an agile environment * Working experience with Kafka Streaming layer * Experience in Spark Framework on both batch and real-time data processing is a plus * Experience in Big Data Integration & Analytics is a plus * Experience in Supply Chain and Logistics data is a plus",glassdoor
341,"Accenture
4.1
Data Engineer
San Francisco, CA

 Accenture Flex offers you the flexibility of local fixed-duration project-based work powered by Accenture, a leading global professional services company. Accenture is consistently recognized on FORTUNE's 100 Best Companies to Work For and Diversity Inc's Top 50 Companies For Diversity lists.
As an Accenture Flex employee, you will apply your skills and experience to help drive business transformation for leading organizations and communities. In addition to delivering innovative solutions for Accenture's clients, you will work with a highly skilled, diverse network of people across Accenture businesses who are using the latest emerging technologies to address today's biggest business challenges.
You will receive competitive rewards and access to benefits programs and world-class learning resources. Accenture Flex employees work in their local metro area onsite at the project, significantly reducing and/or eliminating the demands to travel.
Job Description:
As a Data Engineer, you will:
Utilize strong SQL & Python expertise to engineer sound data pipelines and conduct routine and ad hoc analysis to assess the performance of legacy products and the saliency of new features
Build reporting dashboards and visualizations to design, create, and track campaign/program KPIs
Perform analyses on large data sets to understand drivers of marketing engagement and provide recommendations on campaign and product optimization

Basic Qualifications:
Minimum 2 years of experience in Data Engineering
Minimum 2 years of experience with SQL
Minimum 2 years of experience with Python
High School Diploma or GED
Preferred Qualifications:
Experience with Data Analytics
As required by Colorado Law under the Equal Pay for Equal Work Act, Accenture provides a reasonable range of compensation for roles that may be hired in Colorado. Actual compensation is influenced by a wide array of factors including but not limited to skill set, level of experience, and specific office location. For the state of Colorado only, the starting range of pay for this role is $86.82 - $96.82 per hour, and information on benefits is here.

COVID-19 update:

The safety and well-being of our candidates, our people and their families continues to be a top priority. Until travel restrictions change, interviews will continue to be conducted virtually.

Subject to applicable law, please be aware that Accenture requires all employees to be fully vaccinated as a condition of employment. Accenture will consider requests for accommodation to this vaccination requirement during the recruiting process.

What We Believe

We have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture has the responsibility to create and sustain an inclusive environment.

Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more here

Equal Employment Opportunity Statement

Accenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation.

All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.

Accenture is committed to providing veteran employment opportunities to our service men and women.

For details, view a copy of the Accenture Equal Opportunity and Affirmative Action Policy Statement.

Requesting An Accommodation

Accenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.

If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.

Other Employment Statements

Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States.

Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.

Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.

The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.",glassdoor
342,"Lincoln Financial
3.6
Data Engineer (REMOTE)
Radnor, PA
Employer Provided Salary:$63K - $138K

 Date: Oct 9, 2022
Primary Location: Radnor, PA, US
Company: Lincoln Financial
Alternate Locations: Work from Home

Work Arrangement: Work from Home

Relocation assistance:: is not available for this opportunity.

Pay Range: $63,100 - $137,900

Bonus Potential: 5%

Requisition #: 69444

The Role at a Glance

This is an exciting opportunity within Lincoln’s Work Place Solutions IT Data Team for a Data Engineer/ETL Developer to help build solutions for Lincoln’s Work Place Solutions business. This position will assist Analytic Teams with the design and implementation of Data solutions and systems, including integration with databases and data warehouses, both on-Premise and in AWS Cloud. This candidate must be able to develop, enhance, and support Informatica workflows and processes using Informatica Power Center and Dataiku for the extraction and transformation of data in a UNIX and Oracle database environment. They must also have experience working within BI tools such as Tableau and Microstrategy. Experience working in the cloud using AWS native services such as Glue, Athena, Aurora, Redshift, and/or Snowflake is needed. The candidate must have experience participating in and beginning to lead teams within a Data Organization by suggesting new and innovative ways of gaining data processing efficiencies and participating in architectural and modeling discussions.

What you'll be doing

Participates in defining architecture and modeling best practices within the team
Develop tools and work on integrating disparate systems using ETL
Work on transformation of data into Facts and Dims in a Kimball and/or relational model
Works with Sr. Technical Professionals to implement data development best practices
Develop, enhance and support Informatica workflows and processes using Informatica Power Center for the extraction and translation of data in a UNIX and Oracle database environment
Develop, enhance and support Dataiku workflows and processes for transforming data into Kimball model Facts/Dims
Creates partnerships with stakeholders, POs, BSAs and Analytic teams in requirement, design and coding walkthroughs to ensure the development of quality solutions and understand complex business/technical problems and opportunities and identify potential application solutions.
Demonstrates expertise in a variety of the data warehouse concepts, practices, and procedures. Relies on extensive experience and judgment to plan and accomplish goals
Analyzes operational and analytical data requirements by working with cross functional business and application development teams
Maintains knowledge on current and emerging developments/trends for assigned area(s) of responsibility, assess the impact, and collaborates with senior management to incorporate new trends and developments in current and future solutions.
Participate with collaboration efforts with development teams to review, update and approve the data portion of project designs, participate in cost/benefit analysis and preparation of project plans.
Participate in the design, development and delivery data centric IT solutions, including large scale data staging and orchestration, integration and provisioning mechanisms
Works with business partners to prioritize business and information needs
Provides input and validates increasingly complex project plans, test plans and implementation plans
Creates increasingly complex technical specifications from business requirements/business specifications
Proactively identifies problems and presents/develops solutions
Communicates effectively with internal stakeholders and management
Defines detailed development tasks, task dependencies and estimates to complete work
What we're looking for

4 Year/Bachelor's degree or equivalent work experience (4 years of experience in lieu of Bachelor's) in Computer Science, Computer Information Systems, Information Systems, Information Technology or Computer Engineering or equivalent work experience (Minimum Required
3 - 5+ Years’ experience in application development that directly aligns with the specific responsibilities for this position (Required)
Experience with ETL development
Must have experience with Informatica; Dataiku is a plus
Must have experience with BI tools such as Tableau and Microstrategy
Experience with AWS cloud native services, such as: Glue, Athena, Aurora, Redshift
Must have a proven track record working closely with business stakeholders, BSAs, and POs, Solution Architects to understand requirements and expectations to achieve quality technical solutions
What’s it like to work here?
At Lincoln Financial Group, we love what we do. We make meaningful contributions each and every day to empower our customers to take charge of their lives. Working alongside dedicated and talented colleagues, we build fulfilling careers and stronger communities through a company that values our unique perspectives, insights and contributions and invests in programs that empower each of us to take charge of our own future.

What’s in it for YOU:
A clearly defined career framework to help you successfully manage your career
Leadership development and virtual training opportunities
PTO/parental leave
Competitive 401K and employee benefits
Free financial counseling, health coaching and employee assistance program
Tuition assistance program
A leadership team that prioritizes your health and well-being; offering a remote work environment and flexible work hybrid situations
Effective productivity/technology tools and training

Work Arrangement
Work from Home : Employees will work from home and are not required to work in a Lincoln office on a regular basis.

Lincoln will evaluate the following when setting the successful candidate's wage rate:
Prior work or industry experience.
Education level to the extent education is relevant to the position.
Unique skills

About The Company
Lincoln Financial Group, a Fortune 200 company with over 10,000 employees, provides advice and solutions that help empower Americans to take charge of their financial lives with confidence. Our core business areas — Life Insurance, Annuities, Retirement Plan Services and Group Protection — focus on supporting, preserving and enhancing over 17 million customer’s lifestyles and retirement outcomes.

Headquartered in Radnor, Pennsylvania, Lincoln Financial Group is the marketing name for Lincoln National Corporation (NYSE: LNC) and its affiliates. The company had $324 billion in end-of-period account values as of June 30, 2021.

Ranked one of the Best Large Employers in America and Best Employers for Women by Forbes magazine as well as one of Newsweek’s Most Responsible Companies, Lincoln Financial Group makes a serious investment in our employees’ futures through a broad range of wealth accumulation and protection plans, health and wellness programs, and career development resources designed to help each individual reach their personal and professional goals.

Lincoln is committed to creating a diverse and inclusive environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.

Lincoln Financial Group is a committed corporate citizen included on major sustainability indices including the Dow Jones Sustainability Index North America and FTSE4Good. Dedicated to diversity and inclusion, we earned perfect 100 percent scores on the Corporate Equality Index and the Disability Equality Index. Follow us on Facebook, Twitter, LinkedIn, and Instagram.

Be Aware of Fraudulent Recruiting Activities
If you are interested in a career at Lincoln, we encourage you to review our current openings and apply on our website. Lincoln values the privacy and security of every applicant and urges all applicants to diligently protect their sensitive personal information from scams targeting job seekers. These scams can take many forms including fake employment applications, bogus interviews and falsified offer letters.
Lincoln will not ask applicants to provide their social security numbers, date of birth, bank account information or other sensitive information in job applications. Additionally, our recruiters do not communicate with applicants through free e-mail accounts (Gmail, Yahoo, Hotmail) or conduct interviews utilizing video chat rooms. We will never ask applicants to provide payment during the hiring process or extend an offer without conducting a phone, live video or in-person interview. Please contact Lincoln's fraud team at fraudhotline@lfg.com if you encounter a recruiter or see a job opportunity that seems suspicious.

Additional Information
This position may be subject to Lincoln’s Political Contribution Policy. An offer of employment may be contingent upon disclosing to Lincoln the details of certain political contributions. Lincoln may decline to extend an offer or terminate employment for this role if it determines political contributions made could have an adverse impact on Lincoln’s current or future business interests, misrepresentations were made, or for failure to fully disclose applicable political contributions and or fundraising activities.

Any unsolicited resumes/candidate profiles submitted through our web site or to personal e-mail accounts of employees of Lincoln Financial Group are considered property of Lincoln Financial Group and are not subject to payment of agency fees.

Lincoln Financial Group (“LFG”) is an Equal Opportunity employer and, as such, is committed in policy and practice to recruit, hire, compensate, train and promote, in all job classifications, without regard to race, color, religion, sex (including pregnancy), age, national origin, disability, sexual orientation, gender identity and expression, Veteran status, or genetic information. Applicants are evaluated on the basis of job qualifications. If you are a person with a disability that impedes your ability to express your interest for a position through our online application process, or require TTY/TDD assistance, contact us by calling 260-455-2558.",glassdoor
343,"Ultra Mobile
4.4
Digital Data Engineer I - Remote
Costa Mesa, CA
Employer Provided Salary:$90K - $103K

 ULTRA MOBILE is seeking a talented Digital Data Engineer I to join the Data Management Team! Individual reports to Customer Data Manager. Role is remote; must reside in the United States.
ABOUT THE ROLE
Provide direct data engineering development to data pipelines for ETL establishment and enhancements to and from data warehouses to customer management platform (Braze). Work collaboratively with cross-functional teams to determine digital data needs, establish data collection requirements, and deploy & maintain accurate data to ensure metrics & dimensions are addressed for analytics/reporting requirements.
Your usual day of awesomeness includes:
Transform required data conditions into performance code logic.
Develop high-performance code in SQL and Python.
Develop, automate, and enhance ELT processes for continuous data flow.
Create, modify, and deploy code to production via AWS resources including Lambda, S3, Glue, Redshift, etc.
Partner with stakeholders to support the implementation and development of data requirements.
Troubleshoot data anomalies and provide applicable solutions.
Build, test and maintain database pipeline architectures.
WHAT YOU BRING
Advanced level in SQL and Python for data engineering and backend development.
Understanding of popular code development approaches:
Test-driven development
Continuous Integration/Continuous Deployment (CI/CD)
Experienced working with AWS services (Lambda, S3, Glue, Redshift etc.) and Cloud Data Warehouse.
Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
Define digital data collection methods and implementations to DWH and customer management platforms.
Experienced with QA testing process to verify data is collected & rendered as expected.
Ability to excel in a fast-paced, cross-functional environment.
Ability to work autonomously.
Excellent written and verbal communication skills.
Proactive problem-solving and critical thinking skills.
Ability to manage time effectively and consistently meet deadlines.
NICE TO HAVE
Prior working knowledge of Braze or other Customer Management Platforms
Snowflake Cloud Data Warehouse
Terraform/Bitbucket/Airflow/Jenkins
Looker, Tableau, Power BI
WE ARE ULTRA & MINT MOBILE
We connect people to what's most important in their lives: Easily, affordably and reliably. We strive to be California's Preeminent Destination Employer. Oh yeah, we get it too! We understand what matters to you most. You're an individual with unique needs, and we're prepared to exceed any expectations you have for an ideal employer.
We're smart, strategic, and get things done without a lot of red tape or unnecessary politics. Everyone matters here and everyone has a voice. Expect to spend your time contributing to projects that really matter. We obsess over the employee experience. To start, we provide some of the most competitive salary, benefits, family leave, vacation, retirement and equity options in Southern California. We believe in you and invest in you. Not just your career aspirations, but your life.
In addition, we've got a laundry list of perks you'll brag about on insta - Lunch every day prepared by our very own chef, healthy snacks, onsite gym, free massages, car wash services, and most importantly, a team atmosphere. We even raise the bar on well bars, including Espresso/Cappuccino/Nitro/Cold Brew/Kombucha Bar, Froyo Bar, Breakfast Bar, Snack Bar and a, well, you know, bar (after 5 pm).
And if you feel intrigued right now reading, imagine the co-workers we have already attracted. This is the kind of team you'll want to take home to mom or invite to your kid's next birthday party. This is the kind of close-knit community happening here. Come check out how you can be part of Ultra & Mint!
OUR VALUES – LET'S MAKE LIFE ULTRA TOGETHER!
Ownership: We are all owners; be the outcome and get the job done.
Action Biased: Be brilliant, proactive, and act with urgency.
Embrace the Adventure: Be agile, adaptive, and thrive on change.
Invent and Simplify: Never accept good enough.
$1,000 REFERRAL BONUS
Take a look at this job description, if you are the right person, please apply. If Ultra Mobile doesn't appear to be a fit for you, refer a friend or colleague and get $1,000. Let your friend or colleague know to provide your full name and email when applying to the job. If we hire them and they stay for 90 days, you get $1000. For more details of restrictions and rules, please email recruiting@ultra.me.

Covid-19 Vaccination Requirement
UVNV, Inc. has adopted a mandated vaccination policy to support the health and safety of our team members and our community. The Company requires all employees to be fully vaccinated. The Company will provide accommodations based on medical condition or sincerely held religious beliefs or practices. Please let us know if you'd like to discuss the policy or available accommodations before proceeding with our recruitment process.
We are committed to equal employment opportunities regardless of race, color, genetic information, creed, religion, sex, sexual orientation, gender identity, lawful alien status, national origin, age, marital status, or protected veteran status. We support an inclusive workplace where associates excel based on personal merit, qualification, experience, ability, and job performance.
In support of the Equal Pay for Equal Work Act, the range of starting pay for this role is $90,000 - $103,000. This is not a guarantee of compensation or salary, actual compensation is influenced by a wide range of factors including but not limited to skill set, level of experience, education, certifications, responsibility, and geographic location. We also offer a variety of benefits including health, disability insurance, 401 (k), flexible spending accounts, EAP, education reimbursement, parental leave, unlimited vacation, bonuses, incentive stock options and company paid holidays. The specific programs and options available will vary depending on state, start date, and employment type. Our recruitment team will be happy to answer any questions you may have.
#LI-Remote",glassdoor
344,"Antra, Inc
4.5
Jr. Data Engineer
Sterling, VA
Employer Provided Salary:$60K - $68K

 Antra started its services in the year 2008, since then we have been diligently serving every need of our clients professional and software solutions. With our unique amalgam of innovation and inspiration, backed by Agile processes, we deliver world-class services with our core values to our clients. We identify unique strategies to transforming organizations through picking their sweet spot for innovative thinking and helping them in implementing in-depth cultural shift; ultimately augmenting the innovation process to the next level – fostering the innovation race that never ends.
This role requires the design, development and implementation of data solutions to business problems. An Azure Data Engineer will be expected to perform duties such as: evaluating the performance of current data solutions, designing and implementing cloud and hybrid data solutions. Ability to adapt and learn new technologies per business requirements is also needed.
Responsibilities:
Design and implement data solutions using industry best practices.
Performs ETL, ELT operations and administration of data and systems securely and in accordance with enterprise data governance standards.
Monitor and maintain data pipelines proactively to ensure high service availability.
Works with Data Scientists and ML Engineers to understand mathematical models and optimize data solutions accordingly.
Continuous development through training and mentorship programs.
Create scripts and programs to automate data operations.
You meet our “must haves” for this role if you have:
Minimum Bachelor’s degree in Data Science, Business Intelligence, Computer Science or related fields, or the equivalent combination of education, professional training, and work experience.
0-3 years of experience working with one or more languages commonly used for data operations including SQL, Python, Scala and R.
Experience working with relational databases such as SQL Server, Oracle and MySQL.
Experience working with NoSQL databases such as Redis, Mongo DB, Cosmos DB.
Excellent problem-solving skills and ability to learn through scattered resources.
Thorough understanding of the responsibilities and duties of a data engineer, as well as established industry standards/best practices and documentation guidelines.
Outstanding communication skills, and the ability to stay self-motivated and work with little or no supervision.
Willing to relocate to any US location on Antra projects location.
Authorization(s) to work lawfully in the United States (OPT/CPT is acceptable).
Plus, if you meet any the of requirements:
Experience with cloud-based data technologies.
Experience with distributed systems utilizing tools such as Apache Hadoop, Spark or Kafka.
Working experience in Agile Scrum environments.
Experience with source control tools such as Git, SVN and TFS.
The intent of this position description is to provide a representative summary of the major duties and responsibilities performed by incumbent(s) in this position. Incumbent(s) may not be required to perform all duties in this description and incumbent(s) may be required to perform position-related tasks other than those specifically listed in this description.
Antra Inc. is an equal opportunity employer, providing equal employment opportunities (EEO). All employees and applicants for employment will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity or expression, pregnancy, protected veteran status or other status protected by law. This policy applies to all terms and conditions of employment.
Job Types: Full-time, Contract
Pay: $60,000.00 - $68,000.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Health savings account
Life insurance
Paid time off
Professional development assistance
Referral program
Relocation assistance
Vision insurance
Schedule:
Monday to Friday
Application Question(s):
Are you open for relocation within the US?
Education:
Bachelor's (Preferred)
Work Location: Hybrid remote in Sterling, VA 20166",glassdoor
345,"GenSpark
4.1
Data Engineer
Remote

 Position: Data Engineer
Location: Remote/ Atlanta
** Only US Citizens and GreenCard Holders eligible**
Requirements:
1. 3+ years of working experience on Python on Data side, NymPy, Pandas
2. Should have working experience on SQL
3. Data Engineer mindset
Job Type: Full-time
Salary: $75.00 - $90.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Paid time off
Vision insurance
Schedule:
8 hour shift
Monday to Friday
No weekends
Education:
Bachelor's (Preferred)
Experience:
python: 3 years (Preferred)
Work Location: Remote",glassdoor
